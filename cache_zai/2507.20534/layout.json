{"code":0,"doc_size":6335018,"doc_type":"pdf","dst_path":"oss://glm-data-ocr-data/services/maas/pa/72ea8940-be5d-4994-826e-71afd30fa460.tar","markdown":"## KKIMI K2: OPEN AGENTIC INTELLIGENCE\n\n## TECHNICAL REPORT OF KIMI K2\n\n## Kimi Team\n\n## ABSTRACT\n\nWe introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token effciency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zeroi loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the model improves its capabilities through interactions with real and synthetic environments.\n\nKimi K2 achieves state-of-the-art performance among open-source non-thinking models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench(En), 65.8 on SWE-Bench Verifed, and 47.3 on SWE-Bench Multilingual — surpassing most openi and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding,mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025,75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position Kimi K2 as one of the most capable open-source large language models to date, particularly in software engineering and agentic tasks. We release our base and post-trained model checkpoints1 to facilitate future research and applications of agentic intelligence.\n\n![59c6fa3876c5b81ce8c759ac85a13d1b](imgs/59c6fa3876c5b81ce8c759ac85a13d1b.jpg)\n\nFigure 1: Kimi K2 main results.2\n\n\n\n## 1Introduction\n\nThe development of Large Language Models (LLMs) is undergoing a profound paradigm shift towards Agentic Intelligence – the capabilities for models to autonomously perceive, plan, reason, and act within complex and dynamic environments. This transition marks a departure from static imitation learning towards models that actively learn through interactions, acquire new skills beyond their training distribution, and adapt behavior through experiences [63].It is believed that this approach allows an AI agent to go beyond the limitation of static human-generated data, and acquire superhuman capabilities through its own exploration and exploitation. Agentic intelligence is thus rapidly emerging as a defning capability for the next generation of foundation models, with wide-ranging implications acrossi tool use, software development, and real-world autonomy.\n\nAchieving agentic intelligence introduces challenges in both pre-training and post-training. Pre-training must endow models with broad general-purpose priors under constraints of limited high-quality data, elevating token eff-i ciency—learning signal per token—as a critical scaling coeffcient. Post-training must transform those priors intoi actionable behaviors, yet agentic capabilities such as multi-step reasoning, long-term planning, and tool use are rare in natural data and costly to scale. Scalable synthesis of structured, high-quality agentic trajectories, combined with general reinforcement learning (RL) techniques that incorporate preferences and self-critique, are essential to bridge this gap.\n\nIn this work, we introduce Kimi K2, a 1.04 trillion-parameter Mixture-of-Experts (MoE) LLM with 32 billion activated parameters, purposefully designed to address the core challenges and push the boundaries of agentic capability. Our contributions span both the pre-training and post-training frontiers:\n\nWe present MuonClip, a novel optimizer that integrates the token-effcient Muon algorithm with a stability-i enhancing mechanism called QK-Clip. Using MuonClip, we successfully pre-trained Kimi K2 on 15.5 trillion tokens without a single loss spike.\n\nWe introduce a large-scale agentic data synthesis pipeline that systematically generates tool-use demonstrations via simulated and real-world environments. This system constructs diverse tools, agents, tasks, and trajectories to create high-fdelity, verifably correct agentic interactions at scale.ii\n\nWe design a general reinforcement learning framework that combines verifable rewards (RLVR) with a self-i critique rubric reward mechanism. The model learns not only from externally defned tasks but also from evaluatingi its own outputs, extending alignment from static into open-ended domains.\n\nKimi K2 demonstrates strong performance across a broad spectrum of agentic and frontier benchmarks. It achieves scores of 66.1 on Tau2-bench, 76.5 on ACEBench (en), 65.8 on SWE-bench Verifed, and 47.3 on SWE-benchi Multilingual, outperforming most open- and closed-weight baselines under non-thinking evaluation settings, closing the gap with Claude 4 Opus and Sonnet. In coding, mathematics, and broader STEM domains, Kimi K2 achieves 53.7 on LiveCodeBench v6, 27.1 on OJBench, 49.5 on AIME 2025, and 75.1 on GPQA-Diamond, further highlighting its capabilities in general tasks. On the LMSYS Arena leaderboard (July 17, 2025)3, Kimi K2 ranks as the top 1 open-source model and 5th overall based on over 3,000 user votes.\n\nTo spur further progress in Agentic Intelligence, we are open-sourcing our base and post-trained checkpoints, enabling the community to explore, refne, and deploy agentic intelligence at scale.i\n\n## 2Pre-training\n\nThe base model of Kimi K2 is a trillion-parameter mixture-of-experts (MoE) transformer [72] model, pre-trained on 15.5 trillion high-quality tokens. Given the increasingly limited availability of high-quality human data, we posit that token effciency is emerging as a critical coeffcient in the scaling of large language models. To address this,ii we introduce a suite of pre-training techniques explicitly designed for maximizing token effciency. Specifcally, weii employ the token-effcient Muon optimizer [33, 46] and mitigate its training instabilities through the introduction ofi QK-Clip. Additionally, we incorporate synthetic data generation to further squeeze the intelligence out of available high-quality tokens. The model architecture follows an ultra-sparse MoE with multi-head latent attention (MLA) similar to DeepSeek-V3 [10] , derived from empirical scaling law analysis. The underlying infrastructure is built to optimize both training effciency and research effciency.ii\n\n\n\n## 2.1MuonClip: Stable Training with Weight Clipping\n\nWe train Kimi K2 using the token-effcient Muon optimizer [33], incorporating weight decay and consistent updatei RMS scaling [46]. Experiments in our previous work Moonlight [46] show that, under the same compute budget and model size $.$ and therefore the same amount of training data — Muon substantially outperforms AdamW [36, 48],making it an effective choice for improving token effciency in large language model training.i\n\nTraining instability when scaling MuonDespite its effciency, scaling up Muon training reveals a challenge: trainingi instability due to exploding attention logits, an issue that occurs more frequently with Muon but less with AdamW in our experiments. Existing mitigation strategies are insuffcient. For instance, logit soft-cap [69] directly clips thei attention logits, but the dot products between queries and keys can still grow excessively before capping is applied. On the other hand, Query-Key Normalization (QK-Norm) [11, 81] is not applicable to multi-head latent attention (MLA),because its Key matrices are not fully materialized during inference.\n\nTaming Muon with QK-ClipTo address this issue, we propose a novel weight-clipping mechanism $\\mathit{QK\\text{-}Clip}$  to explicitly constrain attention logits. QK-Clip works by rescaling the query and key projection weights post-update to bound the growth of attention logits.\n\nLet the input representation of a transformer layer be X. For each attention head h, its query, key, and value projections are computed as\n\n$$\\textbf{Q}^{h}=\\textbf{X}\\textbf{W}_{q}^{h},\\quad\\textbf{K}^{h}=\\textbf{X} \\textbf{W}_{k}^{h},\\quad\\textbf{V}^{h}=\\textbf{X}\\textbf{W}_{v}^{h}.$$\n\nwhere $\\mathbf{W}_{q},\\mathbf{W}_{k},\\mathbf{W}_{v}$ are model parameters. The attention output is:\n\n$$\\mathbf{O}^{h}=\\text{softmax}\\left(\\frac{1}{\\sqrt{d}}\\mathbf{Q}^{h}\\mathbf{K}^{h\\top}\\right)\\mathbf{V}^{h}.$$\n\nWe defne the max logit, a per-head scalar, as the maximum input to softmax in this batch Bi\n\n$$S_{\\max}^{h}=\\frac{1}{\\sqrt{d}}\\max_{\\mathbf{X}\\in B}\\max_{i,j}\\mathbf{Q}_{i}^{h}\\mathbf{K}_{j}^{h\\top}$$\n\nwhere $i,j$ are indices of different tokens in a training sample X.\n\nThe core idea of QK-Clip is to rescale $\\mathbf{W}_{k},\\mathbf{W}_{q}$ whenever $S^{h}_{\\max}$ exceeds a target threshold τ. Importantly, this operation does not alter the forward/backward computation in the current step — we merely use the max logit as a guiding signal to determine the strength to control the weight growth.\n\nA naïve implementation clips all heads at the same time:\n\n$$\\mathbf{W}_{q}^{h}\\leftrightarrow\\gamma^{\\alpha}\\mathbf{W}_{q}^{h}\\qquad\\mathbf{W}_{k}^{h}\\leftrightarrow\\gamma^{1-\\alpha}\\mathbf{W}_{k}^{h}$$\n\nwhere $\\gamma=\\min(1,\\tau/S_{\\max})$  with $S_{\\max}=\\text{max}_{h} S_{\\max}^{h},$  and $\\alpha$  is a balancing parameter typically set to 0.5, applying equal scaling to queries and keys.\n\nHowever, we observe that in practice, only a small subset of heads exhibit exploding logits. In order to minimize our intervention on model training, we determine a per-head scaling factor $\\gamma_{h}=\\min(1,\\tau{/S_{\\max}^{h}}),$  and opt to apply per-head QK-Clip. Such clipping is straightforward for regular multi-head attention (MHA). For MLA, we apply clipping only on unshared attention head components:\n\n• $\\mathbf{q}^{\\boldsymbol{C}}$ and $\\mathbf{k}^{\\boldsymbol{C}}$ (head-specifc components): each scaled byi $\\sqrt{\\gamma_{h}}$\n\n• $\\mathbf{q}^{R}$ (head-specifc rotary): scaled by γh,i\n\n· $\\mathbf{k}^{\\boldsymbol{R}}$ (shared rotary): left untouched to avoid effect across heads.\n\nMuonClip: The New OptimizerWe integrate Muon with weight decay, consistent RMS matching, and QK-Clip into a single optimizer, which we refer to as MuonClip (see Algorithm 1).\n\nWe demonstrate the effectiveness of MuonClip from several scaling experiments. First, we train a mid-scale 9B activated and 53B total parameters Mixture-of-Experts (MoE) model using the vanilla Muon. As shown in Figure 2 (Left), we observe that the maximum attention logits quickly exceed a magnitude of 1000, showing that attention logits explosion is already evident in Muon training to this scale. Max logits at this level usually result in instability during training,including signifcant loss spikes and occasional divergence.i\n\n\n\n## Algorithm 1 MuonClip Optimizer\n\n1: for each training step $t$  do\n\n2:// 1. Muon optimizer step\n\n3:for each weight $\\mathbf{W}\\in\\mathbb{R}^{\\tiny n \\times\\tiny m}$  do\n\n4: $\\mathbf{M}_{t}=\\mu\\mathbf{M}_{t-1}+\\mathbf{G}_{t}$\n\n$\\mathbf{O}_{t}=$ Newton-Schulz $(\\mathbf{M}_{t})\\cdot\\sqrt{\\max(n,m)}\\cdot0.2$\n\n6: $\\mathbf{W}_{t}=\\mathbf{W}_{t-1}-\\eta\\big(\\mathbf{O}_{t}+\\lambda\\mathbf{W}_{t-1}\\big)$\n\n7:end for\n\n8: $//2$  QK-Clip\n\n9:for each attention head $h$  in every attention layer of the model do\n\n10:Obtain $S^{h}_{\\max}$  already computed during forward\n\n11:if $S^{h}_{\\max}>\\tau$ then\n\n12: $\\gamma\\leftrightarrow\\tau/S_{\\text{m}}^{h}$ ax\n\n13: $\\mathbf{W}_{qc}^{n}\\leftrightarrow\\mathbf{W}_{qc}^{n}\\cdot\\sqrt{\\gamma}$\n\n14: $\\mathbf{W}_{kc}^{h}\\leftrightarrow\\mathbf{W}_{kc}^{h}\\cdot\\sqrt{\\gamma}$\n\n15: $\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\leftrightarrow\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\cdot\\gamma$\n\n17:end for\n\n![b3f9ae5cd29a76d2069069870c953849](imgs/b3f9ae5cd29a76d2069069870c953849.jpg)\n\nFigure 2: Left: During a mid-scale training run, attention logits rapidly exceed 1000, which could lead to potential numerical instabilities and even training divergence. Right: Maximum logits for Kimi K2 with MuonClip and $\\tau=100$ over the entire training run. The max logits rapidly increase to the capped value of 100, and only decay to a stable range after approximately $30\\%$  of the training steps, demonstrating the effective regulation effect of QK-Clip.\n\nNext, we demonstrate that QK-Clip does not degrade model performance and confrm that the MuonClip optimizeri preserves the optimization characteristics of Muon without adversely affecting the loss trajectory. A detailed discussion of the experiment designs and fndings is provided in the Appendix D.i\n\nFinally, we train Kimi K2, a large-scale MoE model, using MuonClip with $\\tau=100$  and monitor the maximum attention logits throughout the training run (Figure 2 (Right)). Initially, the logits are capped at 100 due to QK-Clip. Over the course of training, the maximum logits gradually decay to a typical operating range without requiring any adjustment toτ. Importantly, the training loss remains smooth and stable, with no observable spikes, as shown in Figure 3, validating that MuonClip provides robust and scalable control over attention dynamics in large-scale language model training.\n\n## 2.2Pre-training Data: Improving Token Utility with Rephrasing\n\nToken effciency in pre-training refers to how much performance improvement is achieved for each token consumedi during training. Increasing token utility—the effective learning signal each token contributes—enhances the per-token impact on model updates, thereby directly improving token effciency. This is particularly important when the supply ofi high-quality tokens is limited and must be maximally leveraged. A naive approach to increasing token utility is through repeated exposure to the same tokens, which can lead to overftting and reduced generalization.i\n\n\n\n![95f11e3a027801e5bd8b4881447ea890](imgs/95f11e3a027801e5bd8b4881447ea890.jpg)\n\nFigure 3: Per-step training loss curve of Kimi K2, without smoothing or sub-sampling. It shows no spikes throughout the entire training process. Note that we omit the very beginning of training for clarity.\n\nA key advancement in the pre-training data of Kimi K2 over Kimi K1.5 is the introduction of a synthetic data generation strategy to increase token utility. Specifcally, a carefully designed rephrasing pipeline is employed to amplify the volumei of high-quality tokens without inducing signifcant overftting. In this report, we describe two domain-specializedii rephrasing techniques—targeted respectively at the Knowledge and Mathematics domains—that enable this controlled data augmentation.\n\nKnowledge Data RephrasingPre-training on natural, knowledge-intensive text presents a trade-off: a single epoch is insuffcient for comprehensive knowledge absorption, while multi-epoch repetition yields diminishing returns andi increases the risk of overftting. To improve the token utility of high-quality knowledge tokens, we propose a synthetici rephrasing framework composed of the following key components:\n\nStyle- and perspective-diverse prompting: To enhance linguistic diversity while maintaining factual integrity, we apply a range of carefully engineered prompts. These prompts guide a large language model to generate faithful rephrasings of the original texts in varied styles and from different perspectives.\n\nChunk-wise autoregressive generation: To preserve global coherence and avoid information loss in long documents, we adopt a chunk-based autoregressive rewriting strategy. Texts are divided into segments, rephrased individually, and then stitched back together to form complete passages. This method mitigates implicit output length limitations that typically exist with LLMs. An overview of this pipeline is presented in Figure 4.\n\nFidelity verifcation: To ensure consistency between original and rewritten content, we perform fdelity checksii that compare the semantic alignment of each rephrased passage with its source. This serves as an initial quality control step prior to training.\n\nWe compare data rephrasing with multi-epoch repetition by testing their corresponding accuracy on SimpleQA. We experiment with an early checkpoint of K2 and evaluate three training strategies: (1) repeating the original dataset for 10 epochs, (2) rephrasing the data once and repeating it for 10 epochs, and (3) rephrasing the data 10 times with a single training pass. As shown in Table 1, the accuracy consistently improves across these strategies, demonstrating the effcacy of our rephrasing-based augmentation. We extended this method to other large-scale knowledge corpora andi observed similarly encouraging results, and each corpora is rephrased at most twice.\n\nTable 1: SimpleQA Accuracy under three rephrasing-epoch confgurationsi\n\n\n\n<html><body><table><thead><tr><td># Rephrasings</td><td># Epochs</td><td>SimpleQA Accuracy</td></tr></thead><tbody><tr><td>0 (raw wiki-text)</td><td>10</td><td>23.76</td></tr><tr><td>1</td><td>10</td><td>27.39</td></tr><tr><td>10</td><td>1</td><td>28.94</td></tr></tbody></table></body></html>\n\n\n\n![9033f0e6f55191cde0a2654b64962987](imgs/9033f0e6f55191cde0a2654b64962987.jpg)\n\nFigure 4: Auto-regressive chunk-wise rephrasing pipeline for long input excerpts. The input is split into smaller chunks with preserved context, rewritten sequentially, and then concatenated into a full rewritten passage.\n\nMathematics Data RephrasingTo enhance mathematical reasoning capabilities, we rewrite high-quality mathematical documents into a “learning-note” style, following the methodology introduced in SwallowMath [15]. In addition,we increased data diversity by translating high-quality mathematical materials from other languages into English.\n\nAlthough initial experiments with rephrased subsets of our datasets show promising results, the use of synthetic data as a strategy for continued scaling remains an active area of investigation. Key challenges include generalizing the approach to diverse source domains without compromising factual accuracy, minimizing hallucinations and unintended toxicity, and ensuring scalability to large-scale datasets.\n\nPre-training Data OverallThe Kimi K2 pre-training corpus comprises 15.5 trillion tokens of curated, high-quality data spanning four primary domains: Web Text, Code, Mathematics, and Knowledge. Most data processing pipelines follow the methodologies outlined in Kimi K1.5 [35]. For each domain, we performed rigorous correctness and quality validation and designed targeted data experiments to ensure the curated dataset achieved both high diversity and effectiveness.\n\n## 2.3Model Architecture\n\nKimi K2 is a 1.04 trillion-parameter Mixture-of-Experts (MoE) transformer model with 32 billion activated parameters.The architecture follows a similar design to DeepSeek-V3 [10] , employing Multi-head Latent Attention (MLA) [44] as the attention mechanism, with a model hidden dimension of 7168 and an MoE expert hidden dimension of 2048. Our scaling law analysis reveals that continued increases in sparsity yield substantial performance improvements, which motivated us to increase the number of experts to 384, compared to 256 in DeepSeek-V3. To reduce computational overhead during inference, we cut the number of attention heads to 64, as opposed to 128 in DeepSeek-V3. Table 2 presents a detailed comparison of architectural parameters between Kimi K2 and DeepSeek-V3.\n\nTable 2: Architectural comparison between Kimi K2 and DeepSeek-V3\n\n\n\n<html><body><table><tr><td></td><td>DeepSeek-V3</td><td>Kimi K2</td><td> $\\Delta$ </td></tr><tr><td>#Layers</td><td>61</td><td>61</td><td>=</td></tr><tr><td>Total Parameters</td><td>671B</td><td>1.04T</td><td>￪54%</td></tr><tr><td>Activated Parameters</td><td>37B</td><td>32.6B</td><td> $\\downarrow13\\%$ </td></tr><tr><td>Experts (total)</td><td>256</td><td>384</td><td> $\\uparrow50\\%$ </td></tr><tr><td>Experts Active per Token</td><td>8</td><td>8</td><td>=</td></tr><tr><td>Shared Experts</td><td>1</td><td>1</td><td>=</td></tr><tr><td>Attention Heads</td><td>128</td><td>64</td><td> $\\downarrow50\\%$ </td></tr><tr><td>Number of Dense Layers</td><td>3</td><td>1</td><td> $\\downarrow67\\%$ </td></tr><tr><td>Expert Grouping</td><td>Yes</td><td>No</td><td>-</td></tr></table></body></html>\n\n\n\nSparsity Scaling LawWe develop a sparsity scaling law tailored for the Mixture-of-Experts (MoE) model family using Muon. Sparsity is defned as the ratio of the total number of experts to the number of activated experts. Throughi carefully controlled small-scale experiments, we observe that — under a fxed number of activated parameters (i.e.,i constant FLOPs) — increasing the total number of experts (i.e., increasing sparsity) consistently lowers both the training and validation loss, thereby enhancing overall model performance (Figure 5). Concretely, under the compute-optimal sparsity scaling law, achieving the same validation loss of 1.5, sparsity 48 reduces FLOPs by $1.69\\times,1.39\\times,$  and $1.15\\times$ compared to sparsity levels 8, 16, and 32, respectively. Though increasing sparsity leads to better performance, this gain comes with increased infrastructure complexity. To balance model performance with cost, we adopt a sparsity of 48 for Kimi K2, activating 8 out of 384 experts per forward pass.\n\n![11ed6a4cdf820f6353e2811ee0fb7663](imgs/11ed6a4cdf820f6353e2811ee0fb7663.jpg)\n\nFigure 5: Sparsity Scaling Law. Increasing sparsity leads to improved model performance. We fxed the number ofi activated experts to 8 and the number of shared experts to 1, and varied the total number of experts, resulting in models with different sparsity levels.\n\n![62bd0134764b8affec17d56f4ca9dca6](imgs/62bd0134764b8affec17d56f4ca9dca6.jpg)\n\nFigure 6: Scaling curves for models with number of attention heads equals to number of layers and their counterparts with doubled attention heads. Doubling the number of attention heads leads to a reduction in validation loss of approximately $0.5\\%$ to $1.2\\%.$\n\nNumber of Attention HeadsDeepSeek-V3 [10] sets the number of attention heads to roughly twice the number of model layers to better utilize memory bandwidth and enhance computational effciency. However, as the context lengthi increases, doubling the number of attention heads leads to signifcant inference overhead, reducing effciency at longerii sequence lengths. This becomes a major limitation in agentic applications, where effcient long context processing isi essential. For example, with a sequence length of 128k, increasing the number of attention heads from 64 to 128, while keeping the total expert count fxed at 384, leads to ani $83\\%$  increase in inference FLOPs. To evaluate the impact of this design, we conduct controlled experiments comparing confgurations where the number of attention heads equalsi the number of layers against those with double number of heads, under varying training FLOPs. Under iso-token training conditions, we observe that doubling the attention heads yields only modest improvements in validation loss(ranging from $0.5\\%$ to $1.2\\%$  across different compute budgets (Figure 6). Given that sparsity 48 already offers strong performance, the marginal gains from doubling attention heads do not justify the inference cost. Therefore we choose to 64 attention heads.\n\n## 2.4Training Infrastructure\n\n## 2.4.1Compute Cluster\n\nKimi K2 was trained on a cluster equipped with NVIDIA H800 GPUs. Each node in the H800 cluster contains 2 TB RAM and 8 GPUs connected by NVLink and NVSwitch within nodes. Across different nodes, $8 \\times400$ Gbps RoCE interconnects are utilized to facilitate communications.\n\n## 2.4.2Parallelism for Model Scaling\n\nTraining of large language models often progresses under dynamic resource availability. Instead of optimizing one parallelism strategy that’s only applicable under specifc amount of resources, we pursue a fexible strategy that allowsil Kimi K2 to be trained on any number of nodes that is a multiple of 32. Our strategy leverages a combination of 16-way\n\n\n\n![542283386872f86ee28651b1b521712e](imgs/542283386872f86ee28651b1b521712e.jpg)\n\nFigure 7: Computation, communication and offoading overlapped in different PP phases.l\n\nPipeline Parallelism (PP) with virtual stages [28, 53, 38, 57, 47, 21], 16-way Expert Parallelism (EP) [39], and ZeRO-1 Data Parallelism [60].\n\nUnder this setting, storing the model parameters in BF16 and their gradient accumulation buffer in FP32 requires approximately 6 TB of GPU memory, distributed over a model-parallel group of 256 GPUs. Placement of optimizer states depends on the training confgurations. When the total number of training nodes is large, the optimizer states arei distributed, reducing its per-device memory footprint to a negligible level. When the total number of training nodes is small (e.g., 32), we can offoad some optimizer states to CPU.l\n\nThis approach allows us to reuse an identical parallelism confguration for both small- and large-scale experiments,i while letting each GPU hold approximately 30 GB of GPU memory for all states. The rest of the GPU memory are used for activations, as described in Sec. 2.4.3. Such a consistent design is important for research effciency, as it simplifesii the system and substantially accelerates experimental iteration.\n\nEP communication overlap with interleaved 1F1BBy increasing the number of warm-up micro-batches, we can overlap EP all-to-all communication with computation under the standard interleaved 1F1B schedule [21, 53]. In comparison, DualPipe [10] doubles the memory required for parameters and gradients, necessitating an increase in parallelism to compensate. Increasing PP introduces more bubbles, while increasing EP, as discussed below, incurs higher overhead. The additional costs are prohibitively high for training a large model with over 1 trillion parameters and thus we opted not to use DualPipe.\n\nHowever, interleaved 1F1B splits the model into more stages, introducing non-trivial PP communication overhead. To mitigate this cost, we decouple the weight-gradient computation from each micro-batch’s backward pass and execute it in parallel with the corresponding PP communication. Consequently, all PP communications can be effectively overlapped except for the warm-up phase.\n\nSmaller EP sizeTo ensure full computation-communication overlap during the 1F1B stage, the reduced attention computation time in K2 (which has 64 attention heads compared to 128 heads in DeepSeek-V3) necessitates minimizing the time of EP operations. This is achieved by adopting the smallest feasible EP parallelization strategy, specifcallyi $\\mathrm{EP}=16.$  Utilizing a smaller EP group also relaxes expert-balance constraints, allowing for near-optimal speed to be achieved without further tuning.\n\n## 2.4.3Activation Reduction\n\nAfter reserving space for parameters, gradient buffers, and optimizer states, the remaining GPU memory on each device is insuffcient to hold the full MoE activations. To ensure the activation memory fts within the constraints, especiallyii for the initial pipeline stages that accumulate the largest activations during the 1F1B warm-up phase, the following techniques are employed.\n\nSelective recomputationRecomputation is applied to inexpensive, high-footprint stages, including LayerNorm,SwiGLU, and MLA up-projections [10]. Additionally, MoE down-projections are recomputed during training to further reduce activation memory. While optional, this recomputation maintains adequate GPU memory, preventing crashes caused by expert imbalance in early training stages.\n\nFP8 storage for insensitive activationsInputs of MoE up-projections and SwiGLU are compressed to FP8-E4M3 in $1 \\times128$ tiles with FP32 scales. Small-scale experiments show no measurable loss increase. Due to potential risks of performance degradation that we observed during preliminary study, we do not apply FP8 in computation.\n\n\n\nActivation CPU offoadAll remaining activations are offoaded to CPU RAM. A copy engine is responsible forll streaming the offoad and onload, overlapping with both computation and communication kernels. During the 1F1Bl phase, we offoad the forward activations of the previous micro-batch while prefetching the backward activations of thel next. The warm-up and cool-down phases are handled similarly and the overall pattern is shown in Figure 7. Although offoading may slightly affect EP traffc due to PCIe traffc congestion, our tests show that EP communication remainslii fully overlapped.\n\n## 2.5Training recipe\n\nWe pre-trained the model with a 4,096-token context window using the MuonClip optimizer (Algorithm 1) and the WSD learning rate schedule [25], processing a total of 15.5T tokens. The frst 10T tokens were trained with a constanti learning rate of 2e-4 after a 500-step warm-up, followed by 5.5T tokens with a cosine decay from 2e-4 to 2e-5. Weight decay was set to 0.1 throughout, and the global batch size was held at 67M tokens. The overall training curve is shown in Figure 3.\n\nTowards the end of pre-training, we conducted an annealing phase followed by a long-context activation stage. The batch size was kept constant at 67M tokens, while the learning rate was decayed from 2e-5 to 7e-6. In this phase, the model was trained on 400 billion tokens with a 4k sequence length, followed by an additional 60 billion tokens with a 32k sequence length. To extend the context window to 128k, we employed the YaRN method [55].\n\n## 3Post-Training\n\n## 3.1Supervised Fine-Tuning\n\nWe employ the Muon optimizer [33] in our post-training and recommend its use for fne-tuning with K2. This followsi from the conclusion of our previous work [46] that a Muon-pre-trained checkpoint produces the best performance with Muon fne-tuning.i\n\nWe construct a large-scale instruction-tuning dataset spanning diverse domains, guided by two core principles: maximizing prompt diversity and ensuring high response quality. To this end, we develop a suite of data generation pipelines tailored to different task domains, each utilizing a combination of human annotation, prompt engineering, and verifcation processes. We adopt K1.5 [35] and other in-house domain-specialized expert models to generate candidatei responses for various tasks, followed by LLMs or human-based judges to perform automated quality evaluation and fltering. For agentic data, we create a data synthesis pipeline to teach models tool-use capabilities through multi-step,i interactive reasoning.\n\n## 3.1.1Large-Scale Agentic Data Synthesis for Tool Use Learning\n\nA critical capability of modern LLM agents is their ability to autonomously use unfamiliar tools, interact with external environments, and iteratively refne their actions through reasoning, execution, and error correction. Agentic tool usei capability is essential for solving complex, multi-step tasks that require dynamic interaction with real-world systems.Recent benchmarks such as ACEBench [6] and $7$ -bench [85] have highlighted the importance of comprehensive tool-use evaluation, while frameworks like ToolLLM [58] and ACEBench [6] have demonstrated the potential of teaching models to use thousands of tools effectively.\n\nHowever, training such capabilities at scale presents a signifcant challenge: while real-world environments providei rich and authentic interaction signals, they are often diffcult to construct at scale due to cost, complexity, privacyi and accessibility constraints. Recent work on synthetic data generation (AgentInstruct [51]; Self-Instruct [75];StableToolBench [20]; ZeroSearch [66]) has shown promising results in creating large-scale data without relying on real-world interactions. Building on these advances and inspired by ACEBench [6]’s comprehensive data synthesis framework, we developed a pipeline that simulates real-world tool-use scenarios at scale, enabling the generation of tens of thousands of diverse and high-quality training examples.\n\nThere are three stages in our data synthesis pipeline, depicted in Fig. 8.\n\nTool spec generation: we frst construct a large repository of tool specs from both real-world tools and LLM-i synthetic tools;\n\nAgent and task generation: for each tool-set sampled from the tool repository, we generate an agent to use the toolset and some corresponding tasks;\n\nTrajectory generation: for each agent and task, we generate trajectories where the agent fnishes the task byi invoking tools.\n\n\n\n![0b37235b5014617bada02aa6cb89bc8c](imgs/0b37235b5014617bada02aa6cb89bc8c.jpg)\n\n![f1591a37d7e82f3d0d80abb607673bfc](imgs/f1591a37d7e82f3d0d80abb607673bfc.jpg)\n\n![ab1f1baceeac607eebb4bc723c616209](imgs/ab1f1baceeac607eebb4bc723c616209.jpg)\n\n(a) Synthesizing tool specs, agents and tasks(b) Generating agent trajectories\n\n(a) Synthesizing tool specs, agents and tasks\n\nFigure 8: Data synthesis pipeline for tool use. (a) Tool specs are from both real-world tools and LLMs; agents and tasks are the generated from the tool repo. (b) Multi-agent pipeline to generate and flter trajectories with tool calling.i\n\n![271fdc0af3c4966658abf7b28861cf5e](imgs/271fdc0af3c4966658abf7b28861cf5e.jpg)\n\n![863e71c6656d07735e38df5719c68927](imgs/863e71c6656d07735e38df5719c68927.jpg)\n\n(b) t-SNE visualization of synthetic tools, colored by pre-defnedi domain categories\n\ni\n\n(a) t-SNE visualization of real MCP tools, colored by their original source categories\n\nFigure 9: t-SNE visualizations of tool embeddings. (a) Real-world MCP tools exhibit natural clustering based on their original source categories. (b) Synthetic tools are organized into pre-defned domain categories, providing systematici coverage of the tool space. Together, they ensure comprehensive representation across different tool functionalities.\n\nDomain Evolution and Tool Generation.We construct a comprehensive tool repository through two complementary approaches. First, we directly fetch 3000+ real MCP (Model Context Protocol) tools from GitHub repositories,leveraging existing high-quality tool specs. Second, we systematically evolve [82] synthetic tools through a hierarchical domain generation process: we begin with key categories (e.g., fnancial trading, software applications, robot control),i then evolve multiple specifc application domains within each category. Specialized tools are then synthesized for eachi domain, with clear interfaces, descriptions, and operational semantics. This evolution process produces over 20,000 synthetic tools. Figure 9 visualizes the diversity of our tool collection through t-SNE embeddings, demonstrating that both MCP and synthetic tools cover complementary regions of the tool space.\n\nAgent Diversifcation.We generate thousands of distinct agents by synthesizing various system prompts andi equipping them with different combinations of tools from our repository. This creates a diverse population of agents with varied capabilities, areas of expertise, and behavioral patterns, ensuring a broad coverage of potential use cases.\n\nRubric-Based Task Generation.For each agent confguration, we generate tasks that range from simple to complexi operations. Each task is paired with an explicit rubric that specifes success criteria, expected tool-use patterns, andi evaluation checkpoints. This rubric-based approach ensures a consistent and objective evaluation of agent performance.\n\nMulti-turn Trajectory Generation.We simulate realistic tool-use scenarios through several components:\n\nUser Simulation: LLM-generated user personas with distinct communication styles and preferences engage in multi-turn dialogues with agents, creating naturalistic interaction patterns.\n\n\n\nTool Execution Environment: A sophisticated tool simulator (functionally equivalent to a world model) executes tool calls and provides realistic feedback. The simulator maintains and updates state after each tool execution,enabling complex multi-step interactions with persistent effects. It introduces controlled stochasticity to produce varied outcomes including successes, partial failures, and edge cases.\n\nQuality Evaluation and Filtering.An LLM-based judge evaluates each trajectory against the task rubrics. Only trajectories that meet the success criteria are retained for training, ensuring high-quality data while allowing natural variation in task-completion strategies.\n\nHybrid Approach with Real Execution Environments.While simulation provides scalability, we acknowledge the inherent limitation of simulation fdelity. To address this, we complement our simulated environments with reali execution sandboxes for scenarios where authenticity is crucial, particularly in coding and software engineering tasks.These real sandboxes execute actual code, interact with genuine development environments, and provide ground-truth feedback through objective metrics such as test suite pass rates. This combination ensures that our models learn from both the diversity of simulated scenarios and the authenticity of real executions, signifcantly strengthening practicali agent capabilities.\n\nBy leveraging this hybrid pipeline that combines scalable simulation with targeted real-world execution, we generate diverse, high-quality tool-use demonstrations that balance coverage and authenticity. The scale and automation of our synthetic data generation, coupled with the grounding provided by real execution environments, effectively implements large-scale rejection sampling [26, 87] through our quality fltering process. This high-quality synthetic data, wheni used for supervised fne-tuning, has demonstrated signifcant improvements in the model’s tool-use capabilities across aii wide range of real-world applications.\n\n## 3.2Reinforcement Learning\n\nReinforcement learning (RL) is believed to have better token effciency and generalization than SFT. Based on the worki of K1.5 [35], we continue to scale RL in both task diversity and training FLOPs in K2. To support this, we develop a Gym-like extensible framework that facilitates RL across a wide range of scenarios. We extend the framework with a large number of tasks with verifable rewards. For tasks that rely on subjective preferences, such as creative writing andi open-ended question answering, we introduce a self-critic reward in which the model performs pairwise comparisons to judge its own outputs. This approach allows tasks from various domains to all beneft from the RL paradigm.i\n\n## 3.2.1Verifable Rewards Gymi\n\nMath, STEM and Logical TasksFor math, stem and logical reasoning domains, our RL data preparation follows two key principles, diverse coverage and moderate diffculty.i\n\nDiverse Coverage. For math and stem tasks, we collect high-quality QA pairs using a combination of expert annotations,internal QA extraction pipelines, and open datasets [41, 52]. During the collection process, we leverage a tagging system to deliberately increase coverage of under-covered domains. For logical tasks, our dataset comprises a variety of formats, including structured data tasks (e.g., multi-hop tabular reasoning, cross-table aggregation) and logic puzzles(e.g., the 24-game, Sudoku, riddles, cryptarithms, and Morse-code decoding).\n\nModerate Diffculty. The RL prompt-set should be neither too easy nor too hard, both of which may produce little signali and reduce learning effciency. We assess the diffculty of each problem using the SFT model’s pass@k accuracy andii select only problems with moderate diffculty.i\n\nComplex Instruction FollowingEffective instruction following requires not only understanding explicit constraints but also navigating implicit requirements, handling edge cases, and maintaining consistency over extended dialogues.We address these challenges through a hybrid verifcation framework that combines automated verifcation withii adversarial detection, coupled with a scalable curriculum generation pipeline. Our approach employs a dual-path system to ensure both precision and robustness:\n\nHybrid Rule Verifcation. We implement two verifcation mechanisms: (1) deterministic evaluation via code interpretersii for instructions with verifable outputs (e.g., length, style constraints), and (2) LLM-as-judge evaluation for instructionsi requiring nuanced understanding of constraints. To address potential adversarial behaviors where models might claim instruction fulfllment without actual compliance, we incorporate an additional hack-check layer that specifcally detectsii such deceptive claims.\n\nMulti-Source Instruction Generation. To construct our training data, we employ three distinct generation strategies to ensure comprehensive coverage: (1) expert-crafted complex conditional prompts and rubrics developed by our datateam (2) agentic instruction augmentation inspired by AutoIF [12], and (3) a fne-tuned model specialized for generatingi additional instructions that probe specifc failure modes or edge cases. This multipronged approach ensures both breadthi and depth in instruction coverage.\n\nFaithfulnessFaithfulness is essential for an agentic model operating in scenarios such as multi-turn tool use, selfgenerated reasoning chains, and open-environment interactions. Inspired by the evaluation framework from FACTS Grounding [30], we train a sentence-level faithfulness judge model to perform automated verifcation. The judge isi effective in detecting sentences that make a factual claim without supporting evidence in context. It serves as a reward model to enhance overall faithfulness performance.\n\nCoding $\\&$  Software EngineeringTo enhance our capability in tackling competition-level programming problems,we gather problems and their judges from both open-source datasets [27, 83] and synthetic sources. To ensure the diversity of the synthetic data and the correctness of reward signals, we incorporate high-quality human-written unit tests retrieved from pre-training data.\n\nFor software engineering tasks, we collect a vast amount of pull requests and issues from GitHub to build software development environment that consists of user prompts/issues and executable unit tests. This environment was built on a robust sandbox infrastructure, powered by Kubernetes for scalability and security. It supports over 10,000 concurrent sandbox instances with stable performance, making it ideal for both competitive coding and software engineering tasks.\n\nSafetyOur work to enhance the safety begins with a human-curated set of seed prompts, manually crafted to encompass prevalent risk categories such as violence, fraud, and discrimination.\n\nTo simulate sophisticated jailbreak attempts (e.g., role-playing, literary narratives, and academic discourse), we employ an automated prompt evolution pipeline with three key components:\n\nAttack Model: Iteratively generates adversarial prompts designed to elicit unsafe responses from the target LLM.\n\nTarget Model: Produces responses to these prompts, simulating potential vulnerabilities.\n\nJudge Model: Evaluates the interaction to determine if the adversarial prompt successfully bypasses safety mechanisms.\n\nEach interaction is assessed using a task-specifc rubric, enabling the judge model to provide a binary success/failurei label.\n\n## 3.2.2Beyond Verifcation: Self-Critique Rubric Rewardi\n\nTo extend model alignment beyond tasks with verifable reward, we introduce a framework for general reinforcementi learning from self-critic feedbacks. This approach is designed to align LLMs with nuanced human preferences,including helpfulness, creativity, depth of reasoning, factuality, and safety, by extending the capabilities learned from verifable scenarios to a broader range of subjective tasks. The framework operates using a Self-Critique Rubric Rewardi mechanism, where the model evaluates its own outputs to generate preference signals. To bootstrap K2 as a competent judge, we curated a mixture of open-source and in-house preference datasets and initialize its critic capability in the SFT stage.\n\nSelf-Critiqued Policy OptimizationIn the frst core process of the learning loop, the K2 actor generates responsesi for general prompts that cover a wide range of use cases. The K2 critic then ranks all results by performing pairwise evaluations against a combination of rubrics, which incorporates both core rubrics (Appendix. F.1), which represent the fundamental values of our AI assistant that Kimi cherish, prescriptive rubrics (Appendix. F.2) that aim to eliminate reward hacking, and human-annotated rubrics crafted by our data team for specifc instructional contexts. Althoughi certain rubrics can be designated as mandatory, K2 retains the fexibility to weigh them against its internal priors. Thisl capacity enables a dynamic and continuous alignment with its evolving on-policy behavior, ensuring that the model’s responses remain coherent with its core identity while adapting to specifc instructions.i\n\nClosed-Loop Critic Refnement and AlignmentDuring RL training, the critic model is refned using verifableiii signals. On-policy rollouts generated from verifable-reward prompts are used to continuously update the critic, a cruciali step that distills objective performance signals from RLVR directly into its evaluation model. This transfer learning process grounds its more subjective judgments in verifable data, allowing the performance gains from verifableii tasks to enhance the critic’s judgment on complex tasks that lack explicit reward signals. This closed-loop process ensures that the critic continuously recalibrates its evaluation standards in lockstep with the policy’s evolution. Bygrounding subjective evaluation in verifable data, the framework enables robust and scalable alignment with complex,i non-verifable human objectives.i\n\nConsequently, this holistic alignment yields comprehensive performance improvements across a wide spectrum of domains, including user intent understanding, creative writing, complex reasoning, and nuanced language comprehension.\n\n## 3.2.3RL Algorithm\n\nWe adopt the policy optimization algorithm introduced in K1.5 [35] as the foundation for K2. For each problem x,we sample $K$  responses $\\{y_{1},\\ldots,y_{k}\\}$  from the previous policy $\\pi_{\\text{old}},$  and optimize the model $\\pi_{\\theta}$  with respect to the following objective:\n\n$$L_{\\text{RL}}(\\theta)=\\mathbb{E}_{x\\sim\\mathcal{D}}\\left[\\frac{1}{K}\\sum_{i=1}^{K}\\left[\\left(r(x,y_{i})-\\bar{r}(x)-\\tau\\log\\frac{\\pi_{\\theta}(y_{i}|x)}{\\pi_{\\text{old}}(y_{i}|x)}\\right)^{2}\\right]\\right] ,$$\n\nwhere $$  is the mean rewards of the sampled responses, $\\tau>0$  is a regularization parameter that promotes stablke learning. As in SFT, we employ the Muon optimizer [33] to minimize this objective. As we scale RL training to encompass a broader range of tasks in K2, a primary challenge is achieving consistent performance improvements across all domains. To address this, we introduce several additions to the RL algorithm.\n\nBudget ControlIt has been widely observed that RL often results in a substantial increase in the length of modelgenerated responses [35, 19]. While longer responses can enable the model to utilize additional test-time compute for improved performance on complex reasoning tasks, the benefts often do not justify its inference cost in non-reasoningi domains. To encourage the model to properly distribute inference budget, we enforce a per-sample maximum token budget throughout RL training, where the budget is determined based on the type of task. Responses that exceed this token budget are truncated and assigned a penalty, which incentivizes the model to generate solutions within the specifed limit. Empirically, this approach signifcantly enhances the model’s token effciency, encouraging concise yetiii effective solutions across all domains.\n\nPTX LossTo prevent the potential forgetting of valuable, high-quality data during joint RL training, we curate a dataset comprising hand-selected, high-quality samples and integrate it into the RL objective through an auxiliary PTX loss [54]. This strategy not only leverages the advantages of high-quality data, but also mitigates the risk of overfttingi to the limited set of tasks explicitly present in the training regime. This augmentation substantially improves the model’s generalization across a broader range of domains.\n\nTemperature DecayFor tasks such as creative writing and complex reasoning, we fnd that promoting explorationi via a high sampling temperature during the initial stages of training is crucial. A high temperature allow the model to generate diverse and innovative responses, thereby facilitating the discovery of effective strategies and reducing the risk of premature convergence to suboptimal solutions. However, retaining a high temperature in the later stages of training or during evaluation can be detrimental, as it introduces excessive randomness and compromises the reliability and consistency of the model’s outputs. To address this, we employ a temperature decay schedule, to shift from exploration to exploitation throughout the training. This strategy ensures that the model leverages exploration when it is most benefcial, while ultimately converge on stable and high-quality outputs.i\n\n## 3.3RL Infrastructure\n\n## 3.3.1Colocated Architecture\n\nSimilar to K1.5 [35], we adopt a hybrid colocated architecture for our synchronized RL training, where the training and inference engines live on the same workers. When one engine is actively working, the other engine releases or offoadsl its GPU resources to accommodate. In each iteration of RL training, a centralized controller frst calls the inferencei engine to generate new data for training. It then notifes the training engine to train on the new data, and send updatedi parameters to the inference engine for the next iteration.\n\nEach engine is heavily optimized for throughput. In addition, as the model scales to the size of K2, the latency of engine switching and failure recovery becomes signifcant. We present our system design considerations in these aspects.i\n\n\n\n![dca6e2033728ddc0e8f9ff276d733311](imgs/dca6e2033728ddc0e8f9ff276d733311.jpg)\n\nFigure 10: Parameter update utilizing a checkpoint engine\n\n## 3.3.2Effcient Engine Switchingi\n\nDuring rollout, the parameters of the training engine are offoaded to DRAM. Bringing up the training engine isl therefore a simple step of H2D transmission. However, bringing up the inference engine is a bigger challenge, as it must obtain updated parameters from the training engine with a different sharding paradigm.\n\nGiven the scale of K2 and the vast number of devices involved, using a network fle system for resharding andi broadcasting parameters is impractical. The aggregate bandwidth required to keep overhead low reaches several petabytes per second. To address this challenge, we developed a distributed checkpoint engine co-located on training nodes to manage parameter states. To perform a parameter update, each checkpoint engine worker obtains a local copy of parameters from the training engine, then broadcasts the full parameter set across all checkpoint engine workers.Subsequently, the inference engine retrieves only the parameter shard it requires from the checkpoint engine. This process is illustrated in Figure 10. To enable this for a 1T model, updates are performed parameter-by-parameter in a pipelined manner, minimizing memory footprint (see Appendix G).\n\nWe opt to broadcast the full parameter set across the entire cluster, regardless of the specifc sharding schemes on eachi inference worker. While this transfers several times more data than a theoretically optimal approach, it offers a simpler system design that is less intrusive to the training and inference engines. We chose to trade off this minor overhead to fully decouple the training engine and the inference engine, signifcantly simplifying maintenance and testing.i\n\nNotably, this approach outperforms the transfer-what-you-need method due to reduced synchronization overhead and higher network bandwidth utilization. Our system can complete a full parameter update for Kimi K2 with less than 30 seconds, a negligible duration for a typical RL training iteration.\n\n## 3.3.3Effcient System Startupi\n\nAs large-scale training is prone to system failure, optimizing the startup time is crucial for models as large as Kimi K2.To start the training engine, we let each training worker selectively read part or none of the parameters from disk, and broadcast necessary parameters to its peers. The design goal is to ensure all workers collectively read the checkpoint only once, minimizing expensive disk IO.\n\nAs the inference engines are independent replicas, we would like to avoid introducing extra synchronization barriers between them. Therefore, we opt to reuse checkpoint engine for startup: we let checkpoint engine collectively read the checkpoint from disk, similar to how the training engine starts. Then it updates the state of the uninitialized inference engine, using the approach introduced in the previous section. By leveraging the dedicated checkpoint engine, the system also becomes robust to single-point failures, because an inference replica can restart without communicating with other replicas.\n\n## 3.3.4Agentic Rollout\n\nOur RL infrastructure supports the training of long-horizon, multi-turn agentic tasks. During rollout, these tasks present distinct challenges, such as complex environmental interactions and prolonged rollout durations. Here we introduce a few optimizations to alleviate these issues.\n\nDue to the diversity of environments, certain interactions may be blocked on waiting for environment feedback (e.g., a virtual machine or a code interpreter), leaving the GPUs idle. We employ two strategies to maximize GPU utilization:(i) we deploy heavy environments as dedicated services that can scale up more easily; (ii) we employ a large number of concurrent rollouts to amortize the latency induced by certain expensive interactions.\n\nAnother challenge in agentic rollout is that individual rollout trajectories can be extremely long. To prevent long-tail trajectories from blocking the entire rollout process, we employ the partial rollout [35] technique. This strategy allows long-tail unfnished tasks to be paused, and resumed in the next RL iteration.i\n\nTo improve research effciency, we also design a unifed interface inspired by the OpenAI Gym framework [49] toii streamline the integration of new environments. We hope to scale our RL infrastructure to more diverse interactive environments in the future.\n\n## 4Evaluations\n\nThis section begins with the post-training evaluation of Kimi-K2-Instruct, followed by a brief overview of the capabilities of Kimi-K2-Base. We conclude with a comprehensive safety evaluation.\n\n## 4.1Post-training Evaluations\n\n## 4.1.1Evaluation Settings\n\nBenchmarksWe assess Kimi-K2-Instruct across different areas. For coding, we adopt LiveCodeBench v6 [31](questions from August 2024 to May 2025), OJBench [77], MultiPL-E [5], SWE-bench Verifed [32, 84], TerminalBench [71],i Multi-SWE-bench [86], SWE-Lancer [50], PaperBench [65], and Aider-Polyglot [16]. For tool use tasks, we evaluate performance on $\\boldsymbol{\\tau^{2}}$ -Bench [3] and AceBench [6], which emphasize multi-turn tool-calling capabilities. In reasoning,we include a wide range of mathematical, science and logical tasks: AIME 2024/2025, MATH-500, HMMT 2025,CNMO 2024, PolyMath-en, ZebraLogic [43], AutoLogi [91], GPQA-Diamond [61], SuperGPQA [13], and Humanity’s Last Exam (Text-Only) [56]. We benchmark the long-context capabilities on: MRCR4 for long-context retrieval, and DROP [14], FRAMES [37] and LongBench v2 [2] for long-context reasoning. For factuality, we evaluate FACTS Grounding [30], the Vectara Hallucination Leaderboard [73], and FaithJudge [68]. Finally, general capabilities are assessed using MMLU [23], MMLU-Redux [17], MMLU-Pro [76], IFEval [90], Multi-Challenge [64], SimpleQA [78],and LiveBench [80] (as of 2024-11-25).\n\nBaselinesWe benchmark against both open-source and proprietary frontier models, ensuring every candidate is evaluated under its non-thinking confguration to eliminate additional gains from test-time compute. Open-sourcei baselines: DeepSeek-V3-0324 and Qwen3-235B-A22B, with the latter run in the vendor-recommended no-thinking regime. Proprietary baselines: Claude Sonnet 4, Claude Opus 4, GPT-4.1, and Gemini 2.5 Flash Preview (2025-05-20).Each invoked in its respective non-thinking mode via offcial APIs under unifed temperature and top-p settings.ii\n\nEvaluation Confgurations All runs query models in their non-thinking mode. Output token length is capped ati 8192 tokens everywhere except SWE-bench Verifed (Agentless), which is raised to 16384. For benchmarks with highi per-question variance, we adopt repeated sampling $k$  times and average the results to obtain stable scores, denoted as Avg@k. For long-context tasks, we set the context window size to 128K tokens during evaluation, truncating any input that exceeds this limit to ft within the window. SWE-bench Verifed is evaluated in two modes: Agentless Codingii via Single Patch without Test (Acc) and Agentic Coding via bash/editor tools under both Single Attempt (Acc) and Multiple Attempts (Acc) using best-of-N selection with an internal verifer; SWE-bench Multilingual is tested only ini the single-attempt agentic setting. Some data points have been omitted due to prohibitively expensive evaluation costs.\n\n## 4.1.2Evaluation Results\n\nA comprehensive evaluation results of Kimi-K2-Instruct is shown in Table 3, with detailed explanation provided in the Appendix C. Below, we highlight key results across four core domains:\n\nAgentic and Competitive CodingKimi-K2-Instruct demonstrates state-of-the-art open-source performance on real-world SWE tasks. It outperforms most baselines on SWE-bench Verifedi $(65.8\\%,71.6\\%$ with multiple attemps),SWE-bench Multilingual $(47.3\\%]$ , and SWE-lancer (39.1%), signifcantly closing the gap with Claude 4 Opus andi Sonnet. On competitive coding benchmarks (e.g., LiveCodeBench v6 $53.7\\%,$  OJBench $\\bar{27.1\\%})$ , it also leads among all models, highlighting its practical coding profciency across diffculty levels.ii\n\n\n\nTable 3: Performance comparison of Kimi-K2-Instruct against leading open-source and proprietary models across diverse tasks. Bold denotes the global SOTA; underlined bold indicates the best open-source result. Data points marked with * are taken directly from the model’s technical report or blog.\n\n\n\n<html><body><table><thead><tr><td></td><td colspan=\"3\">Open Source</td><td colspan=\"3\">Proprietary</td><td></td></tr><tr><td>Benchmark</td><td>Kimi-K2- Instruct</td><td>DeepSeek- V3-0324</td><td>Qwen3- 235B- A22B</td><td>Claude Sonnet 4</td><td>Claude Opus 4</td><td>GPT-4.1</td><td>Gemini 2.5 Flash</td></tr></thead><tbody><tr><td colspan=\"8\">Coding Tasks</td></tr><tr><td>LiveCodeBench v6 (Pass@1)</td><td>53.7</td><td>46.9</td><td>37.0</td><td>48.5</td><td>47.4</td><td>44.7</td><td>44.7</td></tr><tr><td>OJBench (Pass@1)</td><td>27.1</td><td>24.0</td><td>11.3</td><td>15.3</td><td>19.6</td><td>19.5</td><td>19.5</td></tr><tr><td>MultiPL-E (Pass@1) SWE-bench Verifed</td><td>85.7</td><td>83.1</td><td>78.2</td><td>88.6</td><td>89.6</td><td>86.7</td><td>85.6</td></tr><tr><td>Agentless-Single-Patch (Pass@1)</td><td>51.8</td><td>36.6</td><td>39.4</td><td>50.2</td><td>53.0</td><td>40.8</td><td>32.6</td></tr><tr><td>SWE-bench Verifed Agentic-Single-Attempt (Pass@1)</td><td>65.8</td><td>38.8</td><td>34.4</td><td>72.7*</td><td> $72.5\\text{*}$ </td><td>54.6</td><td>—</td></tr><tr><td>SWE-bench Verifed</td><td>71.6</td><td>—</td><td>—</td><td>80.2*</td><td> $79.4\\text{*}$ </td><td>—</td><td>—</td></tr><tr><td>Agentic-Multi-Attempt (Pass@1) SWE-bench Multilingual (Pass@1)</td><td>47.3</td><td>25.8</td><td>20.9</td><td>51.0</td><td>—</td><td>31.5</td><td>—</td></tr><tr><td>Multi-SWE-bench (Pass@1)</td><td>18.3</td><td>8.0</td><td>9.0</td><td>29.2</td><td>—</td><td>11.7</td><td>14.0</td></tr><tr><td>SWE-Lancer (Pass@1)</td><td>39.1</td><td>30.5</td><td>24.1</td><td>40.8</td><td>—</td><td>23.0</td><td>38.5</td></tr><tr><td>Paper Bench Code-Dev (Acc.)</td><td>27.8</td><td>12.2</td><td>13.2</td><td>43.3</td><td></td><td>29.9</td><td>5.7</td></tr><tr><td>Terminal Bench In-House (Acc.)</td><td>30.0</td><td></td><td></td><td>35.5</td><td>43.2</td><td>8.3</td><td>—</td></tr><tr><td>Terminal Bench Terminus (Acc.)</td><td>25.0</td><td>16.3</td><td>6.6</td><td>—</td><td></td><td>30.3</td><td>16.8</td></tr><tr><td>Aider-Polyglot (Acc.)</td><td>60.0</td><td>55.1</td><td>61.8</td><td>56.4</td><td>70.7</td><td>52.4</td><td>44.0</td></tr><tr><td colspan=\"8\">Tool Use Tasks</td></tr><tr><td>Tau2 retail (Avg@4)</td><td>70.6</td><td>69.1</td><td>57.0</td><td>75.0</td><td>81.8</td><td>74.8</td><td>64.3</td></tr><tr><td>Tau2 airline (Avg@4)</td><td>56.5</td><td>39.0</td><td>26.5</td><td>55.5</td><td>60.0</td><td>54.5</td><td>42.5</td></tr><tr><td>Tau2 telecom (Avg@4)</td><td>65.8</td><td>32.5</td><td>22.1</td><td>45.2</td><td>57.0</td><td>38.6</td><td>16.9</td></tr><tr><td>AceBench (Acc.)</td><td>76.5</td><td>72.7</td><td>70.5</td><td>76.2</td><td>75.6</td><td>80.1</td><td>74.5</td></tr><tr><td colspan=\"8\">Math & STEM Tasks</td></tr><tr><td>AIME 2024 (Avg@64)</td><td>69.6</td><td>59.4*</td><td>40.1*</td><td>43.4</td><td>48.2</td><td>46.5</td><td>61.3</td></tr><tr><td>AIME 2025 (Avg@64)</td><td>49.5</td><td>46.7</td><td>24.7*</td><td>33.1*</td><td>33.9*</td><td>37.0</td><td>46.6</td></tr><tr><td>MATH-500 (Acc.)</td><td>97.4</td><td>94.0*</td><td>91.2*</td><td>94.0</td><td>94.4</td><td>92.4</td><td>95.4</td></tr><tr><td>HMMT 2025 (Avg@32)</td><td>38.8</td><td>27.5</td><td>11.9</td><td>15.9</td><td>15.9</td><td>19.4</td><td>34.7</td></tr><tr><td>CNMO 2024 (Avg@16)</td><td>74.3</td><td>74.7</td><td>48.6</td><td>60.4</td><td>57.6</td><td>56.6</td><td>75.0</td></tr><tr><td>PolyMath-en (Avg@4)</td><td>65.1</td><td>59.5</td><td>51.9</td><td>52.8</td><td>49.8</td><td>54.0</td><td>49.9</td></tr><tr><td>ZebraLogic (Acc.)</td><td>89.0</td><td>84.0</td><td>37.7*</td><td>79.7</td><td>59.3</td><td>58.5</td><td>57.9</td></tr><tr><td>AutoLogi (Acc.)</td><td>89.5</td><td>88.9</td><td>83.3*</td><td>89.8</td><td>86.1</td><td>88.2</td><td>84.1</td></tr><tr><td>GPQA-Diamond (Avg@8)</td><td>75.1</td><td>68.4*</td><td>62.9*</td><td>70.0*</td><td>74.9*</td><td>66.3</td><td>68.2</td></tr><tr><td>SuperGPQA (Acc.)</td><td>57.2 4.7</td><td>53.7 5.2</td><td>50.2 5.7</td><td>55.7 5.8</td><td>56.5 7.1</td><td>50.8 3.7</td><td>49.6 5.6</td></tr><tr><td colspan=\"8\">Humanity’s Last Exam (Acc.) General Tasks</td></tr><tr><td>MMLU (EM)</td><td>89.5</td><td>89.4</td><td>87.0</td><td>91.5</td><td>92.9</td><td>90.4</td><td>90.1</td></tr><tr><td>MMLU-Redux (EM)</td><td>92.7</td><td>90.5</td><td>89.2*</td><td>93.6</td><td>94.2</td><td>92.4</td><td>90.6</td></tr><tr><td>MMLU-Pro (EM)</td><td>81.1</td><td>81.2*</td><td>77.3</td><td>83.7</td><td>86.6</td><td>81.8</td><td>79.4</td></tr><tr><td>IFEval (Prompt Strict)</td><td>89.8</td><td>81.1</td><td>83.2*</td><td>87.6</td><td>87.4</td><td>88.0</td><td>84.3</td></tr><tr><td>Multi-Challenge (Acc.)</td><td>54.1</td><td>31.4</td><td>34.0</td><td>46.8</td><td>49.0</td><td>36.4</td><td>39.5</td></tr><tr><td>SimpleQA (Correct)</td><td>31.0</td><td>27.7</td><td>13.2</td><td>15.9</td><td>22.8</td><td>42.3</td><td>23.3</td></tr><tr><td>Livebench (Pass@1) Arena Hard v2.0</td><td>76.4</td><td>72.4</td><td>67.6</td><td>74.8</td><td>74.6</td><td>69.8</td><td>67.8</td></tr><tr><td>Hard Prompt (Win rate)</td><td>54.5</td><td>39.9</td><td>39.9</td><td>51.6</td><td>59.7</td><td>51.7</td><td>48.7</td></tr><tr><td>Arena Hard v2.0</td><td>85.0</td><td>59.3</td><td>59.8</td><td>54.6</td><td>68.5</td><td>61.5</td><td>72.8</td></tr><tr><td>Creative Writing (Win rate) FACTS Grounding (Adjusted)</td><td>88.5</td><td></td><td></td><td></td><td></td><td>79.2</td><td>86.6</td></tr><tr><td>HHEM v2.1 (1-Hallu.)</td><td>98.9</td><td>68.3 88.9</td><td>68.5 94.5</td><td>83.6 94.5</td><td>—</td><td>96.7</td><td>97.8</td></tr><tr><td>FaithJudge (1-Hallu.)</td><td>92.6</td><td>83.4</td><td>75.7</td><td>83.0</td><td>—</td><td>91.0</td><td>93.2</td></tr><tr><td>LongBench v2 (Acc.)</td><td></td><td></td><td></td><td></td><td>—</td><td>54.3</td><td>55.5</td></tr><tr><td>FRAMES (Acc.)</td><td>49.1 77.1</td><td>51.1 79.2</td><td>—</td><td>52.5 76.3</td><td>—</td><td>87.4</td><td>72.9</td></tr><tr><td>MRCR (Acc.)</td><td>55.0</td><td>50.8</td><td>—</td><td>74.4</td><td>—</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>—</td><td>66.9</td><td>81.7</td></tr><tr><td>DROP (Acc.)</td><td>93.5</td><td>91.2</td><td>84.3</td><td>92.0</td><td>—</td><td>79.1</td><td>81.7</td></tr></tbody></table></body></html>\n\n\n\nAgentic Tool UseOn multi-turn tool-use benchmarks, Kimi-K2-Instruct sets a new standard. It achieves 66.1 Pass@1 on $\\tau^{2}$ Bench and 76.5 on ACEBench, substantially outperforming all baselines. These results affrm its strength ini grounded, controlled, and agent-driven tool orchestration across domains.\n\nGeneral CapabilitiesKimi-K2-Instruct exhibits strong, balanced performance across general knowledge, math, instruction following, and long-context tasks. It surpasses open-source peers on SimpleQA $(31.0\\%),$  MMLU $(89.5\\%]$  and MMLU-Redux (92.7%), and leads all models on instruction benchmarks (IFEval: $89.8\\%,$  Multi-Challenge: $54.1\\%)$ In math and STEM, it achieves top-tier scores (AIME 2024: 69.6%, GPQA-Diamond: $75.1\\%)$ , and remains competitive on long-context factuality and retrieval (DROP: 93.5%, MRCR: 55.0%). These results position Kimi-K2-Instruct as a well-rounded and capable generalist across both short- and long-context settings.\n\nOpen-Ended EvaluationOn the LMSYS Arena leaderboard (July 17, 2025), Kimi-K2-Instruct ranks as the top-1 open-source model and 5th overall based on over 3,000 user votes. This real-world preference signal—across diverse,blind prompts—underscores Kimi-K2’s strengths in generating high-quality responses on open-ended tasks.\n\n## 4.2Pre-training Evaluations\n\n## 4.2.1Evaluation Settings\n\nBenchmarksWe evaluate Kimi-K2-Base across diverse capability areas. For general capabilities, we assess on MMLU [23], MMLU-Pro [76], MMLU-Redux [17], BBH [67], TriviaQA [34], SuperGPQA [13], SimpleQA [78], HellaSwag [88], AGIEval [89], GPQA-Diamond [61], ARC-Challenge [8], and WinoGrande [62]. For coding capabilities,we employ EvalPlus [45] (averaging HumanEval [7], MBPP [1], HumanEval+, and MBPP+), LiveCodeBench v6 [31],and CRUXEval [18]. For mathematical reasoning, we utilize GSM8K [9], GSM8K-Platinum [74], MATH [24], and CMATH [79]. For Chinese language capabilities, we evaluate on C-Eval [29], CMMLU [40], and CSimpleQA [22].\n\nBaselinesWe benchmark against leading open-source foundation models: DeepSeek-V3-Base [10], Qwen2.5-72BBase [59] (Note that Qwen3-235B-A22B-Base is not open-sourced, and the largest open-sourced base model in the Qwen series is Qwen2.5-72B-Base), and Llama 4-Maverick [70] (Llama 4-Behemoth is also not open-sourced). All models are evaluated under identical confgurations to ensure fair comparison.i\n\nEvaluation ConfgurationsWe employ perplexity-based evaluation for MMLU, MMLU-Redux, GPQA-Diamond,i HellaSwag, ARC-Challenge, C-Eval, and CMMLU. Generation-based evaluation is used for MMLU-Pro, SuperGPQA,TriviaQA, BBH, CSimpleQA, MATH, CMATH, GSM8K, GSM8K-Platinum, CRUXEval, LiveCodeBench, and EvalPlus. To mitigate the high variance inherent to GPQA-Diamond, we report the mean score across eight independent runs. All evaluations are conducted using our internal framework derived from LM-Harness-Evaluation [4], ensuring consistent settings across all models.\n\n## 4.2.2Evaluation Results\n\nTable 4 presents a comprehensive comparison of Kimi-K2-Base against leading open-source foundation models across diverse evaluation benchmarks. The results demonstrate that Kimi-K2-Base achieves state-of-the-art performance across the majority of evaluated tasks, establishing it as a leading foundation model in the open-source landscape.\n\nGeneral Language UnderstandingKimi-K2-Base achieves state-of-the-art performance on 10 out of 12 English language benchmarks. Notable results include MMLU (87.79%), MMLU-Pro (69.17%), MMLU-Redux (90.17%),SuperGPQA $(44.67\\%)$ , and SimpleQA $(35.25\\%$ , signifcantly outperforming all baselines.i\n\nCoding CapabilitiesOn coding benchmarks, Kimi-K2-Base sets new standards with leading performance across all metrics. It achieves $74.00\\%$  on CRUXEval-I-cot, $83.50\\%$ on CRUXEval-O-cot, $26.29\\%$ on LiveCodeBench v6, and $80.33\\%$ on EvalPlus, demonstrating superior code generation and comprehension abilities, particularly in scenarios requiring step-by-step reasoning.\n\nMathematical ReasoningKimi-K2-Base exhibits exceptional mathematical capabilities, leading on three out of four benchmarks: MATH $(70.22\\%)$  GSM8K (92.12%), and GSM8K-Platinum $(\\hat{94}.21\\%)$  It maintains competitive performance on CMATH $(90.26\\%),$  narrowly behind DeepSeek-V3-Base $(90.53\\%)$ . These results highlight the model’s robust mathematical problem-solving abilities across varying diffculty levels.i\n\n\n\nChinese Language UnderstandingThe model demonstrates superior multilingual capabilities, achieving state-of-theart results across all Chinese language benchmarks: C-Eval $(92.50\\%)$ , CMMLU $(90.90\\%$ , and CSimpleQA (77.57%).These results establish Kimi-K2-Base as a leading model for Chinese language understanding while maintaining strong performance across other languages.\n\nTable 4: Performance comparison of Kimi-K2-Base against leading open-source models across diverse tasks.\n\nBenchmark (Metric)#Shots Kimi-K2-Base DeepSeek-V3-Base Llama4-Maverick-Base Qwen2.5-72B-Base\n\n\n\n<html><body><table><thead><tr><td># Total Params</td><td>Architecture # Activated Params</td><td>- - -</td><td>MoE 32B 1043B</td><td>MoE 37B 671B</td><td>MoE 17B 400B</td><td>Dense 72B 72B</td></tr></thead><tbody><tr><td rowspan=\"10\"></td><td>MMLU</td><td>5-shots</td><td>87.79</td><td>87.10</td><td>84.87</td><td>86.08</td></tr><tr><td>MMLU-pro</td><td>5-shots</td><td>69.17</td><td>60.59</td><td>63.47</td><td>62.80</td></tr><tr><td>MMLU-redux</td><td>5-shots</td><td>90.17</td><td>89.53</td><td>88.18</td><td>87.77</td></tr><tr><td>SuperGPQA</td><td>5-shots</td><td>44.67</td><td>39.20</td><td>38.84</td><td>34.23</td></tr><tr><td>GPQA-Diamond(avg@8)</td><td> 5-shots</td><td>48.11</td><td>50.51</td><td>49.43</td><td>40.78</td></tr><tr><td>SimpleQA</td><td>5-shots</td><td>35.25</td><td>26.49</td><td>23.74</td><td>10.31</td></tr><tr><td>EnglishTriviaQA</td><td>5-shots</td><td>85.09</td><td>84.11</td><td>79.25</td><td>76.03</td></tr><tr><td>BBH</td><td>3-shots</td><td>88.71</td><td>88.37</td><td>87.10</td><td>84.09</td></tr><tr><td>HellaSwag</td><td>5-shots</td><td>94.60</td><td>89.44</td><td>86.02</td><td>95.27</td></tr><tr><td>AGIEval</td><td>-</td><td>84.23</td><td>81.57</td><td>67.55</td><td>76.87</td></tr><tr><td rowspan=\"3\"></td><td>ARC-Challenge</td><td>0-shot</td><td>95.73</td><td>93.77</td><td>94.03</td><td>95.56</td></tr><tr><td>WinoGrande</td><td>5-shots</td><td>85.32</td><td>84.21</td><td>77.58</td><td>84.14</td></tr><tr><td>CRUXEval-I-cot</td><td>0-shots</td><td>74.00</td><td>62.75</td><td>67.13</td><td>61.12</td></tr><tr><td rowspan=\"4\">Code</td><td>CRUXEval-O-cot LiveCodeBench(v6)</td><td>0-shots</td><td>83.50</td><td>75.25</td><td>75.88</td><td>66.13</td></tr><tr><td>EvalPlus</td><td>1-shots</td><td>26.29</td><td>24.57</td><td>25.14</td><td>22.29</td></tr><tr><td></td><td>-</td><td>80.33</td><td>65.61</td><td>65.48</td><td>66.04</td></tr><tr><td>MATH</td><td>4-shots</td><td>70.22</td><td>61.70</td><td>63.02</td><td>62.68</td></tr><tr><td rowspan=\"4\">Math</td><td>GSM8k</td><td>8-shots</td><td>92.12</td><td>91.66</td><td>86.35</td><td>90.37</td></tr><tr><td>GSM8k-platinum</td><td>8-shots</td><td>94.21</td><td>93.38</td><td>88.83</td><td>92.47</td></tr><tr><td>CMATH</td><td>6-shots</td><td>90.26</td><td>90.53</td><td>88.07</td><td>86.98</td></tr><tr><td>C-Eval</td><td>5-shots</td><td>92.50</td><td>90.04</td><td>80.91</td><td>90.86</td></tr><tr><td rowspan=\"2\">ChineseCMMLU</td><td></td><td>5-shots</td><td>90.90</td><td>88.84</td><td>81.24</td><td>90.55</td></tr><tr><td>CSimpleQA</td><td>5-shots</td><td>77.57</td><td>72.13</td><td>53.47</td><td>50.53</td></tr></tbody></table></body></html>\n\n## 4.3Safety Evaluation\n\n## 4.3.1Experiment Settings\n\nWe conducted red-teaming evaluations on Kimi K2 compare with other open-source LLMs. The evaluation covered a range of attack scenarios—including harmful content, privacy content, and security content, as well as different attack strategies such as prompt injection and iterative jailbreak.\n\nWe choose Promptfoo5 to generate adversarial prompts and analyze the responses. By this way, we can evaluate model in a scalable ways.\n\nModel Selection We compare Kimi K2 with three other open-source LLMs: DeepSeek-V3, DeepSeek-R1, and Qwen3.Promptfoo Settings Table 5 lists plugins and strategies evaluated, with each plugin paired with all strategies to assess their performance.\n\nTest Case Count Given the inherent non-determinism of large language model inference, single-pass outputs may exhibit variability. To account for this, we generated 3 attack prompts per plugin for each strategy.\n\nPrompt Language Settings We pre-tested the language compatibility for each plugin-strategy combination. Some plugins support both English and Chinese, while others only support English. For combinations that support both, we generated 3 prompts in each language, resulting in 6 prompts per combination.\n\n\n\nTable 5: Enabled Plugins and Strategies\n\n\n\n<html><body><table><tr><td rowspan=\"5\">Plugin</td><td>Harmful</td><td>Graphic Content, Harassment and Bullying, Hate Speech, Insults, Profanity, Radicalization, Self Harm, Sexual Content, ToxicChat</td></tr><tr><td>Criminal</td><td>Chemical&Biological Weapons, Child Exploitation, Copyright Violations, Cybercrime, Illegal Activities, Illegal Drugs, Indiscriminate Weapons, Intellectual Property Violation, Non-Violent Crime, Violent Crime, Sex Crimes</td></tr><tr><td>Misinformation</td><td> Competitor Endorsement, Unsupervised Contracts, Excessive Agency, Hallucination, Misin- formation and Disinformation, Specialized Advice, Unsafe Practices, Imitation, Overreliance, Political Opinions, Religious Sensitivity</td></tr><tr><td>Privacy</td><td>Privacy Violation, PII in API/Database, Direct PII Exposure, PII in Session Data, PII via Social Engineering</td></tr><tr><td>Security</td><td>ASCII Smuggling, CyberSecEval, Harmbench, Debug Access, Divergent Repetition, DoNotAn-</td></tr><tr><td colspan=\"3\">swer, Malicious Code, Pliny, Prompt Extraction, Reasoning DoS, Tool Discovery Strategy Basic, Prompt Injection, Iterative Jailbreak, Crescendo</td></tr></table></body></html>\n\nManual Review We incorporated human review into the evaluation process. To minimize subjectivity problem, we conducted multiple rounds of review and assigned the same reviewer to evaluate all cases within a given test set to ensure consistency and reduce variability in judgment.\n\n## 4.3.2Safety Evaluation Results\n\nTable 6 presents the passing rates of different models under various plugin–strategy combinations.\n\nTable 6: Safety Evaluation Results\n\n\n\n<html><body><table><tr><td>Plugin Strategy</td><td></td><td colspan=\"4\">Kimi-K2-Instruct DeepSeek-V3-0324 DeepSeek-R1 Qwen3-235B-A22B</td></tr><tr><td rowspan=\"5\">Harmful</td><td>Basic</td><td>98.04</td><td>90.45</td><td>99.02</td><td>98.53</td></tr><tr><td>Base64</td><td>100</td><td>90.20</td><td>100</td><td>100</td></tr><tr><td>Prompt Injection</td><td>93.14</td><td>100</td><td>95.10</td><td>99.02</td></tr><tr><td>Iterative Jailbreak</td><td>92.16</td><td>66.67</td><td>72.55</td><td>74.51</td></tr><tr><td>Crescendo</td><td>64.71</td><td>64.71</td><td>80.39</td><td>86.27</td></tr><tr><td rowspan=\"5\">Criminal</td><td>Basic</td><td>100</td><td>99.62</td><td>95.45</td><td>99.24</td></tr><tr><td>Base64</td><td>96.97</td><td>89.39</td><td>84.85</td><td>98.48</td></tr><tr><td>Prompt Injection</td><td>75.76</td><td>91.67</td><td>69.70</td><td>98.47</td></tr><tr><td>Iterative Jailbreak</td><td>57.57</td><td>21.21</td><td>25.76</td><td>53.03</td></tr><tr><td>Crescendo</td><td>56.06</td><td>31.81</td><td>42.42</td><td>59.09</td></tr><tr><td rowspan=\"5\">Misinformation</td><td>Basic</td><td>97.28</td><td>92.57</td><td>92.46</td><td>94.84</td></tr><tr><td>Base64</td><td>98.48</td><td>90.48</td><td>96.83</td><td>93.65</td></tr><tr><td>Prompt Injection</td><td>98.39</td><td>86.51</td><td>93.65</td><td>93.65</td></tr><tr><td>Iterative Jailbreak</td><td>63.97</td><td>53.97</td><td>84.13</td><td>69.84</td></tr><tr><td>Crescendo</td><td>85.71</td><td>55.56</td><td>88.89</td><td>84.13</td></tr><tr><td rowspan=\"5\">Privacy</td><td>Basic</td><td>100</td><td>100</td><td>100</td><td>100</td></tr><tr><td>Base64</td><td>100</td><td>100</td><td>100</td><td>100</td></tr><tr><td>Prompt Injection</td><td>88.33</td><td>98.33</td><td>100</td><td>91.67</td></tr><tr><td>Iterative Jailbreak</td><td>76.67</td><td>100</td><td>93.33</td><td>96.67</td></tr><tr><td>Crescendo</td><td>96.67</td><td>100</td><td>96.67</td><td>100</td></tr><tr><td rowspan=\"5\">Security</td><td>Basic</td><td>77.84</td><td>75.57</td><td>70.46</td><td>90.09</td></tr><tr><td>Base64</td><td>82.93</td><td>82.93</td><td>63.41</td><td>95.12</td></tr><tr><td>Prompt Injection</td><td>87.80</td><td>97.56</td><td>65.85</td><td>84.13</td></tr><tr><td>Iterative Jailbreak</td><td>43.90</td><td>60.97</td><td>43.90</td><td>78.04</td></tr><tr><td>Crescendo</td><td>68.29</td><td>87.80</td><td>68.29</td><td>87.80</td></tr></table></body></html>\n\nWithout targeted optimization for specifc evaluation scenarios, the passing rate of some complex cases (e.g., Harm-i ful–Iterative Jailbreak) was relatively higher compared to other models.\n\nAcross different attack strategies, the models exhibited varying trends. Under the Base64 strategy, passing rates generally approached or reached $100\\%,$  suggesting that encoding transformations had minimal impact on the models’basic robustness. In contrast, the Crescendo strategy led to a general drop in passing rates, indicating stronger adversarial effectiveness.\n\nIn addition, complex attack strategies do not always outperform basic prompts. Some originally adversarial prompts may lose their intended meaning after multiple rounds of transformation, rendering the resulting model outputs less meaningful.\n\nAutomated Red-teaming Limitations Due to the involvement of human review, the evaluation results inevitably contain a degree of subjectivity. Additionally, certain plugin types involve API misuse or external tool invocation, which are more suitable for evaluating agent models with tool-calling capabilities. In the context of base LLMs, such tests may have limited relevance.\n\n## 5Limitations\n\nIn our internal tests, we have identifed some limitations in current Kimi K2 models. When dealing with hard reasoningi tasks or unclear tool defnition, the model may generate excessive tokens, sometimes leading to truncated outputs ori incomplete tool calls. Additionally, performance may decline on certain tasks if tool use is unnecessarily enabled. When building complete software projects, the success rate of one-shot prompting is not as good as using K2 under an agentic coding framework. We are working to address these issues in future releases and looking forward to more feedbacks.\n\n## 6Conclusions\n\nWe introduced Kimi K2, a 1T-parameter open-weight MoE model built for agentic intelligence. Leveraging the tokeneffcient MuonClip optimizer and a 15.5T-token high-quality dataset, Kimi K2 achieves stable, scalable pre-training.i Post-training combines large-scale synthetic tool-use data with a unifed RL framework using both verifable rewardsii and self-critic feedbacks. Kimi K2 sets new state-of-the-art on agentic and reasoning benchmarks, establishing itself as the most capable open-weight LLM to date.\n\n## 7Acknowledgments\n\nWe would like to acknowledge the valuable support provided by the OpenHands and Multi-SWE-bench teams in evaluating the SWE-bench Verifed and Multi-SWE-bench experimental results.i\n\n\n\n## References\n\n[1]Jacob Austin et al. Program Synthesis with Large Language Models. 2021. arXiv: 2108.07732 [cs.PL]. URL:https://arxiv.org/abs/2108.07732.\n\n[2]Yushi Bai et al. LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks. 2025. arXiv: 2412.15204 [cs.CL]. URL: https://arxiv.org/abs/2412.15204.\n\n[3]Victor Barres et al. $\\boldsymbol{\\tau^{2}}$ Bench: Evaluating Conversational Agents in a Dual-Control Environment. 2025. arXiv:2506.07982 [cs.AI]. URL: https://arxiv.org/abs/2506.07982.\n\n[4]Stella Biderman et al. “Lessons from the trenches on reproducible evaluation of language models”. In: arXiv preprint arXiv:2405.14782 (2024).\n\n[5]Federico Cassano et al. “MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation”. In: IEEE Transactions on Software Engineering 49.7 (2023), pp. 3675–3691. DOI: 10.1109/TSE.2023.3267446.\n\n[6]Chen Chen et al. “ACEBench: Who Wins the Match Point in Tool Learning?” In: arXiv e-prints (2025), arXiv–2501.\n\n[7]Mark Chen et al. “Evaluating Large Language Models Trained on Code”. In: (2021). arXiv: 2107.03374[cs.LG].\n\n[8]Peter Clark et al. “Think you have solved question answering? try arc, the ai2 reasoning challenge”. In: arXiv preprint arXiv:1803.05457 (2018).\n\n[9]Karl Cobbe et al. Training Verifers to Solve Math Word Problems. 2021. arXiv: 2110.14168 [cs.LG]. URL:i https://arxiv.org/abs/2110.14168.\n\n[10]DeepSeek-AI. DeepSeek-V3 Technical Report. 2024. arXiv: 2412.19437 [cs.CL]. URL: https://arxiv.org/abs/2412.19437.\n\n[11]Mostafa Dehghani et al. “Scaling vision transformers to 22 billion parameters”. In: International conference on machine learning. PMLR. 2023, pp. 7480–7512.\n\n[12]Guanting Dong et al. Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models. 2024. arXiv: 2406.13542 [cs.CL]. URL: https://arxiv.org/abs/2406.13542.\n\n[13]Xinrun Du et al. “Supergpqa: Scaling llm evaluation across 285 graduate disciplines”. In: arXiv preprint arXiv:2502.14739 (2025).\n\n[14]Dheeru Dua et al. “DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs”. In: CoRR abs/1903.00161 (2019). arXiv: 1903.00161. URL: http://arxiv.org/abs/1903.00161\n\n[15]Kazuki Fujii et al. Rewriting Pre-Training Data Boosts LLM Performance in Math and Code. 2025. arXiv:2505.02881 [cs.LG]. URL: https://arxiv.org/abs/2505.02881.\n\nl Gauthier. Aider LLM Leaderboards. https://aider.chat/docs/leaderboards/. 2025.\n\n[17]Aryo Pradipta Gema et al. “Are we done with mmlu?” In: arXiv preprint arXiv:2406.04127 (2024).\n\n[18]Alex Gu et al. “Cruxeval: A benchmark for code reasoning, understanding and execution”. In: arXiv preprint arXiv:2401.03065 (2024).\n\n[19]Daya Guo et al. “Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning”. In: arXiv preprint arXiv:2501.12948 (2025).\n\n[20]Zhicheng Guo et al. “StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models”. In: arXiv preprint arXiv:2403.07714 (2025).\n\n[21]Aaron Harlap et al. “Pipedream: Fast and effcient pipeline parallel dnn training”. In: arXiv preprinti arXiv:1806.03377 (2018).\n\n[22]Y He et al. “Chinese simpleqa: A chinese factuality evaluation for large language models, 2024a”. In: URL https://arxiv. org/abs/2411.07140 ().\n\n[23]Dan Hendrycks et al. “Measuring massive multitask language understanding”. In: arXiv preprint arXiv:2009.03300 (2020).\n\n[24]Dan Hendrycks et al. Measuring Mathematical Problem Solving With the MATH Dataset. 2021. arXiv: 2103.03874 [cs.LG]. URL: https://arxiv.org/abs/2103.03874.\n\nal. “Minicpm: Unveiling the potential of small language models with scalable training strategies t arXiv:2404.06395 (2024).\n\n[26]Jiaxin Huang et al. “Large language models can self-improve”. In: arXiv preprint arXiv:2210.11610 (2022).\n\n[27]Siming Huang et al. OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models. 2025. arXiv:2411.04905 [cs.CL]. URL: https://arxiv.org/abs/2411.04905.\n\n\n\n[28]Yanping Huang et al. “Gpipe: Effcient training of giant neural networks using pipeline parallelism”. In: Advancesi in neural information processing systems 32 (2019).\n\n[29]Yuzhen Huang et al. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models.2023. arXiv: 2305.08322 [cs.CL]. URL: https://arxiv.org/abs/2305.08322.\n\n[30]Alon Jacovi et al. The FACTS Grounding Leaderboard: Benchmarking LLMs’ Ability to Ground Responses to Long-Form Input. 2025. arXiv: 2501.03200 [cs.CL]. URL: https://arxiv.org/abs/2501.03200.\n\n[31]Naman Jain et al. “Livecodebench: Holistic and contamination free evaluation of large language models for code”. In: arXiv preprint arXiv:2403.07974 (2024).\n\n[32]Carlos E Jimenez et al. “SWE-bench: Can Language Models Resolve Real-world Github Issues?” In: The Twelfth International Conference on Learning Representations. 2024. URL: https://openreview.net/forum?id=VTF8yNQM66.\n\n[33]Keller Jordan et al. Muon: An optimizer for hidden layers in neural networks. 2024. URL: https : / /kellerjordan.github.io/posts/muon/.\n\n[34]Mandar Joshi et al. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.2017. arXiv: 1705.03551 [cs.CL]. URL: https://arxiv.org/abs/1705.03551.\n\n[35]Kimi Team. “Kimi k1. 5: Scaling reinforcement learning with llms”. In: arXiv preprint arXiv:2501.12599 (2025).\n\n[36]Diederik P. Kingma and Jimmy Ba. “Adam: A Method for Stochastic Optimization”. In: 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings. Ed. by Yoshua Bengio and Yann LeCun. 2015. URL: http://arxiv.org/abs/1412.6980.\n\n[37]Satyapriya Krishna et al. Fact, Fetch, and Reason: A Unifed Evaluation of Retrieval-Augmented Generation.i 2025. arXiv: 2409.12941 [cs.CL]. URL: https://arxiv.org/abs/2409.12941.\n\n[38]Joel Lamy-Poirier. “Breadth-frst pipeline parallelism”. In: Proceedings of Machine Learning and Systems 5i(2023), pp. 48–67.\n\n[39]Dmitry Lepikhin et al. “Gshard: Scaling giant models with conditional computation and automatic sharding”. In:arXiv preprint arXiv:2006.16668 (2020).\n\n[40]Haonan Li et al. CMMLU: Measuring massive multitask language understanding in Chinese. 2024. arXiv:2306.09212 [cs.CL]. URL: https://arxiv.org/abs/2306.09212.\n\n[41]Jia Li et al. “Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions”. In: Hugging Face repository 13.9 (2024), p. 9.\n\n[42]Tianle Li et al. “From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline”.In: arXiv preprint arXiv:2406.11939 (2024).\n\n[43]Bill Yuchen Lin et al. ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning. 2025. arXiv: 2502.01100 [cs.AI]. URL: https://arxiv.org/abs/2502.01100.\n\n[44]Aixin Liu et al. “Deepseek-v2: A strong, economical, and effcient mixture-of-experts language model”. In:i arXiv preprint arXiv:2405.04434 (2024).\n\n[45]Jiawei Liu et al. “Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation”. In: Advances in Neural Information Processing Systems 36 (2023), pp. 21558–21572.\n\nan Liu et al. “Muon is scalable for LLM training”. In: arXiv preprint arXiv:2502.16982 (2025\n\n[47]Ziming Liu et al. “Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training Effciency”. In: Proceedings of the International Conference for High Performance Computing, Networking,i Storage and Analysis. SC ’23. ACM, Nov. 2023, pp. 1–13. DOI: 10.1145/3581784.3607073. URL: http://dx.doi.org/10.1145/3581784.3607073.\n\n[48]Ilya Loshchilov and Frank Hutter. “Decoupled Weight Decay Regularization”. In: International Conference on Learning Representations. 2019. URL: https://openreview.net/forum?id=Bkg6RiCqY7.\n\n[49]Jan Ludziejewski et al. OpenAI Gym. 2025. arXiv: 2502.05172 [cs.LG]. URL: https://arxiv.org/abs/2502.05172.\n\n[50]Samuel Miserendino et al. “SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?” In: arXiv preprint arXiv:2502.12115 (2025).\n\n[51]Arindam Mitra et al. “Agentinstruct: Toward generative teaching with agentic fows”. In: arXiv preprintl arXiv:2407.03502 (2024).\n\n[52]Ivan Moshkov et al. “Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with openmathreasoning dataset”. In: arXiv preprint arXiv:2504.16891 (2025).\n\n[53]Deepak Narayanan et al. “Effcient large-scale language model training on gpu clusters using megatron-lm”. In:i Proceedings of the international conference for high performance computing, networking, storage and analysis.2021, pp. 1–15.\n\n\n\n[54]Long Ouyang et al. “Training language models to follow instructions with human feedback”. In: Advances in neural information processing systems 35 (2022), pp. 27730–27744.\n\n[55]Bowen Peng et al. “Yarn: Effcient context window extension of large language models”. In: arXiv preprinti arXiv:2309.00071 (2023).\n\n[56]Long Phan et al. Humanity’s Last Exam. 2025. arXiv: 2501.14249 [cs.LG]. URL: https://arxiv.org/abs/2501.14249.\n\nghui Qi et al. “Zero bubble pipeline parallelism”. In: arXiv preprint arXiv:2401.10241 (2023)\n\n[58]Yujia Qin et al. “Toolllm: Facilitating large language models to master 16000+ real-world apis”. In: arXiv preprint arXiv:2307.16789 (2023).\n\n[59]Qwen et al. Qwen2.5 Technical Report. 2025. arXiv: 2412.15115 [cs.CL]. URL: https://arxiv.org/abs/2412.15115.\n\n[60]Samyam Rajbhandari et al. “Zero: Memory optimizations toward training trillion parameter models”. In: SC20:International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE. 2020,pp. 1–16.\n\n[61]David Rein et al. “Gpqa: A graduate-level google-proof q&a benchmark”. In: First Conference on Language Modeling. 2024.\n\n[62]Keisuke Sakaguchi et al. “Winogrande: An adversarial winograd schema challenge at scale”. In: Communications of the ACM 64.9 (2021), pp. 99–106.\n\nid Silver and Richard S Sutton. “Welcome to the era of experience”. In: Google AI 1 (2025).\n\n[64]Ved Sirdeshmukh et al. MultiChallenge: $A$  Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs. 2025. arXiv: 2501.17399 [cs.CL]. URL: https://arxiv.org/abs/2501.17399.\n\n[65]Giulio Starace et al. “PaperBench: Evaluating AI’s Ability to Replicate AI Research”. In: arXiv preprint arXiv:2504.01848 (2025).\n\n[66]Hao Sun et al. ZeroSearch: Incentivize the Search Capability of LLMs without Searching. 2025. arXiv: 2505.04588 [cs.CL]. URL: https://arxiv.org/abs/2505.04588.\n\n[67]Mirac Suzgun et al. Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them. 2022. arXiv:2210.09261 [cs.CL]. URL: https://arxiv.org/abs/2210.09261.\n\n[68]Manveer Singh Tamber et al. “Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards”. In: arXiv preprint arXiv:2505.04847 (2025).\n\n[69]Gemma Team et al. “Gemma 2: Improving open language models at a practical size”. In: arXiv preprint arXiv:2408.00118 (2024).\n\n[70]LlaMA Team. The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation — ai.meta.com.https://ai.meta.com/blog/llama-4-multimodal-intelligence/. [Accessed 15-07-2025].\n\n[71]The Terminal-Bench Team. Terminal-Bench: A Benchmark for AI Agents in Terminal Environments. Apr. 2025.URL: https://github.com/laude-institute/terminal-bench.\n\n[72]Ashish Vaswani et al. “Attention is All you Need”. In: Advances in Neural Information Processing Systems.Ed. by I. Guyon et al. Vol. 30. Curran Associates, Inc., 2017. URL: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\n\n[73]Vectara. Hallucination Evaluation Model (Revision 7437011). 2024. URL: https://huggingface.co/vectara/hallucination_evaluation_model\n\n[74]Joshua Vendrow et al. “Do large language model benchmarks test reliability?” In: arXiv preprint arXiv:2502.03461 (2025).\n\n[75]Yizhong Wang et al. “Self-instruct: Aligning language models with self-generated instructions”. In: arXiv preprint arXiv:2212.10560 (2022).\n\n[76]Yubo Wang et al. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark.2024. arXiv: 2406.01574 [cs.CL]. URL: https://arxiv.org/abs/2406.01574.\n\n[77]Zhexu Wang et al. OJBench: A Competition Level Code Benchmark For Large Language Models. 2025. arXiv:2506.16395 [cs.CL]. URL: https://arxiv.org/abs/2506.16395.\n\n[78]Jason Wei et al. “Measuring short-form factuality in large language models”. In: arXiv preprint arXiv:2411.04368(2024).\n\n[79]Tianwen Wei et al. CMATH: Can Your Language Model Pass Chinese Elementary School Math Test? 2023.arXiv: 2306.16636 [cs.CL]. URL: https://arxiv.org/abs/2306.16636.\n\n[80]Colin White et al. “LiveBench: A Challenging, Contamination-Free LLM Benchmark”. In: The Thirteenth International Conference on Learning Representations. 2025.\n\n\n\n[81]Mitchell Wortsman et al. “Small-scale proxies for large-scale transformer training instabilities, 2023”. In: URL https://arxiv. org/abs/2309.14322 ().\n\n[82]Can Xu et al. WizardLM: Empowering large pre-trained language models to follow complex instructions. 2025.arXiv: 2304.12244 [cs.CL]. URL: https://arxiv.org/abs/2304.12244.\n\n[83]Zhangchen Xu et al. KodCode: A Diverse, Challenging, and Verifable Synthetic Dataset for Coding. 2025. arXiv:i 2503.02951 [cs.LG]. URL: https://arxiv.org/abs/2503.02951.\n\n[84]John Yang et al. SWE-smith: Scaling Data for Software Engineering Agents. 2025. arXiv: 2504.21798 [cs.SE].URL: https://arxiv.org/abs/2504.21798.\n\n[85]Shunyu Yao et al. “tau-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains”. In: arXiv preprint arXiv:2406.12045 (2024).\n\n[86]Daoguang Zan et al. “Multi-swe-bench: A multilingual benchmark for issue resolving”. In: arXiv preprint arXiv:2504.02605 (2025).\n\n[87]Eric Zelikman et al. “Star: Bootstrapping reasoning with reasoning”. In: Advances in Neural Information Processing Systems 35 (2022), pp. 15476–15488.\n\n[88]Rowan Zellers et al. “Hellaswag: Can a machine really fnish your sentence?” In: arXiv preprint arXiv:1905.07830i(2019).\n\n[89]Wanjun Zhong et al. “Agieval: A human-centric benchmark for evaluating foundation models”. In: arXiv preprint arXiv:2304.06364 (2023).\n\n[90]Jeffrey Zhou et al. “Instruction-Following Evaluation for Large Language Models”. In: ArXiv abs/2311.07911(2023). URL: https://arxiv.org/abs/2311.07911.\n\n[91]Qin Zhu et al. AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning Abilities of Large Language Models. 2025. arXiv: 2502.16906 [cs.CL]. URL: https://arxiv.org/abs/2502.16906.\n\n\n\n## Appendix\n\n## AContributions\n\nThe listing of authors is in alphabetical order based on their last names. Names marked with an asterisk (*) indicate people who are no longer part of our team.\n\nYifan Bai  \nYiping Bao  \nGuanduo Chen  \nJiahao Chen  \nNingxin Chen  \nRuijue Chen  \nYanru Chen  \nYuankun Chen  \nYutian Chen  \nZhuofu Chen*  \nJialei Cui  \nHao Ding  \nMengnan Dong  \nAng’ang Du  \nChenzhuang Du  \nDikang Du  \nYulun Du  \nYu Fan  \nYichen Feng  \nKelin Fu  \nBofei Gao  \nHongcheng Gao  \nPeizhong Gao  \nTong Gao  \nXinran Gu  \nLongyu Guan  \nHaiqing Guo*  \nJianhang Guo  \nHao Hu  \nXiaoru Hao  \nTianhong He  \nWeiran He  \nWenyang He  \nChao Hong  \nYangyang Hu  \nZhenxing Hu  \nWeixiao Huang  \nZhiqi Huang  \nZihao Huang  \nTao Jiang  \nZhejun Jiang  \nXinyi Jin  \nYongsheng Kang*\n\nGuokun Lai  \nCheng Li  \nFang Li  \nHaoyang Li  \nMing Li  \nWentao Li  \nYanhao Li  \nYiwei Li  \nZhaowei Li  \nZheming Li  \nHongzhan Lin*  \nXiaohan Lin  \nZongyu Lin  \nChengyin Liu  \nChenyu Liu  \nHongzhang Liu  \nJingyuan Liu*  \nJunqi Liu  \nLiang Liu  \nShaowei Liu  \nT.Y. Liu  \nTianwei Liu  \nWeizhou Liu  \nYangyang Liu  \nYibo Liu  \nYiping Liu  \nYue Liu  \nZhengying Liu  \nEnzhe Lu  \nLijun Lu  \nShengling Ma  \nXinyu Ma  \nYingwei Ma  \nShaoguang Mao  \nJie Mei  \nXin Men  \nYibo Miao  \nSiyuan Pan  \nYebo Peng  \nRuoyu Qin  \nBowen Qu  \nZeyu Shang  \nLidong Shi\n\nShengyuan Shi  \nFeifan Song  \nJianlin Su  \nZhengyuan Su  \nXinjie Sun*  \nFlood Sung  \nHeyi Tang  \nJiawen Tao  \nQifeng Teng  \nChensi Wang  \nDinglu Wang  \nFeng Wang  \nHaiming Wang  \nJianzhou Wang*  \nJiaxing Wang  \nJinhong Wang  \nShengjie Wang  \nShuyi Wang  \nYao Wang  \nYejie Wang  \nYiqin Wang  \nYuxin Wang  \nYuzhi Wang  \nZhaoji Wang  \nZhengtao Wang  \nZhexu Wang  \nChu Wei  \nQianqian Wei  \nWenhao Wu  \nXingzhe Wu  \nYuxin Wu  \nChenjun Xiao  \nXiaotong Xie  \nWeimin Xiong*  \nBoyu Xu  \nJing Xu*  \nJinjing Xu  \nL.H. Xu  \nLin Xu  \nSuting Xu  \nWeixin Xu  \nXinran Xu  \nYangchuan Xu\n\nZiyao Xu  \nJunjie Yan  \nYuzi Yan  \nXiaofei Yang  \nYing Yang  \nZhen Yang  \nZhilin Yang  \nZonghan Yang  \nHaotian Yao  \nXingcheng Yao  \nWenjie Ye  \nZhuorui Ye  \nBohong Yin  \nLonghui Yu  \nEnming Yuan  \nHongbang Yuan*  \nMengjie Yuan  \nHaobing Zhan  \nDehao Zhang  \nHao Zhang  \nWanlu Zhang  \nXiaobin Zhang  \nYangkun Zhang  \nYizhi Zhang  \nYongting Zhang  \nYu Zhang  \nYutao Zhang  \nYutong Zhang  \nZheng Zhang  \nHaotian Zhao  \nYikai Zhao  \nHuabin Zheng  \nShaojie Zheng  \nJianren Zhou  \nXinyu Zhou  \nZaida Zhou  \nZhen Zhu  \nWeiyu Zhuang  \nXinxing Zu  \nKimi K2\n\n\n\n## BToken Template of Tool Calling\n\nThere are three components in the token structure for tool-calling:\n\nTool declaration message: defnes the list of available tools and the schema of the argumenti\n\nTool invoking section in assistant message: encodes the model’s request to invoke tools;\n\nTool result message: encapsulates the invoked tool’s execution result.\n\nThe raw tokens of the tool declaration message are formatted as follows:\n\n![47d11a88859d4e6b5c3262995eb318a2](imgs/47d11a88859d4e6b5c3262995eb318a2.jpg)\n\nThe blue highlighted marks represent special tokens, and the green part, quoted by brackets, is the tool declaration content. We use TypeScript to express the tool declaration content, since TypeScript is a concise language with a comprehensive type system, able to express the types and constraints of tool parameters with brief text. The code 1 shows an example for two simple tools in JSON format compatible with OpenAI’s chat completion API, as a comparison,the same tools defned in TypeScript (listed in Code 2) is much shorter. To improve compatibility, part of our trainingi data also uses JSON as the tool declaration language, so that 3rd-party frameworks need not additional development to support our tool calling scheme.\n\nListing 1: Tool defnition with JSON in OpenAI compatible APIi\n\n[{\n\n\"type\": \"function\",\n\n\"function\": {\n\n\"name\": \"get_weather\",\n\n\"description\": \"Getweatherfor a locationand date\",\n\n\"parameters\": {\n\n\"type\": \"object\",\n\n\"properties\": {\n\n\"location\": {\n\n\"type\": \"string\",\n\n\"description\": \"City andcountry e.g. Beijing , China\"\n\n},\n\n\"date\": {\n\n}\n\n\"type\": \"string\",\n\n\"description\": \"Date to query , format in‘%Y-%m-%d’\"\n\n},\n\n\"required\": [\n\n\"location\"\n\n]}}}\n\n{\n\n\"type\": \"function\",\n\n\"function\": {\n\n\"name\": \"Calculator\",\n\n\"description\": \"Simplecalculator\",\n\n\"parameters\": {\n\n\"properties\": {\n\n\"expr\": {\n\n}\n\n\"type\": \"string\",\n\n\"description\": \"Arithmeticexpression in javascript\"\n\n},}\n\n\"type\": \"object\"\n\n}\n\n}]\n\n## Listing 2: Tool defnition in TypeScripti\n\nnamespacefunctions {\n\n// Get weatherfor a locationand date\n\ntypeget_weather = (_: {\n\n// City andcountry e.g. Beijing , China\n\nlocation: string ,\n\n// Date to query , format in‘%Y-%m-%d’\n\ndate ?: string\n\n}) => any;\n\n// Simplecalculator\n\ntypeCalculator = (_: {\n\n// Arithmeticexpression in javascript\n\nexpr ?: string\n\n}) => any;\n\n}\n\nen template of the tool invoking section in the model’s response messages is listed as follows\n\n<tool_call_section_begin|>\n\n<|tool_call_begin|>\n\n// call_id part\n\nfunctions.{{tool name}}:{{counter}}\n\n<|tool_arguments_begin|>\n\n{{ json serialized call arguments }}\n\n<|tool_call_end|>\n\n<|tool_call_begin|>\n\n// more tool calls\n\n<|tool_call_end|>\n\n<|tool_call_section_end|>\n\nAs shown in the template, we support parallel tool calling by placing multiple tool calls in a single response turn. Each tool call has a unique call id, formatted as functions.{tool-name}:{counter}, where tool-name is the name of the tool, and counter is an auto-increasing counter of all tool calls starting from 0 in the dialog.\n\nDuring inference, the model may occasionally generate unexpected tokens, leading to format errors when parsing a tool call. To solve this issue, we developed a constrained decoding module named enforcer, inspired by lm-format-enforcer6.When a <tool_call_section_begin|> token is generated, it ensures that the upcoming tool-related tokens follow the predefned template, and the JSON argument string follows the declared schema.i\n\nThe tool result message is simply a text message encoded with the tool’s call id and the corresponding results.\n\n<|im_begin|>\n\ntool\n\n<|im_middle|>\n\n## Results of {{call_id}}\n\n{{ execution result content }}\n\n<|im_end|>\n\n## CEvaluation Details\n\nCoding Tasks.We evaluate Kimi-K2-Instruct’s capabilities on competitive coding benchmarks, LiveCodeBench and OJBench, where Kimi-K2-Instruct attains superior performance with scores of $53.7\\%$ and $27.1\\%,$  respectively. This excellence spans both medium-level coding challenges, such as LeetCode and AtCoder, and hard-level contests like NOI and ICPC, outperforming leading open-source and proprietary models. For multilingual programming profciency, wei employ MultiPL-E, covering languages including C++, C#, Java, JavaScript, PHP, Go, Kimi-K2-Instruct surpasses topopen-source models with an accuracy of $85.7\\%,$  compared with $83.1\\%$ for DeepSeek-V3-0324 and $78.2\\%$  for Qwen3235B-A22B. In software engineering tasks, Kimi-K2-Instruct demonstrates robust performance on SWE-bench Verifedi(Python), SWE-lancer (Python), SWE-bench Multilingual, and Multi-SWE-bench datasets. It signifcantly outperformsi open-source counterparts in resolving real-world code repository issues and notably narrows the performance gap with proprietary models. For example:\n\nSWE-bench Verifed (multiple attempts):i $71.6\\%$ (Kimi-K2-Instruct) vs. $80.2\\%$ (Claude 4 Sonnet)\n\nSWE-bench Multilingual: $47.3\\%$ (Kimi-K2-Instruct) vs. $51.0\\%$ (Claude 4 Sonnet)\n\nSWE-lancer: $39.1\\%$ (Kimi-K2-Instruct) vs. $40.8\\%$ (Claude 4 Sonnet)\n\nOn PaperBench, Kimi-K2-Instruct achieves an accuracy of $27.8\\%,$ closely matching GPT-4.1 and outperforming DeepSeek-V3-0324 (12.2%) and Qwen3-235B-A22B $(8.2\\%)$  by a substantial margin. In terminal interaction tasks measured by TerminalBench, Kimi-K2-Instruct attains $25.0\\%$  using the default Terminus framework and rises to $30\\%$ within Moonshot’s in-house agentic framework, underscoring its capabilities in real-world agentic programming scenarios. Moreover, on the Aider-Polyglot benchmark, Kimi-K2-Instruct attains a $60.0\\%$  accuracy while employing rigorous decontamination procedures, further illustrating its strength and reliability across diverse coding environments.\n\nTool Use Tasks.We evaluate multi-turn tool use with two complementary suites: $\\boldsymbol{\\tau^{2}}$ -Bench and ACEBench. $\\boldsymbol{\\tau^{2}}$ Bench extends the original $7$ -bench single-control setup to a dual-control environment in which both the agent and an LLMsimulated user have constrained tool affordances over a shared state, adding a realistic Telecom troubleshooting domain alongside the prior Airline/Retail TAU tasks and enabling analysis of coordination vs. pure reasoning. ACEBench is a large bilingual (En/Zh) API-grounded benchmark (4.5K APIs across 8 domains; 2K annotated eval items) partitioned into NORMAL (basic/personalized/atomic), SPECIAL (imperfect or out-of-scope inputs), and AGENT (scenario-driven multi-turn, multi-step sandbox) tracks with automated grading of calls and outcomes. All models run in non-thinking mode; we set the temperature to 0.0, use deterministic tool adapters, score $\\boldsymbol{\\tau^{2}}$  Airline/Retail/Telecom under Avg@4 seeds with Pass@1/4, and report overall on ACEBench English. Kimi-K2-Instruct averages 66.1 micro Pass@1 across $\\boldsymbol{\\tau^{2}}$ vs DeepSeek-V3-0324 48.8 / Qwen3-235B-A22B 37.3. On ACEBench Overall Kimi-K2-Instruct scores 76.5 vs DeepSeek 72.7 / Qwen 70.5 and remains competitive with GPT-4.1 (80.1).\n\nMath & STEM & Logical Tasks.For Math tasks, Kimi-K2-Instruct achieves consistently strong performance,averaging over Geimini-2.5-Flash by 5.3 percentage points, over DeepSeek-V3-0324 by 5.5 points and over GPT4.1 by 15.8 points. For example, on AIME 2024, Kimi-K2-Instruct scores $69.6\\%,$  outperforming another two top open-source models by a large margin, DeepSeek-V3-0324 by 10.2 points and Qwen3-235B-A22B by 29.5 points. In STEM evaluations, Kimi-K2-Instruct achieves $75.1\\%$ on GPQA-Diamond, outperforming DeepSeek-V3-0324 (68.4%) and all non-thinking baselines by at least 5 percentage points. On SuperGPQA, it also exceeds the previous best open-source model, DeepSeek-V3-0324, by 3.5 points. Kimi-K2-Instruct also surpasses the other two leading models in logical reasoning. It achieves $89.0\\%$ on ZebraLogic and $89.5\\%$  on AutoLogi, exceeding DeepSeek-V3-0324 (84.0%, 88.9%) and substantially outperforming Qwen3-235B-A22B $(37.7\\%,83.3\\%).$\n\nGeneral Tasks.Kimi-K2-Instruct ties DeepSeek-V3-0324 on MMLU and MMLU-Pro, and takes the lead on MMLURedux with a 92.7 EM score—slightly ahead of GPT-4.1 (92.4) and just 1.5 points behind Claude-Opus-4. Beyond multiple-choice tasks, the model achieves $31.0\\%$  accuracy on the short-answer SimpleQA—3.3 points above DeepSeekV3-0324 and more than twice that of Qwen3-235B-A22B—though still below GPT-4.1 $(42.\\tilde{3\\%}).$  On the adversarial free-response LiveBench (2024-11-25 snapshot), it reaches $76.4\\%,$  surpassing Claude-Sonnet 4 (74.8%) and leading Gemini 2.5 Flash Preview by 8.6 points. Across this challenging triad measuring breadth, depth, and robustness of world knowledge, Kimi-K2-Instruct secures a top-tier position among open-source models. We evaluate instruction-following with IFEval and Multi-Challenge. On IFEval, Kimi-K2-Instruct scores $89.8\\%,$  higher than DeepSeek-V3-0324 (81.1%)and GPT-4.1 (88.0%). On Multi-Challenge, which involves multi-turn dialogues with conficting instructions, it achievesl 54.1%, outperforming DeepSeek-V3-0324 (31.4%), GPT-4.1 (36.4%), and Claude-Opus-4 $\\left(49.0\\%\\right)$ . These results demonstrate that Kimi-K2-Instruct integrates strong factual knowledge with consistent instruction adherence across both single- and multi-turn settings, supporting robust and reliable real-world deployment.\n\nLong Context and Factuality Tasks.To evaluate the factuality of Kimi-K2-Instruct, we employ three benchmarks:FACTS Grounding, which measures adherence to provided documents using the proprietary models GPT-4o, Gemini 1.5 Pro and Claude 3.5 Sonnet; HHEM, which assesses summarization quality via the open-source HHEM-2.1-Open judge; and FaithJudge, which analyzes faithfulness in RAG tasks with o3-mini as the judge. Kimi-K2-Instruct scores 88.5 on FACTS Grounding, substantially outperforming all open-source rivals and even surpassing the closed-source Gemini 2.5 Flash. With HHEM-2.1-Open it achieves a hallucination rate of 1.1 %, reported in the tables as 1 minus the\n\n\n\n![9ae91e074d2d46c6bf8a0ffffd5fbc9d](imgs/9ae91e074d2d46c6bf8a0ffffd5fbc9d.jpg)\n\nFigure 11: Chinese in-house benchmark evaluation.\n\nrate, i.e. 98.9. On FaithJudge’s RAG tasks the hallucination rate is $7.4 \\%,$ likewise present as 92.6 for table consistency.For long-context capabilities, Kimi-K2-Instruct outperforms all open source and proprietary models on DROP (93.5%),and exceeds DeepSeek-V3-0324 on retrieval task MRCR $(55.0\\%$  vs $50.8\\%$ . For long-context reasoning tasks FRAMES and LongBench v2, Kimi-K2-Instruct $(77.1\\%,49.1\\%)$  lags slightly behind DeepSeek-V3-0324 by around $2\\%.$\n\nOpen-Ended EvaluationBeyond static, closed-ended benchmarks, we evaluate the model’s performance on openended, nuanced tasks that more closely resemble real-world usage.\n\nFor English scenarios, we leverage the Arena-Hard-Auto v2.0 benchmark, which use LLM-as-a-judge protocols to assess generation quality across diverse, open-ended prompts [42]. These evaluations cover a wide range of highdiffculty prompts and are widely recognized in the research community. On Arena-Hard-Auto v2.0, Kimi-K2-Instructi achieves state-of-the-art win-rate on both hard prompts $\\left(54.5\\%\\right)$  and creative writing tasks $(85.0\\%)$ , outperforming all open-source models and rivaling top proprietary systems such as GPT-4.1 and Claude Sonnet. These results underscore the model’s strength in handling complex reasoning and nuanced generation under diverse, unconstrained settings.\n\nHowever, Arena-Hard-Auto provides limited coverage of Chinese-specifc tasks. To address this gap, we developedi an in-house held-out benchmark grounded in authentic user queries. To safeguard the integrity of the evaluation, the benchmark data is access-restricted, thereby eliminating the risk of overftting.i\n\nAs shown in Figure 11, Kimi-K2-Instruct shows strong performance across all comparisons on Chinese in-house benchmarks. It outperforms ChatGPT-4o-latest with a $65.4\\%$  win rate, Claude Sonnet 4 with $64.6\\%,$  and DeepSeek-V30324 with $59.6\\%.$  In all cases, the loss rate stays low (around $17\\%$ ), indicating that Kimi-K2-Instruct rarely falls behind.The high win rates and consistent margins demonstrate its strong ability on open-ended Chinese tasks.\n\nIn addition to controlled evaluations, we also consider real-world user preference through public human assessments.As of July 17, 2025, Kimi-K2-Instruct ranked as the top open-source model and ffth overall on the LMSYS Arenai leaderboard7, based on over 3,000 blind votes from real users. Unlike LLM-as-a-judge protocols, this leaderboard refects direct human preference on diverse, user-submitted prompts, providing a complementary perspective on practicall model performance.\n\nThe results on Arena-Hard-Auto, our in-house benchmark and votes from LMSYS Arena collectively offer a comprehensive view of Kimi-K2-Instruct’s open-ended capabilities, showing that it is a highly preferred model in real-world user experience across English and Chinese.\n\n## DQK-Clip Does Not Impair Model Quality\n\nThe QK-Clip design follows a minimal intervention principle: it activates only when necessary, and deactivates after training stabilizes. Empirical evidence and analysis converge on its negligible impact on model quality.\n\n\n\n![c5ba74d06ce322720c11b9b5373e5d71](imgs/c5ba74d06ce322720c11b9b5373e5d71.jpg)\n\nFigure 12: Applying QK-Clip to Muon in a small-scale setting with an aggresive threshold $(\\tau=30)$  has negligible impact on loss, indicating that it is a safe and effective method for constraining attention logits.\n\nSmall-Scale AblationsWe train two small-scale 0.5B activated and 3B total parameters MoE models, one with vanilla Muon and the other with MuonClip using a low clipping threshold $\\left(\\tau=30\\right)$  As shown in Figure 12, applying MuonClip has negligible effects on the loss curve, indicating that even aggressive clipping does not impair convergence or training dynamics with MuonClip. This demonstrates that MuonClip is a safe and effective method for bounding attention logits without degrading model performance. Furthermore, evaluation on downstream tasks reveals no statistically signifcanti degradation in performance. These results collectively demonstrate that MuonClip is a safe and effective method for bounding attention logits without compromising model quality.\n\nSelf-deactivationIn Kimi K2, QK-Clip was only transiently active:\n\n• Initial 70000 steps: $12.7\\%$ of attention heads triggered QK-Clip for at least once, clamping $S_{\\max}$  to 100.\n\nPost-70000 steps: All heads at some point reduced their $S_{\\max}$ below 100, rendering QK-Clip inactive.\n\nWhen QK-Clip is active, it is applied per-head (rather than per-layer) to minimize potential over-regularization on other heads. After training stabilizes, QK-clip is deactivated and has no effect at all.\n\n## EWhy Muon is More Prone to Logit Explosion\n\nLogit explosion occurs when the largest pre-softmax attention score\n\n$$S_{\\max}=\\max_{i,j} \\left( q_{i} \\cdot k_{j} \\right)$$\n\n(1)\n\ngrows unboundedly during training. Since\n\n$$|q_{i} \\cdot k_{j}|\\leq\\|q_{i}\\|\\|k_{j}\\|\\leq\\|x_{i}\\|\\|x_{j}\\|\\|\\mathbf{W}_{q}\\|\\|\\mathbf{W}_{k}\\|,$$\n\n(2)\n\nand RMS-Norm keeps $\\| x_{i} \\|\\| x_{j} \\|$ bounded, the phenomenon is primarily driven by the growing spectral-norm of $\\mathbf{W}_{q}$ or $\\mathbf{W}_{k}$  Empirically, we found that Muon is more susceptible to logit explosion. We give our hypothesis below.\n\nStructural difference in updatesMuon produces a weight update coming from the msign operation; as a result, $all$ singular values of the update matrix are equal — its effective rank is full. In contrast, a typical update matrix produced by Adam exhibits a skewed spectrum: a few large singular values dominate, and the effective rank is low. This low-rank assumption for Adam is not new; higher-order muP makes the same assumption.\n\nSuch phenomenon is verifed on the 16 B Moonlight model, which shows weights trained with Muon exhibit higheri singular-value entropy (i.e. higher effective rank) than those trained with Adam, corroborating the theoretical intuition.\n\nSVD formulationLet the parameter matrix at step $\\boldsymbol{t}-1$  have the singular value decomposition\n\n$$\\mathbf{W}_{t-1}=\\sum_{i}\\sigma_{i} u_{i}v_{i}^{\\top}$$\n\n(3)\n\n\n\nWe write the update matrices as\n\n$$\\Delta\\mathbf{W}_{t}=\\sum_{j}\\bar{\\sigma} \\bar{u}_{j}\\bar{v}_{j}^{\\top}$$\n\n(4)\n\nThe next parameter update is therefore\n\n$$\\mathbf{W}_{t}\\leftrightarrow\\sum_{i}\\sigma_{i}u_{i}v_{i}^{\\top}+\\sum_{j}\\bar{\\sigma} \\bar{u}_{j}\\bar{v}_{j}^{\\top}$$\n\n(5)\n\nIn Muon, as both the weights and the updates have a higher effective rank than Adam, we hypothesize there is a higher probability for singular-vector pair $u_{i}v_{i}^{\\top}$ to align with $\\bar{\\bar{u}}_{j}\\bar{v}_{j}^{\\top}.$  This could cause the corresponding singular value of $\\mathbf{W}_{t}$ to increase additively.\n\nAttention-specifc amplifcationAttention logits are computed via the bilinear formii\n\n$$q_{i}\\cdot k_{j}=(x_{i}\\mathbf{W}_{q})\\cdot(x_{j}\\mathbf{W}_{k}).$$\n\n(6)\n\nThe product $\\mathbf{W}_{q}\\mathbf{W}_{k}^{\\top}$ squares the spectral norm, so any singular-value increase in either matrix is compounded. Muon’s tendency to enlarge singular values therefore translates into a higher risk of logit explosion.\n\n## FK2 Critic Rubrics for General RL\n\n## F.1Core Rubrics\n\nClarity and Relevance: Assesses the extent to which the response is succinct while fully addressing the user’s intent. The focus is on eliminating unnecessary detail, staying aligned with the central query, and using effcienti formats such as brief paragraphs or compact lists. Unless specifcally required, long itemizations should be avoided.i When a choice is expected, the response should clearly offer a single, well-defned answer.i\n\nConversational Fluency and Engagement: Evaluates the response’s contribution to a natural, fowing dialogue thatl extends beyond simple question-answering. This includes maintaining coherence, showing appropriate engagement with the topic, offering relevant observations or insights, potentially guiding the conversation constructively when appropriate, using follow-up questions judiciously, handling hypothetical or personal-analogy queries gracefully,and adapting tone effectively to suit the conversational context (e.g., empathetic, formal, casual).\n\nObjective and Grounded Interaction: Assesses the response’s ability to maintain an objective and grounded tone, focusing squarely on the substance of the user’s request. It evaluates the avoidance of both metacommentary(analyzing the query’s structure, topic combination, perceived oddity, or the nature of the interaction itself) and unwarranted fattery or excessive praise directed at the user or their input. Excellent responses interact respectfullyl but neutrally, prioritizing direct, task-focused assistance over commentary on the conversational dynamics or attempts to curry favor through compliments.\n\n## F.2Prescriptive Rubrics\n\nInitial Praise: Responses must not begin with compliments directed at the user or the question (e.g., “That’s a beautiful question”, “Good question!”).\n\nExplicit Justifcation: Any sentence or clause that explains why the response is good or how it successfullyi fulflled the user’s request. This is different from simply describing the content.i\n\n## F.3Limitations\n\nOne potential side effect of this evaluation framework is that it may favor responses that appear confdent and assertive,i even in contexts involving ambiguity or subjectivity. This stems from two key constraints in the current rubric:\n\nAvoidance of Self-Qualifcation: The prescriptive rules prohibit self-assessments, explicit disclaimers, or hedgingi language (e.g., “this may not be accurate”, “I might be wrong”). While these phrases can refect epistemic humility,l they are often penalized as non-informative or performative.\n\nPreference for Clarity and Singularity: The rubric reward direct, decisive answers when users ask for a recommendation or explanation. In complex or open-ended scenarios, this may disincentivize appropriately cautious or multi-perspective responses.\n\n\n\nAs a result, the model may occasionally overstate certainty in areas where ambiguity, nuance, or epistemic modesty would be more appropriate. Future iterations of the framework may incorporate more fne-grained handling of calibratedi uncertainty.\n\n## \n\nGEngine Switching Pipeline for RL Training\n\n![9843eaf10fc63c6003417cf5ad5de03d](imgs/9843eaf10fc63c6003417cf5ad5de03d.jpg)\n\nFigure 13: pipeline for RL weight update\n\nThe checkpoint engine manages three equal-size device buffers on each GPU: an H2D buffer for loading the offoadedl model parameters, and two IPC buffers for GPU-to-GPU broadcast. The IPC buffers are shared to inference engines,allowing it to directly access the same physical memory. These three buffers allow us to arrange the three steps in a pipeline.\n\nTheoretical three-stage pipeline.As illustrated in Figure 13a, a three-stage pipeline is introduced. (1) $\\mathit{H2D:}$  a shard of the latest weights is copied into the H2D buffer asynchronously. (2) Broadcast: Once the copy completes, the shard will be copied to one IPC buffers and broadcast to all devices. (3) Reload: Inference engines simultaneously load parameters from the other IPC buffer.\n\nTwo-stage pipeline due to PCIe saturation.On NVIDIA H800 clusters, concurrent H2D and broadcast saturate the shared PCIe fabric, collapsing the three stages into a sequential procedure (Figure 13b). We therefore adopt a simpler,two-stage scheme (Figure 13c): (1) All devices perform a single, synchronous H2D transfer. (2) The broadcast and reload proceed in parallel.\n\nThe two-stage pipeline will be bound by multiple synchronous H2D copy operations. But in large scale devices, model will be split into small shards, the entire parameter set fts into the H2D buffer in one transfer, the overhead willi disappear.\n\nBy overlapping H2D, Broadcast, and Reload weights, we can obtain a high bandwidth to reshard the weights from train engines to all inference engines.\n\n","msg":"","ocr_all":false,"page_count":32,"pages":[{"abandon_blocks":[{"bbox":{"x0":138,"x1":1084,"y0":1403,"y1":1448},"conf":0.5546,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":140,"x1":451,"y0":1422,"y1":1444},"font_size":0.0,"text":"the cost of Claude 4 Opus was prohibitive."},{"bbox":{"x0":165,"x1":1083,"y0":1399,"y1":1426},"font_size":0.0,"text":"2All models evaluated above are non-thinking models. For SWE-bench Multilingual, we evaluated only Claude 4 Sonnet because"}],"source":"layout det","text":""},{"bbox":{"x0":163,"x1":652,"y0":1379,"y1":1404},"conf":0.4338,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":170,"x1":652,"y0":1379,"y1":1402},"font_size":0.0,"text":"1https://huggingface.co/moonshotai/Kimi-K2-Instruct"}],"source":"layout det","text":""},{"bbox":{"x0":18,"x1":74,"y0":442,"y1":1145},"conf":0.3873,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":27,"x1":73,"y0":442,"y1":1137},"font_size":0.0,"text":"8cs.LG]  2[ Jul 2025.rXiv:2507a20534v1  "}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":281,"x1":942,"y0":192,"y1":233},"conf":0.842,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":291,"x1":935,"y0":198,"y1":226},"font_size":131300.0,"text":"KKIMI K2: OPEN AGENTIC INTELLIGENCE"}],"source":"layout det","text":"KKIMI K2: OPEN AGENTIC INTELLIGENCE"},{"bbox":{"x0":463,"x1":758,"y0":279,"y1":307},"conf":0.5749,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":469,"x1":753,"y0":282,"y1":304},"font_size":131300.0,"text":"TECHNICAL REPORT OF KIMI K2"}],"source":"layout det","text":"TECHNICAL REPORT OF KIMI K2"},{"bbox":{"x0":559,"x1":665,"y0":344,"y1":371},"conf":0.8259,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":562,"x1":664,"y0":345,"y1":368},"font_size":131300.0,"text":"Kimi Team"}],"source":"layout det","text":"Kimi Team"},{"bbox":{"x0":548,"x1":674,"y0":423,"y1":451},"conf":0.8085,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":552,"x1":670,"y0":424,"y1":447},"font_size":131300.0,"text":"ABSTRACT"}],"source":"layout det","text":"ABSTRACT"},{"bbox":{"x0":209,"x1":1015,"y0":457,"y1":615},"conf":0.9736,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":213,"x1":1011,"y0":459,"y1":480},"font_size":131300.0,"text":"We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated"},{"bbox":{"x0":213,"x1":1011,"y0":482,"y1":503},"font_size":131300.0,"text":"parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon"},{"bbox":{"x0":213,"x1":1011,"y0":503,"y1":525},"font_size":131300.0,"text":"Muon with a novel QK-clip technique to address training instability while enjoying the advanced"},{"bbox":{"x0":211,"x1":1011,"y0":525,"y1":547},"font_size":131300.0,"text":"token effciency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zeroi"},{"bbox":{"x0":213,"x1":1011,"y0":548,"y1":569},"font_size":131300.0,"text":"loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a"},{"bbox":{"x0":213,"x1":1011,"y0":569,"y1":591},"font_size":131300.0,"text":"large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the"},{"bbox":{"x0":213,"x1":933,"y0":591,"y1":612},"font_size":131300.0,"text":"model improves its capabilities through interactions with real and synthetic environments."}],"source":"layout det","text":"We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token effciency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zeroi loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the model improves its capabilities through interactions with real and synthetic environments."},{"bbox":{"x0":208,"x1":1016,"y0":617,"y1":818},"conf":0.9736,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":213,"x1":1011,"y0":617,"y1":640},"font_size":131300.0,"text":"Kimi K2 achieves state-of-the-art performance among open-source non-thinking models, with"},{"bbox":{"x0":213,"x1":1009,"y0":639,"y1":660},"font_size":131300.0,"text":"strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench"},{"bbox":{"x0":213,"x1":1011,"y0":660,"y1":682},"font_size":131300.0,"text":"(En), 65.8 on SWE-Bench Verifed, and 47.3 on SWE-Bench Multilingual — surpassing most openi"},{"bbox":{"x0":208,"x1":1013,"y0":676,"y1":708},"font_size":131300.0,"text":"and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding,"},{"bbox":{"x0":211,"x1":1011,"y0":701,"y1":726},"font_size":131300.0,"text":"mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025,"},{"bbox":{"x0":213,"x1":1011,"y0":726,"y1":747},"font_size":131300.0,"text":"75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position"},{"bbox":{"x0":211,"x1":1011,"y0":746,"y1":771},"font_size":131300.0,"text":"Kimi K2 as one of the most capable open-source large language models to date, particularly in"},{"bbox":{"x0":213,"x1":1011,"y0":769,"y1":792},"font_size":131300.0,"text":"software engineering and agentic tasks. We release our base and post-trained model checkpoints1 to"},{"bbox":{"x0":213,"x1":732,"y0":792,"y1":813},"font_size":131300.0,"text":"facilitate future research and applications of agentic intelligence."}],"source":"layout det","text":"Kimi K2 achieves state-of-the-art performance among open-source non-thinking models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench(En), 65.8 on SWE-Bench Verifed, and 47.3 on SWE-Bench Multilingual — surpassing most openi and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding,mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025,75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position Kimi K2 as one of the most capable open-source large language models to date, particularly in software engineering and agentic tasks. We release our base and post-trained model checkpoints1 to facilitate future research and applications of agentic intelligence."},{"bbox":{"x0":204,"x1":1019,"y0":843,"y1":1304},"conf":0.9719,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![59c6fa3876c5b81ce8c759ac85a13d1b](imgs/59c6fa3876c5b81ce8c759ac85a13d1b.jpg)"},{"bbox":{"x0":473,"x1":747,"y0":1321,"y1":1352},"conf":0.8793,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":476,"x1":742,"y0":1320,"y1":1347},"font_size":131300.0,"text":"Figure 1: Kimi K2 main results.2"}],"source":"layout det","text":"Figure 1: Kimi K2 main results.2"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":208,"x1":1016,"y0":617,"y1":818},"conf":0.9736,"label":"Text","label_id":1},{"bbox":{"x0":209,"x1":1015,"y0":457,"y1":615},"conf":0.9736,"label":"Text","label_id":1},{"bbox":{"x0":204,"x1":1019,"y0":843,"y1":1304},"conf":0.9719,"label":"Figure","label_id":3},{"bbox":{"x0":473,"x1":747,"y0":1321,"y1":1352},"conf":0.8793,"label":"Figure caption","label_id":4},{"bbox":{"x0":281,"x1":942,"y0":192,"y1":233},"conf":0.842,"label":"Title","label_id":0},{"bbox":{"x0":559,"x1":665,"y0":344,"y1":371},"conf":0.8259,"label":"Title","label_id":0},{"bbox":{"x0":548,"x1":674,"y0":423,"y1":451},"conf":0.8085,"label":"Title","label_id":0},{"bbox":{"x0":463,"x1":758,"y0":279,"y1":307},"conf":0.5749,"label":"Title","label_id":0},{"bbox":{"x0":138,"x1":1084,"y0":1403,"y1":1448},"conf":0.5546,"label":"Abandon","label_id":2},{"bbox":{"x0":163,"x1":652,"y0":1379,"y1":1404},"conf":0.4338,"label":"Abandon","label_id":2},{"bbox":{"x0":18,"x1":74,"y0":442,"y1":1145},"conf":0.3873,"label":"Abandon","label_id":2},{"bbox":{"x0":463,"x1":758,"y0":279,"y1":307},"conf":0.3304,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1084,"y0":1403,"y1":1448},"conf":0.2666,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[140,1422],[451,1422],[451,1444],[140,1444]],"score":0.7866},{"poly":[[165,1399],[1083,1403],[1083,1426],[165,1422]],"score":0.6608},{"poly":[[170,1379],[652,1379],[652,1402],[170,1402]],"score":0.6777},{"poly":[[476,1323],[742,1320],[742,1343],[476,1347]],"score":0.7464},{"poly":[[620,1282],[700,1282],[700,1299],[620,1299]],"score":0.9425},{"poly":[[215,1282],[266,1282],[266,1299],[215,1299]],"score":0.9324},{"poly":[[690,1272],[708,1272],[708,1284],[690,1284]],"score":0.6708},{"poly":[[434,1226],[444,1226],[444,1234],[434,1234]],"score":0.8133},{"poly":[[231,1226],[239,1226],[239,1234],[231,1234]],"score":0.8},{"poly":[[712,1200],[728,1200],[728,1216],[712,1216]],"score":0.8813},{"poly":[[632,1193],[647,1193],[647,1206],[632,1206]],"score":0.7745},{"poly":[[832,1191],[850,1191],[850,1208],[832,1208]],"score":0.7171},{"poly":[[763,1191],[778,1191],[778,1209],[763,1209]],"score":0.7529},{"poly":[[422,1199],[436,1185],[449,1198],[435,1212]],"score":0.7182},{"poly":[[223,1191],[241,1191],[241,1206],[223,1206]],"score":0.7792},{"poly":[[708,1195],[724,1182],[734,1195],[718,1208]],"score":0.7271},{"poly":[[736,1180],[760,1186],[754,1208],[730,1202]],"score":0.6856},{"poly":[[306,1182],[328,1188],[323,1204],[301,1198]],"score":0.7054},{"poly":[[379,1178],[402,1178],[402,1201],[379,1201]],"score":0.7623},{"poly":[[763,1176],[778,1176],[778,1190],[763,1190]],"score":0.7813},{"poly":[[783,1172],[805,1172],[805,1193],[783,1193]],"score":0.8061},{"poly":[[688,1173],[703,1173],[703,1190],[688,1190]],"score":0.684},{"poly":[[311,1175],[319,1175],[319,1183],[311,1183]],"score":0.9289},{"poly":[[662,1172],[680,1172],[680,1188],[662,1188]],"score":0.8551},{"poly":[[288,1170],[297,1174],[292,1184],[283,1180]],"score":0.6165},{"poly":[[379,1165],[402,1165],[402,1185],[379,1185]],"score":0.7802},{"poly":[[331,1158],[354,1165],[347,1187],[324,1180]],"score":0.7619},{"poly":[[796,1158],[805,1165],[797,1176],[788,1169]],"score":0.6378},{"poly":[[832,1160],[850,1160],[850,1176],[832,1176]],"score":0.8092},{"poly":[[629,1160],[647,1160],[647,1176],[629,1176]],"score":0.7835},{"poly":[[424,1158],[447,1158],[447,1178],[424,1178]],"score":0.8212},{"poly":[[223,1160],[241,1160],[241,1176],[223,1176]],"score":0.8843},{"poly":[[915,1153],[933,1153],[933,1170],[915,1170]],"score":0.9267},{"poly":[[334,1153],[349,1153],[349,1163],[334,1163]],"score":0.8867},{"poly":[[936,1148],[960,1148],[960,1170],[936,1170]],"score":0.8106},{"poly":[[254,1148],[278,1148],[278,1172],[254,1172]],"score":0.8681},{"poly":[[891,1148],[906,1148],[906,1162],[891,1162]],"score":0.769},{"poly":[[986,1145],[1009,1145],[1009,1167],[986,1167]],"score":0.8006},{"poly":[[354,1145],[376,1145],[376,1170],[354,1170]],"score":0.8169},{"poly":[[509,1142],[528,1148],[523,1165],[504,1159]],"score":0.658},{"poly":[[486,1142],[501,1142],[501,1157],[486,1157]],"score":0.8722},{"poly":[[580,1138],[604,1138],[604,1158],[580,1158]],"score":0.7234},{"poly":[[963,1137],[985,1137],[985,1160],[963,1160]],"score":0.8137},{"poly":[[861,1137],[885,1137],[885,1160],[861,1160]],"score":0.8081},{"poly":[[559,1137],[580,1137],[580,1158],[559,1158]],"score":0.8026},{"poly":[[456,1137],[481,1137],[481,1158],[456,1158]],"score":0.8173},{"poly":[[356,1135],[374,1135],[374,1150],[356,1150]],"score":0.8507},{"poly":[[256,1135],[274,1135],[274,1148],[256,1148]],"score":0.7129},{"poly":[[988,1134],[1008,1134],[1008,1148],[988,1148]],"score":0.7765},{"poly":[[532,1130],[555,1130],[555,1152],[532,1152]],"score":0.7703},{"poly":[[514,1134],[526,1134],[526,1142],[514,1142]],"score":0.7749},{"poly":[[833,1130],[850,1130],[850,1147],[833,1147]],"score":0.805},{"poly":[[629,1130],[647,1130],[647,1147],[629,1147]],"score":0.8566},{"poly":[[424,1129],[447,1129],[447,1148],[424,1148]],"score":0.7241},{"poly":[[223,1130],[241,1130],[241,1147],[223,1147]],"score":0.7838},{"poly":[[584,1127],[602,1127],[602,1140],[584,1140]],"score":0.6472},{"poly":[[968,1127],[980,1127],[980,1138],[968,1138]],"score":0.7033},{"poly":[[865,1125],[881,1125],[881,1138],[865,1138]],"score":0.738},{"poly":[[828,1099],[850,1099],[850,1114],[828,1114]],"score":0.9024},{"poly":[[624,1099],[649,1099],[649,1115],[624,1115]],"score":0.8876},{"poly":[[422,1099],[444,1099],[444,1114],[422,1114]],"score":0.8992},{"poly":[[221,1099],[241,1099],[241,1114],[221,1114]],"score":0.9064},{"poly":[[230,1079],[403,1081],[402,1099],[229,1097]],"score":0.8085},{"poly":[[883,1079],[990,1079],[990,1096],[883,1096]],"score":0.9722},{"poly":[[697,1079],[770,1079],[770,1096],[697,1096]],"score":0.979},{"poly":[[481,1077],[579,1079],[579,1097],[480,1096]],"score":0.81},{"poly":[[216,1053],[397,1053],[397,1069],[216,1069]],"score":0.8096},{"poly":[[417,1028],[432,1028],[432,1038],[417,1038]],"score":0.7573},{"poly":[[881,1043],[950,1018],[956,1036],[888,1061]],"score":0.6286},{"poly":[[674,1008],[798,1008],[798,1026],[674,1026]],"score":0.7191},{"poly":[[476,1010],[501,1010],[501,1023],[476,1023]],"score":0.6563},{"poly":[[274,1010],[301,1010],[301,1021],[274,1021]],"score":0.648},{"poly":[[905,983],[928,983],[928,1003],[905,1003]],"score":0.8191},{"poly":[[983,978],[998,978],[998,988],[983,988]],"score":0.6745},{"poly":[[953,974],[976,974],[976,993],[953,993]],"score":0.8983},{"poly":[[930,972],[955,972],[955,993],[930,993]],"score":0.8303},{"poly":[[522,974],[539,974],[539,987],[522,987]],"score":0.6903},{"poly":[[890,972],[898,972],[898,980],[890,980]],"score":0.6518},{"poly":[[858,965],[875,965],[875,978],[858,978]],"score":0.7388},{"poly":[[827,964],[840,964],[840,978],[827,978]],"score":0.7817},{"poly":[[630,964],[647,964],[647,978],[630,978]],"score":0.9113},{"poly":[[427,964],[444,964],[444,978],[427,978]],"score":0.9238},{"poly":[[223,964],[241,964],[241,978],[223,978]],"score":0.9521},{"poly":[[547,954],[572,954],[572,975],[547,975]],"score":0.7849},{"poly":[[316,949],[341,949],[341,972],[316,972]],"score":0.7798},{"poly":[[708,945],[732,945],[732,965],[708,965]],"score":0.7773},{"poly":[[289,945],[308,945],[308,959],[289,959]],"score":0.8595},{"poly":[[552,942],[570,942],[570,954],[552,954]],"score":0.7052},{"poly":[[318,939],[339,939],[339,950],[318,950]],"score":0.6642},{"poly":[[785,936],[803,936],[803,950],[785,950]],"score":0.7117},{"poly":[[733,934],[758,934],[758,957],[733,957]],"score":0.7477},{"poly":[[713,936],[728,936],[728,949],[713,949]],"score":0.6699},{"poly":[[830,936],[842,936],[842,947],[830,947]],"score":0.7839},{"poly":[[762,932],[780,932],[780,949],[762,949]],"score":0.8192},{"poly":[[688,932],[705,932],[705,947],[688,947]],"score":0.8791},{"poly":[[630,932],[647,932],[647,949],[630,949]],"score":0.8271},{"poly":[[459,931],[484,931],[484,952],[459,952]],"score":0.8073},{"poly":[[427,932],[446,932],[446,949],[427,949]],"score":0.7209},{"poly":[[291,934],[306,934],[306,944],[291,944]],"score":0.7337},{"poly":[[225,932],[241,932],[241,949],[225,949]],"score":0.8236},{"poly":[[577,924],[602,924],[602,947],[577,947]],"score":0.7978},{"poly":[[660,921],[682,921],[682,944],[660,944]],"score":0.8307},{"poly":[[344,917],[369,917],[369,940],[344,940]],"score":0.7767},{"poly":[[580,912],[600,912],[600,926],[580,926]],"score":0.9299},{"poly":[[660,908],[680,908],[680,921],[660,921]],"score":0.8726},{"poly":[[349,908],[368,908],[368,921],[349,921]],"score":0.8078},{"poly":[[825,903],[843,903],[843,917],[825,917]],"score":0.9077},{"poly":[[629,903],[647,903],[647,917],[629,917]],"score":0.9433},{"poly":[[426,903],[446,903],[446,917],[426,917]],"score":0.9259},{"poly":[[254,901],[283,901],[283,924],[254,924]],"score":0.8658},{"poly":[[221,901],[244,901],[244,921],[221,921]],"score":0.737},{"poly":[[376,889],[399,889],[399,914],[376,914]],"score":0.7892},{"poly":[[258,888],[278,888],[278,901],[258,901]],"score":0.6944},{"poly":[[378,879],[399,879],[399,893],[378,893]],"score":0.8848},{"poly":[[630,873],[645,873],[645,886],[630,886]],"score":0.9032},{"poly":[[426,873],[444,873],[444,886],[426,886]],"score":0.8862},{"poly":[[825,871],[842,871],[842,886],[825,886]],"score":0.6848},{"poly":[[223,871],[241,871],[241,886],[223,886]],"score":0.8393},{"poly":[[896,851],[961,851],[961,870],[896,870]],"score":0.9443},{"poly":[[672,851],[795,851],[795,870],[672,870]],"score":0.6999},{"poly":[[452,850],[609,851],[609,870],[452,868]],"score":0.8145},{"poly":[[263,850],[394,851],[394,870],[263,868]],"score":0.7039},{"poly":[[213,792],[732,792],[732,813],[213,813]],"score":0.8123},{"poly":[[213,769],[1011,769],[1011,792],[213,792]],"score":0.7104},{"poly":[[211,746],[1011,747],[1011,771],[211,769]],"score":0.7724},{"poly":[[213,726],[1011,726],[1011,747],[213,747]],"score":0.7685},{"poly":[[211,703],[1011,701],[1011,724],[211,726]],"score":0.6963},{"poly":[[208,676],[1013,680],[1013,708],[208,705]],"score":0.648},{"poly":[[213,660],[1011,660],[1011,681],[213,681]],"score":0.809},{"poly":[[213,639],[1009,639],[1009,660],[213,660]],"score":0.8083},{"poly":[[213,617],[1011,617],[1011,640],[213,640]],"score":0.6978},{"poly":[[213,591],[933,591],[933,612],[213,612]],"score":0.8042},{"poly":[[213,569],[1011,569],[1011,591],[213,591]],"score":0.8221},{"poly":[[213,548],[1011,548],[1011,569],[213,569]],"score":0.8248},{"poly":[[211,525],[1011,525],[1011,546],[211,546]],"score":0.8094},{"poly":[[213,503],[1011,503],[1011,525],[213,525]],"score":0.8059},{"poly":[[213,482],[1011,482],[1011,503],[213,503]],"score":0.8206},{"poly":[[213,459],[1011,459],[1011,480],[213,480]],"score":0.8568},{"poly":[[27,442],[71,442],[73,1137],[28,1137]],"score":0.779},{"poly":[[552,424],[670,424],[670,447],[552,447]],"score":0.7852},{"poly":[[562,345],[664,345],[664,368],[562,368]],"score":0.8128},{"poly":[[469,282],[753,282],[753,304],[469,304]],"score":0.8628},{"poly":[[311,198],[935,198],[935,226],[311,226]],"score":0.8627},{"poly":[[291,201],[321,201],[321,223],[291,223]],"score":0.8108}],"page_no":0,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7844,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1081,"y0":69,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":154,"x1":1019,"y0":1417,"y1":1508},"conf":0.4284,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":604,"x1":619,"y0":1483,"y1":1502},"font_size":0.0,"text":"2"},{"bbox":{"x0":170,"x1":504,"y0":1422,"y1":1444},"font_size":0.0,"text":"3https://lmarena.ai/leaderboard/text"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":136,"x1":316,"y0":139,"y1":172},"conf":0.8969,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":309,"y0":145,"y1":168},"font_size":8621000000.0,"text":"1Introduction"}],"source":"layout det","text":"1Introduction"},{"bbox":{"x0":135,"x1":1089,"y0":193,"y1":377},"conf":0.9748,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":198,"y1":221},"font_size":8621000000.0,"text":"The development of Large Language Models (LLMs) is undergoing a profound paradigm shift towards Agentic"},{"bbox":{"x0":141,"x1":1079,"y0":221,"y1":243},"font_size":8621000000.0,"text":"Intelligence – the capabilities for models to autonomously perceive, plan, reason, and act within complex and dynamic"},{"bbox":{"x0":141,"x1":1081,"y0":243,"y1":266},"font_size":8621000000.0,"text":"environments. This transition marks a departure from static imitation learning towards models that actively learn"},{"bbox":{"x0":141,"x1":1083,"y0":264,"y1":287},"font_size":8621000000.0,"text":"through interactions, acquire new skills beyond their training distribution, and adapt behavior through experiences [63]."},{"bbox":{"x0":141,"x1":1079,"y0":285,"y1":307},"font_size":8621000000.0,"text":"It is believed that this approach allows an AI agent to go beyond the limitation of static human-generated data, and"},{"bbox":{"x0":141,"x1":1079,"y0":309,"y1":330},"font_size":8621000000.0,"text":"acquire superhuman capabilities through its own exploration and exploitation. Agentic intelligence is thus rapidly"},{"bbox":{"x0":141,"x1":1081,"y0":330,"y1":351},"font_size":8621000000.0,"text":"emerging as a defning capability for the next generation of foundation models, with wide-ranging implications acrossi"},{"bbox":{"x0":138,"x1":607,"y0":350,"y1":375},"font_size":8621000000.0,"text":"tool use, software development, and real-world autonomy."}],"source":"layout det","text":"The development of Large Language Models (LLMs) is undergoing a profound paradigm shift towards Agentic Intelligence – the capabilities for models to autonomously perceive, plan, reason, and act within complex and dynamic environments. This transition marks a departure from static imitation learning towards models that actively learn through interactions, acquire new skills beyond their training distribution, and adapt behavior through experiences [63].It is believed that this approach allows an AI agent to go beyond the limitation of static human-generated data, and acquire superhuman capabilities through its own exploration and exploitation. Agentic intelligence is thus rapidly emerging as a defning capability for the next generation of foundation models, with wide-ranging implications acrossi tool use, software development, and real-world autonomy."},{"bbox":{"x0":137,"x1":1089,"y0":380,"y1":541},"conf":0.9731,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":384,"y1":406},"font_size":8621000000.0,"text":"Achieving agentic intelligence introduces challenges in both pre-training and post-training. Pre-training must en-"},{"bbox":{"x0":140,"x1":1081,"y0":404,"y1":429},"font_size":8621000000.0,"text":"dow models with broad general-purpose priors under constraints of limited high-quality data, elevating token eff-i"},{"bbox":{"x0":141,"x1":1081,"y0":427,"y1":450},"font_size":8621000000.0,"text":"ciency—learning signal per token—as a critical scaling coeffcient. Post-training must transform those priors intoi"},{"bbox":{"x0":140,"x1":1081,"y0":450,"y1":472},"font_size":8621000000.0,"text":"actionable behaviors, yet agentic capabilities such as multi-step reasoning, long-term planning, and tool use are rare"},{"bbox":{"x0":141,"x1":1081,"y0":472,"y1":493},"font_size":8621000000.0,"text":"in natural data and costly to scale. Scalable synthesis of structured, high-quality agentic trajectories, combined with"},{"bbox":{"x0":141,"x1":1079,"y0":493,"y1":516},"font_size":8621000000.0,"text":"general reinforcement learning (RL) techniques that incorporate preferences and self-critique, are essential to bridge"},{"bbox":{"x0":137,"x1":217,"y0":513,"y1":542},"font_size":8621000000.0,"text":"this gap."}],"source":"layout det","text":"Achieving agentic intelligence introduces challenges in both pre-training and post-training. Pre-training must endow models with broad general-purpose priors under constraints of limited high-quality data, elevating token eff-i ciency—learning signal per token—as a critical scaling coeffcient. Post-training must transform those priors intoi actionable behaviors, yet agentic capabilities such as multi-step reasoning, long-term planning, and tool use are rare in natural data and costly to scale. Scalable synthesis of structured, high-quality agentic trajectories, combined with general reinforcement learning (RL) techniques that incorporate preferences and self-critique, are essential to bridge this gap."},{"bbox":{"x0":135,"x1":1090,"y0":544,"y1":619},"conf":0.9494,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":548,"y1":569},"font_size":8621000000.0,"text":"In this work, we introduce Kimi K2, a 1.04 trillion-parameter Mixture-of-Experts (MoE) LLM with 32 billion activated"},{"bbox":{"x0":141,"x1":1081,"y0":569,"y1":592},"font_size":8621000000.0,"text":"parameters, purposefully designed to address the core challenges and push the boundaries of agentic capability. Our"},{"bbox":{"x0":141,"x1":680,"y0":592,"y1":614},"font_size":8621000000.0,"text":"contributions span both the pre-training and post-training frontiers:"}],"source":"layout det","text":"In this work, we introduce Kimi K2, a 1.04 trillion-parameter Mixture-of-Experts (MoE) LLM with 32 billion activated parameters, purposefully designed to address the core challenges and push the boundaries of agentic capability. Our contributions span both the pre-training and post-training frontiers:"},{"bbox":{"x0":170,"x1":1089,"y0":633,"y1":711},"conf":0.9614,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1081,"y0":637,"y1":662},"font_size":8621000000.0,"text":"We present MuonClip, a novel optimizer that integrates the token-effcient Muon algorithm with a stability-i"},{"bbox":{"x0":178,"x1":1081,"y0":662,"y1":683},"font_size":8621000000.0,"text":"enhancing mechanism called QK-Clip. Using MuonClip, we successfully pre-trained Kimi K2 on 15.5 trillion"},{"bbox":{"x0":178,"x1":452,"y0":683,"y1":705},"font_size":8621000000.0,"text":"tokens without a single loss spike."}],"source":"layout det","text":"We present MuonClip, a novel optimizer that integrates the token-effcient Muon algorithm with a stability-i enhancing mechanism called QK-Clip. Using MuonClip, we successfully pre-trained Kimi K2 on 15.5 trillion tokens without a single loss spike."},{"bbox":{"x0":171,"x1":1089,"y0":715,"y1":791},"conf":0.9516,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":1081,"y0":718,"y1":743},"font_size":8621000000.0,"text":"We introduce a large-scale agentic data synthesis pipeline that systematically generates tool-use demonstrations"},{"bbox":{"x0":178,"x1":1081,"y0":742,"y1":764},"font_size":8621000000.0,"text":"via simulated and real-world environments. This system constructs diverse tools, agents, tasks, and trajectories to"},{"bbox":{"x0":178,"x1":707,"y0":766,"y1":787},"font_size":8621000000.0,"text":"create high-fdelity, verifably correct agentic interactions at scale.ii"}],"source":"layout det","text":"We introduce a large-scale agentic data synthesis pipeline that systematically generates tool-use demonstrations via simulated and real-world environments. This system constructs diverse tools, agents, tasks, and trajectories to create high-fdelity, verifably correct agentic interactions at scale.ii"},{"bbox":{"x0":170,"x1":1089,"y0":796,"y1":873},"conf":0.9481,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":1081,"y0":799,"y1":823},"font_size":8621000000.0,"text":"We design a general reinforcement learning framework that combines verifable rewards (RLVR) with a self-i"},{"bbox":{"x0":175,"x1":1083,"y0":820,"y1":850},"font_size":8621000000.0,"text":"critique rubric reward mechanism. The model learns not only from externally defned tasks but also from evaluatingi"},{"bbox":{"x0":178,"x1":777,"y0":846,"y1":868},"font_size":8621000000.0,"text":"its own outputs, extending alignment from static into open-ended domains."}],"source":"layout det","text":"We design a general reinforcement learning framework that combines verifable rewards (RLVR) with a self-i critique rubric reward mechanism. The model learns not only from externally defned tasks but also from evaluatingi its own outputs, extending alignment from static into open-ended domains."},{"bbox":{"x0":137,"x1":1088,"y0":887,"y1":1050},"conf":0.9717,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1079,"y0":893,"y1":916},"font_size":8621000000.0,"text":"Kimi K2 demonstrates strong performance across a broad spectrum of agentic and frontier benchmarks. It achieves"},{"bbox":{"x0":141,"x1":1081,"y0":916,"y1":937},"font_size":8621000000.0,"text":"scores of 66.1 on Tau2-bench, 76.5 on ACEBench (en), 65.8 on SWE-bench Verifed, and 47.3 on SWE-benchi"},{"bbox":{"x0":141,"x1":1081,"y0":937,"y1":960},"font_size":8621000000.0,"text":"Multilingual, outperforming most open- and closed-weight baselines under non-thinking evaluation settings, closing the"},{"bbox":{"x0":136,"x1":1083,"y0":954,"y1":985},"font_size":8621000000.0,"text":"gap with Claude 4 Opus and Sonnet. In coding, mathematics, and broader STEM domains, Kimi K2 achieves 53.7"},{"bbox":{"x0":140,"x1":1081,"y0":980,"y1":1005},"font_size":8621000000.0,"text":"on LiveCodeBench v6, 27.1 on OJBench, 49.5 on AIME 2025, and 75.1 on GPQA-Diamond, further highlighting"},{"bbox":{"x0":140,"x1":1081,"y0":1003,"y1":1025},"font_size":8621000000.0,"text":"its capabilities in general tasks. On the LMSYS Arena leaderboard (July 17, 2025)3, Kimi K2 ranks as the top 1"},{"bbox":{"x0":140,"x1":675,"y0":1023,"y1":1048},"font_size":8621000000.0,"text":"open-source model and 5th overall based on over 3,000 user votes."}],"source":"layout det","text":"Kimi K2 demonstrates strong performance across a broad spectrum of agentic and frontier benchmarks. It achieves scores of 66.1 on Tau2-bench, 76.5 on ACEBench (en), 65.8 on SWE-bench Verifed, and 47.3 on SWE-benchi Multilingual, outperforming most open- and closed-weight baselines under non-thinking evaluation settings, closing the gap with Claude 4 Opus and Sonnet. In coding, mathematics, and broader STEM domains, Kimi K2 achieves 53.7 on LiveCodeBench v6, 27.1 on OJBench, 49.5 on AIME 2025, and 75.1 on GPQA-Diamond, further highlighting its capabilities in general tasks. On the LMSYS Arena leaderboard (July 17, 2025)3, Kimi K2 ranks as the top 1 open-source model and 5th overall based on over 3,000 user votes."},{"bbox":{"x0":135,"x1":1088,"y0":1053,"y1":1106},"conf":0.9323,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1056,"y1":1081},"font_size":8621000000.0,"text":"To spur further progress in Agentic Intelligence, we are open-sourcing our base and post-trained checkpoints, enabling"},{"bbox":{"x0":140,"x1":732,"y0":1077,"y1":1102},"font_size":8621000000.0,"text":"the community to explore, refne, and deploy agentic intelligence at scale.i"}],"source":"layout det","text":"To spur further progress in Agentic Intelligence, we are open-sourcing our base and post-trained checkpoints, enabling the community to explore, refne, and deploy agentic intelligence at scale.i"},{"bbox":{"x0":137,"x1":312,"y0":1137,"y1":1172},"conf":0.893,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":136,"x1":310,"y0":1135,"y1":1170},"font_size":8621000000.0,"text":"2Pre-training"}],"source":"layout det","text":"2Pre-training"},{"bbox":{"x0":136,"x1":1090,"y0":1190,"y1":1398},"conf":0.9788,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1193,"y1":1218},"font_size":8621000000.0,"text":"The base model of Kimi K2 is a trillion-parameter mixture-of-experts (MoE) transformer [72] model, pre-trained"},{"bbox":{"x0":140,"x1":1081,"y0":1218,"y1":1239},"font_size":8621000000.0,"text":"on 15.5 trillion high-quality tokens. Given the increasingly limited availability of high-quality human data, we posit"},{"bbox":{"x0":140,"x1":1083,"y0":1239,"y1":1262},"font_size":8621000000.0,"text":"that token effciency is emerging as a critical coeffcient in the scaling of large language models. To address this,ii"},{"bbox":{"x0":140,"x1":1081,"y0":1262,"y1":1284},"font_size":8621000000.0,"text":"we introduce a suite of pre-training techniques explicitly designed for maximizing token effciency. Specifcally, weii"},{"bbox":{"x0":141,"x1":1081,"y0":1282,"y1":1305},"font_size":8621000000.0,"text":"employ the token-effcient Muon optimizer [33, 46] and mitigate its training instabilities through the introduction ofi"},{"bbox":{"x0":141,"x1":1081,"y0":1305,"y1":1328},"font_size":8621000000.0,"text":"QK-Clip. Additionally, we incorporate synthetic data generation to further squeeze the intelligence out of available"},{"bbox":{"x0":141,"x1":1081,"y0":1327,"y1":1348},"font_size":8621000000.0,"text":"high-quality tokens. The model architecture follows an ultra-sparse MoE with multi-head latent attention (MLA) similar"},{"bbox":{"x0":138,"x1":1081,"y0":1346,"y1":1371},"font_size":8621000000.0,"text":"to DeepSeek-V3 [10] , derived from empirical scaling law analysis. The underlying infrastructure is built to optimize"},{"bbox":{"x0":140,"x1":521,"y0":1368,"y1":1394},"font_size":8621000000.0,"text":"both training effciency and research effciency.ii"}],"source":"layout det","text":"The base model of Kimi K2 is a trillion-parameter mixture-of-experts (MoE) transformer [72] model, pre-trained on 15.5 trillion high-quality tokens. Given the increasingly limited availability of high-quality human data, we posit that token effciency is emerging as a critical coeffcient in the scaling of large language models. To address this,ii we introduce a suite of pre-training techniques explicitly designed for maximizing token effciency. Specifcally, weii employ the token-effcient Muon optimizer [33, 46] and mitigate its training instabilities through the introduction ofi QK-Clip. Additionally, we incorporate synthetic data generation to further squeeze the intelligence out of available high-quality tokens. The model architecture follows an ultra-sparse MoE with multi-head latent attention (MLA) similar to DeepSeek-V3 [10] , derived from empirical scaling law analysis. The underlying infrastructure is built to optimize both training effciency and research effciency.ii"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1090,"y0":1190,"y1":1398},"conf":0.9788,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":193,"y1":377},"conf":0.9748,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":380,"y1":541},"conf":0.9731,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":887,"y1":1050},"conf":0.9717,"label":"Text","label_id":1},{"bbox":{"x0":170,"x1":1089,"y0":633,"y1":711},"conf":0.9614,"label":"Text","label_id":1},{"bbox":{"x0":171,"x1":1089,"y0":715,"y1":791},"conf":0.9516,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1090,"y0":544,"y1":619},"conf":0.9494,"label":"Text","label_id":1},{"bbox":{"x0":170,"x1":1089,"y0":796,"y1":873},"conf":0.9481,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1088,"y0":1053,"y1":1106},"conf":0.9323,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":316,"y0":139,"y1":172},"conf":0.8969,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":312,"y0":1137,"y1":1172},"conf":0.893,"label":"Title","label_id":0},{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7844,"label":"Abandon","label_id":2},{"bbox":{"x0":162,"x1":511,"y0":1419,"y1":1450},"conf":0.4744,"label":"Abandon","label_id":2},{"bbox":{"x0":154,"x1":1019,"y0":1417,"y1":1508},"conf":0.4284,"label":"Abandon","label_id":2},{"bbox":{"x0":599,"x1":623,"y0":1478,"y1":1507},"conf":0.2395,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[604,1483],[619,1483],[619,1502],[604,1502]],"score":0.8147},{"poly":[[170,1422],[504,1422],[504,1444],[170,1444]],"score":0.8341},{"poly":[[140,1368],[521,1371],[520,1394],[140,1391]],"score":0.754},{"poly":[[138,1346],[1081,1348],[1081,1371],[138,1369]],"score":0.725},{"poly":[[141,1327],[1081,1327],[1081,1348],[141,1348]],"score":0.7787},{"poly":[[141,1305],[1081,1305],[1081,1328],[141,1328]],"score":0.7049},{"poly":[[141,1282],[1081,1282],[1081,1305],[141,1305]],"score":0.7063},{"poly":[[140,1262],[1081,1262],[1081,1284],[140,1284]],"score":0.8315},{"poly":[[140,1239],[1083,1239],[1083,1262],[140,1262]],"score":0.6918},{"poly":[[140,1218],[1081,1218],[1081,1239],[140,1239]],"score":0.8173},{"poly":[[140,1193],[1081,1195],[1081,1218],[140,1216]],"score":0.7522},{"poly":[[137,1135],[310,1142],[309,1170],[136,1163]],"score":0.7325},{"poly":[[140,1077],[732,1079],[732,1102],[140,1101]],"score":0.7754},{"poly":[[140,1056],[1081,1058],[1081,1081],[140,1079]],"score":0.7473},{"poly":[[140,1025],[675,1023],[675,1046],[140,1048]],"score":0.7754},{"poly":[[140,1003],[1081,1003],[1081,1025],[140,1025]],"score":0.8246},{"poly":[[140,980],[1081,982],[1081,1005],[140,1003]],"score":0.7692},{"poly":[[136,957],[1083,954],[1083,982],[136,985]],"score":0.6438},{"poly":[[141,937],[1081,937],[1081,960],[141,960]],"score":0.7025},{"poly":[[141,916],[1081,916],[1081,937],[141,937]],"score":0.8307},{"poly":[[143,893],[1079,893],[1079,916],[143,916]],"score":0.7204},{"poly":[[178,846],[777,846],[777,868],[178,868]],"score":0.7977},{"poly":[[175,820],[1083,822],[1083,850],[175,848]],"score":0.6816},{"poly":[[161,802],[1081,799],[1081,820],[161,823]],"score":0.7786},{"poly":[[178,766],[707,766],[707,787],[178,787]],"score":0.8191},{"poly":[[178,742],[1081,742],[1081,764],[178,764]],"score":0.8063},{"poly":[[161,718],[1081,719],[1081,743],[161,741]],"score":0.7645},{"poly":[[178,683],[452,683],[452,705],[178,705]],"score":0.811},{"poly":[[178,662],[1081,662],[1081,683],[178,683]],"score":0.8188},{"poly":[[160,637],[1081,639],[1081,662],[160,660]],"score":0.7591},{"poly":[[141,592],[680,592],[680,614],[141,614]],"score":0.8365},{"poly":[[141,569],[1081,569],[1081,592],[141,592]],"score":0.6958},{"poly":[[140,548],[1081,548],[1081,569],[140,569]],"score":0.8315},{"poly":[[139,513],[217,519],[215,542],[137,536]],"score":0.7441},{"poly":[[141,493],[1079,493],[1079,516],[141,516]],"score":0.7175},{"poly":[[141,472],[1081,472],[1081,493],[141,493]],"score":0.7943},{"poly":[[140,450],[1081,450],[1081,472],[140,472]],"score":0.7777},{"poly":[[141,427],[1081,427],[1081,450],[141,450]],"score":0.6853},{"poly":[[140,406],[1081,404],[1081,427],[140,429]],"score":0.7616},{"poly":[[140,384],[1083,384],[1083,406],[140,406]],"score":0.8146},{"poly":[[138,350],[607,351],[607,375],[138,373]],"score":0.7258},{"poly":[[141,330],[1081,330],[1081,351],[141,351]],"score":0.8092},{"poly":[[141,309],[1079,309],[1079,330],[141,330]],"score":0.8424},{"poly":[[141,285],[1079,285],[1079,307],[141,307]],"score":0.8109},{"poly":[[141,264],[1083,264],[1083,287],[141,287]],"score":0.7024},{"poly":[[141,243],[1081,243],[1081,266],[141,266]],"score":0.7051},{"poly":[[141,221],[1079,221],[1079,243],[141,243]],"score":0.8399},{"poly":[[141,198],[1079,198],[1079,221],[141,221]],"score":0.7734},{"poly":[[140,145],[309,145],[309,168],[140,168]],"score":0.816},{"poly":[[920,69],[1081,71],[1081,92],[920,91]],"score":0.7738},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.841}],"page_no":1,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":559,"x1":1086,"y0":67,"y1":92},"conf":0.8488,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1081,"y0":71,"y1":91},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":660,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":600,"x1":623,"y0":1480,"y1":1505},"conf":0.5023,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":604,"x1":619,"y0":1483,"y1":1502},"font_size":0.0,"text":"3"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":615,"y0":144,"y1":172},"conf":0.9115,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":609,"y0":145,"y1":170},"font_size":9.0,"text":"2.1MuonClip: Stable Training with Weight Clipping"}],"source":"layout det","text":"2.1MuonClip: Stable Training with Weight Clipping"},{"bbox":{"x0":138,"x1":1089,"y0":184,"y1":278},"conf":0.9549,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":188,"y1":210},"font_size":9.0,"text":"We train Kimi K2 using the token-effcient Muon optimizer [33], incorporating weight decay and consistent updatei"},{"bbox":{"x0":141,"x1":1081,"y0":210,"y1":231},"font_size":9.0,"text":"RMS scaling [46]. Experiments in our previous work Moonlight [46] show that, under the same compute budget and"},{"bbox":{"x0":141,"x1":1083,"y0":231,"y1":252},"font_size":9.0,"text":"model size $.$ and therefore the same amount of training data — Muon substantially outperforms AdamW [36, 48],"},{"bbox":{"x0":140,"x1":888,"y0":251,"y1":276},"font_size":9.0,"text":"making it an effective choice for improving token effciency in large language model training.i"}],"source":"layout det","text":"We train Kimi K2 using the token-effcient Muon optimizer [33], incorporating weight decay and consistent updatei RMS scaling [46]. Experiments in our previous work Moonlight [46] show that, under the same compute budget and model size $.$ and therefore the same amount of training data — Muon substantially outperforms AdamW [36, 48],making it an effective choice for improving token effciency in large language model training.i"},{"bbox":{"x0":138,"x1":1088,"y0":294,"y1":432},"conf":0.9673,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":297,"y1":322},"font_size":-0.008663,"text":"Training instability when scaling MuonDespite its effciency, scaling up Muon training reveals a challenge: trainingi"},{"bbox":{"x0":141,"x1":1079,"y0":320,"y1":343},"font_size":-0.008663,"text":"instability due to exploding attention logits, an issue that occurs more frequently with Muon but less with AdamW"},{"bbox":{"x0":141,"x1":1081,"y0":343,"y1":365},"font_size":-0.008663,"text":"in our experiments. Existing mitigation strategies are insuffcient. For instance, logit soft-cap [69] directly clips thei"},{"bbox":{"x0":141,"x1":1081,"y0":365,"y1":388},"font_size":-0.008663,"text":"attention logits, but the dot products between queries and keys can still grow excessively before capping is applied. On"},{"bbox":{"x0":141,"x1":1083,"y0":386,"y1":409},"font_size":-0.008663,"text":"the other hand, Query-Key Normalization (QK-Norm) [11, 81] is not applicable to multi-head latent attention (MLA),"},{"bbox":{"x0":141,"x1":687,"y0":408,"y1":429},"font_size":-0.008663,"text":"because its Key matrices are not fully materialized during inference."}],"source":"layout det","text":"Training instability when scaling MuonDespite its effciency, scaling up Muon training reveals a challenge: trainingi instability due to exploding attention logits, an issue that occurs more frequently with Muon but less with AdamW in our experiments. Existing mitigation strategies are insuffcient. For instance, logit soft-cap [69] directly clips thei attention logits, but the dot products between queries and keys can still grow excessively before capping is applied. On the other hand, Query-Key Normalization (QK-Norm) [11, 81] is not applicable to multi-head latent attention (MLA),because its Key matrices are not fully materialized during inference."},{"bbox":{"x0":137,"x1":1087,"y0":449,"y1":522},"conf":0.9401,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":451,"y1":476},"font_size":9.0,"text":"Taming Muon with QK-ClipTo address this issue, we propose a novel weight-clipping mechanism $\\mathit{QK\\text{-}Clip}$  to"},{"bbox":{"x0":140,"x1":1081,"y0":474,"y1":498},"font_size":9.0,"text":"explicitly constrain attention logits. QK-Clip works by rescaling the query and key projection weights post-update to"},{"bbox":{"x0":140,"x1":436,"y0":495,"y1":520},"font_size":9.0,"text":"bound the growth of attention logits."}],"source":"layout det","text":"Taming Muon with QK-ClipTo address this issue, we propose a novel weight-clipping mechanism $\\mathit{QK\\text{-}Clip}$  to explicitly constrain attention logits. QK-Clip works by rescaling the query and key projection weights post-update to bound the growth of attention logits."},{"bbox":{"x0":137,"x1":1088,"y0":526,"y1":572},"conf":0.5724,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":530,"y1":551},"font_size":9.0,"text":"Let the input representation of a transformer layer be X. For each attention head h, its query, key, and value projections"},{"bbox":{"x0":140,"x1":274,"y0":553,"y1":574},"font_size":9.0,"text":"are computed as"}],"source":"layout det","text":"Let the input representation of a transformer layer be X. For each attention head h, its query, key, and value projections are computed as"},{"bbox":{"x0":421,"x1":801,"y0":572,"y1":601},"conf":0.9003,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$\\textbf{Q}^{h}=\\textbf{X}\\textbf{W}_{q}^{h},\\quad\\textbf{K}^{h}=\\textbf{X} \\textbf{W}_{k}^{h},\\quad\\textbf{V}^{h}=\\textbf{X}\\textbf{W}_{v}^{h}.$$"},{"bbox":{"x0":138,"x1":691,"y0":604,"y1":630},"conf":0.8787,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":687,"y0":599,"y1":628},"font_size":9.0,"text":"where $\\mathbf{W}_{q},\\mathbf{W}_{k},\\mathbf{W}_{v}$ are model parameters. The attention output is:"}],"source":"layout det","text":"where $\\mathbf{W}_{q},\\mathbf{W}_{k},\\mathbf{W}_{v}$ are model parameters. The attention output is:"},{"bbox":{"x0":465,"x1":756,"y0":655,"y1":706},"conf":0.9566,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$\\mathbf{O}^{h}=\\text{softmax}\\left(\\frac{1}{\\sqrt{d}}\\mathbf{Q}^{h}\\mathbf{K}^{h\\top}\\right)\\mathbf{V}^{h}.$$"},{"bbox":{"x0":137,"x1":871,"y0":718,"y1":747},"conf":0.8619,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":883,"y0":721,"y1":744},"font_size":9.0,"text":"We defne the max logit, a per-head scalar, as the maximum input to softmax in this batch Bi"}],"source":"layout det","text":"We defne the max logit, a per-head scalar, as the maximum input to softmax in this batch Bi"},{"bbox":{"x0":484,"x1":737,"y0":755,"y1":802},"conf":0.947,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$S_{\\max}^{h}=\\frac{1}{\\sqrt{d}}\\max_{\\mathbf{X}\\in B}\\max_{i,j}\\mathbf{Q}_{i}^{h}\\mathbf{K}_{j}^{h\\top}$$"},{"bbox":{"x0":137,"x1":659,"y0":810,"y1":837},"conf":0.6386,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":654,"y0":812,"y1":835},"font_size":9.0,"text":"where $i,j$ are indices of different tokens in a training sample X."}],"source":"layout det","text":"where $i,j$ are indices of different tokens in a training sample X."},{"bbox":{"x0":137,"x1":1087,"y0":841,"y1":913},"conf":0.9475,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1080,"y0":841,"y1":868},"font_size":9.0,"text":"The core idea of QK-Clip is to rescale $\\mathbf{W}_{k},\\mathbf{W}_{q}$ whenever $S^{h}_{\\max}$ exceeds a target threshold τ. Importantly, this operation"},{"bbox":{"x0":141,"x1":1079,"y0":866,"y1":889},"font_size":9.0,"text":"does not alter the forward/backward computation in the current step — we merely use the max logit as a guiding signal"},{"bbox":{"x0":140,"x1":579,"y0":889,"y1":911},"font_size":9.0,"text":"to determine the strength to control the weight growth."}],"source":"layout det","text":"The core idea of QK-Clip is to rescale $\\mathbf{W}_{k},\\mathbf{W}_{q}$ whenever $S^{h}_{\\max}$ exceeds a target threshold τ. Importantly, this operation does not alter the forward/backward computation in the current step — we merely use the max logit as a guiding signal to determine the strength to control the weight growth."},{"bbox":{"x0":138,"x1":599,"y0":919,"y1":946},"conf":0.9025,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":595,"y0":919,"y1":944},"font_size":9.0,"text":"A naïve implementation clips all heads at the same time:"}],"source":"layout det","text":"A naïve implementation clips all heads at the same time:"},{"bbox":{"x0":458,"x1":763,"y0":954,"y1":983},"conf":0.9125,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$\\mathbf{W}_{q}^{h}\\leftrightarrow\\gamma^{\\alpha}\\mathbf{W}_{q}^{h}\\qquad\\mathbf{W}_{k}^{h}\\leftrightarrow\\gamma^{1-\\alpha}\\mathbf{W}_{k}^{h}$$"},{"bbox":{"x0":137,"x1":1087,"y0":991,"y1":1044},"conf":0.9263,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":994,"y1":1023},"font_size":9.0,"text":"where $\\gamma=\\min(1,\\tau/S_{\\max})$  with $S_{\\max}=\\text{max}_{h} S_{\\max}^{h},$  and $\\alpha$  is a balancing parameter typically set to 0.5, applying"},{"bbox":{"x0":141,"x1":414,"y0":1020,"y1":1041},"font_size":9.0,"text":"equal scaling to queries and keys."}],"source":"layout det","text":"where $\\gamma=\\min(1,\\tau/S_{\\max})$  with $S_{\\max}=\\text{max}_{h} S_{\\max}^{h},$  and $\\alpha$  is a balancing parameter typically set to 0.5, applying equal scaling to queries and keys."},{"bbox":{"x0":137,"x1":1087,"y0":1048,"y1":1142},"conf":0.9549,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1049,"y1":1074},"font_size":-0.008663,"text":"However, we observe that in practice, only a small subset of heads exhibit exploding logits. In order to minimize our"},{"bbox":{"x0":144,"x1":1079,"y0":1071,"y1":1095},"font_size":9.0,"text":"intervention on model training, we determine a per-head scaling factor $\\gamma_{h}=\\min(1,\\tau{/S_{\\max}^{h}}),$  and opt to apply per-head"},{"bbox":{"x0":141,"x1":1081,"y0":1094,"y1":1117},"font_size":-0.008663,"text":"QK-Clip. Such clipping is straightforward for regular multi-head attention (MHA). For MLA, we apply clipping only"},{"bbox":{"x0":141,"x1":467,"y0":1117,"y1":1138},"font_size":-0.008663,"text":"on unshared attention head components:"}],"source":"layout det","text":"However, we observe that in practice, only a small subset of heads exhibit exploding logits. In order to minimize our intervention on model training, we determine a per-head scaling factor $\\gamma_{h}=\\min(1,\\tau{/S_{\\max}^{h}}),$  and opt to apply per-head QK-Clip. Such clipping is straightforward for regular multi-head attention (MHA). For MLA, we apply clipping only on unshared attention head components:"},{"bbox":{"x0":173,"x1":669,"y0":1156,"y1":1187},"conf":0.8968,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":662,"y0":1158,"y1":1186},"font_size":9.0,"text":"• $\\mathbf{q}^{\\boldsymbol{C}}$ and $\\mathbf{k}^{\\boldsymbol{C}}$ (head-specifc components): each scaled byi $\\sqrt{\\gamma_{h}}$"}],"source":"layout det","text":"• $\\mathbf{q}^{\\boldsymbol{C}}$ and $\\mathbf{k}^{\\boldsymbol{C}}$ (head-specifc components): each scaled byi $\\sqrt{\\gamma_{h}}$"},{"bbox":{"x0":174,"x1":502,"y0":1191,"y1":1219},"conf":0.9098,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":499,"y0":1191,"y1":1218},"font_size":9.0,"text":"• $\\mathbf{q}^{R}$ (head-specifc rotary): scaled by γh,i"}],"source":"layout det","text":"• $\\mathbf{q}^{R}$ (head-specifc rotary): scaled by γh,i"},{"bbox":{"x0":173,"x1":685,"y0":1223,"y1":1250},"conf":0.8677,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":158,"x1":682,"y0":1223,"y1":1247},"font_size":9.0,"text":"· $\\mathbf{k}^{\\boldsymbol{R}}$ (shared rotary): left untouched to avoid effect across heads."}],"source":"layout det","text":"· $\\mathbf{k}^{\\boldsymbol{R}}$ (shared rotary): left untouched to avoid effect across heads."},{"bbox":{"x0":137,"x1":1087,"y0":1278,"y1":1328},"conf":0.9046,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":1279,"y1":1304},"font_size":9.0,"text":"MuonClip: The New OptimizerWe integrate Muon with weight decay, consistent RMS matching, and QK-Clip"},{"bbox":{"x0":141,"x1":738,"y0":1304,"y1":1325},"font_size":9.0,"text":"into a single optimizer, which we refer to as MuonClip (see Algorithm 1)."}],"source":"layout det","text":"MuonClip: The New OptimizerWe integrate Muon with weight decay, consistent RMS matching, and QK-Clip into a single optimizer, which we refer to as MuonClip (see Algorithm 1)."},{"bbox":{"x0":136,"x1":1088,"y0":1333,"y1":1449},"conf":0.9553,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":1336,"y1":1358},"font_size":-0.008663,"text":"We demonstrate the effectiveness of MuonClip from several scaling experiments. First, we train a mid-scale 9B activated"},{"bbox":{"x0":140,"x1":1081,"y0":1358,"y1":1381},"font_size":-0.008663,"text":"and 53B total parameters Mixture-of-Experts (MoE) model using the vanilla Muon. As shown in Figure 2 (Left), we"},{"bbox":{"x0":141,"x1":1081,"y0":1379,"y1":1401},"font_size":-0.008663,"text":"observe that the maximum attention logits quickly exceed a magnitude of 1000, showing that attention logits explosion"},{"bbox":{"x0":136,"x1":1084,"y0":1396,"y1":1427},"font_size":-0.008663,"text":"is already evident in Muon training to this scale. Max logits at this level usually result in instability during training,"},{"bbox":{"x0":141,"x1":615,"y0":1424,"y1":1445},"font_size":-0.008663,"text":"including signifcant loss spikes and occasional divergence.i"}],"source":"layout det","text":"We demonstrate the effectiveness of MuonClip from several scaling experiments. First, we train a mid-scale 9B activated and 53B total parameters Mixture-of-Experts (MoE) model using the vanilla Muon. As shown in Figure 2 (Left), we observe that the maximum attention logits quickly exceed a magnitude of 1000, showing that attention logits explosion is already evident in Muon training to this scale. Max logits at this level usually result in instability during training,including signifcant loss spikes and occasional divergence.i"}],"formula_dets":[{"bbox":{"x0":465,"x1":756,"y0":655,"y1":706},"conf":0.9566,"label":"print_isolated","label_id":1},{"bbox":{"x0":484,"x1":737,"y0":755,"y1":802},"conf":0.947,"label":"print_isolated","label_id":1},{"bbox":{"x0":458,"x1":763,"y0":954,"y1":983},"conf":0.9125,"label":"print_isolated","label_id":1},{"bbox":{"x0":421,"x1":801,"y0":572,"y1":601},"conf":0.9003,"label":"print_isolated","label_id":1},{"bbox":{"x0":598,"x1":642,"y0":844,"y1":868},"conf":0.8948,"label":"print_embedding","label_id":0},{"bbox":{"x0":414,"x1":584,"y0":994,"y1":1020},"conf":0.8895,"label":"print_embedding","label_id":0},{"bbox":{"x0":197,"x1":367,"y0":994,"y1":1019},"conf":0.8859,"label":"print_embedding","label_id":0},{"bbox":{"x0":693,"x1":876,"y0":1071,"y1":1095},"conf":0.8857,"label":"print_embedding","label_id":0},{"bbox":{"x0":195,"x1":314,"y0":599,"y1":628},"conf":0.8584,"label":"print_embedding","label_id":0},{"bbox":{"x0":624,"x1":662,"y0":1163,"y1":1186},"conf":0.8475,"label":"print_embedding","label_id":0},{"bbox":{"x0":240,"x1":266,"y0":1159,"y1":1180},"conf":0.8262,"label":"print_embedding","label_id":0},{"bbox":{"x0":987,"x1":1058,"y0":451,"y1":476},"conf":0.8122,"label":"print_embedding","label_id":0},{"bbox":{"x0":440,"x1":516,"y0":841,"y1":868},"conf":0.7949,"label":"print_embedding","label_id":0},{"bbox":{"x0":195,"x1":222,"y0":812,"y1":835},"conf":0.7913,"label":"print_embedding","label_id":0},{"bbox":{"x0":177,"x1":203,"y0":1224,"y1":1245},"conf":0.7571,"label":"print_embedding","label_id":0},{"bbox":{"x0":177,"x1":203,"y0":1194,"y1":1216},"conf":0.7255,"label":"print_embedding","label_id":0},{"bbox":{"x0":178,"x1":203,"y0":1161,"y1":1183},"conf":0.7008,"label":"print_embedding","label_id":0},{"bbox":{"x0":623,"x1":636,"y0":1004,"y1":1015},"conf":0.5944,"label":"print_embedding","label_id":0},{"bbox":{"x0":234,"x1":257,"y0":236,"y1":249},"conf":0.5109,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":138,"x1":1088,"y0":294,"y1":432},"conf":0.9673,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":1333,"y1":1449},"conf":0.9553,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":1048,"y1":1142},"conf":0.9549,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1089,"y0":184,"y1":278},"conf":0.9549,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":841,"y1":913},"conf":0.9475,"label":"Text","label_id":1},{"bbox":{"x0":418,"x1":807,"y0":569,"y1":602},"conf":0.9463,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":1087,"y0":449,"y1":522},"conf":0.9401,"label":"Text","label_id":1},{"bbox":{"x0":461,"x1":762,"y0":651,"y1":708},"conf":0.9389,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":1087,"y0":991,"y1":1044},"conf":0.9263,"label":"Text","label_id":1},{"bbox":{"x0":454,"x1":768,"y0":951,"y1":986},"conf":0.9171,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":615,"y0":144,"y1":172},"conf":0.9115,"label":"Title","label_id":0},{"bbox":{"x0":174,"x1":502,"y0":1191,"y1":1219},"conf":0.9098,"label":"Text","label_id":1},{"bbox":{"x0":481,"x1":742,"y0":751,"y1":804},"conf":0.9095,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":1087,"y0":1278,"y1":1328},"conf":0.9046,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":599,"y0":919,"y1":946},"conf":0.9025,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":669,"y0":1156,"y1":1187},"conf":0.8968,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":691,"y0":604,"y1":630},"conf":0.8787,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":685,"y0":1223,"y1":1250},"conf":0.8677,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":871,"y0":718,"y1":747},"conf":0.8619,"label":"Text","label_id":1},{"bbox":{"x0":559,"x1":1086,"y0":67,"y1":92},"conf":0.8488,"label":"Abandon","label_id":2},{"bbox":{"x0":137,"x1":659,"y0":810,"y1":837},"conf":0.6386,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":526,"y1":572},"conf":0.5724,"label":"Text","label_id":1},{"bbox":{"x0":329,"x1":1069,"y0":527,"y1":568},"conf":0.5444,"label":"Text","label_id":1},{"bbox":{"x0":600,"x1":623,"y0":1480,"y1":1505},"conf":0.5023,"label":"Abandon","label_id":2},{"bbox":{"x0":602,"x1":621,"y0":1482,"y1":1504},"conf":0.363,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[604,1483],[619,1483],[619,1502],[604,1502]],"score":0.9121},{"poly":[[141,1424],[615,1424],[615,1445],[141,1445]],"score":0.8692},{"poly":[[136,1396],[1084,1399],[1084,1427],[136,1424]],"score":0.6317},{"poly":[[141,1379],[1081,1379],[1081,1401],[141,1401]],"score":0.7672},{"poly":[[140,1358],[1081,1358],[1081,1381],[140,1381]],"score":0.7131},{"poly":[[141,1336],[1079,1336],[1079,1358],[141,1358]],"score":0.8238},{"poly":[[141,1304],[738,1304],[738,1325],[141,1325]],"score":0.8641},{"poly":[[141,1279],[1079,1280],[1079,1304],[141,1302]],"score":0.7607},{"poly":[[158,1223],[682,1224],[682,1247],[158,1246]],"score":0.7581},{"poly":[[160,1191],[499,1193],[499,1218],[160,1216]],"score":0.7231},{"poly":[[160,1158],[662,1162],[662,1185],[160,1181]],"score":0.8058},{"poly":[[141,1117],[467,1117],[467,1138],[141,1138]],"score":0.8562},{"poly":[[141,1094],[1081,1094],[1081,1117],[141,1117]],"score":0.743},{"poly":[[140,1049],[1081,1051],[1081,1074],[140,1072]],"score":0.7461},{"poly":[[141,1020],[414,1020],[414,1041],[141,1041]],"score":0.8692},{"poly":[[140,995],[1081,995],[1081,1023],[140,1023]],"score":0.6855},{"poly":[[457,954],[590,954],[590,982],[457,982]],"score":0.7874},{"poly":[[594,952],[765,950],[765,980],[594,982]],"score":0.6604},{"poly":[[140,919],[595,921],[595,944],[140,942]],"score":0.7701},{"poly":[[140,889],[579,889],[579,911],[140,911]],"score":0.8441},{"poly":[[141,866],[1079,866],[1079,889],[141,889]],"score":0.6886},{"poly":[[141,812],[654,812],[654,835],[141,835]],"score":0.7494},{"poly":[[554,776],[662,776],[662,804],[554,804]],"score":0.6336},{"poly":[[562,756],[582,756],[582,769],[562,769]],"score":0.6927},{"poly":[[141,721],[883,721],[883,744],[141,744]],"score":0.7565},{"poly":[[599,681],[639,681],[639,701],[599,701]],"score":0.622},{"poly":[[460,661],[592,665],[592,693],[459,689]],"score":0.7661},{"poly":[[720,660],[753,660],[753,690],[720,690]],"score":0.8077},{"poly":[[626,661],[718,654],[721,691],[629,697]],"score":0.7059},{"poly":[[614,657],[627,657],[627,672],[614,672]],"score":0.6374},{"poly":[[141,604],[687,604],[687,627],[141,627]],"score":0.7593},{"poly":[[417,569],[802,569],[802,597],[417,597]],"score":0.7286},{"poly":[[140,553],[274,553],[274,574],[140,574]],"score":0.8806},{"poly":[[140,530],[1079,530],[1079,551],[140,551]],"score":0.817},{"poly":[[140,495],[436,497],[436,520],[140,518]],"score":0.7742},{"poly":[[140,474],[1081,475],[1081,498],[140,497]],"score":0.7487},{"poly":[[143,454],[1081,454],[1081,475],[143,475]],"score":0.8219},{"poly":[[141,408],[687,408],[687,429],[141,429]],"score":0.8385},{"poly":[[141,386],[1083,386],[1083,409],[141,409]],"score":0.6865},{"poly":[[141,365],[1081,365],[1081,388],[141,388]],"score":0.6836},{"poly":[[141,343],[1081,343],[1081,365],[141,365]],"score":0.8027},{"poly":[[141,320],[1079,320],[1079,343],[141,343]],"score":0.6908},{"poly":[[140,297],[1081,299],[1081,322],[140,320]],"score":0.7655},{"poly":[[140,251],[888,252],[888,276],[140,274]],"score":0.7265},{"poly":[[141,231],[1083,231],[1083,252],[141,252]],"score":0.8096},{"poly":[[141,210],[1081,210],[1081,231],[141,231]],"score":0.8271},{"poly":[[140,188],[1079,188],[1079,210],[140,210]],"score":0.8241},{"poly":[[140,145],[609,147],[609,170],[140,168]],"score":0.8056},{"poly":[[920,71],[1081,73],[1081,91],[920,89]],"score":0.7948},{"poly":[[562,68],[660,68],[660,91],[562,91]],"score":0.8556}],"page_no":2,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":598,"x1":624,"y0":1479,"y1":1507},"conf":0.5017,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":602,"x1":619,"y0":1483,"y1":1500},"font_size":0.0,"text":"4"}],"source":"layout det","text":""},{"bbox":{"x0":139,"x1":1088,"y0":62,"y1":102},"conf":0.24,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":66,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":138,"x1":426,"y0":143,"y1":172},"conf":0.7041,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":421,"y0":145,"y1":167},"font_size":0.0,"text":"Algorithm 1 MuonClip Optimizer"}],"source":"layout det","text":"Algorithm 1 MuonClip Optimizer"},{"bbox":{"x0":145,"x1":393,"y0":175,"y1":200},"conf":0.74,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":148,"x1":389,"y0":173,"y1":198},"font_size":0.0,"text":"1: for each training step $t$  do"}],"source":"layout det","text":"1: for each training step $t$  do"},{"bbox":{"x0":146,"x1":417,"y0":200,"y1":221},"conf":0.7859,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":414,"y0":198,"y1":221},"font_size":0.0,"text":"2:// 1. Muon optimizer step"}],"source":"layout det","text":"2:// 1. Muon optimizer step"},{"bbox":{"x0":146,"x1":468,"y0":221,"y1":242},"conf":0.8043,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":148,"x1":464,"y0":216,"y1":242},"font_size":0.0,"text":"3:for each weight $\\mathbf{W}\\in\\mathbb{R}^{\\tiny n \\times\\tiny m}$  do"}],"source":"layout det","text":"3:for each weight $\\mathbf{W}\\in\\mathbb{R}^{\\tiny n \\times\\tiny m}$  do"},{"bbox":{"x0":147,"x1":408,"y0":243,"y1":266},"conf":0.32,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":148,"x1":403,"y0":241,"y1":265},"font_size":0.0,"text":"4: $\\mathbf{M}_{t}=\\mu\\mathbf{M}_{t-1}+\\mathbf{G}_{t}$"}],"source":"layout det","text":"4: $\\mathbf{M}_{t}=\\mu\\mathbf{M}_{t-1}+\\mathbf{G}_{t}$"},{"bbox":{"x0":210,"x1":635,"y0":266,"y1":292},"conf":0.4157,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":237,"x1":628,"y0":265,"y1":291},"font_size":0.0,"text":"$\\mathbf{O}_{t}=$ Newton-Schulz $(\\mathbf{M}_{t})\\cdot\\sqrt{\\max(n,m)}\\cdot0.2$"}],"source":"layout det","text":"$\\mathbf{O}_{t}=$ Newton-Schulz $(\\mathbf{M}_{t})\\cdot\\sqrt{\\max(n,m)}\\cdot0.2$"},{"bbox":{"x0":146,"x1":515,"y0":292,"y1":316},"conf":0.3626,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":148,"x1":510,"y0":292,"y1":317},"font_size":0.0,"text":"6: $\\mathbf{W}_{t}=\\mathbf{W}_{t-1}-\\eta\\big(\\mathbf{O}_{t}+\\lambda\\mathbf{W}_{t-1}\\big)$"}],"source":"layout det","text":"6: $\\mathbf{W}_{t}=\\mathbf{W}_{t-1}-\\eta\\big(\\mathbf{O}_{t}+\\lambda\\mathbf{W}_{t-1}\\big)$"},{"bbox":{"x0":146,"x1":275,"y0":315,"y1":335},"conf":0.5953,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":273,"y0":314,"y1":335},"font_size":0.0,"text":"7:end for"}],"source":"layout det","text":"7:end for"},{"bbox":{"x0":144,"x1":320,"y0":336,"y1":357},"conf":0.7265,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":148,"x1":318,"y0":333,"y1":356},"font_size":0.0,"text":"8: $//2$  QK-Clip"}],"source":"layout det","text":"8: $//2$  QK-Clip"},{"bbox":{"x0":142,"x1":736,"y0":357,"y1":380},"conf":0.5982,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":146,"x1":730,"y0":356,"y1":380},"font_size":0.0,"text":"9:for each attention head $h$  in every attention layer of the model do"}],"source":"layout det","text":"9:for each attention head $h$  in every attention layer of the model do"},{"bbox":{"x0":141,"x1":618,"y0":380,"y1":403},"conf":0.7807,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":617,"y0":375,"y1":408},"font_size":0.0,"text":"10:Obtain $S^{h}_{\\max}$  already computed during forward"}],"source":"layout det","text":"10:Obtain $S^{h}_{\\max}$  already computed during forward"},{"bbox":{"x0":140,"x1":385,"y0":402,"y1":428},"conf":0.6903,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":386,"y0":398,"y1":432},"font_size":0.0,"text":"11:if $S^{h}_{\\max}>\\tau$ then"}],"source":"layout det","text":"11:if $S^{h}_{\\max}>\\tau$ then"},{"bbox":{"x0":139,"x1":379,"y0":429,"y1":451},"conf":0.4587,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":372,"y0":424,"y1":452},"font_size":0.0,"text":"12: $\\gamma\\leftrightarrow\\tau/S_{\\text{m}}^{h}$ ax"}],"source":"layout det","text":"12: $\\gamma\\leftrightarrow\\tau/S_{\\text{m}}^{h}$ ax"},{"bbox":{"x0":139,"x1":432,"y0":451,"y1":477},"conf":0.5692,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":421,"y0":449,"y1":477},"font_size":0.0,"text":"13: $\\mathbf{W}_{qc}^{n}\\leftrightarrow\\mathbf{W}_{qc}^{n}\\cdot\\sqrt{\\gamma}$"}],"source":"layout det","text":"13: $\\mathbf{W}_{qc}^{n}\\leftrightarrow\\mathbf{W}_{qc}^{n}\\cdot\\sqrt{\\gamma}$"},{"bbox":{"x0":139,"x1":431,"y0":477,"y1":503},"conf":0.5936,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":422,"y0":477,"y1":503},"font_size":0.0,"text":"14: $\\mathbf{W}_{kc}^{h}\\leftrightarrow\\mathbf{W}_{kc}^{h}\\cdot\\sqrt{\\gamma}$"}],"source":"layout det","text":"14: $\\mathbf{W}_{kc}^{h}\\leftrightarrow\\mathbf{W}_{kc}^{h}\\cdot\\sqrt{\\gamma}$"},{"bbox":{"x0":139,"x1":411,"y0":503,"y1":528},"conf":0.6208,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":407,"y0":500,"y1":530},"font_size":0.0,"text":"15: $\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\leftrightarrow\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\cdot\\gamma$"}],"source":"layout det","text":"15: $\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\leftrightarrow\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\cdot\\gamma$"},{"bbox":{"x0":138,"x1":274,"y0":546,"y1":567},"conf":0.2297,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":273,"y0":541,"y1":570},"font_size":0.0,"text":"17:end for"}],"source":"layout det","text":"17:end for"},{"bbox":{"x0":137,"x1":1083,"y0":625,"y1":904},"conf":0.9318,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![b3f9ae5cd29a76d2069069870c953849](imgs/b3f9ae5cd29a76d2069069870c953849.jpg)"},{"bbox":{"x0":135,"x1":1088,"y0":909,"y1":1007},"conf":0.9573,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":912,"y1":934},"font_size":-1.468e+17,"text":"Figure 2: Left: During a mid-scale training run, attention logits rapidly exceed 1000, which could lead to potential"},{"bbox":{"x0":141,"x1":1079,"y0":934,"y1":955},"font_size":-1.468e+17,"text":"numerical instabilities and even training divergence. Right: Maximum logits for Kimi K2 with MuonClip and $\\tau=100$"},{"bbox":{"x0":138,"x1":1081,"y0":954,"y1":980},"font_size":-1.468e+17,"text":"over the entire training run. The max logits rapidly increase to the capped value of 100, and only decay to a stable range"},{"bbox":{"x0":140,"x1":968,"y0":977,"y1":1002},"font_size":-1.468e+17,"text":"after approximately $30\\%$  of the training steps, demonstrating the effective regulation effect of QK-Clip."}],"source":"layout det","text":"Figure 2: Left: During a mid-scale training run, attention logits rapidly exceed 1000, which could lead to potential numerical instabilities and even training divergence. Right: Maximum logits for Kimi K2 with MuonClip and $\\tau=100$ over the entire training run. The max logits rapidly increase to the capped value of 100, and only decay to a stable range after approximately $30\\%$  of the training steps, demonstrating the effective regulation effect of QK-Clip."},{"bbox":{"x0":135,"x1":1089,"y0":1054,"y1":1131},"conf":0.949,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1056,"y1":1082},"font_size":-1.468e+17,"text":"Next, we demonstrate that QK-Clip does not degrade model performance and confrm that the MuonClip optimizeri"},{"bbox":{"x0":140,"x1":1081,"y0":1079,"y1":1104},"font_size":-1.468e+17,"text":"preserves the optimization characteristics of Muon without adversely affecting the loss trajectory. A detailed discussion"},{"bbox":{"x0":140,"x1":703,"y0":1104,"y1":1125},"font_size":-1.468e+17,"text":"of the experiment designs and fndings is provided in the Appendix D.i"}],"source":"layout det","text":"Next, we demonstrate that QK-Clip does not degrade model performance and confrm that the MuonClip optimizeri preserves the optimization characteristics of Muon without adversely affecting the loss trajectory. A detailed discussion of the experiment designs and fndings is provided in the Appendix D.i"},{"bbox":{"x0":134,"x1":1089,"y0":1133,"y1":1253},"conf":0.9624,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1135,"y1":1158},"font_size":-1.468e+17,"text":"Finally, we train Kimi K2, a large-scale MoE model, using MuonClip with $\\tau=100$  and monitor the maximum attention"},{"bbox":{"x0":141,"x1":1083,"y0":1157,"y1":1178},"font_size":-1.468e+17,"text":"logits throughout the training run (Figure 2 (Right)). Initially, the logits are capped at 100 due to QK-Clip. Over the"},{"bbox":{"x0":140,"x1":1083,"y0":1180,"y1":1201},"font_size":-1.468e+17,"text":"course of training, the maximum logits gradually decay to a typical operating range without requiring any adjustment to"},{"bbox":{"x0":140,"x1":1083,"y0":1200,"y1":1224},"font_size":-1.468e+17,"text":"τ. Importantly, the training loss remains smooth and stable, with no observable spikes, as shown in Figure 3, validating"},{"bbox":{"x0":140,"x1":1064,"y0":1221,"y1":1247},"font_size":-1.468e+17,"text":"that MuonClip provides robust and scalable control over attention dynamics in large-scale language model training."}],"source":"layout det","text":"Finally, we train Kimi K2, a large-scale MoE model, using MuonClip with $\\tau=100$  and monitor the maximum attention logits throughout the training run (Figure 2 (Right)). Initially, the logits are capped at 100 due to QK-Clip. Over the course of training, the maximum logits gradually decay to a typical operating range without requiring any adjustment toτ. Importantly, the training loss remains smooth and stable, with no observable spikes, as shown in Figure 3, validating that MuonClip provides robust and scalable control over attention dynamics in large-scale language model training."},{"bbox":{"x0":136,"x1":713,"y0":1283,"y1":1317},"conf":0.8876,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":707,"y0":1285,"y1":1312},"font_size":-1.468e+17,"text":"2.2Pre-training Data: Improving Token Utility with Rephrasing"}],"source":"layout det","text":"2.2Pre-training Data: Improving Token Utility with Rephrasing"},{"bbox":{"x0":134,"x1":1091,"y0":1331,"y1":1452},"conf":0.9529,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1332,"y1":1357},"font_size":-1.468e+17,"text":"Token effciency in pre-training refers to how much performance improvement is achieved for each token consumedi"},{"bbox":{"x0":141,"x1":1083,"y0":1356,"y1":1379},"font_size":-1.468e+17,"text":"during training. Increasing token utility—the effective learning signal each token contributes—enhances the per-token"},{"bbox":{"x0":141,"x1":1083,"y0":1378,"y1":1401},"font_size":-1.468e+17,"text":"impact on model updates, thereby directly improving token effciency. This is particularly important when the supply ofi"},{"bbox":{"x0":141,"x1":1081,"y0":1401,"y1":1422},"font_size":-1.468e+17,"text":"high-quality tokens is limited and must be maximally leveraged. A naive approach to increasing token utility is through"},{"bbox":{"x0":138,"x1":903,"y0":1421,"y1":1445},"font_size":-1.468e+17,"text":"repeated exposure to the same tokens, which can lead to overftting and reduced generalization.i"}],"source":"layout det","text":"Token effciency in pre-training refers to how much performance improvement is achieved for each token consumedi during training. Increasing token utility—the effective learning signal each token contributes—enhances the per-token impact on model updates, thereby directly improving token effciency. This is particularly important when the supply ofi high-quality tokens is limited and must be maximally leveraged. A naive approach to increasing token utility is through repeated exposure to the same tokens, which can lead to overftting and reduced generalization.i"}],"formula_dets":[{"bbox":{"x0":254,"x1":334,"y0":404,"y1":427},"conf":0.8892,"label":"print_embedding","label_id":0},{"bbox":{"x0":295,"x1":338,"y0":381,"y1":404},"conf":0.8777,"label":"print_embedding","label_id":0},{"bbox":{"x0":1016,"x1":1079,"y0":937,"y1":954},"conf":0.8614,"label":"print_embedding","label_id":0},{"bbox":{"x0":338,"x1":437,"y0":223,"y1":240},"conf":0.8603,"label":"print_embedding","label_id":0},{"bbox":{"x0":727,"x1":795,"y0":1137,"y1":1156},"conf":0.8544,"label":"print_embedding","label_id":0},{"bbox":{"x0":236,"x1":403,"y0":245,"y1":265},"conf":0.8531,"label":"print_embedding","label_id":0},{"bbox":{"x0":266,"x1":421,"y0":454,"y1":477},"conf":0.8444,"label":"print_embedding","label_id":0},{"bbox":{"x0":266,"x1":407,"y0":505,"y1":530},"conf":0.8418,"label":"print_embedding","label_id":0},{"bbox":{"x0":267,"x1":422,"y0":479,"y1":503},"conf":0.8351,"label":"print_embedding","label_id":0},{"bbox":{"x0":304,"x1":342,"y0":979,"y1":999},"conf":0.8284,"label":"print_embedding","label_id":0},{"bbox":{"x0":912,"x1":966,"y0":242,"y1":266},"conf":0.8264,"label":"print_embedding","label_id":0},{"bbox":{"x0":237,"x1":510,"y0":293,"y1":317},"conf":0.8243,"label":"print_embedding","label_id":0},{"bbox":{"x0":265,"x1":354,"y0":429,"y1":451},"conf":0.8194,"label":"print_embedding","label_id":0},{"bbox":{"x0":394,"x1":407,"y0":361,"y1":376},"conf":0.7972,"label":"print_embedding","label_id":0},{"bbox":{"x0":674,"x1":798,"y0":240,"y1":265},"conf":0.7932,"label":"print_embedding","label_id":0},{"bbox":{"x0":417,"x1":628,"y0":265,"y1":291},"conf":0.7341,"label":"print_embedding","label_id":0},{"bbox":{"x0":1067,"x1":1079,"y0":296,"y1":312},"conf":0.7213,"label":"print_embedding","label_id":0},{"bbox":{"x0":351,"x1":360,"y0":182,"y1":195},"conf":0.6749,"label":"print_embedding","label_id":0},{"bbox":{"x0":237,"x1":284,"y0":271,"y1":289},"conf":0.6158,"label":"print_embedding","label_id":0},{"bbox":{"x0":204,"x1":235,"y0":339,"y1":355},"conf":0.5247,"label":"print_embedding","label_id":0},{"bbox":{"x0":935,"x1":952,"y0":298,"y1":315},"conf":0.5014,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":134,"x1":1089,"y0":1133,"y1":1253},"conf":0.9624,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1088,"y0":909,"y1":1007},"conf":0.9573,"label":"Figure caption","label_id":4},{"bbox":{"x0":134,"x1":1091,"y0":1331,"y1":1452},"conf":0.9529,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":1054,"y1":1131},"conf":0.949,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1083,"y0":625,"y1":904},"conf":0.9318,"label":"Figure","label_id":3},{"bbox":{"x0":136,"x1":713,"y0":1283,"y1":1317},"conf":0.8876,"label":"Title","label_id":0},{"bbox":{"x0":146,"x1":468,"y0":221,"y1":242},"conf":0.8043,"label":"Text","label_id":1},{"bbox":{"x0":146,"x1":417,"y0":200,"y1":221},"conf":0.7859,"label":"Text","label_id":1},{"bbox":{"x0":141,"x1":618,"y0":380,"y1":403},"conf":0.7807,"label":"Text","label_id":1},{"bbox":{"x0":145,"x1":393,"y0":175,"y1":200},"conf":0.74,"label":"Text","label_id":1},{"bbox":{"x0":144,"x1":320,"y0":336,"y1":357},"conf":0.7265,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":426,"y0":143,"y1":172},"conf":0.7041,"label":"Title","label_id":0},{"bbox":{"x0":140,"x1":385,"y0":402,"y1":428},"conf":0.6903,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":411,"y0":503,"y1":528},"conf":0.6208,"label":"Text","label_id":1},{"bbox":{"x0":142,"x1":736,"y0":357,"y1":380},"conf":0.5982,"label":"Text","label_id":1},{"bbox":{"x0":146,"x1":275,"y0":315,"y1":335},"conf":0.5953,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":431,"y0":477,"y1":503},"conf":0.5936,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":432,"y0":451,"y1":477},"conf":0.5692,"label":"Text","label_id":1},{"bbox":{"x0":555,"x1":1087,"y0":64,"y1":95},"conf":0.5402,"label":"Abandon","label_id":2},{"bbox":{"x0":200,"x1":378,"y0":429,"y1":451},"conf":0.5199,"label":"Text","label_id":1},{"bbox":{"x0":598,"x1":624,"y0":1479,"y1":1507},"conf":0.5017,"label":"Abandon","label_id":2},{"bbox":{"x0":139,"x1":379,"y0":429,"y1":451},"conf":0.4587,"label":"Text","label_id":1},{"bbox":{"x0":210,"x1":635,"y0":266,"y1":292},"conf":0.4157,"label":"Text","label_id":1},{"bbox":{"x0":146,"x1":515,"y0":292,"y1":316},"conf":0.3626,"label":"Text","label_id":1},{"bbox":{"x0":147,"x1":408,"y0":243,"y1":266},"conf":0.32,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1088,"y0":62,"y1":102},"conf":0.24,"label":"Abandon","label_id":2},{"bbox":{"x0":600,"x1":622,"y0":1480,"y1":1505},"conf":0.236,"label":"Abandon","label_id":2},{"bbox":{"x0":138,"x1":274,"y0":546,"y1":567},"conf":0.2297,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[602,1483],[619,1483],[619,1500],[602,1500]],"score":0.8379},{"poly":[[138,1422],[903,1421],[903,1444],[138,1445]],"score":0.7642},{"poly":[[141,1401],[1081,1401],[1081,1422],[141,1422]],"score":0.8386},{"poly":[[141,1378],[1083,1378],[1083,1401],[141,1401]],"score":0.6959},{"poly":[[141,1356],[1083,1356],[1083,1379],[141,1379]],"score":0.7312},{"poly":[[140,1332],[1083,1333],[1083,1356],[140,1355]],"score":0.7374},{"poly":[[138,1285],[707,1289],[707,1312],[138,1308]],"score":0.7769},{"poly":[[140,1221],[1064,1224],[1064,1247],[140,1244]],"score":0.7527},{"poly":[[140,1200],[1083,1201],[1083,1224],[140,1223]],"score":0.714},{"poly":[[140,1180],[1083,1180],[1083,1201],[140,1201]],"score":0.836},{"poly":[[141,1157],[1083,1157],[1083,1178],[141,1178]],"score":0.8055},{"poly":[[141,1135],[1083,1135],[1083,1158],[141,1158]],"score":0.7168},{"poly":[[140,1104],[703,1104],[703,1125],[140,1125]],"score":0.8526},{"poly":[[140,1081],[1081,1079],[1081,1102],[140,1104]],"score":0.6994},{"poly":[[140,1056],[1083,1059],[1083,1082],[140,1079]],"score":0.7135},{"poly":[[140,977],[968,978],[968,1002],[140,1000]],"score":0.7647},{"poly":[[138,954],[1081,957],[1081,980],[138,977]],"score":0.7087},{"poly":[[141,934],[1081,934],[1081,955],[141,955]],"score":0.8451},{"poly":[[141,912],[1081,912],[1081,934],[141,934]],"score":0.8343},{"poly":[[353,881],[416,881],[416,898],[353,898]],"score":0.8894},{"poly":[[986,874],[1008,874],[1008,886],[986,886]],"score":0.7614},{"poly":[[908,874],[926,874],[926,886],[908,886]],"score":0.7638},{"poly":[[748,874],[767,874],[767,886],[748,886]],"score":0.8334},{"poly":[[469,874],[487,874],[487,886],[469,886]],"score":0.6095},{"poly":[[303,876],[313,876],[313,884],[303,884]],"score":0.809},{"poly":[[630,734],[647,734],[647,779],[630,779]],"score":0.6455},{"poly":[[205,642],[283,642],[283,653],[205,653]],"score":0.8237},{"poly":[[981,639],[1071,639],[1071,655],[981,655]],"score":0.7569},{"poly":[[140,568],[243,568],[243,591],[140,591]],"score":0.853},{"poly":[[202,541],[273,545],[272,570],[201,566]],"score":0.7866},{"poly":[[141,546],[171,546],[171,568],[141,568]],"score":0.9577},{"poly":[[231,523],[293,523],[293,546],[231,546]],"score":0.8411},{"poly":[[141,525],[171,525],[171,546],[141,546]],"score":0.9172},{"poly":[[140,500],[173,500],[173,528],[140,528]],"score":0.8206},{"poly":[[141,477],[171,477],[171,498],[141,498]],"score":0.9423},{"poly":[[259,469],[429,469],[429,508],[259,508]],"score":0.6871},{"poly":[[140,449],[173,449],[173,475],[140,475]],"score":0.8407},{"poly":[[258,439],[429,442],[428,484],[257,480]],"score":0.6058},{"poly":[[140,424],[173,424],[173,452],[140,452]],"score":0.8812},{"poly":[[230,398],[386,398],[386,432],[230,432]],"score":0.6295},{"poly":[[141,403],[173,403],[173,424],[141,424]],"score":0.9276},{"poly":[[231,375],[617,375],[617,408],[231,408]],"score":0.6403},{"poly":[[140,376],[175,376],[175,403],[140,403]],"score":0.8283},{"poly":[[203,356],[730,356],[730,378],[203,378]],"score":0.8718},{"poly":[[146,356],[173,356],[173,380],[146,380]],"score":0.8023},{"poly":[[203,333],[318,333],[318,356],[203,356]],"score":0.8556},{"poly":[[148,335],[173,335],[173,356],[148,356]],"score":0.907},{"poly":[[203,315],[273,315],[273,333],[203,333]],"score":0.9242},{"poly":[[150,314],[173,314],[173,335],[150,335]],"score":0.922},{"poly":[[812,292],[1083,292],[1083,314],[812,314]],"score":0.9496},{"poly":[[231,287],[511,291],[510,319],[231,315]],"score":0.7427},{"poly":[[148,292],[173,292],[173,314],[148,314]],"score":0.9088},{"poly":[[908,266],[1081,266],[1081,289],[908,289]],"score":0.7632},{"poly":[[236,266],[629,266],[629,289],[236,289]],"score":0.8115},{"poly":[[148,266],[173,266],[173,289],[148,289]],"score":0.829},{"poly":[[677,239],[1083,239],[1083,262],[677,262]],"score":0.7127},{"poly":[[234,241],[402,241],[402,264],[234,264]],"score":0.8157},{"poly":[[148,241],[173,241],[173,264],[148,264]],"score":0.7957},{"poly":[[148,219],[173,219],[173,241],[148,241]],"score":0.9199},{"poly":[[198,211],[472,213],[472,246],[198,244]],"score":0.619},{"poly":[[205,198],[414,198],[414,219],[205,219]],"score":0.8259},{"poly":[[150,198],[173,198],[173,221],[150,221]],"score":0.8329},{"poly":[[148,175],[389,173],[389,196],[148,198]],"score":0.7617},{"poly":[[141,145],[421,145],[421,167],[141,167]],"score":0.8781},{"poly":[[918,66],[1083,69],[1082,93],[918,89]],"score":0.7176},{"poly":[[559,64],[664,64],[664,92],[559,92]],"score":0.8132}],"page_no":3,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":94},"conf":0.7207,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":599,"x1":623,"y0":1479,"y1":1507},"conf":0.5024,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":604,"x1":619,"y0":1482,"y1":1502},"font_size":0.0,"text":"5"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":274,"x1":952,"y0":134,"y1":519},"conf":0.9773,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![95f11e3a027801e5bd8b4881447ea890](imgs/95f11e3a027801e5bd8b4881447ea890.jpg)"},{"bbox":{"x0":135,"x1":1087,"y0":522,"y1":577},"conf":0.9432,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":526,"y1":548},"font_size":-6.627000000000001e+26,"text":"Figure 3: Per-step training loss curve of Kimi K2, without smoothing or sub-sampling. It shows no spikes throughout"},{"bbox":{"x0":141,"x1":835,"y0":549,"y1":571},"font_size":-6.627000000000001e+26,"text":"the entire training process. Note that we omit the very beginning of training for clarity."}],"source":"layout det","text":"Figure 3: Per-step training loss curve of Kimi K2, without smoothing or sub-sampling. It shows no spikes throughout the entire training process. Note that we omit the very beginning of training for clarity."},{"bbox":{"x0":136,"x1":1088,"y0":612,"y1":730},"conf":0.9635,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":614,"y1":639},"font_size":-6.627000000000001e+26,"text":"A key advancement in the pre-training data of Kimi K2 over Kimi K1.5 is the introduction of a synthetic data generation"},{"bbox":{"x0":140,"x1":1081,"y0":639,"y1":662},"font_size":-6.627000000000001e+26,"text":"strategy to increase token utility. Specifcally, a carefully designed rephrasing pipeline is employed to amplify the volumei"},{"bbox":{"x0":143,"x1":1079,"y0":663,"y1":682},"font_size":-6.627000000000001e+26,"text":"of high-quality tokens without inducing signifcant overftting. In this report, we describe two domain-specializedii"},{"bbox":{"x0":140,"x1":1083,"y0":683,"y1":705},"font_size":-6.627000000000001e+26,"text":"rephrasing techniques—targeted respectively at the Knowledge and Mathematics domains—that enable this controlled"},{"bbox":{"x0":140,"x1":298,"y0":705,"y1":726},"font_size":-6.627000000000001e+26,"text":"data augmentation."}],"source":"layout det","text":"A key advancement in the pre-training data of Kimi K2 over Kimi K1.5 is the introduction of a synthetic data generation strategy to increase token utility. Specifcally, a carefully designed rephrasing pipeline is employed to amplify the volumei of high-quality tokens without inducing signifcant overftting. In this report, we describe two domain-specializedii rephrasing techniques—targeted respectively at the Knowledge and Mathematics domains—that enable this controlled data augmentation."},{"bbox":{"x0":137,"x1":1089,"y0":747,"y1":846},"conf":0.952,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":752,"y1":774},"font_size":-6.627000000000001e+26,"text":"Knowledge Data RephrasingPre-training on natural, knowledge-intensive text presents a trade-off: a single epoch"},{"bbox":{"x0":141,"x1":1083,"y0":774,"y1":795},"font_size":-6.627000000000001e+26,"text":"is insuffcient for comprehensive knowledge absorption, while multi-epoch repetition yields diminishing returns andi"},{"bbox":{"x0":140,"x1":1081,"y0":794,"y1":818},"font_size":-6.627000000000001e+26,"text":"increases the risk of overftting. To improve the token utility of high-quality knowledge tokens, we propose a synthetici"},{"bbox":{"x0":141,"x1":680,"y0":818,"y1":840},"font_size":-6.627000000000001e+26,"text":"rephrasing framework composed of the following key components:"}],"source":"layout det","text":"Knowledge Data RephrasingPre-training on natural, knowledge-intensive text presents a trade-off: a single epoch is insuffcient for comprehensive knowledge absorption, while multi-epoch repetition yields diminishing returns andi increases the risk of overftting. To improve the token utility of high-quality knowledge tokens, we propose a synthetici rephrasing framework composed of the following key components:"},{"bbox":{"x0":170,"x1":1089,"y0":856,"y1":932},"conf":0.9541,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1083,"y0":861,"y1":883},"font_size":-6.627000000000001e+26,"text":"Style- and perspective-diverse prompting: To enhance linguistic diversity while maintaining factual integrity, we"},{"bbox":{"x0":176,"x1":1081,"y0":881,"y1":906},"font_size":-6.627000000000001e+26,"text":"apply a range of carefully engineered prompts. These prompts guide a large language model to generate faithful"},{"bbox":{"x0":178,"x1":820,"y0":906,"y1":927},"font_size":-6.627000000000001e+26,"text":"rephrasings of the original texts in varied styles and from different perspectives."}],"source":"layout det","text":"Style- and perspective-diverse prompting: To enhance linguistic diversity while maintaining factual integrity, we apply a range of carefully engineered prompts. These prompts guide a large language model to generate faithful rephrasings of the original texts in varied styles and from different perspectives."},{"bbox":{"x0":170,"x1":1088,"y0":934,"y1":1029},"conf":0.9584,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":168,"x1":1081,"y0":934,"y1":960},"font_size":-6.627000000000001e+26,"text":"Chunk-wise autoregressive generation: To preserve global coherence and avoid information loss in long"},{"bbox":{"x0":178,"x1":1083,"y0":959,"y1":982},"font_size":-6.627000000000001e+26,"text":"documents, we adopt a chunk-based autoregressive rewriting strategy. Texts are divided into segments, rephrased"},{"bbox":{"x0":178,"x1":1083,"y0":980,"y1":1003},"font_size":-6.627000000000001e+26,"text":"individually, and then stitched back together to form complete passages. This method mitigates implicit output"},{"bbox":{"x0":176,"x1":1001,"y0":1003,"y1":1025},"font_size":-6.627000000000001e+26,"text":"length limitations that typically exist with LLMs. An overview of this pipeline is presented in Figure 4."}],"source":"layout det","text":"Chunk-wise autoregressive generation: To preserve global coherence and avoid information loss in long documents, we adopt a chunk-based autoregressive rewriting strategy. Texts are divided into segments, rephrased individually, and then stitched back together to form complete passages. This method mitigates implicit output length limitations that typically exist with LLMs. An overview of this pipeline is presented in Figure 4."},{"bbox":{"x0":170,"x1":1089,"y0":1032,"y1":1107},"conf":0.9559,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":1079,"y0":1033,"y1":1056},"font_size":-6.627000000000001e+26,"text":"Fidelity verifcation: To ensure consistency between original and rewritten content, we perform fdelity checksii"},{"bbox":{"x0":176,"x1":1081,"y0":1054,"y1":1079},"font_size":-6.627000000000001e+26,"text":"that compare the semantic alignment of each rephrased passage with its source. This serves as an initial quality"},{"bbox":{"x0":176,"x1":409,"y0":1076,"y1":1104},"font_size":-6.627000000000001e+26,"text":"control step prior to training."}],"source":"layout det","text":"Fidelity verifcation: To ensure consistency between original and rewritten content, we perform fdelity checksii that compare the semantic alignment of each rephrased passage with its source. This serves as an initial quality control step prior to training."},{"bbox":{"x0":135,"x1":1090,"y0":1118,"y1":1260},"conf":0.9684,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1122,"y1":1143},"font_size":-6.627000000000001e+26,"text":"We compare data rephrasing with multi-epoch repetition by testing their corresponding accuracy on SimpleQA. We"},{"bbox":{"x0":140,"x1":1081,"y0":1142,"y1":1165},"font_size":-6.627000000000001e+26,"text":"experiment with an early checkpoint of K2 and evaluate three training strategies: (1) repeating the original dataset for"},{"bbox":{"x0":138,"x1":1083,"y0":1163,"y1":1188},"font_size":-6.627000000000001e+26,"text":"10 epochs, (2) rephrasing the data once and repeating it for 10 epochs, and (3) rephrasing the data 10 times with a"},{"bbox":{"x0":140,"x1":1081,"y0":1188,"y1":1209},"font_size":-6.627000000000001e+26,"text":"single training pass. As shown in Table 1, the accuracy consistently improves across these strategies, demonstrating the"},{"bbox":{"x0":141,"x1":1083,"y0":1209,"y1":1231},"font_size":-6.627000000000001e+26,"text":"effcacy of our rephrasing-based augmentation. We extended this method to other large-scale knowledge corpora andi"},{"bbox":{"x0":141,"x1":815,"y0":1233,"y1":1254},"font_size":-6.627000000000001e+26,"text":"observed similarly encouraging results, and each corpora is rephrased at most twice."}],"source":"layout det","text":"We compare data rephrasing with multi-epoch repetition by testing their corresponding accuracy on SimpleQA. We experiment with an early checkpoint of K2 and evaluate three training strategies: (1) repeating the original dataset for 10 epochs, (2) rephrasing the data once and repeating it for 10 epochs, and (3) rephrasing the data 10 times with a single training pass. As shown in Table 1, the accuracy consistently improves across these strategies, demonstrating the effcacy of our rephrasing-based augmentation. We extended this method to other large-scale knowledge corpora andi observed similarly encouraging results, and each corpora is rephrased at most twice."},{"bbox":{"x0":308,"x1":915,"y0":1287,"y1":1314},"conf":0.9142,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":313,"x1":910,"y0":1290,"y1":1312},"font_size":-6.627000000000001e+26,"text":"Table 1: SimpleQA Accuracy under three rephrasing-epoch confgurationsi"}],"source":"layout det","text":"Table 1: SimpleQA Accuracy under three rephrasing-epoch confgurationsi"},{"bbox":{"x0":310,"x1":839,"y0":1315,"y1":1430},"conf":0.9512,"font_size":0.0,"label":"Table","label_id":5,"lines":[{"bbox":{"x0":404,"x1":530,"y0":1317,"y1":1345},"font_size":0.0,"text":"# Rephrasings"},{"bbox":{"x0":553,"x1":638,"y0":1319,"y1":1344},"font_size":0.0,"text":"# Epochs"},{"bbox":{"x0":651,"x1":825,"y0":1317,"y1":1345},"font_size":0.0,"text":"SimpleQA Accuracy"},{"bbox":{"x0":396,"x1":538,"y0":1350,"y1":1374},"font_size":0.0,"text":"0 (raw wiki-text)"},{"bbox":{"x0":583,"x1":610,"y0":1350,"y1":1373},"font_size":0.0,"text":"10"},{"bbox":{"x0":713,"x1":767,"y0":1350,"y1":1373},"font_size":0.0,"text":"23.76"},{"bbox":{"x0":457,"x1":479,"y0":1374,"y1":1396},"font_size":0.0,"text":"1"},{"bbox":{"x0":581,"x1":610,"y0":1373,"y1":1396},"font_size":0.0,"text":"10"},{"bbox":{"x0":712,"x1":766,"y0":1373,"y1":1395},"font_size":0.0,"text":"27.39"},{"bbox":{"x0":454,"x1":484,"y0":1393,"y1":1417},"font_size":0.0,"text":"10"},{"bbox":{"x0":585,"x1":608,"y0":1395,"y1":1417},"font_size":0.0,"text":"1"},{"bbox":{"x0":713,"x1":767,"y0":1394,"y1":1417},"font_size":0.0,"text":"28.94"}],"source":"layout det","text":"<html><body><table><thead><tr><td># Rephrasings</td><td># Epochs</td><td>SimpleQA Accuracy</td></tr></thead><tbody><tr><td>0 (raw wiki-text)</td><td>10</td><td>23.76</td></tr><tr><td>1</td><td>10</td><td>27.39</td></tr><tr><td>10</td><td>1</td><td>28.94</td></tr></tbody></table></body></html>"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":274,"x1":952,"y0":134,"y1":519},"conf":0.9773,"label":"Figure","label_id":3},{"bbox":{"x0":135,"x1":1090,"y0":1118,"y1":1260},"conf":0.9684,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":612,"y1":730},"conf":0.9635,"label":"Text","label_id":1},{"bbox":{"x0":170,"x1":1088,"y0":934,"y1":1029},"conf":0.9584,"label":"Text","label_id":1},{"bbox":{"x0":170,"x1":1089,"y0":1032,"y1":1107},"conf":0.9559,"label":"Text","label_id":1},{"bbox":{"x0":170,"x1":1089,"y0":856,"y1":932},"conf":0.9541,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":747,"y1":846},"conf":0.952,"label":"Text","label_id":1},{"bbox":{"x0":310,"x1":839,"y0":1315,"y1":1430},"conf":0.9512,"label":"Table","label_id":5},{"bbox":{"x0":135,"x1":1087,"y0":522,"y1":577},"conf":0.9432,"label":"Figure caption","label_id":4},{"bbox":{"x0":308,"x1":915,"y0":1287,"y1":1314},"conf":0.9142,"label":"Table caption","label_id":6},{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":94},"conf":0.7207,"label":"Abandon","label_id":2},{"bbox":{"x0":599,"x1":623,"y0":1479,"y1":1507},"conf":0.5024,"label":"Abandon","label_id":2},{"bbox":{"x0":602,"x1":621,"y0":1481,"y1":1505},"conf":0.3811,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[604,1482],[619,1482],[619,1502],[604,1502]],"score":0.8455},{"poly":[[713,1393],[767,1393],[767,1417],[713,1417]],"score":0.951},{"poly":[[585,1394],[607,1394],[607,1416],[585,1416]],"score":0.6886},{"poly":[[456,1393],[482,1393],[482,1416],[456,1416]],"score":0.8106},{"poly":[[461,1376],[477,1376],[477,1394],[461,1394]],"score":0.7603},{"poly":[[710,1370],[768,1370],[768,1399],[710,1399]],"score":0.8695},{"poly":[[582,1373],[610,1373],[610,1396],[582,1396]],"score":0.8026},{"poly":[[394,1350],[539,1351],[539,1375],[394,1373]],"score":0.8119},{"poly":[[710,1346],[768,1346],[768,1376],[710,1376]],"score":0.8104},{"poly":[[582,1350],[610,1350],[610,1373],[582,1373]],"score":0.8695},{"poly":[[552,1318],[825,1320],[825,1343],[552,1341]],"score":0.7474},{"poly":[[406,1318],[529,1322],[528,1343],[406,1340]],"score":0.8474},{"poly":[[313,1290],[910,1290],[910,1312],[313,1312]],"score":0.9024},{"poly":[[141,1233],[815,1233],[815,1254],[141,1254]],"score":0.8632},{"poly":[[141,1209],[1083,1209],[1083,1231],[141,1231]],"score":0.8384},{"poly":[[140,1188],[1081,1188],[1081,1209],[140,1209]],"score":0.8006},{"poly":[[138,1163],[1083,1165],[1083,1188],[138,1186]],"score":0.7642},{"poly":[[140,1142],[1081,1142],[1081,1165],[140,1165]],"score":0.699},{"poly":[[141,1122],[1081,1122],[1081,1143],[141,1143]],"score":0.8535},{"poly":[[177,1076],[409,1081],[409,1104],[176,1099]],"score":0.7077},{"poly":[[176,1054],[1081,1056],[1081,1079],[176,1077]],"score":0.7641},{"poly":[[163,1033],[1079,1033],[1079,1054],[163,1054]],"score":0.7215},{"poly":[[176,1003],[1001,1003],[1001,1025],[176,1025]],"score":0.8198},{"poly":[[178,980],[1083,980],[1083,1003],[178,1003]],"score":0.7118},{"poly":[[178,959],[1083,959],[1083,982],[178,982]],"score":0.7096},{"poly":[[168,934],[1081,937],[1081,960],[168,957]],"score":0.7277},{"poly":[[178,906],[820,906],[820,927],[178,927]],"score":0.8568},{"poly":[[176,883],[1081,881],[1081,904],[176,906]],"score":0.7618},{"poly":[[160,861],[1083,861],[1083,883],[160,883]],"score":0.8475},{"poly":[[141,818],[680,818],[680,840],[141,840]],"score":0.8309},{"poly":[[140,794],[1081,795],[1081,818],[140,817]],"score":0.7777},{"poly":[[141,774],[1083,774],[1083,795],[141,795]],"score":0.846},{"poly":[[141,752],[1081,752],[1081,774],[141,774]],"score":0.8233},{"poly":[[140,705],[298,705],[298,726],[140,726]],"score":0.8553},{"poly":[[140,683],[1083,683],[1083,705],[140,705]],"score":0.8446},{"poly":[[143,663],[1079,663],[1079,680],[143,680]],"score":0.96},{"poly":[[140,639],[1081,639],[1081,662],[140,662]],"score":0.7109},{"poly":[[140,614],[1081,615],[1081,639],[140,637]],"score":0.743},{"poly":[[141,549],[835,549],[835,571],[141,571]],"score":0.8262},{"poly":[[141,526],[1083,526],[1083,548],[141,548]],"score":0.8739},{"poly":[[585,497],[693,497],[693,515],[585,515]],"score":0.9387},{"poly":[[564,483],[572,483],[572,493],[564,493]],"score":0.6544},{"poly":[[923,480],[940,480],[940,495],[923,495]],"score":0.8252},{"poly":[[490,479],[501,482],[498,496],[486,493]],"score":0.706},{"poly":[[855,478],[873,478],[873,495],[855,495]],"score":0.8221},{"poly":[[780,477],[803,477],[803,498],[780,498]],"score":0.7652},{"poly":[[705,477],[728,477],[728,497],[705,497]],"score":0.871},{"poly":[[412,478],[427,478],[427,495],[412,495]],"score":0.7557},{"poly":[[301,446],[318,446],[318,460],[301,460]],"score":0.8406},{"poly":[[299,401],[319,401],[319,416],[299,416]],"score":0.8376},{"poly":[[299,356],[318,356],[318,371],[299,371]],"score":0.8731},{"poly":[[298,266],[321,266],[321,285],[298,285]],"score":0.8016},{"poly":[[299,223],[318,223],[318,239],[299,239]],"score":0.8293},{"poly":[[299,180],[319,180],[319,195],[299,195]],"score":0.8384},{"poly":[[299,142],[319,142],[319,157],[299,157]],"score":0.8262},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.743},{"poly":[[560,64],[664,64],[664,92],[560,92]],"score":0.8179}],"page_no":4,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":556,"x1":1088,"y0":64,"y1":94},"conf":0.7096,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":599,"x1":623,"y0":1480,"y1":1506},"conf":0.5563,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":604,"x1":619,"y0":1483,"y1":1502},"font_size":0.0,"text":"6"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":279,"x1":949,"y0":162,"y1":462},"conf":0.9674,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![9033f0e6f55191cde0a2654b64962987](imgs/9033f0e6f55191cde0a2654b64962987.jpg)"},{"bbox":{"x0":229,"x1":994,"y0":478,"y1":555},"conf":0.9532,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":233,"x1":986,"y0":482,"y1":503},"font_size":-1.8879999999999998e-24,"text":"Figure 4: Auto-regressive chunk-wise rephrasing pipeline for long input excerpts. The input is"},{"bbox":{"x0":233,"x1":988,"y0":503,"y1":528},"font_size":-1.8879999999999998e-24,"text":"split into smaller chunks with preserved context, rewritten sequentially, and then concatenated"},{"bbox":{"x0":233,"x1":464,"y0":525,"y1":551},"font_size":-1.8879999999999998e-24,"text":"into a full rewritten passage."}],"source":"layout det","text":"Figure 4: Auto-regressive chunk-wise rephrasing pipeline for long input excerpts. The input is split into smaller chunks with preserved context, rewritten sequentially, and then concatenated into a full rewritten passage."},{"bbox":{"x0":137,"x1":1090,"y0":593,"y1":668},"conf":0.9415,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":596,"y1":617},"font_size":-1.8879999999999998e-24,"text":"Mathematics Data RephrasingTo enhance mathematical reasoning capabilities, we rewrite high-quality mathemati-"},{"bbox":{"x0":140,"x1":1083,"y0":619,"y1":640},"font_size":-1.8879999999999998e-24,"text":"cal documents into a “learning-note” style, following the methodology introduced in SwallowMath [15]. In addition,"},{"bbox":{"x0":140,"x1":1046,"y0":640,"y1":662},"font_size":-1.8879999999999998e-24,"text":"we increased data diversity by translating high-quality mathematical materials from other languages into English."}],"source":"layout det","text":"Mathematics Data RephrasingTo enhance mathematical reasoning capabilities, we rewrite high-quality mathematical documents into a “learning-note” style, following the methodology introduced in SwallowMath [15]. In addition,we increased data diversity by translating high-quality mathematical materials from other languages into English."},{"bbox":{"x0":137,"x1":1089,"y0":671,"y1":767},"conf":0.9562,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":673,"y1":695},"font_size":-1.8879999999999998e-24,"text":"Although initial experiments with rephrased subsets of our datasets show promising results, the use of synthetic data"},{"bbox":{"x0":140,"x1":1081,"y0":695,"y1":716},"font_size":-1.8879999999999998e-24,"text":"as a strategy for continued scaling remains an active area of investigation. Key challenges include generalizing the"},{"bbox":{"x0":141,"x1":1083,"y0":716,"y1":739},"font_size":-1.8879999999999998e-24,"text":"approach to diverse source domains without compromising factual accuracy, minimizing hallucinations and unintended"},{"bbox":{"x0":140,"x1":589,"y0":739,"y1":761},"font_size":-1.8879999999999998e-24,"text":"toxicity, and ensuring scalability to large-scale datasets."}],"source":"layout det","text":"Although initial experiments with rephrased subsets of our datasets show promising results, the use of synthetic data as a strategy for continued scaling remains an active area of investigation. Key challenges include generalizing the approach to diverse source domains without compromising factual accuracy, minimizing hallucinations and unintended toxicity, and ensuring scalability to large-scale datasets."},{"bbox":{"x0":136,"x1":1089,"y0":781,"y1":902},"conf":0.9564,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":785,"y1":808},"font_size":-1.8879999999999998e-24,"text":"Pre-training Data OverallThe Kimi K2 pre-training corpus comprises 15.5 trillion tokens of curated, high-quality"},{"bbox":{"x0":140,"x1":1083,"y0":808,"y1":832},"font_size":-1.8879999999999998e-24,"text":"data spanning four primary domains: Web Text, Code, Mathematics, and Knowledge. Most data processing pipelines"},{"bbox":{"x0":140,"x1":1081,"y0":830,"y1":853},"font_size":-1.8879999999999998e-24,"text":"follow the methodologies outlined in Kimi K1.5 [35]. For each domain, we performed rigorous correctness and"},{"bbox":{"x0":140,"x1":1083,"y0":853,"y1":874},"font_size":-1.8879999999999998e-24,"text":"quality validation and designed targeted data experiments to ensure the curated dataset achieved both high diversity and"},{"bbox":{"x0":141,"x1":253,"y0":876,"y1":894},"font_size":-1.8879999999999998e-24,"text":"effectiveness."}],"source":"layout det","text":"Pre-training Data OverallThe Kimi K2 pre-training corpus comprises 15.5 trillion tokens of curated, high-quality data spanning four primary domains: Web Text, Code, Mathematics, and Knowledge. Most data processing pipelines follow the methodologies outlined in Kimi K1.5 [35]. For each domain, we performed rigorous correctness and quality validation and designed targeted data experiments to ensure the curated dataset achieved both high diversity and effectiveness."},{"bbox":{"x0":136,"x1":363,"y0":921,"y1":952},"conf":0.8911,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":358,"y0":924,"y1":947},"font_size":-1.8879999999999998e-24,"text":"2.3Model Architecture"}],"source":"layout det","text":"2.3Model Architecture"},{"bbox":{"x0":135,"x1":1090,"y0":965,"y1":1128},"conf":0.9734,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":967,"y1":990},"font_size":-1.8879999999999998e-24,"text":"Kimi K2 is a 1.04 trillion-parameter Mixture-of-Experts (MoE) transformer model with 32 billion activated parameters."},{"bbox":{"x0":141,"x1":1083,"y0":988,"y1":1011},"font_size":-1.8879999999999998e-24,"text":"The architecture follows a similar design to DeepSeek-V3 [10] , employing Multi-head Latent Attention (MLA) [44] as"},{"bbox":{"x0":141,"x1":1083,"y0":1011,"y1":1033},"font_size":-1.8879999999999998e-24,"text":"the attention mechanism, with a model hidden dimension of 7168 and an MoE expert hidden dimension of 2048. Our"},{"bbox":{"x0":138,"x1":1081,"y0":1031,"y1":1056},"font_size":-1.8879999999999998e-24,"text":"scaling law analysis reveals that continued increases in sparsity yield substantial performance improvements, which"},{"bbox":{"x0":140,"x1":1081,"y0":1054,"y1":1077},"font_size":-1.8879999999999998e-24,"text":"motivated us to increase the number of experts to 384, compared to 256 in DeepSeek-V3. To reduce computational"},{"bbox":{"x0":140,"x1":1083,"y0":1077,"y1":1099},"font_size":-1.8879999999999998e-24,"text":"overhead during inference, we cut the number of attention heads to 64, as opposed to 128 in DeepSeek-V3. Table 2"},{"bbox":{"x0":138,"x1":910,"y0":1096,"y1":1122},"font_size":-1.8879999999999998e-24,"text":"presents a detailed comparison of architectural parameters between Kimi K2 and DeepSeek-V3."}],"source":"layout det","text":"Kimi K2 is a 1.04 trillion-parameter Mixture-of-Experts (MoE) transformer model with 32 billion activated parameters.The architecture follows a similar design to DeepSeek-V3 [10] , employing Multi-head Latent Attention (MLA) [44] as the attention mechanism, with a model hidden dimension of 7168 and an MoE expert hidden dimension of 2048. Our scaling law analysis reveals that continued increases in sparsity yield substantial performance improvements, which motivated us to increase the number of experts to 384, compared to 256 in DeepSeek-V3. To reduce computational overhead during inference, we cut the number of attention heads to 64, as opposed to 128 in DeepSeek-V3. Table 2 presents a detailed comparison of architectural parameters between Kimi K2 and DeepSeek-V3."},{"bbox":{"x0":318,"x1":904,"y0":1155,"y1":1183},"conf":0.9217,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":326,"x1":898,"y0":1158,"y1":1180},"font_size":-1.8879999999999998e-24,"text":"Table 2: Architectural comparison between Kimi K2 and DeepSeek-V3"}],"source":"layout det","text":"Table 2: Architectural comparison between Kimi K2 and DeepSeek-V3"},{"bbox":{"x0":325,"x1":895,"y0":1184,"y1":1430},"conf":0.9789,"font_size":0.0,"label":"Table","label_id":5,"lines":[{"bbox":{"x0":579,"x1":699,"y0":1187,"y1":1211},"font_size":0.0,"text":"DeepSeek-V3"},{"bbox":{"x0":717,"x1":797,"y0":1186,"y1":1209},"font_size":0.0,"text":"Kimi K2"},{"bbox":{"x0":832,"x1":851,"y0":1192,"y1":1208},"font_size":0.0,"text":" $\\Delta$ "},{"bbox":{"x0":348,"x1":423,"y0":1218,"y1":1245},"font_size":0.0,"text":"#Layers"},{"bbox":{"x0":625,"x1":651,"y0":1220,"y1":1241},"font_size":0.0,"text":"61"},{"bbox":{"x0":743,"x1":768,"y0":1220,"y1":1241},"font_size":0.0,"text":"61"},{"bbox":{"x0":834,"x1":852,"y0":1222,"y1":1240},"font_size":0.0,"text":"="},{"bbox":{"x0":352,"x1":491,"y0":1241,"y1":1263},"font_size":0.0,"text":"Total Parameters"},{"bbox":{"x0":614,"x1":662,"y0":1242,"y1":1263},"font_size":0.0,"text":"671B"},{"bbox":{"x0":731,"x1":783,"y0":1242,"y1":1262},"font_size":0.0,"text":"1.04T"},{"bbox":{"x0":811,"x1":872,"y0":1241,"y1":1265},"font_size":0.0,"text":"￪54%"},{"bbox":{"x0":352,"x1":527,"y0":1264,"y1":1285},"font_size":0.0,"text":"Activated Parameters"},{"bbox":{"x0":616,"x1":659,"y0":1260,"y1":1285},"font_size":0.0,"text":"37B"},{"bbox":{"x0":729,"x1":782,"y0":1264,"y1":1285},"font_size":0.0,"text":"32.6B"},{"bbox":{"x0":815,"x1":870,"y0":1267,"y1":1286},"font_size":0.0,"text":" $\\downarrow13\\%$ "},{"bbox":{"x0":352,"x1":472,"y0":1285,"y1":1308},"font_size":0.0,"text":"Experts (total)"},{"bbox":{"x0":619,"x1":657,"y0":1285,"y1":1307},"font_size":0.0,"text":"256"},{"bbox":{"x0":737,"x1":775,"y0":1285,"y1":1307},"font_size":0.0,"text":"384"},{"bbox":{"x0":814,"x1":870,"y0":1289,"y1":1308},"font_size":0.0,"text":" $\\uparrow50\\%$ "},{"bbox":{"x0":352,"x1":560,"y0":1307,"y1":1330},"font_size":0.0,"text":"Experts Active per Token"},{"bbox":{"x0":625,"x1":651,"y0":1307,"y1":1328},"font_size":0.0,"text":"8"},{"bbox":{"x0":746,"x1":766,"y0":1308,"y1":1328},"font_size":0.0,"text":"8"},{"bbox":{"x0":834,"x1":851,"y0":1311,"y1":1328},"font_size":0.0,"text":"="},{"bbox":{"x0":352,"x1":481,"y0":1328,"y1":1353},"font_size":0.0,"text":"Shared Experts"},{"bbox":{"x0":627,"x1":651,"y0":1328,"y1":1349},"font_size":0.0,"text":"1"},{"bbox":{"x0":746,"x1":767,"y0":1328,"y1":1350},"font_size":0.0,"text":"1"},{"bbox":{"x0":833,"x1":851,"y0":1333,"y1":1349},"font_size":0.0,"text":"="},{"bbox":{"x0":353,"x1":486,"y0":1350,"y1":1370},"font_size":0.0,"text":"Attention Heads"},{"bbox":{"x0":622,"x1":657,"y0":1350,"y1":1372},"font_size":0.0,"text":"128"},{"bbox":{"x0":743,"x1":769,"y0":1351,"y1":1371},"font_size":0.0,"text":"64"},{"bbox":{"x0":812,"x1":872,"y0":1351,"y1":1372},"font_size":0.0,"text":" $\\downarrow50\\%$ "},{"bbox":{"x0":352,"x1":558,"y0":1372,"y1":1394},"font_size":0.0,"text":"Number of Dense Layers"},{"bbox":{"x0":625,"x1":651,"y0":1372,"y1":1394},"font_size":0.0,"text":"3"},{"bbox":{"x0":744,"x1":767,"y0":1372,"y1":1394},"font_size":0.0,"text":"1"},{"bbox":{"x0":813,"x1":872,"y0":1375,"y1":1396},"font_size":0.0,"text":" $\\downarrow67\\%$ "},{"bbox":{"x0":351,"x1":491,"y0":1394,"y1":1421},"font_size":0.0,"text":"Expert Grouping"},{"bbox":{"x0":619,"x1":658,"y0":1393,"y1":1418},"font_size":0.0,"text":"Yes"},{"bbox":{"x0":740,"x1":772,"y0":1393,"y1":1417},"font_size":0.0,"text":"No"},{"bbox":{"x0":837,"x1":849,"y0":1401,"y1":1414},"font_size":0.0,"text":"-"}],"source":"layout det","text":"<html><body><table><tr><td></td><td>DeepSeek-V3</td><td>Kimi K2</td><td> $\\Delta$ </td></tr><tr><td>#Layers</td><td>61</td><td>61</td><td>=</td></tr><tr><td>Total Parameters</td><td>671B</td><td>1.04T</td><td>￪54%</td></tr><tr><td>Activated Parameters</td><td>37B</td><td>32.6B</td><td> $\\downarrow13\\%$ </td></tr><tr><td>Experts (total)</td><td>256</td><td>384</td><td> $\\uparrow50\\%$ </td></tr><tr><td>Experts Active per Token</td><td>8</td><td>8</td><td>=</td></tr><tr><td>Shared Experts</td><td>1</td><td>1</td><td>=</td></tr><tr><td>Attention Heads</td><td>128</td><td>64</td><td> $\\downarrow50\\%$ </td></tr><tr><td>Number of Dense Layers</td><td>3</td><td>1</td><td> $\\downarrow67\\%$ </td></tr><tr><td>Expert Grouping</td><td>Yes</td><td>No</td><td>-</td></tr></table></body></html>"}],"formula_dets":[{"bbox":{"x0":812,"x1":872,"y0":1351,"y1":1372},"conf":0.6629,"label":"print_embedding","label_id":0},{"bbox":{"x0":815,"x1":870,"y0":1267,"y1":1286},"conf":0.6477,"label":"print_embedding","label_id":0},{"bbox":{"x0":813,"x1":872,"y0":1375,"y1":1396},"conf":0.6439,"label":"print_embedding","label_id":0},{"bbox":{"x0":814,"x1":870,"y0":1289,"y1":1308},"conf":0.638,"label":"print_embedding","label_id":0},{"bbox":{"x0":832,"x1":851,"y0":1192,"y1":1208},"conf":0.5083,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":325,"x1":895,"y0":1184,"y1":1430},"conf":0.9789,"label":"Table","label_id":5},{"bbox":{"x0":135,"x1":1090,"y0":965,"y1":1128},"conf":0.9734,"label":"Text","label_id":1},{"bbox":{"x0":279,"x1":949,"y0":162,"y1":462},"conf":0.9674,"label":"Figure","label_id":3},{"bbox":{"x0":136,"x1":1089,"y0":781,"y1":902},"conf":0.9564,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":671,"y1":767},"conf":0.9562,"label":"Text","label_id":1},{"bbox":{"x0":229,"x1":994,"y0":478,"y1":555},"conf":0.9532,"label":"Figure caption","label_id":4},{"bbox":{"x0":137,"x1":1090,"y0":593,"y1":668},"conf":0.9415,"label":"Text","label_id":1},{"bbox":{"x0":318,"x1":904,"y0":1155,"y1":1183},"conf":0.9217,"label":"Table caption","label_id":6},{"bbox":{"x0":136,"x1":363,"y0":921,"y1":952},"conf":0.8911,"label":"Title","label_id":0},{"bbox":{"x0":556,"x1":1088,"y0":64,"y1":94},"conf":0.7096,"label":"Abandon","label_id":2},{"bbox":{"x0":599,"x1":623,"y0":1480,"y1":1506},"conf":0.5563,"label":"Abandon","label_id":2},{"bbox":{"x0":602,"x1":621,"y0":1482,"y1":1504},"conf":0.2878,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[604,1483],[619,1483],[619,1502],[604,1502]],"score":0.9258},{"poly":[[350,1392],[492,1396],[492,1419],[349,1416]],"score":0.8096},{"poly":[[738,1391],[775,1391],[775,1419],[738,1419]],"score":0.8147},{"poly":[[620,1388],[660,1393],[656,1422],[616,1417]],"score":0.757},{"poly":[[811,1370],[872,1366],[874,1394],[813,1398]],"score":0.8347},{"poly":[[743,1373],[767,1373],[767,1394],[743,1394]],"score":0.8328},{"poly":[[349,1369],[559,1373],[559,1396],[349,1392]],"score":0.755},{"poly":[[624,1371],[650,1371],[650,1394],[624,1394]],"score":0.7967},{"poly":[[351,1351],[487,1351],[487,1373],[351,1373]],"score":0.9812},{"poly":[[811,1347],[870,1343],[872,1372],[813,1377]],"score":0.7794},{"poly":[[742,1350],[770,1350],[770,1373],[742,1373]],"score":0.8664},{"poly":[[619,1348],[659,1348],[659,1374],[619,1374]],"score":0.88},{"poly":[[832,1330],[855,1330],[855,1350],[832,1350]],"score":0.7424},{"poly":[[351,1328],[482,1328],[482,1351],[351,1351]],"score":0.7847},{"poly":[[745,1328],[767,1328],[767,1350],[745,1350]],"score":0.9191},{"poly":[[629,1330],[647,1330],[647,1346],[629,1346]],"score":0.9084},{"poly":[[832,1308],[855,1308],[855,1330],[832,1330]],"score":0.8149},{"poly":[[351,1307],[560,1307],[560,1330],[351,1330]],"score":0.7935},{"poly":[[743,1307],[767,1307],[767,1328],[743,1328]],"score":0.8762},{"poly":[[625,1307],[650,1307],[650,1328],[625,1328]],"score":0.8192},{"poly":[[351,1285],[472,1285],[472,1308],[351,1308]],"score":0.7965},{"poly":[[813,1284],[873,1284],[873,1308],[813,1308]],"score":0.9159},{"poly":[[733,1284],[777,1284],[777,1308],[733,1308]],"score":0.9086},{"poly":[[619,1282],[659,1282],[659,1308],[619,1308]],"score":0.89},{"poly":[[351,1264],[527,1264],[527,1285],[351,1285]],"score":0.9512},{"poly":[[813,1259],[875,1259],[875,1289],[813,1289]],"score":0.7119},{"poly":[[728,1261],[783,1261],[783,1285],[728,1285]],"score":0.8889},{"poly":[[615,1261],[660,1261],[660,1287],[615,1287]],"score":0.8685},{"poly":[[351,1239],[492,1243],[492,1266],[351,1262]],"score":0.7799},{"poly":[[812,1239],[871,1239],[871,1264],[812,1264]],"score":0.8663},{"poly":[[728,1239],[783,1239],[783,1264],[728,1264]],"score":0.8443},{"poly":[[612,1239],[664,1239],[664,1264],[612,1264]],"score":0.8909},{"poly":[[351,1219],[422,1219],[422,1242],[351,1242]],"score":0.8444},{"poly":[[832,1219],[855,1219],[855,1241],[832,1241]],"score":0.7393},{"poly":[[740,1218],[768,1218],[768,1241],[740,1241]],"score":0.8276},{"poly":[[620,1216],[654,1216],[654,1242],[620,1242]],"score":0.8171},{"poly":[[579,1186],[797,1186],[797,1209],[579,1209]],"score":0.7858},{"poly":[[828,1186],[855,1186],[855,1209],[828,1209]],"score":0.819},{"poly":[[326,1158],[898,1158],[898,1180],[326,1180]],"score":0.8594},{"poly":[[138,1099],[910,1096],[910,1119],[138,1122]],"score":0.7111},{"poly":[[140,1077],[1083,1077],[1083,1099],[140,1099]],"score":0.8196},{"poly":[[140,1054],[1081,1054],[1081,1077],[140,1077]],"score":0.7029},{"poly":[[138,1033],[1081,1031],[1081,1054],[138,1056]],"score":0.7671},{"poly":[[141,1011],[1083,1011],[1083,1033],[141,1033]],"score":0.8382},{"poly":[[141,988],[1083,988],[1083,1011],[141,1011]],"score":0.7199},{"poly":[[140,967],[1084,967],[1084,990],[140,990]],"score":0.7153},{"poly":[[140,924],[358,924],[358,947],[140,947]],"score":0.7524},{"poly":[[141,876],[253,876],[253,894],[141,894]],"score":0.8811},{"poly":[[140,853],[1083,853],[1083,874],[140,874]],"score":0.8498},{"poly":[[140,830],[1081,830],[1081,853],[140,853]],"score":0.6917},{"poly":[[140,808],[1083,808],[1083,832],[140,832]],"score":0.723},{"poly":[[140,785],[1081,785],[1081,808],[140,808]],"score":0.7291},{"poly":[[140,739],[589,739],[589,761],[140,761]],"score":0.8238},{"poly":[[141,716],[1083,716],[1083,739],[141,739]],"score":0.7123},{"poly":[[140,695],[1081,695],[1081,716],[140,716]],"score":0.8249},{"poly":[[140,673],[1081,673],[1081,695],[140,695]],"score":0.7858},{"poly":[[140,640],[1046,640],[1046,662],[140,662]],"score":0.8224},{"poly":[[140,619],[1083,619],[1083,640],[140,640]],"score":0.8576},{"poly":[[141,596],[1083,596],[1083,617],[141,617]],"score":0.8409},{"poly":[[233,525],[464,528],[464,551],[233,548]],"score":0.7483},{"poly":[[233,505],[988,503],[988,526],[233,528]],"score":0.7421},{"poly":[[233,482],[986,482],[986,503],[233,503]],"score":0.7835},{"poly":[[703,429],[712,429],[712,439],[703,439]],"score":0.6153},{"poly":[[531,429],[542,429],[542,441],[531,441]],"score":0.7204},{"poly":[[601,392],[615,396],[610,413],[596,410]],"score":0.6565},{"poly":[[647,389],[742,389],[742,406],[647,406]],"score":0.8895},{"poly":[[712,350],[861,350],[861,371],[712,371]],"score":0.8263},{"poly":[[560,351],[647,351],[647,370],[560,370]],"score":0.8298},{"poly":[[349,350],[491,350],[491,371],[349,371]],"score":0.8251},{"poly":[[647,317],[742,317],[742,335],[647,335]],"score":0.8013},{"poly":[[712,277],[861,277],[861,299],[712,299]],"score":0.9013},{"poly":[[349,277],[489,277],[489,299],[349,299]],"score":0.8339},{"poly":[[557,277],[646,274],[647,293],[558,297]],"score":0.7257},{"poly":[[387,236],[456,240],[455,259],[385,255]],"score":0.7289},{"poly":[[893,206],[940,206],[940,224],[893,224]],"score":0.9342},{"poly":[[529,206],[645,206],[645,223],[529,223]],"score":0.9825},{"poly":[[729,199],[847,203],[846,226],[728,223]],"score":0.7584},{"poly":[[366,199],[476,203],[475,226],[366,223]],"score":0.7507},{"poly":[[279,203],[318,203],[318,228],[279,228]],"score":0.7896},{"poly":[[383,165],[461,169],[460,187],[382,183]],"score":0.8051},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7558},{"poly":[[560,64],[664,64],[664,92],[560,92]],"score":0.7978}],"page_no":5,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":556,"x1":1088,"y0":65,"y1":94},"conf":0.7425,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":919,"x1":1081,"y0":68,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":597,"x1":624,"y0":1478,"y1":1507},"conf":0.5304,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":604,"x1":620,"y0":1482,"y1":1500},"font_size":0.0,"text":"7"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":134,"x1":1090,"y0":141,"y1":350},"conf":0.9732,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":145,"y1":168},"font_size":3.15e-05,"text":"Sparsity Scaling LawWe develop a sparsity scaling law tailored for the Mixture-of-Experts (MoE) model family"},{"bbox":{"x0":141,"x1":1081,"y0":168,"y1":190},"font_size":3.15e-05,"text":"using Muon. Sparsity is defned as the ratio of the total number of experts to the number of activated experts. Throughi"},{"bbox":{"x0":140,"x1":1083,"y0":188,"y1":213},"font_size":3.15e-05,"text":"carefully controlled small-scale experiments, we observe that — under a fxed number of activated parameters (i.e.,i"},{"bbox":{"x0":138,"x1":1081,"y0":210,"y1":234},"font_size":3.15e-05,"text":"constant FLOPs) — increasing the total number of experts (i.e., increasing sparsity) consistently lowers both the training"},{"bbox":{"x0":140,"x1":1081,"y0":233,"y1":254},"font_size":3.15e-05,"text":"and validation loss, thereby enhancing overall model performance (Figure 5). Concretely, under the compute-optimal"},{"bbox":{"x0":141,"x1":1082,"y0":254,"y1":277},"font_size":3.15e-05,"text":"sparsity scaling law, achieving the same validation loss of 1.5, sparsity 48 reduces FLOPs by $1.69\\times,1.39\\times,$  and $1.15\\times$"},{"bbox":{"x0":140,"x1":1081,"y0":277,"y1":299},"font_size":3.15e-05,"text":"compared to sparsity levels 8, 16, and 32, respectively. Though increasing sparsity leads to better performance, this"},{"bbox":{"x0":141,"x1":1083,"y0":299,"y1":322},"font_size":3.15e-05,"text":"gain comes with increased infrastructure complexity. To balance model performance with cost, we adopt a sparsity of"},{"bbox":{"x0":138,"x1":660,"y0":317,"y1":343},"font_size":3.15e-05,"text":"48 for Kimi K2, activating 8 out of 384 experts per forward pass."}],"source":"layout det","text":"Sparsity Scaling LawWe develop a sparsity scaling law tailored for the Mixture-of-Experts (MoE) model family using Muon. Sparsity is defned as the ratio of the total number of experts to the number of activated experts. Throughi carefully controlled small-scale experiments, we observe that — under a fxed number of activated parameters (i.e.,i constant FLOPs) — increasing the total number of experts (i.e., increasing sparsity) consistently lowers both the training and validation loss, thereby enhancing overall model performance (Figure 5). Concretely, under the compute-optimal sparsity scaling law, achieving the same validation loss of 1.5, sparsity 48 reduces FLOPs by $1.69\\times,1.39\\times,$  and $1.15\\times$ compared to sparsity levels 8, 16, and 32, respectively. Though increasing sparsity leads to better performance, this gain comes with increased infrastructure complexity. To balance model performance with cost, we adopt a sparsity of 48 for Kimi K2, activating 8 out of 384 experts per forward pass."},{"bbox":{"x0":143,"x1":594,"y0":371,"y1":703},"conf":0.9544,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![11ed6a4cdf820f6353e2811ee0fb7663](imgs/11ed6a4cdf820f6353e2811ee0fb7663.jpg)"},{"bbox":{"x0":136,"x1":602,"y0":713,"y1":833},"conf":0.9581,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":141,"x1":595,"y0":718,"y1":739},"font_size":3.15e-05,"text":"Figure 5: Sparsity Scaling Law. Increasing sparsity leads"},{"bbox":{"x0":138,"x1":595,"y0":738,"y1":762},"font_size":3.15e-05,"text":"to improved model performance. We fxed the number ofi"},{"bbox":{"x0":140,"x1":595,"y0":762,"y1":784},"font_size":3.15e-05,"text":"activated experts to 8 and the number of shared experts"},{"bbox":{"x0":140,"x1":595,"y0":785,"y1":807},"font_size":3.15e-05,"text":"to 1, and varied the total number of experts, resulting in"},{"bbox":{"x0":140,"x1":439,"y0":805,"y1":827},"font_size":3.15e-05,"text":"models with different sparsity levels."}],"source":"layout det","text":"Figure 5: Sparsity Scaling Law. Increasing sparsity leads to improved model performance. We fxed the number ofi activated experts to 8 and the number of shared experts to 1, and varied the total number of experts, resulting in models with different sparsity levels."},{"bbox":{"x0":629,"x1":1083,"y0":372,"y1":703},"conf":0.958,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![62bd0134764b8affec17d56f4ca9dca6](imgs/62bd0134764b8affec17d56f4ca9dca6.jpg)"},{"bbox":{"x0":622,"x1":1089,"y0":714,"y1":833},"conf":0.9479,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":629,"x1":1083,"y0":718,"y1":739},"font_size":3.15e-05,"text":"Figure 6: Scaling curves for models with number of atten-"},{"bbox":{"x0":630,"x1":1081,"y0":742,"y1":759},"font_size":3.15e-05,"text":"tion heads equals to number of layers and their counter-"},{"bbox":{"x0":627,"x1":1083,"y0":762,"y1":784},"font_size":3.15e-05,"text":"parts with doubled attention heads. Doubling the number"},{"bbox":{"x0":629,"x1":1081,"y0":787,"y1":804},"font_size":3.15e-05,"text":"of attention heads leads to a reduction in validation loss"},{"bbox":{"x0":625,"x1":888,"y0":803,"y1":828},"font_size":3.15e-05,"text":"of approximately $0.5\\%$ to $1.2\\%.$"}],"source":"layout det","text":"Figure 6: Scaling curves for models with number of attention heads equals to number of layers and their counterparts with doubled attention heads. Doubling the number of attention heads leads to a reduction in validation loss of approximately $0.5\\%$ to $1.2\\%.$"},{"bbox":{"x0":136,"x1":1089,"y0":869,"y1":1142},"conf":0.9775,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":871,"y1":896},"font_size":3.15e-05,"text":"Number of Attention HeadsDeepSeek-V3 [10] sets the number of attention heads to roughly twice the number of"},{"bbox":{"x0":141,"x1":1083,"y0":896,"y1":917},"font_size":3.15e-05,"text":"model layers to better utilize memory bandwidth and enhance computational effciency. However, as the context lengthi"},{"bbox":{"x0":140,"x1":1083,"y0":917,"y1":939},"font_size":3.15e-05,"text":"increases, doubling the number of attention heads leads to signifcant inference overhead, reducing effciency at longerii"},{"bbox":{"x0":140,"x1":1083,"y0":939,"y1":961},"font_size":3.15e-05,"text":"sequence lengths. This becomes a major limitation in agentic applications, where effcient long context processing isi"},{"bbox":{"x0":140,"x1":1081,"y0":960,"y1":982},"font_size":3.15e-05,"text":"essential. For example, with a sequence length of 128k, increasing the number of attention heads from 64 to 128, while"},{"bbox":{"x0":141,"x1":1083,"y0":983,"y1":1005},"font_size":3.15e-05,"text":"keeping the total expert count fxed at 384, leads to ani $83\\%$  increase in inference FLOPs. To evaluate the impact of"},{"bbox":{"x0":140,"x1":1083,"y0":1005,"y1":1026},"font_size":3.15e-05,"text":"this design, we conduct controlled experiments comparing confgurations where the number of attention heads equalsi"},{"bbox":{"x0":140,"x1":1079,"y0":1025,"y1":1046},"font_size":3.15e-05,"text":"the number of layers against those with double number of heads, under varying training FLOPs. Under iso-token"},{"bbox":{"x0":140,"x1":1083,"y0":1048,"y1":1069},"font_size":3.15e-05,"text":"training conditions, we observe that doubling the attention heads yields only modest improvements in validation loss"},{"bbox":{"x0":140,"x1":1081,"y0":1070,"y1":1092},"font_size":3.15e-05,"text":"(ranging from $0.5\\%$ to $1.2\\%$  across different compute budgets (Figure 6). Given that sparsity 48 already offers strong"},{"bbox":{"x0":140,"x1":1081,"y0":1092,"y1":1114},"font_size":3.15e-05,"text":"performance, the marginal gains from doubling attention heads do not justify the inference cost. Therefore we choose"},{"bbox":{"x0":141,"x1":314,"y0":1117,"y1":1134},"font_size":3.15e-05,"text":"to 64 attention heads."}],"source":"layout det","text":"Number of Attention HeadsDeepSeek-V3 [10] sets the number of attention heads to roughly twice the number of model layers to better utilize memory bandwidth and enhance computational effciency. However, as the context lengthi increases, doubling the number of attention heads leads to signifcant inference overhead, reducing effciency at longerii sequence lengths. This becomes a major limitation in agentic applications, where effcient long context processing isi essential. For example, with a sequence length of 128k, increasing the number of attention heads from 64 to 128, while keeping the total expert count fxed at 384, leads to ani $83\\%$  increase in inference FLOPs. To evaluate the impact of this design, we conduct controlled experiments comparing confgurations where the number of attention heads equalsi the number of layers against those with double number of heads, under varying training FLOPs. Under iso-token training conditions, we observe that doubling the attention heads yields only modest improvements in validation loss(ranging from $0.5\\%$ to $1.2\\%$  across different compute budgets (Figure 6). Given that sparsity 48 already offers strong performance, the marginal gains from doubling attention heads do not justify the inference cost. Therefore we choose to 64 attention heads."},{"bbox":{"x0":136,"x1":398,"y0":1161,"y1":1194},"conf":0.8744,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":393,"y0":1163,"y1":1188},"font_size":3.15e-05,"text":"2.4Training Infrastructure"}],"source":"layout det","text":"2.4Training Infrastructure"},{"bbox":{"x0":136,"x1":357,"y0":1204,"y1":1235},"conf":0.8893,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":353,"y0":1206,"y1":1228},"font_size":3.15e-05,"text":"2.4.1Compute Cluster"}],"source":"layout det","text":"2.4.1Compute Cluster"},{"bbox":{"x0":137,"x1":1088,"y0":1242,"y1":1317},"conf":0.9453,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1246,"y1":1269},"font_size":3.15e-05,"text":"Kimi K2 was trained on a cluster equipped with NVIDIA H800 GPUs. Each node in the H800 cluster contains 2 TB"},{"bbox":{"x0":141,"x1":1081,"y0":1267,"y1":1289},"font_size":3.15e-05,"text":"RAM and 8 GPUs connected by NVLink and NVSwitch within nodes. Across different nodes, $8 \\times400$ Gbps RoCE"},{"bbox":{"x0":140,"x1":580,"y0":1290,"y1":1312},"font_size":3.15e-05,"text":"interconnects are utilized to facilitate communications."}],"source":"layout det","text":"Kimi K2 was trained on a cluster equipped with NVIDIA H800 GPUs. Each node in the H800 cluster contains 2 TB RAM and 8 GPUs connected by NVLink and NVSwitch within nodes. Across different nodes, $8 \\times400$ Gbps RoCE interconnects are utilized to facilitate communications."},{"bbox":{"x0":136,"x1":463,"y0":1336,"y1":1369},"conf":0.8931,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":459,"y0":1336,"y1":1363},"font_size":3.15e-05,"text":"2.4.2Parallelism for Model Scaling"}],"source":"layout det","text":"2.4.2Parallelism for Model Scaling"},{"bbox":{"x0":135,"x1":1088,"y0":1375,"y1":1452},"conf":0.9324,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1378,"y1":1399},"font_size":3.15e-05,"text":"Training of large language models often progresses under dynamic resource availability. Instead of optimizing one"},{"bbox":{"x0":141,"x1":1081,"y0":1401,"y1":1422},"font_size":3.15e-05,"text":"parallelism strategy that’s only applicable under specifc amount of resources, we pursue a fexible strategy that allowsil"},{"bbox":{"x0":140,"x1":1081,"y0":1421,"y1":1445},"font_size":3.15e-05,"text":"Kimi K2 to be trained on any number of nodes that is a multiple of 32. Our strategy leverages a combination of 16-way"}],"source":"layout det","text":"Training of large language models often progresses under dynamic resource availability. Instead of optimizing one parallelism strategy that’s only applicable under specifc amount of resources, we pursue a fexible strategy that allowsil Kimi K2 to be trained on any number of nodes that is a multiple of 32. Our strategy leverages a combination of 16-way"}],"formula_dets":[{"bbox":{"x0":770,"x1":815,"y0":805,"y1":826},"conf":0.8512,"label":"print_embedding","label_id":0},{"bbox":{"x0":257,"x1":301,"y0":1070,"y1":1090},"conf":0.8207,"label":"print_embedding","label_id":0},{"bbox":{"x0":917,"x1":978,"y0":1268,"y1":1289},"conf":0.8192,"label":"print_embedding","label_id":0},{"bbox":{"x0":587,"x1":626,"y0":983,"y1":1003},"conf":0.8183,"label":"print_embedding","label_id":0},{"bbox":{"x0":838,"x1":888,"y0":804,"y1":826},"conf":0.8153,"label":"print_embedding","label_id":0},{"bbox":{"x0":887,"x1":996,"y0":254,"y1":277},"conf":0.795,"label":"print_embedding","label_id":0},{"bbox":{"x0":325,"x1":370,"y0":1070,"y1":1091},"conf":0.7863,"label":"print_embedding","label_id":0},{"bbox":{"x0":1034,"x1":1082,"y0":256,"y1":275},"conf":0.675,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1089,"y0":869,"y1":1142},"conf":0.9775,"label":"Text","label_id":1},{"bbox":{"x0":134,"x1":1090,"y0":141,"y1":350},"conf":0.9732,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":602,"y0":713,"y1":833},"conf":0.9581,"label":"Figure caption","label_id":4},{"bbox":{"x0":629,"x1":1083,"y0":372,"y1":703},"conf":0.958,"label":"Figure","label_id":3},{"bbox":{"x0":143,"x1":594,"y0":371,"y1":703},"conf":0.9544,"label":"Figure","label_id":3},{"bbox":{"x0":622,"x1":1089,"y0":714,"y1":833},"conf":0.9479,"label":"Figure caption","label_id":4},{"bbox":{"x0":137,"x1":1088,"y0":1242,"y1":1317},"conf":0.9453,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1088,"y0":1375,"y1":1452},"conf":0.9324,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":463,"y0":1336,"y1":1369},"conf":0.8931,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":357,"y0":1204,"y1":1235},"conf":0.8893,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":398,"y0":1161,"y1":1194},"conf":0.8744,"label":"Title","label_id":0},{"bbox":{"x0":556,"x1":1088,"y0":65,"y1":94},"conf":0.7425,"label":"Abandon","label_id":2},{"bbox":{"x0":597,"x1":624,"y0":1478,"y1":1507},"conf":0.5304,"label":"Abandon","label_id":2},{"bbox":{"x0":600,"x1":622,"y0":1479,"y1":1506},"conf":0.2153,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[604,1482],[620,1482],[620,1500],[604,1500]],"score":0.7925},{"poly":[[140,1421],[1081,1422],[1081,1445],[140,1444]],"score":0.7309},{"poly":[[141,1401],[1081,1401],[1081,1422],[141,1422]],"score":0.8205},{"poly":[[141,1378],[1081,1378],[1081,1399],[141,1399]],"score":0.8064},{"poly":[[138,1336],[459,1340],[459,1363],[138,1360]],"score":0.7281},{"poly":[[140,1290],[580,1290],[580,1312],[140,1312]],"score":0.8218},{"poly":[[141,1267],[1081,1267],[1081,1289],[141,1289]],"score":0.834},{"poly":[[141,1246],[1081,1246],[1081,1269],[141,1269]],"score":0.7002},{"poly":[[140,1206],[353,1206],[353,1228],[140,1228]],"score":0.8574},{"poly":[[140,1163],[393,1165],[392,1188],[140,1186]],"score":0.8158},{"poly":[[141,1117],[314,1117],[314,1134],[141,1134]],"score":0.9878},{"poly":[[140,1092],[1081,1092],[1081,1114],[140,1114]],"score":0.8089},{"poly":[[140,1071],[1081,1071],[1081,1092],[140,1092]],"score":0.8248},{"poly":[[140,1048],[1083,1048],[1083,1069],[140,1069]],"score":0.8056},{"poly":[[140,1025],[1079,1025],[1079,1046],[140,1046]],"score":0.7376},{"poly":[[140,1005],[1083,1005],[1083,1026],[140,1026]],"score":0.7929},{"poly":[[141,983],[1083,983],[1083,1005],[141,1005]],"score":0.7829},{"poly":[[140,960],[1081,960],[1081,982],[140,982]],"score":0.8031},{"poly":[[140,939],[1083,939],[1083,960],[140,960]],"score":0.7671},{"poly":[[140,917],[1083,917],[1083,939],[140,939]],"score":0.7526},{"poly":[[141,896],[1083,896],[1083,917],[141,917]],"score":0.806},{"poly":[[140,871],[1083,873],[1083,896],[140,894]],"score":0.7228},{"poly":[[625,807],[888,803],[888,825],[625,828]],"score":0.8073},{"poly":[[140,805],[439,805],[439,827],[140,827]],"score":0.7589},{"poly":[[629,787],[1081,787],[1081,804],[629,804]],"score":0.9684},{"poly":[[140,785],[595,785],[595,807],[140,807]],"score":0.8282},{"poly":[[627,762],[1083,762],[1083,784],[627,784]],"score":0.7652},{"poly":[[140,762],[595,762],[595,784],[140,784]],"score":0.7566},{"poly":[[630,742],[1081,742],[1081,759],[630,759]],"score":0.994},{"poly":[[138,739],[595,738],[595,761],[138,762]],"score":0.7674},{"poly":[[629,718],[1083,718],[1083,739],[629,739]],"score":0.8003},{"poly":[[141,718],[595,718],[595,739],[141,739]],"score":0.8521},{"poly":[[837,681],[916,681],[916,698],[837,698]],"score":0.9527},{"poly":[[346,681],[424,681],[424,698],[346,698]],"score":0.9632},{"poly":[[476,667],[504,662],[508,682],[480,687]],"score":0.7228},{"poly":[[215,667],[241,667],[241,686],[215,686]],"score":0.7817},{"poly":[[953,662],[980,662],[980,681],[953,681]],"score":0.7113},{"poly":[[657,653],[682,653],[682,670],[657,670]],"score":0.928},{"poly":[[710,644],[775,644],[775,660],[710,660]],"score":0.8058},{"poly":[[165,644],[183,644],[183,658],[165,658]],"score":0.8068},{"poly":[[557,640],[567,640],[567,655],[557,655]],"score":0.9687},{"poly":[[712,620],[775,620],[775,637],[712,637]],"score":0.825},{"poly":[[654,619],[682,619],[682,637],[654,637]],"score":0.7544},{"poly":[[712,607],[777,609],[776,626],[712,624]],"score":0.6937},{"poly":[[708,597],[881,597],[881,614],[708,614]],"score":0.7914},{"poly":[[165,594],[181,594],[181,609],[165,609]],"score":0.8334},{"poly":[[655,582],[680,582],[680,602],[655,602]],"score":0.8079},{"poly":[[654,548],[682,548],[682,568],[654,568]],"score":0.668},{"poly":[[656,509],[683,514],[679,536],[652,530]],"score":0.6929},{"poly":[[657,446],[682,446],[682,462],[657,462]],"score":0.9191},{"poly":[[166,446],[181,446],[181,455],[166,455]],"score":0.7039},{"poly":[[529,429],[577,429],[577,441],[529,441]],"score":0.7716},{"poly":[[527,416],[579,416],[579,432],[527,432]],"score":0.7363},{"poly":[[654,409],[682,409],[682,427],[654,427]],"score":0.8605},{"poly":[[531,406],[577,406],[577,417],[531,417]],"score":0.8716},{"poly":[[527,393],[579,393],[579,409],[527,409]],"score":0.8178},{"poly":[[165,391],[183,391],[183,406],[165,406]],"score":0.8931},{"poly":[[529,383],[574,383],[574,394],[529,394]],"score":0.6475},{"poly":[[654,375],[684,375],[684,393],[654,393]],"score":0.8318},{"poly":[[138,317],[660,320],[660,343],[138,340]],"score":0.6974},{"poly":[[141,299],[1083,299],[1083,322],[141,322]],"score":0.6933},{"poly":[[140,277],[1081,277],[1081,299],[140,299]],"score":0.7932},{"poly":[[141,256],[1083,256],[1083,277],[141,277]],"score":0.7976},{"poly":[[140,233],[1081,233],[1081,254],[140,254]],"score":0.8184},{"poly":[[138,210],[1081,211],[1081,234],[138,233]],"score":0.6849},{"poly":[[140,188],[1083,190],[1083,213],[140,211]],"score":0.6854},{"poly":[[141,168],[1081,168],[1081,190],[141,190]],"score":0.8257},{"poly":[[141,145],[1079,145],[1079,168],[141,168]],"score":0.7361},{"poly":[[920,68],[1081,71],[1081,93],[919,89]],"score":0.7973},{"poly":[[560,64],[664,64],[664,92],[560,92]],"score":0.7514}],"page_no":6,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.7523,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":919,"x1":1081,"y0":68,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":600,"x1":623,"y0":1480,"y1":1506},"conf":0.5117,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":602,"x1":622,"y0":1480,"y1":1503},"font_size":0.0,"text":"8"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":156,"x1":1066,"y0":141,"y1":318},"conf":0.9681,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![542283386872f86ee28651b1b521712e](imgs/542283386872f86ee28651b1b521712e.jpg)"},{"bbox":{"x0":250,"x1":970,"y0":324,"y1":353},"conf":0.9365,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":253,"x1":966,"y0":327,"y1":348},"font_size":-34110000.0,"text":"Figure 7: Computation, communication and offoading overlapped in different PP phases.l"}],"source":"layout det","text":"Figure 7: Computation, communication and offoading overlapped in different PP phases.l"},{"bbox":{"x0":136,"x1":1086,"y0":398,"y1":448},"conf":0.9119,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":398,"y1":422},"font_size":-34110000.0,"text":"Pipeline Parallelism (PP) with virtual stages [28, 53, 38, 57, 47, 21], 16-way Expert Parallelism (EP) [39], and ZeRO-1"},{"bbox":{"x0":141,"x1":321,"y0":422,"y1":444},"font_size":-34110000.0,"text":"Data Parallelism [60]."}],"source":"layout det","text":"Pipeline Parallelism (PP) with virtual stages [28, 53, 38, 57, 47, 21], 16-way Expert Parallelism (EP) [39], and ZeRO-1 Data Parallelism [60]."},{"bbox":{"x0":137,"x1":1087,"y0":452,"y1":568},"conf":0.9649,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":454,"y1":475},"font_size":-34110000.0,"text":"Under this setting, storing the model parameters in BF16 and their gradient accumulation buffer in FP32 requires"},{"bbox":{"x0":138,"x1":1081,"y0":475,"y1":500},"font_size":-34110000.0,"text":"approximately 6 TB of GPU memory, distributed over a model-parallel group of 256 GPUs. Placement of optimizer"},{"bbox":{"x0":140,"x1":1083,"y0":498,"y1":520},"font_size":-34110000.0,"text":"states depends on the training confgurations. When the total number of training nodes is large, the optimizer states arei"},{"bbox":{"x0":140,"x1":1081,"y0":520,"y1":541},"font_size":-34110000.0,"text":"distributed, reducing its per-device memory footprint to a negligible level. When the total number of training nodes is"},{"bbox":{"x0":140,"x1":637,"y0":541,"y1":564},"font_size":-34110000.0,"text":"small (e.g., 32), we can offoad some optimizer states to CPU.l"}],"source":"layout det","text":"Under this setting, storing the model parameters in BF16 and their gradient accumulation buffer in FP32 requires approximately 6 TB of GPU memory, distributed over a model-parallel group of 256 GPUs. Placement of optimizer states depends on the training confgurations. When the total number of training nodes is large, the optimizer states arei distributed, reducing its per-device memory footprint to a negligible level. When the total number of training nodes is small (e.g., 32), we can offoad some optimizer states to CPU.l"},{"bbox":{"x0":138,"x1":1088,"y0":573,"y1":666},"conf":0.9551,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":573,"y1":597},"font_size":-34110000.0,"text":"This approach allows us to reuse an identical parallelism confguration for both small- and large-scale experiments,i"},{"bbox":{"x0":138,"x1":1081,"y0":594,"y1":619},"font_size":-34110000.0,"text":"while letting each GPU hold approximately 30 GB of GPU memory for all states. The rest of the GPU memory are used"},{"bbox":{"x0":141,"x1":1083,"y0":619,"y1":640},"font_size":-34110000.0,"text":"for activations, as described in Sec. 2.4.3. Such a consistent design is important for research effciency, as it simplifesii"},{"bbox":{"x0":143,"x1":647,"y0":644,"y1":660},"font_size":-34110000.0,"text":"the system and substantially accelerates experimental iteration."}],"source":"layout det","text":"This approach allows us to reuse an identical parallelism confguration for both small- and large-scale experiments,i while letting each GPU hold approximately 30 GB of GPU memory for all states. The rest of the GPU memory are used for activations, as described in Sec. 2.4.3. Such a consistent design is important for research effciency, as it simplifesii the system and substantially accelerates experimental iteration."},{"bbox":{"x0":138,"x1":1086,"y0":691,"y1":831},"conf":0.9678,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":693,"y1":716},"font_size":-34110000.0,"text":"EP communication overlap with interleaved 1F1BBy increasing the number of warm-up micro-batches, we can"},{"bbox":{"x0":141,"x1":1083,"y0":716,"y1":738},"font_size":-34110000.0,"text":"overlap EP all-to-all communication with computation under the standard interleaved 1F1B schedule [21, 53]. In"},{"bbox":{"x0":141,"x1":1079,"y0":741,"y1":757},"font_size":-34110000.0,"text":"comparison, DualPipe [10] doubles the memory required for parameters and gradients, necessitating an increase in"},{"bbox":{"x0":141,"x1":1081,"y0":761,"y1":782},"font_size":-34110000.0,"text":"parallelism to compensate. Increasing PP introduces more bubbles, while increasing EP, as discussed below, incurs"},{"bbox":{"x0":140,"x1":1083,"y0":780,"y1":805},"font_size":-34110000.0,"text":"higher overhead. The additional costs are prohibitively high for training a large model with over 1 trillion parameters"},{"bbox":{"x0":138,"x1":457,"y0":805,"y1":827},"font_size":-34110000.0,"text":"and thus we opted not to use DualPipe."}],"source":"layout det","text":"EP communication overlap with interleaved 1F1BBy increasing the number of warm-up micro-batches, we can overlap EP all-to-all communication with computation under the standard interleaved 1F1B schedule [21, 53]. In comparison, DualPipe [10] doubles the memory required for parameters and gradients, necessitating an increase in parallelism to compensate. Increasing PP introduces more bubbles, while increasing EP, as discussed below, incurs higher overhead. The additional costs are prohibitively high for training a large model with over 1 trillion parameters and thus we opted not to use DualPipe."},{"bbox":{"x0":136,"x1":1087,"y0":834,"y1":930},"conf":0.9567,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":837,"y1":858},"font_size":-34110000.0,"text":"However, interleaved 1F1B splits the model into more stages, introducing non-trivial PP communication overhead. To"},{"bbox":{"x0":141,"x1":1081,"y0":858,"y1":879},"font_size":-34110000.0,"text":"mitigate this cost, we decouple the weight-gradient computation from each micro-batch’s backward pass and execute"},{"bbox":{"x0":140,"x1":1079,"y0":881,"y1":903},"font_size":-34110000.0,"text":"it in parallel with the corresponding PP communication. Consequently, all PP communications can be effectively"},{"bbox":{"x0":138,"x1":481,"y0":901,"y1":926},"font_size":-34110000.0,"text":"overlapped except for the warm-up phase."}],"source":"layout det","text":"However, interleaved 1F1B splits the model into more stages, introducing non-trivial PP communication overhead. To mitigate this cost, we decouple the weight-gradient computation from each micro-batch’s backward pass and execute it in parallel with the corresponding PP communication. Consequently, all PP communications can be effectively overlapped except for the warm-up phase."},{"bbox":{"x0":137,"x1":1086,"y0":953,"y1":1071},"conf":0.967,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":955,"y1":977},"font_size":-34110000.0,"text":"Smaller EP sizeTo ensure full computation-communication overlap during the 1F1B stage, the reduced attention"},{"bbox":{"x0":138,"x1":1081,"y0":977,"y1":1002},"font_size":-34110000.0,"text":"computation time in K2 (which has 64 attention heads compared to 128 heads in DeepSeek-V3) necessitates minimizing"},{"bbox":{"x0":140,"x1":1081,"y0":1000,"y1":1023},"font_size":-34110000.0,"text":"the time of EP operations. This is achieved by adopting the smallest feasible EP parallelization strategy, specifcallyi"},{"bbox":{"x0":142,"x1":1081,"y0":1020,"y1":1044},"font_size":-34110000.0,"text":"$\\mathrm{EP}=16.$  Utilizing a smaller EP group also relaxes expert-balance constraints, allowing for near-optimal speed to be"},{"bbox":{"x0":138,"x1":399,"y0":1043,"y1":1068},"font_size":-34110000.0,"text":"achieved without further tuning."}],"source":"layout det","text":"Smaller EP sizeTo ensure full computation-communication overlap during the 1F1B stage, the reduced attention computation time in K2 (which has 64 attention heads compared to 128 heads in DeepSeek-V3) necessitates minimizing the time of EP operations. This is achieved by adopting the smallest feasible EP parallelization strategy, specifcallyi $\\mathrm{EP}=16.$  Utilizing a smaller EP group also relaxes expert-balance constraints, allowing for near-optimal speed to be achieved without further tuning."},{"bbox":{"x0":138,"x1":389,"y0":1096,"y1":1123},"conf":0.818,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":386,"y0":1097,"y1":1119},"font_size":-34110000.0,"text":"2.4.3Activation Reduction"}],"source":"layout det","text":"2.4.3Activation Reduction"},{"bbox":{"x0":137,"x1":1088,"y0":1137,"y1":1231},"conf":0.9522,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1138,"y1":1162},"font_size":-34110000.0,"text":"After reserving space for parameters, gradient buffers, and optimizer states, the remaining GPU memory on each device"},{"bbox":{"x0":140,"x1":1081,"y0":1160,"y1":1182},"font_size":-34110000.0,"text":"is insuffcient to hold the full MoE activations. To ensure the activation memory fts within the constraints, especiallyii"},{"bbox":{"x0":140,"x1":1081,"y0":1180,"y1":1206},"font_size":-34110000.0,"text":"for the initial pipeline stages that accumulate the largest activations during the 1F1B warm-up phase, the following"},{"bbox":{"x0":138,"x1":348,"y0":1203,"y1":1228},"font_size":-34110000.0,"text":"techniques are employed."}],"source":"layout det","text":"After reserving space for parameters, gradient buffers, and optimizer states, the remaining GPU memory on each device is insuffcient to hold the full MoE activations. To ensure the activation memory fts within the constraints, especiallyii for the initial pipeline stages that accumulate the largest activations during the 1F1B warm-up phase, the following techniques are employed."},{"bbox":{"x0":137,"x1":1088,"y0":1256,"y1":1351},"conf":0.9595,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1259,"y1":1280},"font_size":-34110000.0,"text":"Selective recomputationRecomputation is applied to inexpensive, high-footprint stages, including LayerNorm,"},{"bbox":{"x0":141,"x1":1081,"y0":1280,"y1":1304},"font_size":-34110000.0,"text":"SwiGLU, and MLA up-projections [10]. Additionally, MoE down-projections are recomputed during training to further"},{"bbox":{"x0":138,"x1":1081,"y0":1300,"y1":1325},"font_size":-34110000.0,"text":"reduce activation memory. While optional, this recomputation maintains adequate GPU memory, preventing crashes"},{"bbox":{"x0":141,"x1":555,"y0":1325,"y1":1346},"font_size":-34110000.0,"text":"caused by expert imbalance in early training stages."}],"source":"layout det","text":"Selective recomputationRecomputation is applied to inexpensive, high-footprint stages, including LayerNorm,SwiGLU, and MLA up-projections [10]. Additionally, MoE down-projections are recomputed during training to further reduce activation memory. While optional, this recomputation maintains adequate GPU memory, preventing crashes caused by expert imbalance in early training stages."},{"bbox":{"x0":137,"x1":1087,"y0":1376,"y1":1451},"conf":0.9262,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1378,"y1":1399},"font_size":-34110000.0,"text":"FP8 storage for insensitive activationsInputs of MoE up-projections and SwiGLU are compressed to FP8-E4M3 in"},{"bbox":{"x0":141,"x1":1083,"y0":1398,"y1":1422},"font_size":-34110000.0,"text":"$1 \\times128$ tiles with FP32 scales. Small-scale experiments show no measurable loss increase. Due to potential risks of"},{"bbox":{"x0":141,"x1":990,"y0":1422,"y1":1445},"font_size":-34110000.0,"text":"performance degradation that we observed during preliminary study, we do not apply FP8 in computation."}],"source":"layout det","text":"FP8 storage for insensitive activationsInputs of MoE up-projections and SwiGLU are compressed to FP8-E4M3 in $1 \\times128$ tiles with FP32 scales. Small-scale experiments show no measurable loss increase. Due to potential risks of performance degradation that we observed during preliminary study, we do not apply FP8 in computation."}],"formula_dets":[{"bbox":{"x0":141,"x1":204,"y0":1402,"y1":1421},"conf":0.786,"label":"print_embedding","label_id":0},{"bbox":{"x0":142,"x1":213,"y0":1023,"y1":1042},"conf":0.7553,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":156,"x1":1066,"y0":141,"y1":318},"conf":0.9681,"label":"Figure","label_id":3},{"bbox":{"x0":138,"x1":1086,"y0":691,"y1":831},"conf":0.9678,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":953,"y1":1071},"conf":0.967,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":452,"y1":568},"conf":0.9649,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":1256,"y1":1351},"conf":0.9595,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1087,"y0":834,"y1":930},"conf":0.9567,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":573,"y1":666},"conf":0.9551,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":1137,"y1":1231},"conf":0.9522,"label":"Text","label_id":1},{"bbox":{"x0":250,"x1":970,"y0":324,"y1":353},"conf":0.9365,"label":"Figure caption","label_id":4},{"bbox":{"x0":137,"x1":1087,"y0":1376,"y1":1451},"conf":0.9262,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":398,"y1":448},"conf":0.9119,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":389,"y0":1096,"y1":1123},"conf":0.818,"label":"Title","label_id":0},{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.7523,"label":"Abandon","label_id":2},{"bbox":{"x0":600,"x1":623,"y0":1480,"y1":1506},"conf":0.5117,"label":"Abandon","label_id":2},{"bbox":{"x0":602,"x1":621,"y0":1482,"y1":1504},"conf":0.378,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[602,1480],[622,1480],[622,1503],[602,1503]],"score":0.8253},{"poly":[[141,1422],[990,1422],[990,1445],[141,1445]],"score":0.7121},{"poly":[[140,1398],[1083,1399],[1083,1422],[140,1421]],"score":0.7601},{"poly":[[141,1378],[1081,1378],[1081,1399],[141,1399]],"score":0.8236},{"poly":[[141,1325],[555,1325],[555,1346],[141,1346]],"score":0.8464},{"poly":[[138,1300],[1081,1302],[1081,1325],[138,1323]],"score":0.7325},{"poly":[[141,1280],[1081,1280],[1081,1304],[141,1304]],"score":0.6959},{"poly":[[141,1259],[1083,1259],[1083,1280],[141,1280]],"score":0.832},{"poly":[[138,1205],[347,1203],[348,1226],[138,1228]],"score":0.7631},{"poly":[[140,1180],[1081,1183],[1081,1206],[140,1203]],"score":0.6906},{"poly":[[140,1160],[1081,1160],[1081,1181],[140,1181]],"score":0.8002},{"poly":[[140,1138],[1081,1138],[1081,1162],[140,1162]],"score":0.7011},{"poly":[[141,1097],[386,1097],[386,1119],[141,1119]],"score":0.8207},{"poly":[[138,1043],[399,1044],[399,1068],[138,1066]],"score":0.7164},{"poly":[[138,1020],[1081,1021],[1081,1044],[138,1043]],"score":0.7477},{"poly":[[140,1000],[1081,1000],[1081,1023],[140,1023]],"score":0.6821},{"poly":[[138,977],[1081,978],[1081,1002],[138,1000]],"score":0.7333},{"poly":[[140,955],[1081,955],[1081,977],[140,977]],"score":0.8325},{"poly":[[138,901],[481,903],[481,926],[138,924]],"score":0.7635},{"poly":[[140,881],[1079,881],[1079,903],[140,903]],"score":0.8206},{"poly":[[141,858],[1081,858],[1081,879],[141,879]],"score":0.8032},{"poly":[[141,837],[1081,837],[1081,858],[141,858]],"score":0.8286},{"poly":[[138,805],[457,805],[457,827],[138,827]],"score":0.8133},{"poly":[[140,780],[1083,782],[1083,805],[140,804]],"score":0.7735},{"poly":[[141,761],[1081,761],[1081,782],[141,782]],"score":0.7897},{"poly":[[141,741],[1079,741],[1079,757],[141,757]],"score":0.9754},{"poly":[[141,716],[1083,716],[1083,738],[141,738]],"score":0.8252},{"poly":[[141,693],[1079,693],[1079,716],[141,716]],"score":0.7128},{"poly":[[143,644],[647,644],[647,660],[143,660]],"score":0.9795},{"poly":[[141,619],[1083,619],[1083,640],[141,640]],"score":0.832},{"poly":[[138,594],[1081,596],[1081,619],[138,617]],"score":0.7184},{"poly":[[140,573],[1081,574],[1081,597],[140,596]],"score":0.7662},{"poly":[[140,541],[637,541],[637,563],[140,563]],"score":0.7588},{"poly":[[140,520],[1081,520],[1081,541],[140,541]],"score":0.8275},{"poly":[[140,498],[1083,498],[1083,520],[140,520]],"score":0.808},{"poly":[[138,477],[1081,475],[1081,498],[138,500]],"score":0.7492},{"poly":[[141,454],[1081,454],[1081,475],[141,475]],"score":0.8223},{"poly":[[141,422],[321,422],[321,444],[141,444]],"score":0.7658},{"poly":[[141,399],[1081,398],[1081,421],[141,422]],"score":0.7722},{"poly":[[253,327],[966,327],[966,348],[253,348]],"score":0.8743},{"poly":[[253,297],[274,297],[274,309],[253,309]],"score":0.7298},{"poly":[[956,294],[1056,294],[1056,310],[956,310]],"score":0.8065},{"poly":[[830,292],[945,292],[945,309],[830,309]],"score":0.6713},{"poly":[[679,294],[753,294],[753,310],[679,310]],"score":0.9553},{"poly":[[486,290],[549,294],[548,312],[485,308]],"score":0.7861},{"poly":[[290,290],[348,294],[347,312],[289,308]],"score":0.783},{"poly":[[953,271],[968,271],[968,280],[953,280]],"score":0.6873},{"poly":[[293,266],[363,266],[363,282],[293,282]],"score":0.7064},{"poly":[[768,254],[782,254],[782,271],[768,271]],"score":0.6438},{"poly":[[640,256],[652,256],[652,264],[640,264]],"score":0.7944},{"poly":[[471,256],[482,256],[482,267],[471,267]],"score":0.7974},{"poly":[[557,254],[565,254],[565,264],[557,264]],"score":0.6142},{"poly":[[511,252],[527,252],[527,267],[511,267]],"score":0.7375},{"poly":[[276,251],[349,251],[349,269],[276,269]],"score":0.6257},{"poly":[[682,251],[695,251],[695,266],[682,266]],"score":0.7405},{"poly":[[173,244],[239,244],[239,262],[173,262]],"score":0.8111},{"poly":[[349,241],[373,241],[373,252],[349,252]],"score":0.6862},{"poly":[[722,236],[742,236],[742,271],[722,271]],"score":0.6419},{"poly":[[682,238],[695,238],[695,254],[682,254]],"score":0.7177},{"poly":[[765,228],[785,228],[785,239],[765,239]],"score":0.6756},{"poly":[[406,228],[421,228],[421,249],[406,249]],"score":0.7138},{"poly":[[249,221],[374,221],[374,239],[249,239]],"score":0.6612},{"poly":[[674,185],[708,185],[708,196],[674,196]],"score":0.8584},{"poly":[[575,185],[605,185],[605,196],[575,196]],"score":0.9148},{"poly":[[321,185],[349,185],[349,196],[321,196]],"score":0.8675},{"poly":[[875,183],[900,183],[900,196],[875,196]],"score":0.6994},{"poly":[[188,183],[225,183],[225,196],[188,196]],"score":0.7673},{"poly":[[309,170],[333,170],[333,182],[309,182]],"score":0.933},{"poly":[[171,168],[239,168],[239,185],[171,185]],"score":0.8046},{"poly":[[935,168],[960,168],[960,185],[935,185]],"score":0.7295},{"poly":[[848,168],[871,168],[871,182],[848,182]],"score":0.8063},{"poly":[[674,167],[728,167],[728,183],[674,183]],"score":0.8004},{"poly":[[619,167],[647,167],[647,185],[619,185]],"score":0.7217},{"poly":[[534,167],[594,167],[594,183],[534,183]],"score":0.7488},{"poly":[[394,168],[421,168],[421,182],[394,182]],"score":0.7054},{"poly":[[679,155],[725,155],[725,167],[679,167]],"score":0.7818},{"poly":[[349,155],[381,155],[381,168],[349,168]],"score":0.6261},{"poly":[[180,153],[233,153],[233,170],[180,170]],"score":0.8497},{"poly":[[278,152],[306,152],[306,170],[278,170]],"score":0.806},{"poly":[[920,68],[1081,71],[1081,93],[919,89]],"score":0.7731},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8185}],"page_no":7,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":67,"y1":93},"conf":0.8123,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1081,"y0":69,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":600,"x1":622,"y0":1480,"y1":1505},"conf":0.4256,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":604,"x1":619,"y0":1483,"y1":1502},"font_size":0.0,"text":"9"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":1087,"y0":143,"y1":282},"conf":0.9688,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":147,"y1":170},"font_size":-210000.0,"text":"Activation CPU offoadAll remaining activations are offoaded to CPU RAM. A copy engine is responsible forll"},{"bbox":{"x0":141,"x1":1079,"y0":170,"y1":191},"font_size":-210000.0,"text":"streaming the offoad and onload, overlapping with both computation and communication kernels. During the 1F1Bl"},{"bbox":{"x0":141,"x1":1081,"y0":190,"y1":215},"font_size":-210000.0,"text":"phase, we offoad the forward activations of the previous micro-batch while prefetching the backward activations of thel"},{"bbox":{"x0":141,"x1":1079,"y0":213,"y1":234},"font_size":-210000.0,"text":"next. The warm-up and cool-down phases are handled similarly and the overall pattern is shown in Figure 7. Although"},{"bbox":{"x0":141,"x1":1081,"y0":234,"y1":256},"font_size":-210000.0,"text":"offoading may slightly affect EP traffc due to PCIe traffc congestion, our tests show that EP communication remainslii"},{"bbox":{"x0":139,"x1":283,"y0":254,"y1":282},"font_size":-210000.0,"text":"fully overlapped."}],"source":"layout det","text":"Activation CPU offoadAll remaining activations are offoaded to CPU RAM. A copy engine is responsible forll streaming the offoad and onload, overlapping with both computation and communication kernels. During the 1F1Bl phase, we offoad the forward activations of the previous micro-batch while prefetching the backward activations of thel next. The warm-up and cool-down phases are handled similarly and the overall pattern is shown in Figure 7. Although offoading may slightly affect EP traffc due to PCIe traffc congestion, our tests show that EP communication remainslii fully overlapped."},{"bbox":{"x0":138,"x1":324,"y0":300,"y1":328},"conf":0.9041,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":321,"y0":300,"y1":325},"font_size":-210000.0,"text":"2.5Training recipe"}],"source":"layout det","text":"2.5Training recipe"},{"bbox":{"x0":137,"x1":1088,"y0":340,"y1":458},"conf":0.9588,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":343,"y1":365},"font_size":-210000.0,"text":"We pre-trained the model with a 4,096-token context window using the MuonClip optimizer (Algorithm 1) and the"},{"bbox":{"x0":140,"x1":1081,"y0":363,"y1":388},"font_size":-210000.0,"text":"WSD learning rate schedule [25], processing a total of 15.5T tokens. The frst 10T tokens were trained with a constanti"},{"bbox":{"x0":141,"x1":1081,"y0":388,"y1":409},"font_size":-210000.0,"text":"learning rate of 2e-4 after a 500-step warm-up, followed by 5.5T tokens with a cosine decay from 2e-4 to 2e-5. Weight"},{"bbox":{"x0":140,"x1":1081,"y0":409,"y1":432},"font_size":-210000.0,"text":"decay was set to 0.1 throughout, and the global batch size was held at 67M tokens. The overall training curve is shown"},{"bbox":{"x0":141,"x1":238,"y0":434,"y1":452},"font_size":-210000.0,"text":"in Figure 3."}],"source":"layout det","text":"We pre-trained the model with a 4,096-token context window using the MuonClip optimizer (Algorithm 1) and the WSD learning rate schedule [25], processing a total of 15.5T tokens. The frst 10T tokens were trained with a constanti learning rate of 2e-4 after a 500-step warm-up, followed by 5.5T tokens with a cosine decay from 2e-4 to 2e-5. Weight decay was set to 0.1 throughout, and the global batch size was held at 67M tokens. The overall training curve is shown in Figure 3."},{"bbox":{"x0":137,"x1":1088,"y0":461,"y1":555},"conf":0.9553,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1078,"y0":462,"y1":483},"font_size":-210000.0,"text":"Towards the end of pre-training, we conducted an annealing phase followed by a long-context activation stage. The"},{"bbox":{"x0":141,"x1":1081,"y0":485,"y1":508},"font_size":-210000.0,"text":"batch size was kept constant at 67M tokens, while the learning rate was decayed from 2e-5 to 7e-6. In this phase, the"},{"bbox":{"x0":141,"x1":1081,"y0":508,"y1":530},"font_size":-210000.0,"text":"model was trained on 400 billion tokens with a 4k sequence length, followed by an additional 60 billion tokens with a"},{"bbox":{"x0":140,"x1":928,"y0":526,"y1":553},"font_size":-210000.0,"text":"32k sequence length. To extend the context window to 128k, we employed the YaRN method [55]."}],"source":"layout det","text":"Towards the end of pre-training, we conducted an annealing phase followed by a long-context activation stage. The batch size was kept constant at 67M tokens, while the learning rate was decayed from 2e-5 to 7e-6. In this phase, the model was trained on 400 billion tokens with a 4k sequence length, followed by an additional 60 billion tokens with a 32k sequence length. To extend the context window to 128k, we employed the YaRN method [55]."},{"bbox":{"x0":138,"x1":325,"y0":578,"y1":611},"conf":0.8993,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":321,"y0":576,"y1":609},"font_size":-210000.0,"text":"3Post-Training"}],"source":"layout det","text":"3Post-Training"},{"bbox":{"x0":137,"x1":398,"y0":625,"y1":654},"conf":0.9033,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":394,"y0":625,"y1":654},"font_size":-210000.0,"text":"3.1Supervised Fine-Tuning"}],"source":"layout det","text":"3.1Supervised Fine-Tuning"},{"bbox":{"x0":137,"x1":1088,"y0":665,"y1":740},"conf":0.9383,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":667,"y1":691},"font_size":-210000.0,"text":"We employ the Muon optimizer [33] in our post-training and recommend its use for fne-tuning with K2. This followsi"},{"bbox":{"x0":141,"x1":1081,"y0":691,"y1":714},"font_size":-210000.0,"text":"from the conclusion of our previous work [46] that a Muon-pre-trained checkpoint produces the best performance with"},{"bbox":{"x0":139,"x1":290,"y0":709,"y1":738},"font_size":-210000.0,"text":"Muon fne-tuning.i"}],"source":"layout det","text":"We employ the Muon optimizer [33] in our post-training and recommend its use for fne-tuning with K2. This followsi from the conclusion of our previous work [46] that a Muon-pre-trained checkpoint produces the best performance with Muon fne-tuning.i"},{"bbox":{"x0":137,"x1":1088,"y0":742,"y1":902},"conf":0.9726,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":746,"y1":767},"font_size":-210000.0,"text":"We construct a large-scale instruction-tuning dataset spanning diverse domains, guided by two core principles: max-"},{"bbox":{"x0":140,"x1":1078,"y0":767,"y1":790},"font_size":-210000.0,"text":"imizing prompt diversity and ensuring high response quality. To this end, we develop a suite of data generation"},{"bbox":{"x0":138,"x1":1081,"y0":787,"y1":813},"font_size":-210000.0,"text":"pipelines tailored to different task domains, each utilizing a combination of human annotation, prompt engineering, and"},{"bbox":{"x0":141,"x1":1081,"y0":812,"y1":833},"font_size":-210000.0,"text":"verifcation processes. We adopt K1.5 [35] and other in-house domain-specialized expert models to generate candidatei"},{"bbox":{"x0":140,"x1":1081,"y0":833,"y1":855},"font_size":-210000.0,"text":"responses for various tasks, followed by LLMs or human-based judges to perform automated quality evaluation and"},{"bbox":{"x0":140,"x1":1083,"y0":853,"y1":878},"font_size":-210000.0,"text":"fltering. For agentic data, we create a data synthesis pipeline to teach models tool-use capabilities through multi-step,i"},{"bbox":{"x0":138,"x1":316,"y0":874,"y1":901},"font_size":-210000.0,"text":"interactive reasoning."}],"source":"layout det","text":"We construct a large-scale instruction-tuning dataset spanning diverse domains, guided by two core principles: maximizing prompt diversity and ensuring high response quality. To this end, we develop a suite of data generation pipelines tailored to different task domains, each utilizing a combination of human annotation, prompt engineering, and verifcation processes. We adopt K1.5 [35] and other in-house domain-specialized expert models to generate candidatei responses for various tasks, followed by LLMs or human-based judges to perform automated quality evaluation and fltering. For agentic data, we create a data synthesis pipeline to teach models tool-use capabilities through multi-step,i interactive reasoning."},{"bbox":{"x0":138,"x1":703,"y0":918,"y1":946},"conf":0.8939,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":699,"y0":919,"y1":945},"font_size":-210000.0,"text":"3.1.1Large-Scale Agentic Data Synthesis for Tool Use Learning"}],"source":"layout det","text":"3.1.1Large-Scale Agentic Data Synthesis for Tool Use Learning"},{"bbox":{"x0":138,"x1":1087,"y0":955,"y1":1092},"conf":0.9688,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":959,"y1":980},"font_size":-210000.0,"text":"A critical capability of modern LLM agents is their ability to autonomously use unfamiliar tools, interact with external"},{"bbox":{"x0":138,"x1":1081,"y0":978,"y1":1003},"font_size":-210000.0,"text":"environments, and iteratively refne their actions through reasoning, execution, and error correction. Agentic tool usei"},{"bbox":{"x0":140,"x1":1083,"y0":1003,"y1":1025},"font_size":-210000.0,"text":"capability is essential for solving complex, multi-step tasks that require dynamic interaction with real-world systems."},{"bbox":{"x0":141,"x1":1081,"y0":1025,"y1":1046},"font_size":-210000.0,"text":"Recent benchmarks such as ACEBench [6] and $7$ -bench [85] have highlighted the importance of comprehensive tool-use"},{"bbox":{"x0":136,"x1":1083,"y0":1041,"y1":1073},"font_size":-210000.0,"text":"evaluation, while frameworks like ToolLLM [58] and ACEBench [6] have demonstrated the potential of teaching"},{"bbox":{"x0":140,"x1":497,"y0":1066,"y1":1091},"font_size":-210000.0,"text":"models to use thousands of tools effectively."}],"source":"layout det","text":"A critical capability of modern LLM agents is their ability to autonomously use unfamiliar tools, interact with external environments, and iteratively refne their actions through reasoning, execution, and error correction. Agentic tool usei capability is essential for solving complex, multi-step tasks that require dynamic interaction with real-world systems.Recent benchmarks such as ACEBench [6] and $7$ -bench [85] have highlighted the importance of comprehensive tool-use evaluation, while frameworks like ToolLLM [58] and ACEBench [6] have demonstrated the potential of teaching models to use thousands of tools effectively."},{"bbox":{"x0":137,"x1":1088,"y0":1097,"y1":1257},"conf":0.9737,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1101,"y1":1122},"font_size":-210000.0,"text":"However, training such capabilities at scale presents a signifcant challenge: while real-world environments providei"},{"bbox":{"x0":141,"x1":1079,"y0":1124,"y1":1145},"font_size":-210000.0,"text":"rich and authentic interaction signals, they are often diffcult to construct at scale due to cost, complexity, privacyi"},{"bbox":{"x0":141,"x1":1083,"y0":1145,"y1":1167},"font_size":-210000.0,"text":"and accessibility constraints. Recent work on synthetic data generation (AgentInstruct [51]; Self-Instruct [75];"},{"bbox":{"x0":141,"x1":1081,"y0":1167,"y1":1190},"font_size":-210000.0,"text":"StableToolBench [20]; ZeroSearch [66]) has shown promising results in creating large-scale data without relying on"},{"bbox":{"x0":140,"x1":1081,"y0":1188,"y1":1209},"font_size":-210000.0,"text":"real-world interactions. Building on these advances and inspired by ACEBench [6]’s comprehensive data synthesis"},{"bbox":{"x0":141,"x1":1083,"y0":1209,"y1":1233},"font_size":-210000.0,"text":"framework, we developed a pipeline that simulates real-world tool-use scenarios at scale, enabling the generation of"},{"bbox":{"x0":141,"x1":654,"y0":1233,"y1":1254},"font_size":-210000.0,"text":"tens of thousands of diverse and high-quality training examples."}],"source":"layout det","text":"However, training such capabilities at scale presents a signifcant challenge: while real-world environments providei rich and authentic interaction signals, they are often diffcult to construct at scale due to cost, complexity, privacyi and accessibility constraints. Recent work on synthetic data generation (AgentInstruct [51]; Self-Instruct [75];StableToolBench [20]; ZeroSearch [66]) has shown promising results in creating large-scale data without relying on real-world interactions. Building on these advances and inspired by ACEBench [6]’s comprehensive data synthesis framework, we developed a pipeline that simulates real-world tool-use scenarios at scale, enabling the generation of tens of thousands of diverse and high-quality training examples."},{"bbox":{"x0":137,"x1":714,"y0":1261,"y1":1290},"conf":0.8945,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":710,"y0":1262,"y1":1287},"font_size":-210000.0,"text":"There are three stages in our data synthesis pipeline, depicted in Fig. 8."}],"source":"layout det","text":"There are three stages in our data synthesis pipeline, depicted in Fig. 8."},{"bbox":{"x0":171,"x1":1089,"y0":1299,"y1":1346},"conf":0.9427,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1081,"y0":1302,"y1":1323},"font_size":-210000.0,"text":"Tool spec generation: we frst construct a large repository of tool specs from both real-world tools and LLM-i"},{"bbox":{"x0":175,"x1":306,"y0":1322,"y1":1347},"font_size":-210000.0,"text":"synthetic tools;"}],"source":"layout det","text":"Tool spec generation: we frst construct a large repository of tool specs from both real-world tools and LLM-i synthetic tools;"},{"bbox":{"x0":171,"x1":1088,"y0":1350,"y1":1397},"conf":0.943,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":165,"x1":1081,"y0":1351,"y1":1373},"font_size":-210000.0,"text":"Agent and task generation: for each tool-set sampled from the tool repository, we generate an agent to use the"},{"bbox":{"x0":176,"x1":486,"y0":1374,"y1":1396},"font_size":-210000.0,"text":"toolset and some corresponding tasks;"}],"source":"layout det","text":"Agent and task generation: for each tool-set sampled from the tool repository, we generate an agent to use the toolset and some corresponding tasks;"},{"bbox":{"x0":173,"x1":1087,"y0":1400,"y1":1448},"conf":0.9163,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":166,"x1":1081,"y0":1399,"y1":1426},"font_size":-210000.0,"text":"Trajectory generation: for each agent and task, we generate trajectories where the agent fnishes the task byi"},{"bbox":{"x0":178,"x1":298,"y0":1426,"y1":1444},"font_size":-210000.0,"text":"invoking tools."}],"source":"layout det","text":"Trajectory generation: for each agent and task, we generate trajectories where the agent fnishes the task byi invoking tools."}],"formula_dets":[{"bbox":{"x0":513,"x1":524,"y0":1030,"y1":1042},"conf":0.5703,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1088,"y0":1097,"y1":1257},"conf":0.9737,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":742,"y1":902},"conf":0.9726,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":955,"y1":1092},"conf":0.9688,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":143,"y1":282},"conf":0.9688,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":340,"y1":458},"conf":0.9588,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":461,"y1":555},"conf":0.9553,"label":"Text","label_id":1},{"bbox":{"x0":171,"x1":1088,"y0":1350,"y1":1397},"conf":0.943,"label":"Text","label_id":1},{"bbox":{"x0":171,"x1":1089,"y0":1299,"y1":1346},"conf":0.9427,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":665,"y1":740},"conf":0.9383,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":1087,"y0":1400,"y1":1448},"conf":0.9163,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":324,"y0":300,"y1":328},"conf":0.9041,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":398,"y0":625,"y1":654},"conf":0.9033,"label":"Title","label_id":0},{"bbox":{"x0":138,"x1":325,"y0":578,"y1":611},"conf":0.8993,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":714,"y0":1261,"y1":1290},"conf":0.8945,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":703,"y0":918,"y1":946},"conf":0.8939,"label":"Title","label_id":0},{"bbox":{"x0":558,"x1":1086,"y0":67,"y1":93},"conf":0.8123,"label":"Abandon","label_id":2},{"bbox":{"x0":602,"x1":620,"y0":1482,"y1":1503},"conf":0.4675,"label":"Abandon","label_id":2},{"bbox":{"x0":600,"x1":622,"y0":1480,"y1":1505},"conf":0.4256,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[604,1483],[619,1483],[619,1502],[604,1502]],"score":0.7532},{"poly":[[178,1426],[298,1426],[298,1444],[178,1444]],"score":0.9276},{"poly":[[166,1399],[1081,1403],[1081,1426],[166,1422]],"score":0.7095},{"poly":[[176,1374],[486,1374],[486,1396],[176,1396]],"score":0.8319},{"poly":[[165,1351],[1081,1351],[1081,1373],[165,1373]],"score":0.8277},{"poly":[[175,1323],[306,1322],[306,1345],[175,1347]],"score":0.7337},{"poly":[[160,1302],[1081,1302],[1081,1323],[160,1323]],"score":0.8346},{"poly":[[141,1262],[710,1264],[710,1287],[141,1285]],"score":0.7751},{"poly":[[141,1233],[654,1233],[654,1254],[141,1254]],"score":0.8574},{"poly":[[141,1209],[1083,1209],[1083,1233],[141,1233]],"score":0.7069},{"poly":[[140,1188],[1081,1188],[1081,1209],[140,1209]],"score":0.7873},{"poly":[[141,1167],[1081,1167],[1081,1190],[141,1190]],"score":0.7137},{"poly":[[141,1145],[1083,1145],[1083,1167],[141,1167]],"score":0.8258},{"poly":[[141,1124],[1079,1124],[1079,1145],[141,1145]],"score":0.8263},{"poly":[[141,1101],[1081,1101],[1081,1122],[141,1122]],"score":0.8278},{"poly":[[140,1066],[497,1068],[497,1091],[140,1089]],"score":0.7707},{"poly":[[136,1041],[1083,1044],[1083,1073],[136,1069]],"score":0.6308},{"poly":[[141,1025],[1081,1025],[1081,1046],[141,1046]],"score":0.8174},{"poly":[[140,1003],[1083,1003],[1083,1025],[140,1025]],"score":0.8087},{"poly":[[138,978],[1081,980],[1081,1003],[138,1002]],"score":0.7466},{"poly":[[140,959],[1081,959],[1081,980],[140,980]],"score":0.8326},{"poly":[[140,919],[699,922],[698,945],[140,942]],"score":0.7524},{"poly":[[138,874],[316,878],[316,901],[138,897]],"score":0.7463},{"poly":[[140,853],[1083,855],[1083,878],[140,876]],"score":0.7236},{"poly":[[140,833],[1081,833],[1081,855],[140,855]],"score":0.7929},{"poly":[[141,812],[1081,812],[1081,833],[141,833]],"score":0.7979},{"poly":[[138,790],[1081,787],[1081,810],[138,813]],"score":0.6839},{"poly":[[140,767],[1078,767],[1078,790],[140,790]],"score":0.6951},{"poly":[[141,746],[1081,746],[1081,767],[141,767]],"score":0.8405},{"poly":[[140,709],[290,715],[289,738],[139,732]],"score":0.7266},{"poly":[[141,691],[1081,691],[1081,714],[141,714]],"score":0.7223},{"poly":[[140,667],[1081,668],[1081,691],[140,690]],"score":0.7638},{"poly":[[138,625],[394,630],[394,654],[138,648]],"score":0.7089},{"poly":[[139,576],[321,581],[320,609],[138,604]],"score":0.7368},{"poly":[[140,526],[928,530],[928,553],[140,549]],"score":0.7032},{"poly":[[141,508],[1081,508],[1081,530],[141,530]],"score":0.8272},{"poly":[[141,485],[1081,485],[1081,508],[141,508]],"score":0.7007},{"poly":[[141,462],[1078,462],[1078,483],[141,483]],"score":0.7578},{"poly":[[141,434],[238,434],[238,452],[141,452]],"score":0.974},{"poly":[[140,409],[1081,409],[1081,432],[140,432]],"score":0.702},{"poly":[[141,388],[1081,388],[1081,409],[141,409]],"score":0.8436},{"poly":[[140,363],[1081,365],[1081,388],[140,386]],"score":0.7553},{"poly":[[141,343],[1081,343],[1081,365],[141,365]],"score":0.85},{"poly":[[140,300],[321,302],[321,325],[140,323]],"score":0.8657},{"poly":[[140,254],[283,258],[282,282],[139,279]],"score":0.7557},{"poly":[[141,234],[1081,234],[1081,256],[141,256]],"score":0.8465},{"poly":[[141,213],[1079,213],[1079,234],[141,234]],"score":0.7764},{"poly":[[141,191],[1081,190],[1081,213],[141,215]],"score":0.7341},{"poly":[[141,170],[1079,170],[1079,191],[141,191]],"score":0.8459},{"poly":[[143,147],[1081,147],[1081,170],[143,170]],"score":0.7416},{"poly":[[920,69],[1081,71],[1081,92],[920,91]],"score":0.7897},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8562}],"page_no":8,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":556,"x1":1088,"y0":64,"y1":95},"conf":0.729,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":66,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":595,"x1":628,"y0":1479,"y1":1507},"conf":0.6598,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"10"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":202,"x1":1022,"y0":133,"y1":376},"conf":0.6175,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![0b37235b5014617bada02aa6cb89bc8c](imgs/0b37235b5014617bada02aa6cb89bc8c.jpg)"},{"bbox":{"x0":205,"x1":601,"y0":142,"y1":344},"conf":0.8543,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![f1591a37d7e82f3d0d80abb607673bfc](imgs/f1591a37d7e82f3d0d80abb607673bfc.jpg)"},{"bbox":{"x0":625,"x1":1017,"y0":135,"y1":340},"conf":0.8834,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![ab1f1baceeac607eebb4bc723c616209](imgs/ab1f1baceeac607eebb4bc723c616209.jpg)"},{"bbox":{"x0":234,"x1":947,"y0":348,"y1":375},"conf":0.3436,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":242,"x1":937,"y0":353,"y1":369},"font_size":8.0,"text":"(a) Synthesizing tool specs, agents and tasks(b) Generating agent trajectories"}],"source":"layout det","text":"(a) Synthesizing tool specs, agents and tasks(b) Generating agent trajectories"},{"bbox":{"x0":237,"x1":568,"y0":348,"y1":375},"conf":0.3688,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":242,"x1":561,"y0":353,"y1":369},"font_size":8.0,"text":"(a) Synthesizing tool specs, agents and tasks"}],"source":"layout det","text":"(a) Synthesizing tool specs, agents and tasks"},{"bbox":{"x0":131,"x1":1088,"y0":380,"y1":435},"conf":0.9346,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":383,"y1":404},"font_size":-3.011e-17,"text":"Figure 8: Data synthesis pipeline for tool use. (a) Tool specs are from both real-world tools and LLMs; agents and tasks"},{"bbox":{"x0":138,"x1":1036,"y0":404,"y1":429},"font_size":-3.011e-17,"text":"are the generated from the tool repo. (b) Multi-agent pipeline to generate and flter trajectories with tool calling.i"}],"source":"layout det","text":"Figure 8: Data synthesis pipeline for tool use. (a) Tool specs are from both real-world tools and LLMs; agents and tasks are the generated from the tool repo. (b) Multi-agent pipeline to generate and flter trajectories with tool calling.i"},{"bbox":{"x0":623,"x1":1089,"y0":450,"y1":798},"conf":0.605,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![271fdc0af3c4966658abf7b28861cf5e](imgs/271fdc0af3c4966658abf7b28861cf5e.jpg)"},{"bbox":{"x0":137,"x1":604,"y0":457,"y1":797},"conf":0.9107,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![863e71c6656d07735e38df5719c68927](imgs/863e71c6656d07735e38df5719c68927.jpg)"},{"bbox":{"x0":623,"x1":1087,"y0":801,"y1":850},"conf":0.8462,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":627,"x1":1083,"y0":804,"y1":825},"font_size":-3.011e-17,"text":"(b) t-SNE visualization of synthetic tools, colored by pre-defnedi"},{"bbox":{"x0":627,"x1":767,"y0":823,"y1":845},"font_size":-3.011e-17,"text":"domain categories"}],"source":"layout det","text":"(b) t-SNE visualization of synthetic tools, colored by pre-defnedi domain categories"},{"bbox":{"x0":135,"x1":1087,"y0":802,"y1":851},"conf":0.3433,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":1054,"x1":1054,"y0":808,"y1":824},"font_size":8.0,"text":"i"}],"source":"layout det","text":"i"},{"bbox":{"x0":135,"x1":601,"y0":801,"y1":850},"conf":0.7637,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":140,"x1":599,"y0":804,"y1":825},"font_size":-3.011e-17,"text":"(a) t-SNE visualization of real MCP tools, colored by their"},{"bbox":{"x0":141,"x1":333,"y0":827,"y1":843},"font_size":-3.011e-17,"text":"original source categories"}],"source":"layout det","text":"(a) t-SNE visualization of real MCP tools, colored by their original source categories"},{"bbox":{"x0":134,"x1":1087,"y0":855,"y1":932},"conf":0.8976,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":858,"y1":879},"font_size":-3.011e-17,"text":"Figure 9: t-SNE visualizations of tool embeddings. (a) Real-world MCP tools exhibit natural clustering based on their"},{"bbox":{"x0":140,"x1":1081,"y0":881,"y1":903},"font_size":-3.011e-17,"text":"original source categories. (b) Synthetic tools are organized into pre-defned domain categories, providing systematici"},{"bbox":{"x0":140,"x1":1064,"y0":903,"y1":924},"font_size":-3.011e-17,"text":"coverage of the tool space. Together, they ensure comprehensive representation across different tool functionalities."}],"source":"layout det","text":"Figure 9: t-SNE visualizations of tool embeddings. (a) Real-world MCP tools exhibit natural clustering based on their original source categories. (b) Synthetic tools are organized into pre-defned domain categories, providing systematici coverage of the tool space. Together, they ensure comprehensive representation across different tool functionalities."},{"bbox":{"x0":136,"x1":1089,"y0":966,"y1":1153},"conf":0.9741,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":969,"y1":993},"font_size":-3.011e-17,"text":"Domain Evolution and Tool Generation.We construct a comprehensive tool repository through two complementary"},{"bbox":{"x0":140,"x1":1083,"y0":990,"y1":1015},"font_size":-3.011e-17,"text":"approaches. First, we directly fetch 3000+ real MCP (Model Context Protocol) tools from GitHub repositories,"},{"bbox":{"x0":141,"x1":1079,"y0":1013,"y1":1035},"font_size":-3.011e-17,"text":"leveraging existing high-quality tool specs. Second, we systematically evolve [82] synthetic tools through a hierarchical"},{"bbox":{"x0":141,"x1":1083,"y0":1036,"y1":1058},"font_size":-3.011e-17,"text":"domain generation process: we begin with key categories (e.g., fnancial trading, software applications, robot control),i"},{"bbox":{"x0":140,"x1":1083,"y0":1058,"y1":1080},"font_size":-3.011e-17,"text":"then evolve multiple specifc application domains within each category. Specialized tools are then synthesized for eachi"},{"bbox":{"x0":138,"x1":1081,"y0":1077,"y1":1102},"font_size":-3.011e-17,"text":"domain, with clear interfaces, descriptions, and operational semantics. This evolution process produces over 20,000"},{"bbox":{"x0":140,"x1":1081,"y0":1101,"y1":1122},"font_size":-3.011e-17,"text":"synthetic tools. Figure 9 visualizes the diversity of our tool collection through t-SNE embeddings, demonstrating that"},{"bbox":{"x0":140,"x1":762,"y0":1122,"y1":1143},"font_size":-3.011e-17,"text":"both MCP and synthetic tools cover complementary regions of the tool space."}],"source":"layout det","text":"Domain Evolution and Tool Generation.We construct a comprehensive tool repository through two complementary approaches. First, we directly fetch 3000+ real MCP (Model Context Protocol) tools from GitHub repositories,leveraging existing high-quality tool specs. Second, we systematically evolve [82] synthetic tools through a hierarchical domain generation process: we begin with key categories (e.g., fnancial trading, software applications, robot control),i then evolve multiple specifc application domains within each category. Specialized tools are then synthesized for eachi domain, with clear interfaces, descriptions, and operational semantics. This evolution process produces over 20,000 synthetic tools. Figure 9 visualizes the diversity of our tool collection through t-SNE embeddings, demonstrating that both MCP and synthetic tools cover complementary regions of the tool space."},{"bbox":{"x0":135,"x1":1088,"y0":1166,"y1":1247},"conf":0.9385,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":1172,"y1":1194},"font_size":-3.011e-17,"text":"Agent Diversifcation.We generate thousands of distinct agents by synthesizing various system prompts andi"},{"bbox":{"x0":138,"x1":1081,"y0":1193,"y1":1218},"font_size":-3.011e-17,"text":"equipping them with different combinations of tools from our repository. This creates a diverse population of agents"},{"bbox":{"x0":140,"x1":1073,"y0":1216,"y1":1238},"font_size":-3.011e-17,"text":"with varied capabilities, areas of expertise, and behavioral patterns, ensuring a broad coverage of potential use cases."}],"source":"layout det","text":"Agent Diversifcation.We generate thousands of distinct agents by synthesizing various system prompts andi equipping them with different combinations of tools from our repository. This creates a diverse population of agents with varied capabilities, areas of expertise, and behavioral patterns, ensuring a broad coverage of potential use cases."},{"bbox":{"x0":134,"x1":1089,"y0":1260,"y1":1340},"conf":0.9369,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1262,"y1":1287},"font_size":-3.011e-17,"text":"Rubric-Based Task Generation.For each agent confguration, we generate tasks that range from simple to complexi"},{"bbox":{"x0":140,"x1":1083,"y0":1287,"y1":1309},"font_size":-3.011e-17,"text":"operations. Each task is paired with an explicit rubric that specifes success criteria, expected tool-use patterns, andi"},{"bbox":{"x0":140,"x1":1083,"y0":1310,"y1":1332},"font_size":-3.011e-17,"text":"evaluation checkpoints. This rubric-based approach ensures a consistent and objective evaluation of agent performance."}],"source":"layout det","text":"Rubric-Based Task Generation.For each agent confguration, we generate tasks that range from simple to complexi operations. Each task is paired with an explicit rubric that specifes success criteria, expected tool-use patterns, andi evaluation checkpoints. This rubric-based approach ensures a consistent and objective evaluation of agent performance."},{"bbox":{"x0":136,"x1":1015,"y0":1352,"y1":1388},"conf":0.8889,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1008,"y0":1358,"y1":1379},"font_size":-3.011e-17,"text":"Multi-turn Trajectory Generation.We simulate realistic tool-use scenarios through several components:"}],"source":"layout det","text":"Multi-turn Trajectory Generation.We simulate realistic tool-use scenarios through several components:"},{"bbox":{"x0":170,"x1":1087,"y0":1396,"y1":1452},"conf":0.9137,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1083,"y0":1398,"y1":1422},"font_size":-3.011e-17,"text":"User Simulation: LLM-generated user personas with distinct communication styles and preferences engage in"},{"bbox":{"x0":176,"x1":768,"y0":1422,"y1":1444},"font_size":-3.011e-17,"text":"multi-turn dialogues with agents, creating naturalistic interaction patterns."}],"source":"layout det","text":"User Simulation: LLM-generated user personas with distinct communication styles and preferences engage in multi-turn dialogues with agents, creating naturalistic interaction patterns."}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1089,"y0":966,"y1":1153},"conf":0.9741,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1088,"y0":1166,"y1":1247},"conf":0.9385,"label":"Text","label_id":1},{"bbox":{"x0":134,"x1":1089,"y0":1260,"y1":1340},"conf":0.9369,"label":"Text","label_id":1},{"bbox":{"x0":131,"x1":1088,"y0":380,"y1":435},"conf":0.9346,"label":"Figure caption","label_id":4},{"bbox":{"x0":170,"x1":1087,"y0":1396,"y1":1452},"conf":0.9137,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":604,"y0":457,"y1":797},"conf":0.9107,"label":"Figure","label_id":3},{"bbox":{"x0":134,"x1":1087,"y0":855,"y1":932},"conf":0.8976,"label":"Figure caption","label_id":4},{"bbox":{"x0":136,"x1":1015,"y0":1352,"y1":1388},"conf":0.8889,"label":"Text","label_id":1},{"bbox":{"x0":625,"x1":1017,"y0":135,"y1":340},"conf":0.8834,"label":"Figure","label_id":3},{"bbox":{"x0":205,"x1":601,"y0":142,"y1":344},"conf":0.8543,"label":"Figure","label_id":3},{"bbox":{"x0":623,"x1":1087,"y0":801,"y1":850},"conf":0.8462,"label":"Figure caption","label_id":4},{"bbox":{"x0":135,"x1":601,"y0":801,"y1":850},"conf":0.7637,"label":"Figure caption","label_id":4},{"bbox":{"x0":556,"x1":1088,"y0":64,"y1":95},"conf":0.729,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":628,"y0":1479,"y1":1507},"conf":0.6598,"label":"Abandon","label_id":2},{"bbox":{"x0":202,"x1":1022,"y0":133,"y1":376},"conf":0.6175,"label":"Figure","label_id":3},{"bbox":{"x0":623,"x1":1089,"y0":450,"y1":798},"conf":0.605,"label":"Figure","label_id":3},{"bbox":{"x0":237,"x1":568,"y0":348,"y1":375},"conf":0.3688,"label":"Figure caption","label_id":4},{"bbox":{"x0":234,"x1":947,"y0":348,"y1":375},"conf":0.3436,"label":"Figure caption","label_id":4},{"bbox":{"x0":135,"x1":1087,"y0":802,"y1":851},"conf":0.3433,"label":"Figure caption","label_id":4}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8125},{"poly":[[176,1422],[768,1422],[768,1444],[176,1444]],"score":0.8417},{"poly":[[160,1398],[1083,1399],[1083,1422],[160,1421]],"score":0.7755},{"poly":[[141,1358],[1008,1358],[1008,1379],[141,1379]],"score":0.859},{"poly":[[140,1310],[1083,1310],[1083,1332],[140,1332]],"score":0.825},{"poly":[[140,1287],[1083,1287],[1083,1308],[140,1308]],"score":0.7604},{"poly":[[140,1262],[1083,1264],[1083,1287],[140,1285]],"score":0.7735},{"poly":[[140,1216],[1073,1216],[1073,1238],[140,1238]],"score":0.7937},{"poly":[[138,1195],[1081,1193],[1081,1216],[138,1218]],"score":0.7466},{"poly":[[143,1172],[1081,1172],[1081,1193],[143,1193]],"score":0.8174},{"poly":[[140,1122],[762,1122],[762,1143],[140,1143]],"score":0.7887},{"poly":[[140,1101],[1081,1101],[1081,1122],[140,1122]],"score":0.8157},{"poly":[[138,1079],[1081,1077],[1081,1101],[138,1102]],"score":0.7387},{"poly":[[140,1058],[1083,1058],[1083,1079],[140,1079]],"score":0.7984},{"poly":[[141,1036],[1083,1036],[1083,1058],[141,1058]],"score":0.7891},{"poly":[[141,1013],[1079,1013],[1079,1035],[141,1035]],"score":0.8121},{"poly":[[140,992],[1083,990],[1083,1013],[140,1015]],"score":0.7251},{"poly":[[140,969],[1081,970],[1081,993],[140,992]],"score":0.7719},{"poly":[[140,903],[1064,903],[1064,924],[140,924]],"score":0.8441},{"poly":[[140,881],[1081,881],[1081,903],[140,903]],"score":0.8181},{"poly":[[140,858],[1081,858],[1081,879],[140,879]],"score":0.8231},{"poly":[[141,827],[333,827],[333,843],[141,843]],"score":0.9789},{"poly":[[627,823],[767,823],[767,845],[627,845]],"score":0.8163},{"poly":[[627,804],[1083,804],[1083,825],[627,825]],"score":0.8484},{"poly":[[140,804],[599,804],[599,825],[140,825]],"score":0.8395},{"poly":[[807,782],[828,782],[828,794],[807,794]],"score":0.8923},{"poly":[[323,780],[348,780],[348,794],[323,794]],"score":0.7112},{"poly":[[260,459],[411,460],[411,479],[259,477]],"score":0.7623},{"poly":[[730,452],[906,452],[906,469],[730,469]],"score":0.9035},{"poly":[[138,404],[1036,406],[1036,429],[138,427]],"score":0.7623},{"poly":[[141,383],[1083,383],[1083,404],[141,404]],"score":0.8307},{"poly":[[702,348],[940,348],[940,370],[702,370]],"score":0.8555},{"poly":[[239,348],[564,348],[564,370],[239,370]],"score":0.8288},{"poly":[[274,317],[376,317],[376,335],[274,335]],"score":0.8286},{"poly":[[507,314],[562,314],[562,337],[507,337]],"score":0.8355},{"poly":[[653,301],[717,306],[716,329],[651,325]],"score":0.8053},{"poly":[[948,304],[985,304],[985,323],[948,323]],"score":0.7739},{"poly":[[820,302],[858,302],[858,322],[820,322]],"score":0.8517},{"poly":[[737,295],[788,295],[788,314],[737,314]],"score":0.8364},{"poly":[[343,292],[416,292],[416,310],[343,310]],"score":0.9201},{"poly":[[669,290],[702,290],[702,309],[669,309]],"score":0.8423},{"poly":[[232,287],[306,291],[305,314],[231,310]],"score":0.8193},{"poly":[[939,285],[992,289],[990,312],[937,308]],"score":0.8109},{"poly":[[818,287],[860,287],[860,307],[818,307]],"score":0.8367},{"poly":[[341,276],[421,276],[421,294],[341,294]],"score":0.8423},{"poly":[[233,274],[306,274],[306,292],[233,292]],"score":0.8117},{"poly":[[644,261],[720,261],[720,279],[644,279]],"score":0.6997},{"poly":[[494,251],[575,251],[575,269],[494,269]],"score":0.9208},{"poly":[[514,233],[557,233],[557,252],[514,252]],"score":0.8218},{"poly":[[812,228],[868,228],[868,251],[812,251]],"score":0.8025},{"poly":[[665,229],[707,229],[707,249],[665,249]],"score":0.8158},{"poly":[[334,213],[426,213],[426,236],[334,236]],"score":0.9085},{"poly":[[227,209],[310,213],[308,238],[226,234]],"score":0.8042},{"poly":[[660,198],[712,198],[712,223],[660,223]],"score":0.7534},{"poly":[[665,170],[707,170],[707,188],[665,188]],"score":0.9558},{"poly":[[823,160],[860,160],[860,180],[823,180]],"score":0.7691},{"poly":[[346,158],[414,158],[414,177],[346,177]],"score":0.9286},{"poly":[[667,153],[703,153],[703,173],[667,173]],"score":0.8063},{"poly":[[918,66],[1083,69],[1082,93],[918,89]],"score":0.6991},{"poly":[[559,64],[664,64],[664,92],[559,92]],"score":0.7481}],"page_no":9,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7885,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1081,"y0":71,"y1":91},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":595,"x1":625,"y0":1480,"y1":1506},"conf":0.6732,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":622,"y0":1482,"y1":1503},"font_size":0.0,"text":"11"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":168,"x1":1090,"y0":142,"y1":239},"conf":0.9557,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1081,"y0":147,"y1":168},"font_size":9.177e-15,"text":"Tool Execution Environment: A sophisticated tool simulator (functionally equivalent to a world model) executes"},{"bbox":{"x0":176,"x1":1083,"y0":170,"y1":191},"font_size":9.177e-15,"text":"tool calls and provides realistic feedback. The simulator maintains and updates state after each tool execution,"},{"bbox":{"x0":180,"x1":1081,"y0":191,"y1":213},"font_size":9.177e-15,"text":"enabling complex multi-step interactions with persistent effects. It introduces controlled stochasticity to produce"},{"bbox":{"x0":180,"x1":730,"y0":213,"y1":234},"font_size":9.177e-15,"text":"varied outcomes including successes, partial failures, and edge cases."}],"source":"layout det","text":"Tool Execution Environment: A sophisticated tool simulator (functionally equivalent to a world model) executes tool calls and provides realistic feedback. The simulator maintains and updates state after each tool execution,enabling complex multi-step interactions with persistent effects. It introduces controlled stochasticity to produce varied outcomes including successes, partial failures, and edge cases."},{"bbox":{"x0":136,"x1":1089,"y0":251,"y1":328},"conf":0.947,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1079,"y0":257,"y1":279},"font_size":9.177e-15,"text":"Quality Evaluation and Filtering.An LLM-based judge evaluates each trajectory against the task rubrics. Only"},{"bbox":{"x0":141,"x1":1079,"y0":280,"y1":302},"font_size":9.177e-15,"text":"trajectories that meet the success criteria are retained for training, ensuring high-quality data while allowing natural"},{"bbox":{"x0":141,"x1":454,"y0":302,"y1":323},"font_size":9.177e-15,"text":"variation in task-completion strategies."}],"source":"layout det","text":"Quality Evaluation and Filtering.An LLM-based judge evaluates each trajectory against the task rubrics. Only trajectories that meet the success criteria are retained for training, ensuring high-quality data while allowing natural variation in task-completion strategies."},{"bbox":{"x0":137,"x1":1088,"y0":340,"y1":503},"conf":0.9707,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":346,"y1":368},"font_size":9.177e-15,"text":"Hybrid Approach with Real Execution Environments.While simulation provides scalability, we acknowledge"},{"bbox":{"x0":141,"x1":1078,"y0":371,"y1":389},"font_size":9.177e-15,"text":"the inherent limitation of simulation fdelity. To address this, we complement our simulated environments with reali"},{"bbox":{"x0":140,"x1":1081,"y0":391,"y1":412},"font_size":9.177e-15,"text":"execution sandboxes for scenarios where authenticity is crucial, particularly in coding and software engineering tasks."},{"bbox":{"x0":140,"x1":1079,"y0":409,"y1":434},"font_size":9.177e-15,"text":"These real sandboxes execute actual code, interact with genuine development environments, and provide ground-truth"},{"bbox":{"x0":140,"x1":1081,"y0":434,"y1":455},"font_size":9.177e-15,"text":"feedback through objective metrics such as test suite pass rates. This combination ensures that our models learn from"},{"bbox":{"x0":138,"x1":1081,"y0":454,"y1":479},"font_size":9.177e-15,"text":"both the diversity of simulated scenarios and the authenticity of real executions, signifcantly strengthening practicali"},{"bbox":{"x0":138,"x1":289,"y0":477,"y1":502},"font_size":9.177e-15,"text":"agent capabilities."}],"source":"layout det","text":"Hybrid Approach with Real Execution Environments.While simulation provides scalability, we acknowledge the inherent limitation of simulation fdelity. To address this, we complement our simulated environments with reali execution sandboxes for scenarios where authenticity is crucial, particularly in coding and software engineering tasks.These real sandboxes execute actual code, interact with genuine development environments, and provide ground-truth feedback through objective metrics such as test suite pass rates. This combination ensures that our models learn from both the diversity of simulated scenarios and the authenticity of real executions, signifcantly strengthening practicali agent capabilities."},{"bbox":{"x0":137,"x1":1088,"y0":507,"y1":647},"conf":0.9723,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":512,"y1":533},"font_size":9.177e-15,"text":"By leveraging this hybrid pipeline that combines scalable simulation with targeted real-world execution, we generate"},{"bbox":{"x0":141,"x1":1081,"y0":533,"y1":556},"font_size":9.177e-15,"text":"diverse, high-quality tool-use demonstrations that balance coverage and authenticity. The scale and automation of our"},{"bbox":{"x0":141,"x1":1081,"y0":554,"y1":576},"font_size":9.177e-15,"text":"synthetic data generation, coupled with the grounding provided by real execution environments, effectively implements"},{"bbox":{"x0":141,"x1":1079,"y0":576,"y1":599},"font_size":9.177e-15,"text":"large-scale rejection sampling [26, 87] through our quality fltering process. This high-quality synthetic data, wheni"},{"bbox":{"x0":141,"x1":1081,"y0":597,"y1":620},"font_size":9.177e-15,"text":"used for supervised fne-tuning, has demonstrated signifcant improvements in the model’s tool-use capabilities across aii"},{"bbox":{"x0":141,"x1":447,"y0":620,"y1":642},"font_size":9.177e-15,"text":"wide range of real-world applications."}],"source":"layout det","text":"By leveraging this hybrid pipeline that combines scalable simulation with targeted real-world execution, we generate diverse, high-quality tool-use demonstrations that balance coverage and authenticity. The scale and automation of our synthetic data generation, coupled with the grounding provided by real execution environments, effectively implements large-scale rejection sampling [26, 87] through our quality fltering process. This high-quality synthetic data, wheni used for supervised fne-tuning, has demonstrated signifcant improvements in the model’s tool-use capabilities across aii wide range of real-world applications."},{"bbox":{"x0":136,"x1":404,"y0":661,"y1":692},"conf":0.9006,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":399,"y0":665,"y1":690},"font_size":9.177e-15,"text":"3.2Reinforcement Learning"}],"source":"layout det","text":"3.2Reinforcement Learning"},{"bbox":{"x0":137,"x1":1087,"y0":702,"y1":843},"conf":0.9697,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":706,"y1":728},"font_size":9.177e-15,"text":"Reinforcement learning (RL) is believed to have better token effciency and generalization than SFT. Based on the worki"},{"bbox":{"x0":138,"x1":1083,"y0":726,"y1":752},"font_size":9.177e-15,"text":"of K1.5 [35], we continue to scale RL in both task diversity and training FLOPs in K2. To support this, we develop a"},{"bbox":{"x0":141,"x1":1081,"y0":751,"y1":772},"font_size":9.177e-15,"text":"Gym-like extensible framework that facilitates RL across a wide range of scenarios. We extend the framework with a"},{"bbox":{"x0":141,"x1":1081,"y0":772,"y1":794},"font_size":9.177e-15,"text":"large number of tasks with verifable rewards. For tasks that rely on subjective preferences, such as creative writing andi"},{"bbox":{"x0":141,"x1":1081,"y0":795,"y1":817},"font_size":9.177e-15,"text":"open-ended question answering, we introduce a self-critic reward in which the model performs pairwise comparisons to"},{"bbox":{"x0":140,"x1":1011,"y0":817,"y1":840},"font_size":9.177e-15,"text":"judge its own outputs. This approach allows tasks from various domains to all beneft from the RL paradigm.i"}],"source":"layout det","text":"Reinforcement learning (RL) is believed to have better token effciency and generalization than SFT. Based on the worki of K1.5 [35], we continue to scale RL in both task diversity and training FLOPs in K2. To support this, we develop a Gym-like extensible framework that facilitates RL across a wide range of scenarios. We extend the framework with a large number of tasks with verifable rewards. For tasks that rely on subjective preferences, such as creative writing andi open-ended question answering, we introduce a self-critic reward in which the model performs pairwise comparisons to judge its own outputs. This approach allows tasks from various domains to all beneft from the RL paradigm.i"},{"bbox":{"x0":136,"x1":419,"y0":857,"y1":887},"conf":0.8746,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":416,"y0":861,"y1":883},"font_size":9.177e-15,"text":"3.2.1Verifable Rewards Gymi"}],"source":"layout det","text":"3.2.1Verifable Rewards Gymi"},{"bbox":{"x0":137,"x1":1089,"y0":894,"y1":946},"conf":0.9298,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":896,"y1":921},"font_size":9.177e-15,"text":"Math, STEM and Logical TasksFor math, stem and logical reasoning domains, our RL data preparation follows"},{"bbox":{"x0":141,"x1":627,"y0":921,"y1":942},"font_size":9.177e-15,"text":"two key principles, diverse coverage and moderate diffculty.i"}],"source":"layout det","text":"Math, STEM and Logical TasksFor math, stem and logical reasoning domains, our RL data preparation follows two key principles, diverse coverage and moderate diffculty.i"},{"bbox":{"x0":137,"x1":1088,"y0":949,"y1":1066},"conf":0.9667,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":950,"y1":975},"font_size":9.177e-15,"text":"Diverse Coverage. For math and stem tasks, we collect high-quality QA pairs using a combination of expert annotations,"},{"bbox":{"x0":138,"x1":1081,"y0":972,"y1":998},"font_size":9.177e-15,"text":"internal QA extraction pipelines, and open datasets [41, 52]. During the collection process, we leverage a tagging"},{"bbox":{"x0":141,"x1":1083,"y0":997,"y1":1018},"font_size":9.177e-15,"text":"system to deliberately increase coverage of under-covered domains. For logical tasks, our dataset comprises a variety of"},{"bbox":{"x0":140,"x1":1081,"y0":1016,"y1":1041},"font_size":9.177e-15,"text":"formats, including structured data tasks (e.g., multi-hop tabular reasoning, cross-table aggregation) and logic puzzles"},{"bbox":{"x0":138,"x1":762,"y0":1039,"y1":1064},"font_size":9.177e-15,"text":"(e.g., the 24-game, Sudoku, riddles, cryptarithms, and Morse-code decoding)."}],"source":"layout det","text":"Diverse Coverage. For math and stem tasks, we collect high-quality QA pairs using a combination of expert annotations,internal QA extraction pipelines, and open datasets [41, 52]. During the collection process, we leverage a tagging system to deliberately increase coverage of under-covered domains. For logical tasks, our dataset comprises a variety of formats, including structured data tasks (e.g., multi-hop tabular reasoning, cross-table aggregation) and logic puzzles(e.g., the 24-game, Sudoku, riddles, cryptarithms, and Morse-code decoding)."},{"bbox":{"x0":137,"x1":1089,"y0":1069,"y1":1143},"conf":0.94,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1072,"y1":1094},"font_size":9.177e-15,"text":"Moderate Diffculty. The RL prompt-set should be neither too easy nor too hard, both of which may produce little signali"},{"bbox":{"x0":141,"x1":1081,"y0":1096,"y1":1117},"font_size":9.177e-15,"text":"and reduce learning effciency. We assess the diffculty of each problem using the SFT model’s pass@k accuracy andii"},{"bbox":{"x0":141,"x1":511,"y0":1117,"y1":1138},"font_size":9.177e-15,"text":"select only problems with moderate diffculty.i"}],"source":"layout det","text":"Moderate Diffculty. The RL prompt-set should be neither too easy nor too hard, both of which may produce little signali and reduce learning effciency. We assess the diffculty of each problem using the SFT model’s pass@k accuracy andii select only problems with moderate diffculty.i"},{"bbox":{"x0":136,"x1":1089,"y0":1156,"y1":1273},"conf":0.9676,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1158,"y1":1183},"font_size":9.177e-15,"text":"Complex Instruction FollowingEffective instruction following requires not only understanding explicit constraints"},{"bbox":{"x0":138,"x1":1081,"y0":1181,"y1":1206},"font_size":9.177e-15,"text":"but also navigating implicit requirements, handling edge cases, and maintaining consistency over extended dialogues."},{"bbox":{"x0":140,"x1":1081,"y0":1203,"y1":1228},"font_size":9.177e-15,"text":"We address these challenges through a hybrid verifcation framework that combines automated verifcation withii"},{"bbox":{"x0":140,"x1":1081,"y0":1228,"y1":1249},"font_size":9.177e-15,"text":"adversarial detection, coupled with a scalable curriculum generation pipeline. Our approach employs a dual-path system"},{"bbox":{"x0":140,"x1":466,"y0":1249,"y1":1270},"font_size":9.177e-15,"text":"to ensure both precision and robustness:"}],"source":"layout det","text":"Complex Instruction FollowingEffective instruction following requires not only understanding explicit constraints but also navigating implicit requirements, handling edge cases, and maintaining consistency over extended dialogues.We address these challenges through a hybrid verifcation framework that combines automated verifcation withii adversarial detection, coupled with a scalable curriculum generation pipeline. Our approach employs a dual-path system to ensure both precision and robustness:"},{"bbox":{"x0":135,"x1":1090,"y0":1278,"y1":1393},"conf":0.9565,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1282,"y1":1304},"font_size":9.177e-15,"text":"Hybrid Rule Verifcation. We implement two verifcation mechanisms: (1) deterministic evaluation via code interpretersii"},{"bbox":{"x0":140,"x1":1079,"y0":1304,"y1":1325},"font_size":9.177e-15,"text":"for instructions with verifable outputs (e.g., length, style constraints), and (2) LLM-as-judge evaluation for instructionsi"},{"bbox":{"x0":141,"x1":1081,"y0":1327,"y1":1348},"font_size":9.177e-15,"text":"requiring nuanced understanding of constraints. To address potential adversarial behaviors where models might claim"},{"bbox":{"x0":141,"x1":1081,"y0":1348,"y1":1370},"font_size":9.177e-15,"text":"instruction fulfllment without actual compliance, we incorporate an additional hack-check layer that specifcally detectsii"},{"bbox":{"x0":140,"x1":323,"y0":1370,"y1":1391},"font_size":9.177e-15,"text":"such deceptive claims."}],"source":"layout det","text":"Hybrid Rule Verifcation. We implement two verifcation mechanisms: (1) deterministic evaluation via code interpretersii for instructions with verifable outputs (e.g., length, style constraints), and (2) LLM-as-judge evaluation for instructionsi requiring nuanced understanding of constraints. To address potential adversarial behaviors where models might claim instruction fulfllment without actual compliance, we incorporate an additional hack-check layer that specifcally detectsii such deceptive claims."},{"bbox":{"x0":135,"x1":1091,"y0":1398,"y1":1450},"conf":0.9169,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1081,"y0":1399,"y1":1424},"font_size":9.177e-15,"text":"Multi-Source Instruction Generation. To construct our training data, we employ three distinct generation strategies to"},{"bbox":{"x0":140,"x1":1081,"y0":1424,"y1":1445},"font_size":9.177e-15,"text":"ensure comprehensive coverage: (1) expert-crafted complex conditional prompts and rubrics developed by our data"}],"source":"layout det","text":"Multi-Source Instruction Generation. To construct our training data, we employ three distinct generation strategies to ensure comprehensive coverage: (1) expert-crafted complex conditional prompts and rubrics developed by our data"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1088,"y0":507,"y1":647},"conf":0.9723,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":340,"y1":503},"conf":0.9707,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":702,"y1":843},"conf":0.9697,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":1156,"y1":1273},"conf":0.9676,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":949,"y1":1066},"conf":0.9667,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1090,"y0":1278,"y1":1393},"conf":0.9565,"label":"Text","label_id":1},{"bbox":{"x0":168,"x1":1090,"y0":142,"y1":239},"conf":0.9557,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":251,"y1":328},"conf":0.947,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":1069,"y1":1143},"conf":0.94,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":894,"y1":946},"conf":0.9298,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1091,"y0":1398,"y1":1450},"conf":0.9169,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":404,"y0":661,"y1":692},"conf":0.9006,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":419,"y0":857,"y1":887},"conf":0.8746,"label":"Title","label_id":0},{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7885,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":625,"y0":1480,"y1":1506},"conf":0.6732,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1482],[622,1482],[622,1503],[599,1503]],"score":0.9467},{"poly":[[140,1424],[1081,1424],[1081,1445],[140,1445]],"score":0.9051},{"poly":[[138,1399],[1081,1401],[1081,1424],[138,1422]],"score":0.7538},{"poly":[[140,1370],[323,1370],[323,1391],[140,1391]],"score":0.8219},{"poly":[[141,1348],[1081,1348],[1081,1370],[141,1370]],"score":0.7761},{"poly":[[141,1327],[1081,1327],[1081,1348],[141,1348]],"score":0.8069},{"poly":[[140,1304],[1079,1304],[1079,1325],[140,1325]],"score":0.8081},{"poly":[[140,1282],[1081,1282],[1081,1304],[140,1304]],"score":0.8294},{"poly":[[140,1249],[466,1249],[466,1270],[140,1270]],"score":0.8143},{"poly":[[140,1228],[1081,1228],[1081,1249],[140,1249]],"score":0.8226},{"poly":[[140,1203],[1081,1205],[1081,1228],[140,1226]],"score":0.7431},{"poly":[[138,1181],[1081,1183],[1081,1206],[138,1204]],"score":0.72},{"poly":[[140,1158],[1081,1160],[1081,1183],[140,1181]],"score":0.7541},{"poly":[[141,1117],[511,1117],[511,1138],[141,1138]],"score":0.8618},{"poly":[[141,1096],[1081,1096],[1081,1117],[141,1117]],"score":0.8524},{"poly":[[140,1072],[1081,1072],[1081,1094],[140,1094]],"score":0.8043},{"poly":[[138,1041],[762,1039],[762,1063],[138,1064]],"score":0.7768},{"poly":[[140,1016],[1081,1018],[1081,1041],[140,1039]],"score":0.7467},{"poly":[[141,997],[1083,997],[1083,1018],[141,1018]],"score":0.8092},{"poly":[[138,972],[1081,975],[1081,998],[138,995]],"score":0.6961},{"poly":[[138,950],[1083,952],[1083,975],[138,973]],"score":0.7596},{"poly":[[141,921],[627,921],[627,942],[141,942]],"score":0.7918},{"poly":[[140,896],[1081,898],[1081,921],[140,919]],"score":0.7894},{"poly":[[141,861],[416,861],[416,883],[141,883]],"score":0.828},{"poly":[[140,817],[1011,817],[1011,840],[140,840]],"score":0.7512},{"poly":[[141,795],[1081,795],[1081,817],[141,817]],"score":0.7982},{"poly":[[141,772],[1081,772],[1081,794],[141,794]],"score":0.7998},{"poly":[[141,751],[1081,751],[1081,772],[141,772]],"score":0.8104},{"poly":[[138,726],[1083,729],[1083,752],[138,749]],"score":0.7065},{"poly":[[141,706],[1081,706],[1081,728],[141,728]],"score":0.8422},{"poly":[[138,665],[399,667],[399,690],[138,688]],"score":0.7834},{"poly":[[141,620],[447,620],[447,642],[141,642]],"score":0.8484},{"poly":[[141,597],[1081,597],[1081,620],[141,620]],"score":0.6875},{"poly":[[141,576],[1079,576],[1079,599],[141,599]],"score":0.7067},{"poly":[[141,554],[1081,554],[1081,576],[141,576]],"score":0.7811},{"poly":[[141,533],[1081,533],[1081,556],[141,556]],"score":0.6982},{"poly":[[141,512],[1079,512],[1079,533],[141,533]],"score":0.8258},{"poly":[[138,479],[289,477],[289,500],[138,502]],"score":0.7344},{"poly":[[138,454],[1081,455],[1081,479],[138,477]],"score":0.7286},{"poly":[[140,434],[1081,434],[1081,455],[140,455]],"score":0.7871},{"poly":[[140,409],[1079,411],[1079,434],[140,432]],"score":0.7304},{"poly":[[140,391],[1081,391],[1081,412],[140,412]],"score":0.7992},{"poly":[[141,371],[1078,371],[1078,388],[141,388]],"score":0.9944},{"poly":[[141,346],[1081,346],[1081,368],[141,368]],"score":0.8027},{"poly":[[141,302],[454,302],[454,323],[141,323]],"score":0.832},{"poly":[[141,280],[1079,280],[1079,302],[141,302]],"score":0.8111},{"poly":[[143,257],[1079,257],[1079,279],[143,279]],"score":0.8429},{"poly":[[180,213],[730,213],[730,234],[180,234]],"score":0.816},{"poly":[[180,191],[1081,191],[1081,213],[180,213]],"score":0.8094},{"poly":[[176,170],[1083,170],[1083,191],[176,191]],"score":0.8374},{"poly":[[160,147],[1081,147],[1081,168],[160,168]],"score":0.8389},{"poly":[[920,71],[1081,73],[1081,91],[920,89]],"score":0.7551},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8194}],"page_no":10,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1506},"conf":0.7032,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":624,"y0":1482,"y1":1503},"font_size":0.0,"text":"12"}],"source":"layout det","text":""},{"bbox":{"x0":136,"x1":1088,"y0":64,"y1":101},"conf":0.2401,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1081,"y0":71,"y1":91},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":1089,"y0":141,"y1":219},"conf":0.94,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":145,"y1":170},"font_size":-1.355e-07,"text":"team (2) agentic instruction augmentation inspired by AutoIF [12], and (3) a fne-tuned model specialized for generatingi"},{"bbox":{"x0":141,"x1":1081,"y0":170,"y1":193},"font_size":-1.355e-07,"text":"additional instructions that probe specifc failure modes or edge cases. This multipronged approach ensures both breadthi"},{"bbox":{"x0":140,"x1":416,"y0":193,"y1":214},"font_size":-1.355e-07,"text":"and depth in instruction coverage."}],"source":"layout det","text":"team (2) agentic instruction augmentation inspired by AutoIF [12], and (3) a fne-tuned model specialized for generatingi additional instructions that probe specifc failure modes or edge cases. This multipronged approach ensures both breadthi and depth in instruction coverage."},{"bbox":{"x0":137,"x1":1089,"y0":233,"y1":352},"conf":0.9578,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":236,"y1":261},"font_size":-1.355e-07,"text":"FaithfulnessFaithfulness is essential for an agentic model operating in scenarios such as multi-turn tool use, self-"},{"bbox":{"x0":138,"x1":1079,"y0":257,"y1":284},"font_size":-1.355e-07,"text":"generated reasoning chains, and open-environment interactions. Inspired by the evaluation framework from FACTS"},{"bbox":{"x0":141,"x1":1081,"y0":282,"y1":305},"font_size":-1.355e-07,"text":"Grounding [30], we train a sentence-level faithfulness judge model to perform automated verifcation. The judge isi"},{"bbox":{"x0":141,"x1":1079,"y0":304,"y1":325},"font_size":-1.355e-07,"text":"effective in detecting sentences that make a factual claim without supporting evidence in context. It serves as a reward"},{"bbox":{"x0":140,"x1":554,"y0":327,"y1":348},"font_size":-1.355e-07,"text":"model to enhance overall faithfulness performance."}],"source":"layout det","text":"FaithfulnessFaithfulness is essential for an agentic model operating in scenarios such as multi-turn tool use, selfgenerated reasoning chains, and open-environment interactions. Inspired by the evaluation framework from FACTS Grounding [30], we train a sentence-level faithfulness judge model to perform automated verifcation. The judge isi effective in detecting sentences that make a factual claim without supporting evidence in context. It serves as a reward model to enhance overall faithfulness performance."},{"bbox":{"x0":136,"x1":1089,"y0":367,"y1":465},"conf":0.9523,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":371,"y1":396},"font_size":-1.355e-07,"text":"Coding $\\&$  Software EngineeringTo enhance our capability in tackling competition-level programming problems,"},{"bbox":{"x0":141,"x1":1081,"y0":396,"y1":417},"font_size":-1.355e-07,"text":"we gather problems and their judges from both open-source datasets [27, 83] and synthetic sources. To ensure the"},{"bbox":{"x0":140,"x1":1081,"y0":416,"y1":441},"font_size":-1.355e-07,"text":"diversity of the synthetic data and the correctness of reward signals, we incorporate high-quality human-written unit"},{"bbox":{"x0":140,"x1":442,"y0":441,"y1":462},"font_size":-1.355e-07,"text":"tests retrieved from pre-training data."}],"source":"layout det","text":"Coding $\\&$  Software EngineeringTo enhance our capability in tackling competition-level programming problems,we gather problems and their judges from both open-source datasets [27, 83] and synthetic sources. To ensure the diversity of the synthetic data and the correctness of reward signals, we incorporate high-quality human-written unit tests retrieved from pre-training data."},{"bbox":{"x0":136,"x1":1089,"y0":468,"y1":566},"conf":0.9543,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":472,"y1":493},"font_size":-1.355e-07,"text":"For software engineering tasks, we collect a vast amount of pull requests and issues from GitHub to build software"},{"bbox":{"x0":140,"x1":1081,"y0":492,"y1":516},"font_size":-1.355e-07,"text":"development environment that consists of user prompts/issues and executable unit tests. This environment was built on"},{"bbox":{"x0":140,"x1":1081,"y0":516,"y1":538},"font_size":-1.355e-07,"text":"a robust sandbox infrastructure, powered by Kubernetes for scalability and security. It supports over 10,000 concurrent"},{"bbox":{"x0":141,"x1":1081,"y0":541,"y1":558},"font_size":-1.355e-07,"text":"sandbox instances with stable performance, making it ideal for both competitive coding and software engineering tasks."}],"source":"layout det","text":"For software engineering tasks, we collect a vast amount of pull requests and issues from GitHub to build software development environment that consists of user prompts/issues and executable unit tests. This environment was built on a robust sandbox infrastructure, powered by Kubernetes for scalability and security. It supports over 10,000 concurrent sandbox instances with stable performance, making it ideal for both competitive coding and software engineering tasks."},{"bbox":{"x0":135,"x1":1088,"y0":581,"y1":632},"conf":0.9246,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":586,"y1":607},"font_size":-1.355e-07,"text":"SafetyOur work to enhance the safety begins with a human-curated set of seed prompts, manually crafted to"},{"bbox":{"x0":141,"x1":782,"y0":607,"y1":629},"font_size":-1.355e-07,"text":"encompass prevalent risk categories such as violence, fraud, and discrimination."}],"source":"layout det","text":"SafetyOur work to enhance the safety begins with a human-curated set of seed prompts, manually crafted to encompass prevalent risk categories such as violence, fraud, and discrimination."},{"bbox":{"x0":136,"x1":1090,"y0":636,"y1":689},"conf":0.9208,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":640,"y1":663},"font_size":-1.355e-07,"text":"To simulate sophisticated jailbreak attempts (e.g., role-playing, literary narratives, and academic discourse), we employ"},{"bbox":{"x0":140,"x1":687,"y0":663,"y1":685},"font_size":-1.355e-07,"text":"an automated prompt evolution pipeline with three key components:"}],"source":"layout det","text":"To simulate sophisticated jailbreak attempts (e.g., role-playing, literary narratives, and academic discourse), we employ an automated prompt evolution pipeline with three key components:"},{"bbox":{"x0":171,"x1":1093,"y0":697,"y1":728},"conf":0.9053,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1083,"y0":703,"y1":724},"font_size":-1.355e-07,"text":"Attack Model: Iteratively generates adversarial prompts designed to elicit unsafe responses from the target LLM."}],"source":"layout det","text":"Attack Model: Iteratively generates adversarial prompts designed to elicit unsafe responses from the target LLM."},{"bbox":{"x0":173,"x1":896,"y0":730,"y1":758},"conf":0.707,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":891,"y0":731,"y1":756},"font_size":-1.355e-07,"text":"Target Model: Produces responses to these prompts, simulating potential vulnerabilities."}],"source":"layout det","text":"Target Model: Produces responses to these prompts, simulating potential vulnerabilities."},{"bbox":{"x0":171,"x1":1089,"y0":761,"y1":811},"conf":0.947,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":1079,"y0":766,"y1":787},"font_size":-1.355e-07,"text":"Judge Model: Evaluates the interaction to determine if the adversarial prompt successfully bypasses safety"},{"bbox":{"x0":180,"x1":286,"y0":789,"y1":807},"font_size":-1.355e-07,"text":"mechanisms."}],"source":"layout det","text":"Judge Model: Evaluates the interaction to determine if the adversarial prompt successfully bypasses safety mechanisms."},{"bbox":{"x0":136,"x1":1086,"y0":823,"y1":874},"conf":0.9256,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":828,"y1":851},"font_size":-1.355e-07,"text":"Each interaction is assessed using a task-specifc rubric, enabling the judge model to provide a binary success/failurei"},{"bbox":{"x0":140,"x1":191,"y0":848,"y1":873},"font_size":-1.355e-07,"text":"label."}],"source":"layout det","text":"Each interaction is assessed using a task-specifc rubric, enabling the judge model to provide a binary success/failurei label."},{"bbox":{"x0":137,"x1":639,"y0":892,"y1":923},"conf":0.9138,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":632,"y0":898,"y1":919},"font_size":-1.355e-07,"text":"3.2.2Beyond Verifcation: Self-Critique Rubric Rewardi"}],"source":"layout det","text":"3.2.2Beyond Verifcation: Self-Critique Rubric Rewardi"},{"bbox":{"x0":136,"x1":1089,"y0":930,"y1":1094},"conf":0.9701,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":936,"y1":957},"font_size":-1.355e-07,"text":"To extend model alignment beyond tasks with verifable reward, we introduce a framework for general reinforcementi"},{"bbox":{"x0":141,"x1":1083,"y0":957,"y1":980},"font_size":-1.355e-07,"text":"learning from self-critic feedbacks. This approach is designed to align LLMs with nuanced human preferences,"},{"bbox":{"x0":140,"x1":1081,"y0":980,"y1":1002},"font_size":-1.355e-07,"text":"including helpfulness, creativity, depth of reasoning, factuality, and safety, by extending the capabilities learned from"},{"bbox":{"x0":141,"x1":1081,"y0":1002,"y1":1023},"font_size":-1.355e-07,"text":"verifable scenarios to a broader range of subjective tasks. The framework operates using a Self-Critique Rubric Rewardi"},{"bbox":{"x0":141,"x1":1081,"y0":1023,"y1":1046},"font_size":-1.355e-07,"text":"mechanism, where the model evaluates its own outputs to generate preference signals. To bootstrap K2 as a competent"},{"bbox":{"x0":140,"x1":1081,"y0":1043,"y1":1068},"font_size":-1.355e-07,"text":"judge, we curated a mixture of open-source and in-house preference datasets and initialize its critic capability in the"},{"bbox":{"x0":139,"x1":233,"y0":1064,"y1":1091},"font_size":-1.355e-07,"text":"SFT stage."}],"source":"layout det","text":"To extend model alignment beyond tasks with verifable reward, we introduce a framework for general reinforcementi learning from self-critic feedbacks. This approach is designed to align LLMs with nuanced human preferences,including helpfulness, creativity, depth of reasoning, factuality, and safety, by extending the capabilities learned from verifable scenarios to a broader range of subjective tasks. The framework operates using a Self-Critique Rubric Rewardi mechanism, where the model evaluates its own outputs to generate preference signals. To bootstrap K2 as a competent judge, we curated a mixture of open-source and in-house preference datasets and initialize its critic capability in the SFT stage."},{"bbox":{"x0":136,"x1":1089,"y0":1108,"y1":1295},"conf":0.975,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1112,"y1":1137},"font_size":-1.355e-07,"text":"Self-Critiqued Policy OptimizationIn the frst core process of the learning loop, the K2 actor generates responsesi"},{"bbox":{"x0":141,"x1":1081,"y0":1135,"y1":1158},"font_size":-1.355e-07,"text":"for general prompts that cover a wide range of use cases. The K2 critic then ranks all results by performing pairwise"},{"bbox":{"x0":141,"x1":1081,"y0":1158,"y1":1180},"font_size":-1.355e-07,"text":"evaluations against a combination of rubrics, which incorporates both core rubrics (Appendix. F.1), which represent the"},{"bbox":{"x0":141,"x1":1081,"y0":1180,"y1":1201},"font_size":-1.355e-07,"text":"fundamental values of our AI assistant that Kimi cherish, prescriptive rubrics (Appendix. F.2) that aim to eliminate"},{"bbox":{"x0":140,"x1":1081,"y0":1201,"y1":1223},"font_size":-1.355e-07,"text":"reward hacking, and human-annotated rubrics crafted by our data team for specifc instructional contexts. Althoughi"},{"bbox":{"x0":141,"x1":1081,"y0":1224,"y1":1246},"font_size":-1.355e-07,"text":"certain rubrics can be designated as mandatory, K2 retains the fexibility to weigh them against its internal priors. Thisl"},{"bbox":{"x0":141,"x1":1081,"y0":1244,"y1":1267},"font_size":-1.355e-07,"text":"capacity enables a dynamic and continuous alignment with its evolving on-policy behavior, ensuring that the model’s"},{"bbox":{"x0":141,"x1":837,"y0":1267,"y1":1289},"font_size":-1.355e-07,"text":"responses remain coherent with its core identity while adapting to specifc instructions.i"}],"source":"layout det","text":"Self-Critiqued Policy OptimizationIn the frst core process of the learning loop, the K2 actor generates responsesi for general prompts that cover a wide range of use cases. The K2 critic then ranks all results by performing pairwise evaluations against a combination of rubrics, which incorporates both core rubrics (Appendix. F.1), which represent the fundamental values of our AI assistant that Kimi cherish, prescriptive rubrics (Appendix. F.2) that aim to eliminate reward hacking, and human-annotated rubrics crafted by our data team for specifc instructional contexts. Althoughi certain rubrics can be designated as mandatory, K2 retains the fexibility to weigh them against its internal priors. Thisl capacity enables a dynamic and continuous alignment with its evolving on-policy behavior, ensuring that the model’s responses remain coherent with its core identity while adapting to specifc instructions.i"},{"bbox":{"x0":135,"x1":1090,"y0":1308,"y1":1451},"conf":0.9652,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1312,"y1":1337},"font_size":-1.355e-07,"text":"Closed-Loop Critic Refnement and AlignmentDuring RL training, the critic model is refned using verifableiii"},{"bbox":{"x0":141,"x1":1079,"y0":1336,"y1":1358},"font_size":-1.355e-07,"text":"signals. On-policy rollouts generated from verifable-reward prompts are used to continuously update the critic, a cruciali"},{"bbox":{"x0":140,"x1":1081,"y0":1358,"y1":1381},"font_size":-1.355e-07,"text":"step that distills objective performance signals from RLVR directly into its evaluation model. This transfer learning"},{"bbox":{"x0":140,"x1":1081,"y0":1378,"y1":1403},"font_size":-1.355e-07,"text":"process grounds its more subjective judgments in verifable data, allowing the performance gains from verifableii"},{"bbox":{"x0":140,"x1":1081,"y0":1401,"y1":1424},"font_size":-1.355e-07,"text":"tasks to enhance the critic’s judgment on complex tasks that lack explicit reward signals. This closed-loop process"},{"bbox":{"x0":140,"x1":1081,"y0":1424,"y1":1445},"font_size":-1.355e-07,"text":"ensures that the critic continuously recalibrates its evaluation standards in lockstep with the policy’s evolution. By"}],"source":"layout det","text":"Closed-Loop Critic Refnement and AlignmentDuring RL training, the critic model is refned using verifableiii signals. On-policy rollouts generated from verifable-reward prompts are used to continuously update the critic, a cruciali step that distills objective performance signals from RLVR directly into its evaluation model. This transfer learning process grounds its more subjective judgments in verifable data, allowing the performance gains from verifableii tasks to enhance the critic’s judgment on complex tasks that lack explicit reward signals. This closed-loop process ensures that the critic continuously recalibrates its evaluation standards in lockstep with the policy’s evolution. By"}],"formula_dets":[{"bbox":{"x0":211,"x1":227,"y0":376,"y1":392},"conf":0.5903,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1089,"y0":1108,"y1":1295},"conf":0.975,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":930,"y1":1094},"conf":0.9701,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1090,"y0":1308,"y1":1451},"conf":0.9652,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":233,"y1":352},"conf":0.9578,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":468,"y1":566},"conf":0.9543,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":367,"y1":465},"conf":0.9523,"label":"Text","label_id":1},{"bbox":{"x0":171,"x1":1089,"y0":761,"y1":811},"conf":0.947,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":141,"y1":219},"conf":0.94,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":823,"y1":874},"conf":0.9256,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1088,"y0":581,"y1":632},"conf":0.9246,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1090,"y0":636,"y1":689},"conf":0.9208,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":639,"y0":892,"y1":923},"conf":0.9138,"label":"Title","label_id":0},{"bbox":{"x0":171,"x1":1093,"y0":697,"y1":728},"conf":0.9053,"label":"Text","label_id":1},{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7578,"label":"Abandon","label_id":2},{"bbox":{"x0":173,"x1":896,"y0":730,"y1":758},"conf":0.707,"label":"Text","label_id":1},{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1506},"conf":0.7032,"label":"Abandon","label_id":2},{"bbox":{"x0":136,"x1":1088,"y0":64,"y1":101},"conf":0.2401,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1482],[624,1482],[624,1503],[599,1503]],"score":0.9218},{"poly":[[140,1424],[1081,1424],[1081,1445],[140,1445]],"score":0.8914},{"poly":[[140,1401],[1081,1401],[1081,1424],[140,1424]],"score":0.6925},{"poly":[[140,1379],[1081,1378],[1081,1401],[140,1403]],"score":0.716},{"poly":[[140,1358],[1081,1358],[1081,1381],[140,1381]],"score":0.7023},{"poly":[[141,1336],[1079,1336],[1079,1358],[141,1358]],"score":0.7827},{"poly":[[141,1312],[1081,1313],[1081,1337],[141,1335]],"score":0.7745},{"poly":[[141,1267],[837,1267],[837,1289],[141,1289]],"score":0.8167},{"poly":[[141,1244],[1081,1244],[1081,1267],[141,1267]],"score":0.703},{"poly":[[141,1224],[1081,1224],[1081,1246],[141,1246]],"score":0.8117},{"poly":[[140,1201],[1081,1201],[1081,1223],[140,1223]],"score":0.811},{"poly":[[141,1180],[1081,1180],[1081,1201],[141,1201]],"score":0.8288},{"poly":[[141,1158],[1081,1158],[1081,1180],[141,1180]],"score":0.8154},{"poly":[[141,1135],[1081,1135],[1081,1158],[141,1158]],"score":0.6826},{"poly":[[140,1112],[1081,1114],[1081,1137],[140,1135]],"score":0.7441},{"poly":[[141,1064],[233,1070],[232,1091],[139,1085]],"score":0.8354},{"poly":[[140,1044],[1081,1043],[1081,1066],[140,1068]],"score":0.7168},{"poly":[[141,1023],[1081,1023],[1081,1046],[141,1046]],"score":0.6746},{"poly":[[141,1002],[1081,1002],[1081,1023],[141,1023]],"score":0.8214},{"poly":[[140,980],[1081,980],[1081,1002],[140,1002]],"score":0.7874},{"poly":[[141,957],[1083,957],[1083,980],[141,980]],"score":0.7113},{"poly":[[141,936],[1081,936],[1081,957],[141,957]],"score":0.8363},{"poly":[[141,898],[632,898],[632,919],[141,919]],"score":0.8362},{"poly":[[140,848],[191,848],[191,873],[140,873]],"score":0.7656},{"poly":[[141,828],[1081,828],[1081,851],[141,851]],"score":0.7146},{"poly":[[180,789],[286,789],[286,807],[180,807]],"score":0.9003},{"poly":[[161,766],[1079,766],[1079,787],[161,787]],"score":0.8566},{"poly":[[160,731],[891,733],[891,756],[160,754]],"score":0.7334},{"poly":[[160,703],[1083,703],[1083,724],[160,724]],"score":0.7801},{"poly":[[140,663],[687,663],[687,685],[140,685]],"score":0.8057},{"poly":[[141,640],[1081,640],[1081,663],[141,663]],"score":0.6999},{"poly":[[141,607],[782,607],[782,629],[141,629]],"score":0.7694},{"poly":[[141,586],[1081,586],[1081,607],[141,607]],"score":0.7978},{"poly":[[141,541],[1081,541],[1081,558],[141,558]],"score":0.9758},{"poly":[[140,516],[1081,516],[1081,538],[140,538]],"score":0.7737},{"poly":[[140,492],[1081,493],[1081,516],[140,515]],"score":0.762},{"poly":[[140,472],[1081,472],[1081,493],[140,493]],"score":0.7727},{"poly":[[140,441],[442,441],[442,462],[140,462]],"score":0.797},{"poly":[[140,416],[1081,417],[1081,441],[140,439]],"score":0.7671},{"poly":[[141,396],[1081,396],[1081,417],[141,417]],"score":0.7886},{"poly":[[140,371],[1083,373],[1083,396],[140,394]],"score":0.7424},{"poly":[[140,327],[554,327],[554,348],[140,348]],"score":0.7933},{"poly":[[141,304],[1079,304],[1079,325],[141,325]],"score":0.7286},{"poly":[[141,282],[1081,282],[1081,305],[141,305]],"score":0.7111},{"poly":[[138,261],[1079,257],[1079,280],[138,284]],"score":0.6497},{"poly":[[140,236],[1081,238],[1081,261],[140,259]],"score":0.7658},{"poly":[[140,193],[416,193],[416,214],[140,214]],"score":0.8284},{"poly":[[141,170],[1081,170],[1081,193],[141,193]],"score":0.7206},{"poly":[[140,145],[1081,147],[1081,170],[140,168]],"score":0.7334},{"poly":[[920,71],[1081,73],[1081,91],[920,89]],"score":0.7918},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8105}],"page_no":11,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1087,"y0":65,"y1":94},"conf":0.7767,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1081,"y0":71,"y1":91},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":595,"x1":626,"y0":1479,"y1":1506},"conf":0.6932,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":624,"y0":1482,"y1":1503},"font_size":0.0,"text":"13"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":1091,"y0":142,"y1":195},"conf":0.9153,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1084,"y0":144,"y1":173},"font_size":9.0,"text":"grounding subjective evaluation in verifable data, the framework enables robust and scalable alignment with complex,i"},{"bbox":{"x0":140,"x1":406,"y0":170,"y1":191},"font_size":9.0,"text":"non-verifable human objectives.i"}],"source":"layout det","text":"grounding subjective evaluation in verifable data, the framework enables robust and scalable alignment with complex,i non-verifable human objectives.i"},{"bbox":{"x0":137,"x1":1092,"y0":198,"y1":251},"conf":0.9223,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":200,"y1":224},"font_size":9.0,"text":"Consequently, this holistic alignment yields comprehensive performance improvements across a wide spectrum of do-"},{"bbox":{"x0":141,"x1":1083,"y0":224,"y1":246},"font_size":9.0,"text":"mains, including user intent understanding, creative writing, complex reasoning, and nuanced language comprehension."}],"source":"layout det","text":"Consequently, this holistic alignment yields comprehensive performance improvements across a wide spectrum of domains, including user intent understanding, creative writing, complex reasoning, and nuanced language comprehension."},{"bbox":{"x0":137,"x1":332,"y0":276,"y1":307},"conf":0.8894,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":326,"y0":280,"y1":302},"font_size":9.0,"text":"3.2.3RL Algorithm"}],"source":"layout det","text":"3.2.3RL Algorithm"},{"bbox":{"x0":136,"x1":1090,"y0":318,"y1":394},"conf":0.9446,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":323,"y1":345},"font_size":9.0,"text":"We adopt the policy optimization algorithm introduced in K1.5 [35] as the foundation for K2. For each problem x,"},{"bbox":{"x0":140,"x1":1081,"y0":344,"y1":368},"font_size":9.0,"text":"we sample $K$  responses $\\{y_{1},\\ldots,y_{k}\\}$  from the previous policy $\\pi_{\\text{old}},$  and optimize the model $\\pi_{\\theta}$  with respect to the"},{"bbox":{"x0":140,"x1":304,"y0":363,"y1":388},"font_size":9.0,"text":"following objective:"}],"source":"layout det","text":"We adopt the policy optimization algorithm introduced in K1.5 [35] as the foundation for K2. For each problem x,we sample $K$  responses $\\{y_{1},\\ldots,y_{k}\\}$  from the previous policy $\\pi_{\\text{old}},$  and optimize the model $\\pi_{\\theta}$  with respect to the following objective:"},{"bbox":{"x0":326,"x1":896,"y0":412,"y1":478},"conf":0.942,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$L_{\\text{RL}}(\\theta)=\\mathbb{E}_{x\\sim\\mathcal{D}}\\left[\\frac{1}{K}\\sum_{i=1}^{K}\\left[\\left(r(x,y_{i})-\\bar{r}(x)-\\tau\\log\\frac{\\pi_{\\theta}(y_{i}|x)}{\\pi_{\\text{old}}(y_{i}|x)}\\right)^{2}\\right]\\right] ,$$"},{"bbox":{"x0":135,"x1":1089,"y0":495,"y1":598},"conf":0.9524,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1080,"y0":499,"y1":529},"font_size":9.0,"text":"where $$  is the mean rewards of the sampled responses, $\\tau>0$  is a regularization parameter that"},{"bbox":{"x0":141,"x1":1081,"y0":526,"y1":549},"font_size":1.355e-07,"text":"promotes stablke learning. As in SFT, we employ the Muon optimizer [33] to minimize this objective. As we scale"},{"bbox":{"x0":143,"x1":1081,"y0":549,"y1":571},"font_size":1.355e-07,"text":"RL training to encompass a broader range of tasks in K2, a primary challenge is achieving consistent performance"},{"bbox":{"x0":141,"x1":958,"y0":571,"y1":592},"font_size":1.355e-07,"text":"improvements across all domains. To address this, we introduce several additions to the RL algorithm."}],"source":"layout det","text":"where $$  is the mean rewards of the sampled responses, $\\tau>0$  is a regularization parameter that promotes stablke learning. As in SFT, we employ the Muon optimizer [33] to minimize this objective. As we scale RL training to encompass a broader range of tasks in K2, a primary challenge is achieving consistent performance improvements across all domains. To address this, we introduce several additions to the RL algorithm."},{"bbox":{"x0":137,"x1":1089,"y0":621,"y1":806},"conf":0.9746,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1083,"y0":627,"y1":648},"font_size":1.355e-07,"text":"Budget ControlIt has been widely observed that RL often results in a substantial increase in the length of model-"},{"bbox":{"x0":141,"x1":1081,"y0":650,"y1":672},"font_size":1.355e-07,"text":"generated responses [35, 19]. While longer responses can enable the model to utilize additional test-time compute for"},{"bbox":{"x0":140,"x1":1081,"y0":670,"y1":695},"font_size":1.355e-07,"text":"improved performance on complex reasoning tasks, the benefts often do not justify its inference cost in non-reasoningi"},{"bbox":{"x0":141,"x1":1079,"y0":693,"y1":714},"font_size":1.355e-07,"text":"domains. To encourage the model to properly distribute inference budget, we enforce a per-sample maximum token"},{"bbox":{"x0":140,"x1":1081,"y0":714,"y1":736},"font_size":1.355e-07,"text":"budget throughout RL training, where the budget is determined based on the type of task. Responses that exceed"},{"bbox":{"x0":140,"x1":1081,"y0":734,"y1":759},"font_size":1.355e-07,"text":"this token budget are truncated and assigned a penalty, which incentivizes the model to generate solutions within the"},{"bbox":{"x0":141,"x1":1081,"y0":759,"y1":780},"font_size":1.355e-07,"text":"specifed limit. Empirically, this approach signifcantly enhances the model’s token effciency, encouraging concise yetiii"},{"bbox":{"x0":141,"x1":446,"y0":779,"y1":802},"font_size":1.355e-07,"text":"effective solutions across all domains."}],"source":"layout det","text":"Budget ControlIt has been widely observed that RL often results in a substantial increase in the length of modelgenerated responses [35, 19]. While longer responses can enable the model to utilize additional test-time compute for improved performance on complex reasoning tasks, the benefts often do not justify its inference cost in non-reasoningi domains. To encourage the model to properly distribute inference budget, we enforce a per-sample maximum token budget throughout RL training, where the budget is determined based on the type of task. Responses that exceed this token budget are truncated and assigned a penalty, which incentivizes the model to generate solutions within the specifed limit. Empirically, this approach signifcantly enhances the model’s token effciency, encouraging concise yetiii effective solutions across all domains."},{"bbox":{"x0":136,"x1":1089,"y0":832,"y1":953},"conf":0.9596,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":835,"y1":860},"font_size":1.355e-07,"text":"PTX LossTo prevent the potential forgetting of valuable, high-quality data during joint RL training, we curate a"},{"bbox":{"x0":141,"x1":1081,"y0":860,"y1":881},"font_size":1.355e-07,"text":"dataset comprising hand-selected, high-quality samples and integrate it into the RL objective through an auxiliary PTX"},{"bbox":{"x0":141,"x1":1081,"y0":881,"y1":904},"font_size":1.355e-07,"text":"loss [54]. This strategy not only leverages the advantages of high-quality data, but also mitigates the risk of overfttingi"},{"bbox":{"x0":141,"x1":1079,"y0":903,"y1":924},"font_size":1.355e-07,"text":"to the limited set of tasks explicitly present in the training regime. This augmentation substantially improves the model’s"},{"bbox":{"x0":140,"x1":541,"y0":924,"y1":949},"font_size":1.355e-07,"text":"generalization across a broader range of domains."}],"source":"layout det","text":"PTX LossTo prevent the potential forgetting of valuable, high-quality data during joint RL training, we curate a dataset comprising hand-selected, high-quality samples and integrate it into the RL objective through an auxiliary PTX loss [54]. This strategy not only leverages the advantages of high-quality data, but also mitigates the risk of overfttingi to the limited set of tasks explicitly present in the training regime. This augmentation substantially improves the model’s generalization across a broader range of domains."},{"bbox":{"x0":137,"x1":1088,"y0":977,"y1":1163},"conf":0.975,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":980,"y1":1005},"font_size":1.355e-07,"text":"Temperature DecayFor tasks such as creative writing and complex reasoning, we fnd that promoting explorationi"},{"bbox":{"x0":141,"x1":1081,"y0":1005,"y1":1026},"font_size":1.355e-07,"text":"via a high sampling temperature during the initial stages of training is crucial. A high temperature allow the model to"},{"bbox":{"x0":138,"x1":1081,"y0":1023,"y1":1049},"font_size":1.355e-07,"text":"generate diverse and innovative responses, thereby facilitating the discovery of effective strategies and reducing the risk"},{"bbox":{"x0":140,"x1":1081,"y0":1046,"y1":1071},"font_size":1.355e-07,"text":"of premature convergence to suboptimal solutions. However, retaining a high temperature in the later stages of training"},{"bbox":{"x0":140,"x1":1081,"y0":1069,"y1":1091},"font_size":1.355e-07,"text":"or during evaluation can be detrimental, as it introduces excessive randomness and compromises the reliability and"},{"bbox":{"x0":141,"x1":1078,"y0":1091,"y1":1112},"font_size":1.355e-07,"text":"consistency of the model’s outputs. To address this, we employ a temperature decay schedule, to shift from exploration"},{"bbox":{"x0":141,"x1":1081,"y0":1114,"y1":1135},"font_size":1.355e-07,"text":"to exploitation throughout the training. This strategy ensures that the model leverages exploration when it is most"},{"bbox":{"x0":138,"x1":718,"y0":1134,"y1":1158},"font_size":1.355e-07,"text":"benefcial, while ultimately converge on stable and high-quality outputs.i"}],"source":"layout det","text":"Temperature DecayFor tasks such as creative writing and complex reasoning, we fnd that promoting explorationi via a high sampling temperature during the initial stages of training is crucial. A high temperature allow the model to generate diverse and innovative responses, thereby facilitating the discovery of effective strategies and reducing the risk of premature convergence to suboptimal solutions. However, retaining a high temperature in the later stages of training or during evaluation can be detrimental, as it introduces excessive randomness and compromises the reliability and consistency of the model’s outputs. To address this, we employ a temperature decay schedule, to shift from exploration to exploitation throughout the training. This strategy ensures that the model leverages exploration when it is most benefcial, while ultimately converge on stable and high-quality outputs.i"},{"bbox":{"x0":136,"x1":351,"y0":1191,"y1":1220},"conf":0.8818,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":346,"y0":1193,"y1":1218},"font_size":9.0,"text":"3.3RL Infrastructure"}],"source":"layout det","text":"3.3RL Infrastructure"},{"bbox":{"x0":136,"x1":408,"y0":1235,"y1":1263},"conf":0.8786,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":404,"y0":1239,"y1":1261},"font_size":9.0,"text":"3.3.1Colocated Architecture"}],"source":"layout det","text":"3.3.1Colocated Architecture"},{"bbox":{"x0":135,"x1":1089,"y0":1277,"y1":1393},"conf":0.9579,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1081,"y0":1279,"y1":1304},"font_size":1.355e-07,"text":"Similar to K1.5 [35], we adopt a hybrid colocated architecture for our synchronized RL training, where the training and"},{"bbox":{"x0":141,"x1":1078,"y0":1304,"y1":1325},"font_size":1.355e-07,"text":"inference engines live on the same workers. When one engine is actively working, the other engine releases or offoadsl"},{"bbox":{"x0":140,"x1":1081,"y0":1323,"y1":1348},"font_size":1.355e-07,"text":"its GPU resources to accommodate. In each iteration of RL training, a centralized controller frst calls the inferencei"},{"bbox":{"x0":140,"x1":1081,"y0":1348,"y1":1370},"font_size":1.355e-07,"text":"engine to generate new data for training. It then notifes the training engine to train on the new data, and send updatedi"},{"bbox":{"x0":138,"x1":590,"y0":1366,"y1":1393},"font_size":1.355e-07,"text":"parameters to the inference engine for the next iteration."}],"source":"layout det","text":"Similar to K1.5 [35], we adopt a hybrid colocated architecture for our synchronized RL training, where the training and inference engines live on the same workers. When one engine is actively working, the other engine releases or offoadsl its GPU resources to accommodate. In each iteration of RL training, a centralized controller frst calls the inferencei engine to generate new data for training. It then notifes the training engine to train on the new data, and send updatedi parameters to the inference engine for the next iteration."},{"bbox":{"x0":136,"x1":1089,"y0":1397,"y1":1451},"conf":0.9115,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":1401,"y1":1424},"font_size":9.0,"text":"Each engine is heavily optimized for throughput. In addition, as the model scales to the size of K2, the latency of engine"},{"bbox":{"x0":140,"x1":1051,"y0":1424,"y1":1445},"font_size":9.0,"text":"switching and failure recovery becomes signifcant. We present our system design considerations in these aspects.i"}],"source":"layout det","text":"Each engine is heavily optimized for throughput. In addition, as the model scales to the size of K2, the latency of engine switching and failure recovery becomes signifcant. We present our system design considerations in these aspects.i"}],"formula_dets":[{"bbox":{"x0":326,"x1":896,"y0":412,"y1":478},"conf":0.942,"label":"print_isolated","label_id":1},{"bbox":{"x0":194,"x1":388,"y0":499,"y1":529},"conf":0.9077,"label":"print_embedding","label_id":0},{"bbox":{"x0":344,"x1":446,"y0":344,"y1":368},"conf":0.8968,"label":"print_embedding","label_id":0},{"bbox":{"x0":765,"x1":813,"y0":505,"y1":524},"conf":0.8568,"label":"print_embedding","label_id":0},{"bbox":{"x0":234,"x1":252,"y0":347,"y1":362},"conf":0.831,"label":"print_embedding","label_id":0},{"bbox":{"x0":658,"x1":696,"y0":350,"y1":366},"conf":0.6885,"label":"print_embedding","label_id":0},{"bbox":{"x0":901,"x1":921,"y0":352,"y1":365},"conf":0.6789,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1088,"y0":977,"y1":1163},"conf":0.975,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":621,"y1":806},"conf":0.9746,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":832,"y1":953},"conf":0.9596,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":1277,"y1":1393},"conf":0.9579,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":495,"y1":598},"conf":0.9524,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1090,"y0":318,"y1":394},"conf":0.9446,"label":"Text","label_id":1},{"bbox":{"x0":318,"x1":905,"y0":406,"y1":482},"conf":0.942,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":1092,"y0":198,"y1":251},"conf":0.9223,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1091,"y0":142,"y1":195},"conf":0.9153,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":1397,"y1":1451},"conf":0.9115,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":332,"y0":276,"y1":307},"conf":0.8894,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":351,"y0":1191,"y1":1220},"conf":0.8818,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":408,"y0":1235,"y1":1263},"conf":0.8786,"label":"Title","label_id":0},{"bbox":{"x0":557,"x1":1087,"y0":65,"y1":94},"conf":0.7767,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":626,"y0":1479,"y1":1506},"conf":0.6932,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1482],[624,1482],[624,1503],[599,1503]],"score":0.9254},{"poly":[[140,1424],[1051,1424],[1051,1445],[140,1445]],"score":0.8832},{"poly":[[141,1401],[1079,1401],[1079,1424],[141,1424]],"score":0.6997},{"poly":[[138,1370],[590,1366],[590,1389],[138,1393]],"score":0.739},{"poly":[[140,1348],[1081,1348],[1081,1370],[140,1370]],"score":0.7676},{"poly":[[140,1323],[1081,1325],[1081,1348],[140,1346]],"score":0.7574},{"poly":[[141,1304],[1078,1304],[1078,1325],[141,1325]],"score":0.8131},{"poly":[[138,1279],[1081,1280],[1081,1304],[138,1302]],"score":0.7755},{"poly":[[140,1239],[404,1239],[404,1261],[140,1261]],"score":0.8243},{"poly":[[138,1193],[346,1195],[346,1218],[138,1216]],"score":0.7881},{"poly":[[138,1134],[718,1135],[718,1158],[138,1157]],"score":0.7514},{"poly":[[141,1114],[1081,1114],[1081,1135],[141,1135]],"score":0.8305},{"poly":[[141,1091],[1078,1091],[1078,1112],[141,1112]],"score":0.8076},{"poly":[[140,1069],[1081,1069],[1081,1091],[140,1091]],"score":0.7467},{"poly":[[140,1046],[1081,1048],[1081,1071],[140,1069]],"score":0.7028},{"poly":[[138,1026],[1081,1023],[1081,1046],[138,1049]],"score":0.6437},{"poly":[[141,1005],[1081,1005],[1081,1026],[141,1026]],"score":0.7698},{"poly":[[140,980],[1081,982],[1081,1005],[140,1003]],"score":0.7628},{"poly":[[140,926],[540,924],[541,947],[140,949]],"score":0.686},{"poly":[[141,903],[1079,903],[1079,924],[141,924]],"score":0.7889},{"poly":[[141,881],[1081,881],[1081,904],[141,904]],"score":0.6777},{"poly":[[141,860],[1081,860],[1081,881],[141,881]],"score":0.8065},{"poly":[[140,835],[1081,837],[1081,860],[140,858]],"score":0.7621},{"poly":[[141,779],[446,780],[446,802],[141,800]],"score":0.7858},{"poly":[[141,759],[1081,759],[1081,780],[141,780]],"score":0.8104},{"poly":[[140,734],[1081,736],[1081,759],[140,757]],"score":0.7577},{"poly":[[140,714],[1081,714],[1081,736],[140,736]],"score":0.746},{"poly":[[141,693],[1079,693],[1079,714],[141,714]],"score":0.7567},{"poly":[[140,670],[1081,672],[1081,695],[140,693]],"score":0.7122},{"poly":[[141,650],[1081,650],[1081,672],[141,672]],"score":0.8083},{"poly":[[143,627],[1083,627],[1083,648],[143,648]],"score":0.8325},{"poly":[[141,571],[958,571],[958,592],[141,592]],"score":0.8054},{"poly":[[143,549],[1081,549],[1081,571],[143,571]],"score":0.828},{"poly":[[141,526],[1081,526],[1081,549],[141,549]],"score":0.6984},{"poly":[[504,457],[536,457],[536,477],[504,477]],"score":0.7428},{"poly":[[750,444],[845,444],[845,474],[750,474]],"score":0.8356},{"poly":[[476,439],[504,439],[504,469],[476,469]],"score":0.7783},{"poly":[[554,431],[753,431],[753,459],[554,459]],"score":0.8376},{"poly":[[320,422],[466,428],[465,462],[319,457]],"score":0.6703},{"poly":[[497,422],[534,422],[534,464],[497,464]],"score":0.8435},{"poly":[[755,416],[838,416],[838,446],[755,446]],"score":0.7492},{"poly":[[482,419],[496,419],[496,444],[482,444]],"score":0.705},{"poly":[[504,411],[531,411],[531,432],[504,432]],"score":0.7732},{"poly":[[140,363],[304,365],[304,388],[140,386]],"score":0.8173},{"poly":[[140,345],[1081,345],[1081,368],[140,368]],"score":0.7367},{"poly":[[141,323],[1083,323],[1083,345],[141,345]],"score":0.8339},{"poly":[[141,280],[326,280],[326,302],[141,302]],"score":0.8701},{"poly":[[141,224],[1083,224],[1083,246],[141,246]],"score":0.8307},{"poly":[[140,200],[1083,201],[1083,224],[140,223]],"score":0.7297},{"poly":[[140,170],[406,170],[406,191],[140,191]],"score":0.8584},{"poly":[[138,145],[1084,144],[1084,172],[138,173]],"score":0.6707},{"poly":[[920,71],[1081,73],[1081,91],[920,89]],"score":0.759},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8434}],"page_no":12,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":556,"x1":1087,"y0":65,"y1":94},"conf":0.774,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":919,"x1":1081,"y0":68,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":595,"x1":627,"y0":1480,"y1":1506},"conf":0.6932,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":625,"y0":1482,"y1":1503},"font_size":0.0,"text":"14"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":377,"x1":854,"y0":140,"y1":409},"conf":0.9776,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![dca6e2033728ddc0e8f9ff276d733311](imgs/dca6e2033728ddc0e8f9ff276d733311.jpg)"},{"bbox":{"x0":373,"x1":850,"y0":422,"y1":455},"conf":0.9055,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":377,"x1":845,"y0":424,"y1":449},"font_size":9.478e-27,"text":"Figure 10: Parameter update utilizing a checkpoint engine"}],"source":"layout det","text":"Figure 10: Parameter update utilizing a checkpoint engine"},{"bbox":{"x0":136,"x1":437,"y0":491,"y1":521},"conf":0.895,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":432,"y0":492,"y1":518},"font_size":9.478e-27,"text":"3.3.2Effcient Engine Switchingi"}],"source":"layout det","text":"3.3.2Effcient Engine Switchingi"},{"bbox":{"x0":135,"x1":1088,"y0":528,"y1":603},"conf":0.9411,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":531,"y1":554},"font_size":9.478e-27,"text":"During rollout, the parameters of the training engine are offoaded to DRAM. Bringing up the training engine isl"},{"bbox":{"x0":141,"x1":1083,"y0":554,"y1":576},"font_size":9.478e-27,"text":"therefore a simple step of H2D transmission. However, bringing up the inference engine is a bigger challenge, as it"},{"bbox":{"x0":138,"x1":880,"y0":574,"y1":599},"font_size":9.478e-27,"text":"must obtain updated parameters from the training engine with a different sharding paradigm."}],"source":"layout det","text":"During rollout, the parameters of the training engine are offoaded to DRAM. Bringing up the training engine isl therefore a simple step of H2D transmission. However, bringing up the inference engine is a bigger challenge, as it must obtain updated parameters from the training engine with a different sharding paradigm."},{"bbox":{"x0":136,"x1":1089,"y0":606,"y1":789},"conf":0.9772,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":609,"y1":630},"font_size":9.478e-27,"text":"Given the scale of K2 and the vast number of devices involved, using a network fle system for resharding andi"},{"bbox":{"x0":141,"x1":1079,"y0":630,"y1":653},"font_size":9.478e-27,"text":"broadcasting parameters is impractical. The aggregate bandwidth required to keep overhead low reaches several"},{"bbox":{"x0":141,"x1":1081,"y0":652,"y1":675},"font_size":9.478e-27,"text":"petabytes per second. To address this challenge, we developed a distributed checkpoint engine co-located on training"},{"bbox":{"x0":140,"x1":1081,"y0":675,"y1":696},"font_size":9.478e-27,"text":"nodes to manage parameter states. To perform a parameter update, each checkpoint engine worker obtains a local copy"},{"bbox":{"x0":140,"x1":1083,"y0":696,"y1":718},"font_size":9.478e-27,"text":"of parameters from the training engine, then broadcasts the full parameter set across all checkpoint engine workers."},{"bbox":{"x0":140,"x1":1083,"y0":716,"y1":741},"font_size":9.478e-27,"text":"Subsequently, the inference engine retrieves only the parameter shard it requires from the checkpoint engine. This"},{"bbox":{"x0":141,"x1":1083,"y0":741,"y1":762},"font_size":9.478e-27,"text":"process is illustrated in Figure 10. To enable this for a 1T model, updates are performed parameter-by-parameter in a"},{"bbox":{"x0":138,"x1":682,"y0":761,"y1":785},"font_size":9.478e-27,"text":"pipelined manner, minimizing memory footprint (see Appendix G)."}],"source":"layout det","text":"Given the scale of K2 and the vast number of devices involved, using a network fle system for resharding andi broadcasting parameters is impractical. The aggregate bandwidth required to keep overhead low reaches several petabytes per second. To address this challenge, we developed a distributed checkpoint engine co-located on training nodes to manage parameter states. To perform a parameter update, each checkpoint engine worker obtains a local copy of parameters from the training engine, then broadcasts the full parameter set across all checkpoint engine workers.Subsequently, the inference engine retrieves only the parameter shard it requires from the checkpoint engine. This process is illustrated in Figure 10. To enable this for a 1T model, updates are performed parameter-by-parameter in a pipelined manner, minimizing memory footprint (see Appendix G)."},{"bbox":{"x0":136,"x1":1091,"y0":791,"y1":886},"conf":0.9572,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":794,"y1":815},"font_size":9.478e-27,"text":"We opt to broadcast the full parameter set across the entire cluster, regardless of the specifc sharding schemes on eachi"},{"bbox":{"x0":140,"x1":1081,"y0":817,"y1":838},"font_size":9.478e-27,"text":"inference worker. While this transfers several times more data than a theoretically optimal approach, it offers a simpler"},{"bbox":{"x0":141,"x1":1081,"y0":838,"y1":860},"font_size":9.478e-27,"text":"system design that is less intrusive to the training and inference engines. We chose to trade off this minor overhead to"},{"bbox":{"x0":140,"x1":1019,"y0":858,"y1":883},"font_size":9.478e-27,"text":"fully decouple the training engine and the inference engine, signifcantly simplifying maintenance and testing.i"}],"source":"layout det","text":"We opt to broadcast the full parameter set across the entire cluster, regardless of the specifc sharding schemes on eachi inference worker. While this transfers several times more data than a theoretically optimal approach, it offers a simpler system design that is less intrusive to the training and inference engines. We chose to trade off this minor overhead to fully decouple the training engine and the inference engine, signifcantly simplifying maintenance and testing.i"},{"bbox":{"x0":136,"x1":1091,"y0":890,"y1":965},"conf":0.9527,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":893,"y1":914},"font_size":9.478e-27,"text":"Notably, this approach outperforms the transfer-what-you-need method due to reduced synchronization overhead and"},{"bbox":{"x0":141,"x1":1081,"y0":914,"y1":936},"font_size":9.478e-27,"text":"higher network bandwidth utilization. Our system can complete a full parameter update for Kimi K2 with less than 30"},{"bbox":{"x0":143,"x1":657,"y0":939,"y1":955},"font_size":9.478e-27,"text":"seconds, a negligible duration for a typical RL training iteration."}],"source":"layout det","text":"Notably, this approach outperforms the transfer-what-you-need method due to reduced synchronization overhead and higher network bandwidth utilization. Our system can complete a full parameter update for Kimi K2 with less than 30 seconds, a negligible duration for a typical RL training iteration."},{"bbox":{"x0":137,"x1":418,"y0":980,"y1":1010},"conf":0.8846,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":412,"y0":982,"y1":1007},"font_size":9.478e-27,"text":"3.3.3Effcient System Startupi"}],"source":"layout det","text":"3.3.3Effcient System Startupi"},{"bbox":{"x0":135,"x1":1089,"y0":1017,"y1":1125},"conf":0.9647,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1081,"y0":1018,"y1":1043},"font_size":9.478e-27,"text":"As large-scale training is prone to system failure, optimizing the startup time is crucial for models as large as Kimi K2."},{"bbox":{"x0":141,"x1":1081,"y0":1053,"y1":1076},"font_size":9.478e-27,"text":"To start the training engine, we let each training worker selectively read part or none of the parameters from disk, and"},{"bbox":{"x0":141,"x1":1081,"y0":1076,"y1":1099},"font_size":9.478e-27,"text":"broadcast necessary parameters to its peers. The design goal is to ensure all workers collectively read the checkpoint"},{"bbox":{"x0":140,"x1":477,"y0":1096,"y1":1119},"font_size":9.478e-27,"text":"only once, minimizing expensive disk IO."}],"source":"layout det","text":"As large-scale training is prone to system failure, optimizing the startup time is crucial for models as large as Kimi K2.To start the training engine, we let each training worker selectively read part or none of the parameters from disk, and broadcast necessary parameters to its peers. The design goal is to ensure all workers collectively read the checkpoint only once, minimizing expensive disk IO."},{"bbox":{"x0":136,"x1":1088,"y0":1128,"y1":1267},"conf":0.9696,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1130,"y1":1152},"font_size":9.478e-27,"text":"As the inference engines are independent replicas, we would like to avoid introducing extra synchronization barriers"},{"bbox":{"x0":141,"x1":1081,"y0":1152,"y1":1175},"font_size":9.478e-27,"text":"between them. Therefore, we opt to reuse checkpoint engine for startup: we let checkpoint engine collectively read the"},{"bbox":{"x0":140,"x1":1081,"y0":1171,"y1":1196},"font_size":9.478e-27,"text":"checkpoint from disk, similar to how the training engine starts. Then it updates the state of the uninitialized inference"},{"bbox":{"x0":140,"x1":1081,"y0":1196,"y1":1218},"font_size":9.478e-27,"text":"engine, using the approach introduced in the previous section. By leveraging the dedicated checkpoint engine, the"},{"bbox":{"x0":138,"x1":1083,"y0":1214,"y1":1244},"font_size":9.478e-27,"text":"system also becomes robust to single-point failures, because an inference replica can restart without communicating"},{"bbox":{"x0":140,"x1":296,"y0":1241,"y1":1262},"font_size":9.478e-27,"text":"with other replicas."}],"source":"layout det","text":"As the inference engines are independent replicas, we would like to avoid introducing extra synchronization barriers between them. Therefore, we opt to reuse checkpoint engine for startup: we let checkpoint engine collectively read the checkpoint from disk, similar to how the training engine starts. Then it updates the state of the uninitialized inference engine, using the approach introduced in the previous section. By leveraging the dedicated checkpoint engine, the system also becomes robust to single-point failures, because an inference replica can restart without communicating with other replicas."},{"bbox":{"x0":136,"x1":344,"y0":1283,"y1":1314},"conf":0.8967,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":339,"y0":1284,"y1":1309},"font_size":9.478e-27,"text":"3.3.4Agentic Rollout"}],"source":"layout det","text":"3.3.4Agentic Rollout"},{"bbox":{"x0":136,"x1":1090,"y0":1321,"y1":1393},"conf":0.9443,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1322,"y1":1348},"font_size":9.478e-27,"text":"Our RL infrastructure supports the training of long-horizon, multi-turn agentic tasks. During rollout, these tasks present"},{"bbox":{"x0":143,"x1":1081,"y0":1350,"y1":1366},"font_size":9.478e-27,"text":"distinct challenges, such as complex environmental interactions and prolonged rollout durations. Here we introduce a"},{"bbox":{"x0":141,"x1":482,"y0":1368,"y1":1389},"font_size":9.478e-27,"text":"few optimizations to alleviate these issues."}],"source":"layout det","text":"Our RL infrastructure supports the training of long-horizon, multi-turn agentic tasks. During rollout, these tasks present distinct challenges, such as complex environmental interactions and prolonged rollout durations. Here we introduce a few optimizations to alleviate these issues."},{"bbox":{"x0":136,"x1":1090,"y0":1396,"y1":1451},"conf":0.9216,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1398,"y1":1424},"font_size":9.478e-27,"text":"Due to the diversity of environments, certain interactions may be blocked on waiting for environment feedback (e.g., a"},{"bbox":{"x0":140,"x1":1083,"y0":1421,"y1":1445},"font_size":9.478e-27,"text":"virtual machine or a code interpreter), leaving the GPUs idle. We employ two strategies to maximize GPU utilization:"}],"source":"layout det","text":"Due to the diversity of environments, certain interactions may be blocked on waiting for environment feedback (e.g., a virtual machine or a code interpreter), leaving the GPUs idle. We employ two strategies to maximize GPU utilization:"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":377,"x1":854,"y0":140,"y1":409},"conf":0.9776,"label":"Figure","label_id":3},{"bbox":{"x0":136,"x1":1089,"y0":606,"y1":789},"conf":0.9772,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":1128,"y1":1267},"conf":0.9696,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":1017,"y1":1125},"conf":0.9647,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1091,"y0":791,"y1":886},"conf":0.9572,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1091,"y0":890,"y1":965},"conf":0.9527,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1090,"y0":1321,"y1":1393},"conf":0.9443,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1088,"y0":528,"y1":603},"conf":0.9411,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1090,"y0":1396,"y1":1451},"conf":0.9216,"label":"Text","label_id":1},{"bbox":{"x0":373,"x1":850,"y0":422,"y1":455},"conf":0.9055,"label":"Figure caption","label_id":4},{"bbox":{"x0":136,"x1":344,"y0":1283,"y1":1314},"conf":0.8967,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":437,"y0":491,"y1":521},"conf":0.895,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":418,"y0":980,"y1":1010},"conf":0.8846,"label":"Title","label_id":0},{"bbox":{"x0":556,"x1":1087,"y0":65,"y1":94},"conf":0.774,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":627,"y0":1480,"y1":1506},"conf":0.6932,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1482],[625,1482],[625,1503],[599,1503]],"score":0.9003},{"poly":[[140,1421],[1083,1422],[1083,1445],[140,1444]],"score":0.7244},{"poly":[[140,1398],[1083,1401],[1083,1424],[140,1421]],"score":0.6448},{"poly":[[141,1368],[482,1368],[482,1389],[141,1389]],"score":0.7793},{"poly":[[143,1350],[1081,1350],[1081,1366],[143,1366]],"score":0.9867},{"poly":[[140,1322],[1081,1325],[1081,1348],[140,1345]],"score":0.6724},{"poly":[[138,1284],[339,1285],[339,1309],[138,1307]],"score":0.7426},{"poly":[[140,1241],[296,1241],[296,1262],[140,1262]],"score":0.849},{"poly":[[138,1214],[1083,1216],[1083,1244],[138,1242]],"score":0.6652},{"poly":[[140,1196],[1081,1196],[1081,1218],[140,1218]],"score":0.8097},{"poly":[[140,1171],[1081,1173],[1081,1196],[140,1195]],"score":0.7579},{"poly":[[141,1152],[1081,1152],[1081,1175],[141,1175]],"score":0.6953},{"poly":[[140,1130],[1081,1130],[1081,1152],[140,1152]],"score":0.8121},{"poly":[[140,1097],[477,1096],[477,1117],[140,1119]],"score":0.782},{"poly":[[141,1076],[1081,1076],[1081,1099],[141,1099]],"score":0.7027},{"poly":[[141,1053],[1081,1053],[1081,1076],[141,1076]],"score":0.7151},{"poly":[[138,1020],[1081,1018],[1081,1041],[138,1043]],"score":0.774},{"poly":[[138,982],[412,983],[412,1007],[138,1005]],"score":0.7885},{"poly":[[143,939],[657,939],[657,955],[143,955]],"score":0.9831},{"poly":[[141,914],[1081,914],[1081,936],[141,936]],"score":0.8038},{"poly":[[141,893],[1081,893],[1081,914],[141,914]],"score":0.8196},{"poly":[[140,858],[1019,861],[1019,883],[140,879]],"score":0.7847},{"poly":[[141,838],[1081,838],[1081,860],[141,860]],"score":0.7884},{"poly":[[140,817],[1081,817],[1081,838],[140,838]],"score":0.7901},{"poly":[[141,794],[1081,794],[1081,815],[141,815]],"score":0.7979},{"poly":[[138,762],[682,761],[682,784],[138,785]],"score":0.7447},{"poly":[[141,741],[1083,741],[1083,762],[141,762]],"score":0.7892},{"poly":[[140,716],[1083,718],[1083,741],[140,739]],"score":0.7364},{"poly":[[140,696],[1083,696],[1083,718],[140,718]],"score":0.7879},{"poly":[[140,675],[1081,675],[1081,696],[140,696]],"score":0.7993},{"poly":[[141,652],[1081,652],[1081,675],[141,675]],"score":0.6884},{"poly":[[141,630],[1079,630],[1079,653],[141,653]],"score":0.6746},{"poly":[[141,609],[1083,609],[1083,630],[141,630]],"score":0.7903},{"poly":[[138,574],[880,576],[880,599],[138,597]],"score":0.7073},{"poly":[[141,554],[1083,554],[1083,576],[141,576]],"score":0.807},{"poly":[[141,531],[1083,531],[1083,554],[141,554]],"score":0.6962},{"poly":[[138,492],[432,495],[432,518],[138,515]],"score":0.738},{"poly":[[378,424],[845,426],[845,449],[377,447]],"score":0.7679},{"poly":[[569,384],[634,384],[634,403],[569,403]],"score":0.8294},{"poly":[[429,305],[464,305],[464,325],[429,325]],"score":0.8373},{"poly":[[718,302],[785,302],[785,325],[718,325]],"score":0.791},{"poly":[[567,302],[609,302],[609,328],[567,328]],"score":0.7632},{"poly":[[718,234],[784,238],[782,260],[716,255]],"score":0.7675},{"poly":[[565,236],[609,236],[609,261],[565,261]],"score":0.7994},{"poly":[[427,238],[466,238],[466,257],[427,257]],"score":0.7716},{"poly":[[698,198],[805,198],[805,216],[698,216]],"score":0.8338},{"poly":[[406,198],[486,198],[486,216],[406,216]],"score":0.8237},{"poly":[[527,193],[654,195],[653,218],[527,216]],"score":0.7682},{"poly":[[389,162],[419,162],[419,182],[389,182]],"score":0.729},{"poly":[[920,68],[1081,71],[1081,93],[919,89]],"score":0.7729},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8492}],"page_no":13,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1086,"y0":66,"y1":93},"conf":0.7581,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":919,"x1":1079,"y0":68,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":154,"x1":1035,"y0":1418,"y1":1508},"conf":0.3361,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":624,"y0":1480,"y1":1503},"font_size":0.0,"text":"15"},{"bbox":{"x0":170,"x1":580,"y0":1422,"y1":1444},"font_size":0.0,"text":"4https://huggingface.co/datasets/openai/mrcr"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":1090,"y0":143,"y1":195},"conf":0.9235,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":147,"y1":168},"font_size":-9.944e+21,"text":"(i) we deploy heavy environments as dedicated services that can scale up more easily; (ii) we employ a large number of"},{"bbox":{"x0":141,"x1":822,"y0":170,"y1":191},"font_size":-9.944e+21,"text":"concurrent rollouts to amortize the latency induced by certain expensive interactions."}],"source":"layout det","text":"(i) we deploy heavy environments as dedicated services that can scale up more easily; (ii) we employ a large number of concurrent rollouts to amortize the latency induced by certain expensive interactions."},{"bbox":{"x0":137,"x1":1089,"y0":199,"y1":270},"conf":0.9469,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":200,"y1":224},"font_size":-9.944e+21,"text":"Another challenge in agentic rollout is that individual rollout trajectories can be extremely long. To prevent long-tail"},{"bbox":{"x0":141,"x1":1081,"y0":224,"y1":246},"font_size":-9.944e+21,"text":"trajectories from blocking the entire rollout process, we employ the partial rollout [35] technique. This strategy allows"},{"bbox":{"x0":141,"x1":758,"y0":246,"y1":267},"font_size":-9.944e+21,"text":"long-tail unfnished tasks to be paused, and resumed in the next RL iteration.i"}],"source":"layout det","text":"Another challenge in agentic rollout is that individual rollout trajectories can be extremely long. To prevent long-tail trajectories from blocking the entire rollout process, we employ the partial rollout [35] technique. This strategy allows long-tail unfnished tasks to be paused, and resumed in the next RL iteration.i"},{"bbox":{"x0":138,"x1":1088,"y0":275,"y1":347},"conf":0.9397,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":276,"y1":300},"font_size":-9.944e+21,"text":"To improve research effciency, we also design a unifed interface inspired by the OpenAI Gym framework [49] toii"},{"bbox":{"x0":141,"x1":1081,"y0":300,"y1":322},"font_size":-9.944e+21,"text":"streamline the integration of new environments. We hope to scale our RL infrastructure to more diverse interactive"},{"bbox":{"x0":141,"x1":358,"y0":325,"y1":342},"font_size":-9.944e+21,"text":"environments in the future."}],"source":"layout det","text":"To improve research effciency, we also design a unifed interface inspired by the OpenAI Gym framework [49] toii streamline the integration of new environments. We hope to scale our RL infrastructure to more diverse interactive environments in the future."},{"bbox":{"x0":136,"x1":307,"y0":375,"y1":408},"conf":0.8981,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":303,"y0":378,"y1":403},"font_size":-9.944e+21,"text":"4Evaluations"}],"source":"layout det","text":"4Evaluations"},{"bbox":{"x0":136,"x1":1086,"y0":426,"y1":480},"conf":0.9299,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":431,"y1":452},"font_size":-9.944e+21,"text":"This section begins with the post-training evaluation of Kimi-K2-Instruct, followed by a brief overview of the capabilities"},{"bbox":{"x0":140,"x1":720,"y0":450,"y1":475},"font_size":-9.944e+21,"text":"of Kimi-K2-Base. We conclude with a comprehensive safety evaluation."}],"source":"layout det","text":"This section begins with the post-training evaluation of Kimi-K2-Instruct, followed by a brief overview of the capabilities of Kimi-K2-Base. We conclude with a comprehensive safety evaluation."},{"bbox":{"x0":136,"x1":412,"y0":502,"y1":532},"conf":0.893,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":407,"y0":505,"y1":526},"font_size":-9.944e+21,"text":"4.1Post-training Evaluations"}],"source":"layout det","text":"4.1Post-training Evaluations"},{"bbox":{"x0":136,"x1":375,"y0":544,"y1":575},"conf":0.8984,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":369,"y0":544,"y1":571},"font_size":-9.944e+21,"text":"4.1.1Evaluation Settings"}],"source":"layout det","text":"4.1.1Evaluation Settings"},{"bbox":{"x0":136,"x1":1090,"y0":582,"y1":831},"conf":0.9796,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":586,"y1":609},"font_size":-9.944e+21,"text":"BenchmarksWe assess Kimi-K2-Instruct across different areas. For coding, we adopt LiveCodeBench v6 [31](ques-"},{"bbox":{"x0":141,"x1":1081,"y0":609,"y1":630},"font_size":-9.944e+21,"text":"tions from August 2024 to May 2025), OJBench [77], MultiPL-E [5], SWE-bench Verifed [32, 84], TerminalBench [71],i"},{"bbox":{"x0":141,"x1":1081,"y0":630,"y1":652},"font_size":-9.944e+21,"text":"Multi-SWE-bench [86], SWE-Lancer [50], PaperBench [65], and Aider-Polyglot [16]. For tool use tasks, we evaluate"},{"bbox":{"x0":140,"x1":1081,"y0":652,"y1":675},"font_size":-9.944e+21,"text":"performance on $\\boldsymbol{\\tau^{2}}$ -Bench [3] and AceBench [6], which emphasize multi-turn tool-calling capabilities. In reasoning,"},{"bbox":{"x0":138,"x1":1083,"y0":672,"y1":696},"font_size":-9.944e+21,"text":"we include a wide range of mathematical, science and logical tasks: AIME 2024/2025, MATH-500, HMMT 2025,"},{"bbox":{"x0":141,"x1":1081,"y0":696,"y1":718},"font_size":-9.944e+21,"text":"CNMO 2024, PolyMath-en, ZebraLogic [43], AutoLogi [91], GPQA-Diamond [61], SuperGPQA [13], and Humanity’s"},{"bbox":{"x0":141,"x1":1079,"y0":718,"y1":741},"font_size":-9.944e+21,"text":"Last Exam (Text-Only) [56]. We benchmark the long-context capabilities on: MRCR4 for long-context retrieval, and"},{"bbox":{"x0":141,"x1":1079,"y0":741,"y1":762},"font_size":-9.944e+21,"text":"DROP [14], FRAMES [37] and LongBench v2 [2] for long-context reasoning. For factuality, we evaluate FACTS"},{"bbox":{"x0":138,"x1":1081,"y0":757,"y1":787},"font_size":-9.944e+21,"text":"Grounding [30], the Vectara Hallucination Leaderboard [73], and FaithJudge [68]. Finally, general capabilities are"},{"bbox":{"x0":141,"x1":1081,"y0":782,"y1":805},"font_size":-9.944e+21,"text":"assessed using MMLU [23], MMLU-Redux [17], MMLU-Pro [76], IFEval [90], Multi-Challenge [64], SimpleQA [78],"},{"bbox":{"x0":140,"x1":464,"y0":805,"y1":827},"font_size":-9.944e+21,"text":"and LiveBench [80] (as of 2024-11-25)."}],"source":"layout det","text":"BenchmarksWe assess Kimi-K2-Instruct across different areas. For coding, we adopt LiveCodeBench v6 [31](questions from August 2024 to May 2025), OJBench [77], MultiPL-E [5], SWE-bench Verifed [32, 84], TerminalBench [71],i Multi-SWE-bench [86], SWE-Lancer [50], PaperBench [65], and Aider-Polyglot [16]. For tool use tasks, we evaluate performance on $\\boldsymbol{\\tau^{2}}$ -Bench [3] and AceBench [6], which emphasize multi-turn tool-calling capabilities. In reasoning,we include a wide range of mathematical, science and logical tasks: AIME 2024/2025, MATH-500, HMMT 2025,CNMO 2024, PolyMath-en, ZebraLogic [43], AutoLogi [91], GPQA-Diamond [61], SuperGPQA [13], and Humanity’s Last Exam (Text-Only) [56]. We benchmark the long-context capabilities on: MRCR4 for long-context retrieval, and DROP [14], FRAMES [37] and LongBench v2 [2] for long-context reasoning. For factuality, we evaluate FACTS Grounding [30], the Vectara Hallucination Leaderboard [73], and FaithJudge [68]. Finally, general capabilities are assessed using MMLU [23], MMLU-Redux [17], MMLU-Pro [76], IFEval [90], Multi-Challenge [64], SimpleQA [78],and LiveBench [80] (as of 2024-11-25)."},{"bbox":{"x0":137,"x1":1088,"y0":851,"y1":969},"conf":0.9642,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":855,"y1":878},"font_size":-9.944e+21,"text":"BaselinesWe benchmark against both open-source and proprietary frontier models, ensuring every candidate is"},{"bbox":{"x0":141,"x1":1081,"y0":878,"y1":899},"font_size":-9.944e+21,"text":"evaluated under its non-thinking confguration to eliminate additional gains from test-time compute. Open-sourcei"},{"bbox":{"x0":140,"x1":1081,"y0":896,"y1":921},"font_size":-9.944e+21,"text":"baselines: DeepSeek-V3-0324 and Qwen3-235B-A22B, with the latter run in the vendor-recommended no-thinking"},{"bbox":{"x0":138,"x1":1083,"y0":919,"y1":944},"font_size":-9.944e+21,"text":"regime. Proprietary baselines: Claude Sonnet 4, Claude Opus 4, GPT-4.1, and Gemini 2.5 Flash Preview (2025-05-20)."},{"bbox":{"x0":141,"x1":1034,"y0":944,"y1":965},"font_size":-9.944e+21,"text":"Each invoked in its respective non-thinking mode via offcial APIs under unifed temperature and top-p settings.ii"}],"source":"layout det","text":"BaselinesWe benchmark against both open-source and proprietary frontier models, ensuring every candidate is evaluated under its non-thinking confguration to eliminate additional gains from test-time compute. Open-sourcei baselines: DeepSeek-V3-0324 and Qwen3-235B-A22B, with the latter run in the vendor-recommended no-thinking regime. Proprietary baselines: Claude Sonnet 4, Claude Opus 4, GPT-4.1, and Gemini 2.5 Flash Preview (2025-05-20).Each invoked in its respective non-thinking mode via offcial APIs under unifed temperature and top-p settings.ii"},{"bbox":{"x0":138,"x1":1088,"y0":972,"y1":1156},"conf":0.9741,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":973,"y1":998},"font_size":-9.944e+21,"text":"Evaluation Confgurations All runs query models in their non-thinking mode. Output token length is capped ati"},{"bbox":{"x0":141,"x1":1079,"y0":998,"y1":1020},"font_size":-9.944e+21,"text":"8192 tokens everywhere except SWE-bench Verifed (Agentless), which is raised to 16384. For benchmarks with highi"},{"bbox":{"x0":141,"x1":1081,"y0":1020,"y1":1041},"font_size":-9.944e+21,"text":"per-question variance, we adopt repeated sampling $k$  times and average the results to obtain stable scores, denoted as"},{"bbox":{"x0":141,"x1":1081,"y0":1041,"y1":1063},"font_size":-9.944e+21,"text":"Avg@k. For long-context tasks, we set the context window size to 128K tokens during evaluation, truncating any input"},{"bbox":{"x0":140,"x1":1079,"y0":1059,"y1":1086},"font_size":-9.944e+21,"text":"that exceeds this limit to ft within the window. SWE-bench Verifed is evaluated in two modes: Agentless Codingii"},{"bbox":{"x0":141,"x1":1081,"y0":1086,"y1":1107},"font_size":-9.944e+21,"text":"via Single Patch without Test (Acc) and Agentic Coding via bash/editor tools under both Single Attempt (Acc) and"},{"bbox":{"x0":141,"x1":1081,"y0":1107,"y1":1129},"font_size":-9.944e+21,"text":"Multiple Attempts (Acc) using best-of-N selection with an internal verifer; SWE-bench Multilingual is tested only ini"},{"bbox":{"x0":141,"x1":1074,"y0":1129,"y1":1150},"font_size":-9.944e+21,"text":"the single-attempt agentic setting. Some data points have been omitted due to prohibitively expensive evaluation costs."}],"source":"layout det","text":"Evaluation Confgurations All runs query models in their non-thinking mode. Output token length is capped ati 8192 tokens everywhere except SWE-bench Verifed (Agentless), which is raised to 16384. For benchmarks with highi per-question variance, we adopt repeated sampling $k$  times and average the results to obtain stable scores, denoted as Avg@k. For long-context tasks, we set the context window size to 128K tokens during evaluation, truncating any input that exceeds this limit to ft within the window. SWE-bench Verifed is evaluated in two modes: Agentless Codingii via Single Patch without Test (Acc) and Agentic Coding via bash/editor tools under both Single Attempt (Acc) and Multiple Attempts (Acc) using best-of-N selection with an internal verifer; SWE-bench Multilingual is tested only ini the single-attempt agentic setting. Some data points have been omitted due to prohibitively expensive evaluation costs."},{"bbox":{"x0":137,"x1":370,"y0":1175,"y1":1203},"conf":0.8904,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":366,"y0":1178,"y1":1200},"font_size":-9.944e+21,"text":"4.1.2Evaluation Results"}],"source":"layout det","text":"4.1.2Evaluation Results"},{"bbox":{"x0":136,"x1":1088,"y0":1214,"y1":1267},"conf":0.9187,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1218,"y1":1239},"font_size":-9.944e+21,"text":"A comprehensive evaluation results of Kimi-K2-Instruct is shown in Table 3, with detailed explanation provided in the"},{"bbox":{"x0":140,"x1":712,"y0":1241,"y1":1262},"font_size":-9.944e+21,"text":"Appendix C. Below, we highlight key results across four core domains:"}],"source":"layout det","text":"A comprehensive evaluation results of Kimi-K2-Instruct is shown in Table 3, with detailed explanation provided in the Appendix C. Below, we highlight key results across four core domains:"},{"bbox":{"x0":136,"x1":1089,"y0":1285,"y1":1404},"conf":0.9551,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1287,"y1":1312},"font_size":-9.944e+21,"text":"Agentic and Competitive CodingKimi-K2-Instruct demonstrates state-of-the-art open-source performance on"},{"bbox":{"x0":140,"x1":1083,"y0":1310,"y1":1335},"font_size":-9.944e+21,"text":"real-world SWE tasks. It outperforms most baselines on SWE-bench Verifedi $(65.8\\%,71.6\\%$ with multiple attemps),"},{"bbox":{"x0":140,"x1":1081,"y0":1333,"y1":1356},"font_size":-9.944e+21,"text":"SWE-bench Multilingual $(47.3\\%]$ , and SWE-lancer (39.1%), signifcantly closing the gap with Claude 4 Opus andi"},{"bbox":{"x0":141,"x1":1081,"y0":1354,"y1":1378},"font_size":-9.944e+21,"text":"Sonnet. On competitive coding benchmarks (e.g., LiveCodeBench v6 $53.7\\%,$  OJBench $\\bar{27.1\\%})$ , it also leads among all"},{"bbox":{"x0":141,"x1":748,"y0":1378,"y1":1399},"font_size":-9.944e+21,"text":"models, highlighting its practical coding profciency across diffculty levels.ii"}],"source":"layout det","text":"Agentic and Competitive CodingKimi-K2-Instruct demonstrates state-of-the-art open-source performance on real-world SWE tasks. It outperforms most baselines on SWE-bench Verifedi $(65.8\\%,71.6\\%$ with multiple attemps),SWE-bench Multilingual $(47.3\\%]$ , and SWE-lancer (39.1%), signifcantly closing the gap with Claude 4 Opus andi Sonnet. On competitive coding benchmarks (e.g., LiveCodeBench v6 $53.7\\%,$  OJBench $\\bar{27.1\\%})$ , it also leads among all models, highlighting its practical coding profciency across diffculty levels.ii"}],"formula_dets":[{"bbox":{"x0":769,"x1":891,"y0":1310,"y1":1332},"conf":0.811,"label":"print_embedding","label_id":0},{"bbox":{"x0":274,"x1":295,"y0":652,"y1":670},"conf":0.7594,"label":"print_embedding","label_id":0},{"bbox":{"x0":554,"x1":565,"y0":1023,"y1":1038},"conf":0.736,"label":"print_embedding","label_id":0},{"bbox":{"x0":354,"x1":416,"y0":1333,"y1":1354},"conf":0.6909,"label":"print_embedding","label_id":0},{"bbox":{"x0":695,"x1":753,"y0":1354,"y1":1376},"conf":0.6748,"label":"print_embedding","label_id":0},{"bbox":{"x0":833,"x1":893,"y0":1355,"y1":1377},"conf":0.6158,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1090,"y0":582,"y1":831},"conf":0.9796,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":972,"y1":1156},"conf":0.9741,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":851,"y1":969},"conf":0.9642,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":1285,"y1":1404},"conf":0.9551,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":199,"y1":270},"conf":0.9469,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":275,"y1":347},"conf":0.9397,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":426,"y1":480},"conf":0.9299,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1090,"y0":143,"y1":195},"conf":0.9235,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":1214,"y1":1267},"conf":0.9187,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":375,"y0":544,"y1":575},"conf":0.8984,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":307,"y0":375,"y1":408},"conf":0.8981,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":412,"y0":502,"y1":532},"conf":0.893,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":370,"y0":1175,"y1":1203},"conf":0.8904,"label":"Title","label_id":0},{"bbox":{"x0":557,"x1":1086,"y0":66,"y1":93},"conf":0.7581,"label":"Abandon","label_id":2},{"bbox":{"x0":161,"x1":588,"y0":1420,"y1":1450},"conf":0.5239,"label":"Abandon","label_id":2},{"bbox":{"x0":596,"x1":627,"y0":1479,"y1":1507},"conf":0.438,"label":"Abandon","label_id":2},{"bbox":{"x0":154,"x1":1035,"y0":1418,"y1":1508},"conf":0.3361,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1480],[624,1480],[624,1503],[599,1503]],"score":0.8273},{"poly":[[170,1422],[580,1422],[580,1444],[170,1444]],"score":0.8308},{"poly":[[141,1378],[748,1378],[748,1399],[141,1399]],"score":0.8583},{"poly":[[141,1356],[1081,1356],[1081,1378],[141,1378]],"score":0.8301},{"poly":[[140,1335],[1081,1335],[1081,1356],[140,1356]],"score":0.8268},{"poly":[[140,1310],[1083,1312],[1083,1335],[140,1333]],"score":0.7274},{"poly":[[141,1287],[1081,1289],[1081,1312],[141,1310]],"score":0.7702},{"poly":[[140,1241],[712,1241],[712,1262],[140,1262]],"score":0.8192},{"poly":[[141,1218],[1081,1218],[1081,1239],[141,1239]],"score":0.7813},{"poly":[[141,1178],[366,1178],[366,1200],[141,1200]],"score":0.8226},{"poly":[[141,1129],[1074,1129],[1074,1150],[141,1150]],"score":0.8109},{"poly":[[141,1107],[1081,1107],[1081,1129],[141,1129]],"score":0.8015},{"poly":[[141,1086],[1081,1086],[1081,1107],[141,1107]],"score":0.8182},{"poly":[[140,1059],[1079,1063],[1079,1086],[140,1082]],"score":0.7138},{"poly":[[141,1041],[1081,1041],[1081,1063],[141,1063]],"score":0.8029},{"poly":[[141,1020],[1081,1020],[1081,1041],[141,1041]],"score":0.8177},{"poly":[[141,998],[1079,998],[1079,1020],[141,1020]],"score":0.8063},{"poly":[[140,973],[1083,975],[1083,998],[140,997]],"score":0.7306},{"poly":[[141,944],[1034,944],[1034,965],[141,965]],"score":0.8249},{"poly":[[138,921],[1083,919],[1083,942],[138,944]],"score":0.6962},{"poly":[[140,896],[1081,899],[1081,921],[140,917]],"score":0.7963},{"poly":[[141,878],[1081,878],[1081,899],[141,899]],"score":0.814},{"poly":[[141,855],[1081,855],[1081,878],[141,878]],"score":0.7},{"poly":[[140,805],[464,805],[464,827],[140,827]],"score":0.83},{"poly":[[141,782],[1081,782],[1081,805],[141,805]],"score":0.7298},{"poly":[[138,757],[1081,759],[1081,787],[138,785]],"score":0.6687},{"poly":[[141,741],[1079,741],[1079,762],[141,762]],"score":0.8199},{"poly":[[141,718],[1079,718],[1079,741],[141,741]],"score":0.7096},{"poly":[[141,696],[1081,696],[1081,718],[141,718]],"score":0.829},{"poly":[[138,673],[1083,672],[1083,695],[138,696]],"score":0.7304},{"poly":[[140,652],[1081,652],[1081,675],[140,675]],"score":0.7101},{"poly":[[141,630],[1081,630],[1081,652],[141,652]],"score":0.8084},{"poly":[[141,609],[1081,609],[1081,630],[141,630]],"score":0.8204},{"poly":[[141,586],[1083,586],[1083,609],[141,609]],"score":0.7015},{"poly":[[138,544],[369,548],[369,571],[138,567]],"score":0.762},{"poly":[[141,505],[407,505],[407,526],[141,526]],"score":0.8222},{"poly":[[140,450],[720,452],[720,475],[140,474]],"score":0.803},{"poly":[[143,431],[1081,431],[1081,452],[143,452]],"score":0.8551},{"poly":[[140,378],[303,380],[303,403],[140,401]],"score":0.8268},{"poly":[[141,325],[358,325],[358,342],[141,342]],"score":0.9862},{"poly":[[141,300],[1081,300],[1081,322],[141,322]],"score":0.8121},{"poly":[[140,276],[1081,277],[1081,300],[140,299]],"score":0.7309},{"poly":[[141,246],[758,246],[758,267],[141,267]],"score":0.8225},{"poly":[[141,224],[1081,224],[1081,246],[141,246]],"score":0.8112},{"poly":[[140,200],[1081,201],[1081,224],[140,223]],"score":0.7232},{"poly":[[141,170],[822,170],[822,191],[141,191]],"score":0.8493},{"poly":[[141,147],[1083,147],[1083,168],[141,168]],"score":0.8608},{"poly":[[920,68],[1079,71],[1079,93],[919,89]],"score":0.7702},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8612}],"page_no":14,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":595,"x1":627,"y0":1480,"y1":1506},"conf":0.708,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":595,"x1":629,"y0":1478,"y1":1506},"font_size":0.0,"text":"16"}],"source":"layout det","text":""},{"bbox":{"x0":134,"x1":1089,"y0":62,"y1":104},"conf":0.3884,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":916,"x1":1083,"y0":66,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":665,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":134,"x1":1090,"y0":148,"y1":222},"conf":0.9312,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":153,"y1":177},"font_size":-1.972e+29,"text":"Table 3: Performance comparison of Kimi-K2-Instruct against leading open-source and proprietary models across"},{"bbox":{"x0":140,"x1":1083,"y0":175,"y1":198},"font_size":-1.972e+29,"text":"diverse tasks. Bold denotes the global SOTA; underlined bold indicates the best open-source result. Data points"},{"bbox":{"x0":140,"x1":742,"y0":198,"y1":221},"font_size":-1.972e+29,"text":"marked with * are taken directly from the model’s technical report or blog."}],"source":"layout det","text":"Table 3: Performance comparison of Kimi-K2-Instruct against leading open-source and proprietary models across diverse tasks. Bold denotes the global SOTA; underlined bold indicates the best open-source result. Data points marked with * are taken directly from the model’s technical report or blog."},{"bbox":{"x0":142,"x1":1085,"y0":221,"y1":1474},"conf":0.9893,"font_size":0.0,"label":"Table","label_id":5,"lines":[{"bbox":{"x0":503,"x1":608,"y0":226,"y1":250},"font_size":0.0,"text":"Open Source"},{"bbox":{"x0":835,"x1":934,"y0":225,"y1":251},"font_size":0.0,"text":"Proprietary"},{"bbox":{"x0":148,"x1":243,"y0":259,"y1":277},"font_size":0.0,"text":"Benchmark"},{"bbox":{"x0":423,"x1":507,"y0":255,"y1":278},"font_size":0.0,"text":"Kimi-K2-"},{"bbox":{"x0":511,"x1":603,"y0":256,"y1":278},"font_size":0.0,"text":"DeepSeek-"},{"bbox":{"x0":617,"x1":687,"y0":253,"y1":281},"font_size":0.0,"text":"Qwen3-"},{"bbox":{"x0":715,"x1":780,"y0":255,"y1":278},"font_size":0.0,"text":"Claude"},{"bbox":{"x0":811,"x1":876,"y0":255,"y1":278},"font_size":0.0,"text":"Claude"},{"bbox":{"x0":900,"x1":972,"y0":255,"y1":278},"font_size":0.0,"text":"GPT-4.1"},{"bbox":{"x0":1000,"x1":1066,"y0":258,"y1":278},"font_size":0.0,"text":"Gemini"},{"bbox":{"x0":425,"x1":497,"y0":277,"y1":299},"font_size":0.0,"text":"Instruct"},{"bbox":{"x0":519,"x1":593,"y0":276,"y1":299},"font_size":0.0,"text":"V3-0324"},{"bbox":{"x0":624,"x1":680,"y0":276,"y1":299},"font_size":0.0,"text":"235B-"},{"bbox":{"x0":708,"x1":785,"y0":276,"y1":299},"font_size":0.0,"text":"Sonnet 4"},{"bbox":{"x0":810,"x1":876,"y0":275,"y1":302},"font_size":0.0,"text":"Opus 4"},{"bbox":{"x0":992,"x1":1071,"y0":274,"y1":300},"font_size":0.0,"text":"2.5 Flash"},{"bbox":{"x0":625,"x1":678,"y0":295,"y1":319},"font_size":0.0,"text":"A22B"},{"bbox":{"x0":148,"x1":257,"y0":327,"y1":349},"font_size":0.0,"text":"Coding Tasks"},{"bbox":{"x0":146,"x1":366,"y0":355,"y1":379},"font_size":0.0,"text":"LiveCodeBench v6 (Pass@1)"},{"bbox":{"x0":437,"x1":482,"y0":352,"y1":381},"font_size":0.0,"text":"53.7"},{"bbox":{"x0":535,"x1":578,"y0":357,"y1":379},"font_size":0.0,"text":"46.9"},{"bbox":{"x0":631,"x1":674,"y0":357,"y1":379},"font_size":0.0,"text":"37.0"},{"bbox":{"x0":726,"x1":766,"y0":357,"y1":378},"font_size":0.0,"text":"48.5"},{"bbox":{"x0":819,"x1":864,"y0":352,"y1":381},"font_size":0.0,"text":"47.4"},{"bbox":{"x0":917,"x1":956,"y0":357,"y1":378},"font_size":0.0,"text":"44.7"},{"bbox":{"x0":1012,"x1":1052,"y0":357,"y1":378},"font_size":0.0,"text":"44.7"},{"bbox":{"x0":148,"x1":293,"y0":379,"y1":397},"font_size":0.0,"text":"OJBench (Pass@1)"},{"bbox":{"x0":439,"x1":480,"y0":375,"y1":400},"font_size":0.0,"text":"27.1"},{"bbox":{"x0":533,"x1":578,"y0":373,"y1":402},"font_size":0.0,"text":"24.0"},{"bbox":{"x0":631,"x1":672,"y0":375,"y1":400},"font_size":0.0,"text":"11.3"},{"bbox":{"x0":726,"x1":767,"y0":375,"y1":400},"font_size":0.0,"text":"15.3"},{"bbox":{"x0":824,"x1":862,"y0":378,"y1":399},"font_size":0.0,"text":"19.6"},{"bbox":{"x0":917,"x1":958,"y0":375,"y1":400},"font_size":0.0,"text":"19.5"},{"bbox":{"x0":1012,"x1":1054,"y0":375,"y1":400},"font_size":0.0,"text":"19.5"},{"bbox":{"x0":147,"x1":303,"y0":399,"y1":417},"font_size":0.0,"text":"MultiPL-E (Pass@1)"},{"bbox":{"x0":439,"x1":482,"y0":396,"y1":421},"font_size":0.0,"text":"85.7"},{"bbox":{"x0":535,"x1":576,"y0":396,"y1":421},"font_size":0.0,"text":"83.1"},{"bbox":{"x0":628,"x1":673,"y0":393,"y1":423},"font_size":0.0,"text":"78.2"},{"bbox":{"x0":726,"x1":767,"y0":396,"y1":421},"font_size":0.0,"text":"88.6"},{"bbox":{"x0":819,"x1":864,"y0":393,"y1":423},"font_size":0.0,"text":"89.6"},{"bbox":{"x0":916,"x1":957,"y0":396,"y1":421},"font_size":0.0,"text":"86.7"},{"bbox":{"x0":1012,"x1":1054,"y0":396,"y1":421},"font_size":0.0,"text":"85.6"},{"bbox":{"x0":147,"x1":303,"y0":417,"y1":439},"font_size":0.0,"text":"SWE-bench Verifed"},{"bbox":{"x0":282,"x1":282,"y0":422,"y1":438},"font_size":8.0,"text":"i"},{"bbox":{"x0":439,"x1":482,"y0":426,"y1":451},"font_size":0.0,"text":"51.8"},{"bbox":{"x0":537,"x1":576,"y0":427,"y1":448},"font_size":0.0,"text":"36.6"},{"bbox":{"x0":631,"x1":671,"y0":427,"y1":448},"font_size":0.0,"text":"39.4"},{"bbox":{"x0":726,"x1":767,"y0":426,"y1":451},"font_size":0.0,"text":"50.2"},{"bbox":{"x0":821,"x1":863,"y0":427,"y1":449},"font_size":0.0,"text":"53.0"},{"bbox":{"x0":917,"x1":957,"y0":427,"y1":448},"font_size":0.0,"text":"40.8"},{"bbox":{"x0":1013,"x1":1052,"y0":427,"y1":448},"font_size":0.0,"text":"32.6"},{"bbox":{"x0":146,"x1":393,"y0":438,"y1":460},"font_size":0.0,"text":"Agentless-Single-Patch (Pass@1)"},{"bbox":{"x0":148,"x1":301,"y0":459,"y1":477},"font_size":0.0,"text":"SWE-bench Verifed"},{"bbox":{"x0":282,"x1":282,"y0":462,"y1":478},"font_size":8.0,"text":"i"},{"bbox":{"x0":439,"x1":483,"y0":465,"y1":491},"font_size":0.0,"text":"65.8"},{"bbox":{"x0":535,"x1":578,"y0":465,"y1":490},"font_size":0.0,"text":"38.8"},{"bbox":{"x0":630,"x1":674,"y0":465,"y1":490},"font_size":0.0,"text":"34.4"},{"bbox":{"x0":722,"x1":771,"y0":465,"y1":490},"font_size":0.0,"text":"72.7*"},{"bbox":{"x0":816,"x1":867,"y0":466,"y1":490},"font_size":0.0,"text":" $72.5\\text{*}$ "},{"bbox":{"x0":916,"x1":959,"y0":465,"y1":490},"font_size":0.0,"text":"54.6"},{"bbox":{"x0":147,"x1":396,"y0":477,"y1":499},"font_size":0.0,"text":"Agentic-Single-Attempt (Pass@1)"},{"bbox":{"x0":1019,"x1":1045,"y0":471,"y1":490},"font_size":0.0,"text":"—"},{"bbox":{"x0":148,"x1":301,"y0":499,"y1":517},"font_size":0.0,"text":"SWE-bench Verifed"},{"bbox":{"x0":282,"x1":282,"y0":502,"y1":518},"font_size":8.0,"text":"i"},{"bbox":{"x0":439,"x1":482,"y0":506,"y1":532},"font_size":0.0,"text":"71.6"},{"bbox":{"x0":544,"x1":567,"y0":512,"y1":528},"font_size":0.0,"text":"—"},{"bbox":{"x0":640,"x1":662,"y0":512,"y1":526},"font_size":0.0,"text":"—"},{"bbox":{"x0":721,"x1":771,"y0":506,"y1":530},"font_size":0.0,"text":"80.2*"},{"bbox":{"x0":815,"x1":868,"y0":505,"y1":530},"font_size":0.0,"text":" $79.4\\text{*}$ "},{"bbox":{"x0":147,"x1":391,"y0":517,"y1":539},"font_size":0.0,"text":"Agentic-Multi-Attempt (Pass@1)"},{"bbox":{"x0":928,"x1":946,"y0":513,"y1":529},"font_size":8.0,"text":"—"},{"bbox":{"x0":1022,"x1":1044,"y0":513,"y1":529},"font_size":0.0,"text":"—"},{"bbox":{"x0":147,"x1":408,"y0":537,"y1":559},"font_size":0.0,"text":"SWE-bench Multilingual (Pass@1)"},{"bbox":{"x0":439,"x1":482,"y0":536,"y1":562},"font_size":0.0,"text":"47.3"},{"bbox":{"x0":535,"x1":576,"y0":536,"y1":560},"font_size":0.0,"text":"25.8"},{"bbox":{"x0":631,"x1":671,"y0":537,"y1":558},"font_size":0.0,"text":"20.9"},{"bbox":{"x0":728,"x1":766,"y0":537,"y1":558},"font_size":0.0,"text":"51.0"},{"bbox":{"x0":833,"x1":851,"y0":542,"y1":558},"font_size":8.0,"text":"—"},{"bbox":{"x0":916,"x1":958,"y0":536,"y1":560},"font_size":0.0,"text":"31.5"},{"bbox":{"x0":1024,"x1":1042,"y0":542,"y1":558},"font_size":8.0,"text":"—"},{"bbox":{"x0":147,"x1":361,"y0":558,"y1":580},"font_size":0.0,"text":"Multi-SWE-bench (Pass@1)"},{"bbox":{"x0":439,"x1":482,"y0":555,"y1":581},"font_size":0.0,"text":"18.3"},{"bbox":{"x0":538,"x1":572,"y0":558,"y1":579},"font_size":0.0,"text":"8.0"},{"bbox":{"x0":634,"x1":669,"y0":558,"y1":579},"font_size":0.0,"text":"9.0"},{"bbox":{"x0":726,"x1":767,"y0":555,"y1":580},"font_size":0.0,"text":"29.2"},{"bbox":{"x0":833,"x1":851,"y0":563,"y1":579},"font_size":0.0,"text":"—"},{"bbox":{"x0":917,"x1":958,"y0":555,"y1":580},"font_size":0.0,"text":"11.7"},{"bbox":{"x0":1013,"x1":1053,"y0":558,"y1":579},"font_size":0.0,"text":"14.0"},{"bbox":{"x0":146,"x1":321,"y0":576,"y1":600},"font_size":0.0,"text":"SWE-Lancer (Pass@1)"},{"bbox":{"x0":439,"x1":480,"y0":576,"y1":601},"font_size":0.0,"text":"39.1"},{"bbox":{"x0":535,"x1":576,"y0":576,"y1":601},"font_size":0.0,"text":"30.5"},{"bbox":{"x0":630,"x1":671,"y0":576,"y1":601},"font_size":0.0,"text":"24.1"},{"bbox":{"x0":725,"x1":767,"y0":576,"y1":601},"font_size":0.0,"text":"40.8"},{"bbox":{"x0":831,"x1":852,"y0":583,"y1":601},"font_size":0.0,"text":"—"},{"bbox":{"x0":916,"x1":958,"y0":576,"y1":601},"font_size":0.0,"text":"23.0"},{"bbox":{"x0":1012,"x1":1053,"y0":576,"y1":601},"font_size":0.0,"text":"38.5"},{"bbox":{"x0":147,"x1":373,"y0":598,"y1":620},"font_size":0.0,"text":"Paper Bench Code-Dev (Acc.)"},{"bbox":{"x0":441,"x1":480,"y0":597,"y1":622},"font_size":0.0,"text":"27.8"},{"bbox":{"x0":535,"x1":576,"y0":596,"y1":622},"font_size":0.0,"text":"12.2"},{"bbox":{"x0":633,"x1":672,"y0":596,"y1":622},"font_size":0.0,"text":"13.2"},{"bbox":{"x0":726,"x1":767,"y0":596,"y1":620},"font_size":0.0,"text":"43.3"},{"bbox":{"x0":916,"x1":958,"y0":596,"y1":622},"font_size":0.0,"text":"29.9"},{"bbox":{"x0":1015,"x1":1049,"y0":596,"y1":622},"font_size":0.0,"text":"5.7"},{"bbox":{"x0":147,"x1":389,"y0":616,"y1":640},"font_size":0.0,"text":"Terminal Bench In-House (Acc.)"},{"bbox":{"x0":437,"x1":482,"y0":613,"y1":642},"font_size":0.0,"text":"30.0"},{"bbox":{"x0":726,"x1":767,"y0":616,"y1":641},"font_size":0.0,"text":"35.5"},{"bbox":{"x0":822,"x1":862,"y0":616,"y1":641},"font_size":0.0,"text":"43.2"},{"bbox":{"x0":921,"x1":953,"y0":618,"y1":639},"font_size":0.0,"text":"8.3"},{"bbox":{"x0":1026,"x1":1043,"y0":624,"y1":635},"font_size":0.0,"text":"—"},{"bbox":{"x0":150,"x1":388,"y0":640,"y1":658},"font_size":0.0,"text":"Terminal Bench Terminus (Acc.)"},{"bbox":{"x0":441,"x1":482,"y0":636,"y1":661},"font_size":0.0,"text":"25.0"},{"bbox":{"x0":535,"x1":576,"y0":636,"y1":661},"font_size":0.0,"text":"16.3"},{"bbox":{"x0":635,"x1":667,"y0":637,"y1":660},"font_size":0.0,"text":"6.6"},{"bbox":{"x0":739,"x1":756,"y0":645,"y1":654},"font_size":0.0,"text":"—"},{"bbox":{"x0":916,"x1":958,"y0":636,"y1":661},"font_size":0.0,"text":"30.3"},{"bbox":{"x0":1013,"x1":1053,"y0":636,"y1":661},"font_size":0.0,"text":"16.8"},{"bbox":{"x0":148,"x1":310,"y0":658,"y1":680},"font_size":0.0,"text":"Aider-Polyglot (Acc.)"},{"bbox":{"x0":442,"x1":480,"y0":658,"y1":679},"font_size":0.0,"text":"60.0"},{"bbox":{"x0":535,"x1":575,"y0":656,"y1":680},"font_size":0.0,"text":"55.1"},{"bbox":{"x0":630,"x1":672,"y0":657,"y1":682},"font_size":0.0,"text":"61.8"},{"bbox":{"x0":726,"x1":767,"y0":656,"y1":680},"font_size":0.0,"text":"56.4"},{"bbox":{"x0":821,"x1":862,"y0":656,"y1":680},"font_size":0.0,"text":"70.7"},{"bbox":{"x0":916,"x1":958,"y0":656,"y1":680},"font_size":0.0,"text":"52.4"},{"bbox":{"x0":1013,"x1":1053,"y0":658,"y1":679},"font_size":0.0,"text":"44.0"},{"bbox":{"x0":147,"x1":268,"y0":685,"y1":711},"font_size":0.0,"text":"Tool Use Tasks"},{"bbox":{"x0":148,"x1":303,"y0":718,"y1":740},"font_size":0.0,"text":"Tau2 retail (Avg@4)"},{"bbox":{"x0":437,"x1":482,"y0":715,"y1":744},"font_size":0.0,"text":"70.6"},{"bbox":{"x0":535,"x1":574,"y0":720,"y1":740},"font_size":0.0,"text":"69.1"},{"bbox":{"x0":630,"x1":672,"y0":717,"y1":742},"font_size":0.0,"text":"57.0"},{"bbox":{"x0":726,"x1":769,"y0":717,"y1":742},"font_size":0.0,"text":"75.0"},{"bbox":{"x0":820,"x1":863,"y0":717,"y1":742},"font_size":0.0,"text":"81.8"},{"bbox":{"x0":916,"x1":958,"y0":717,"y1":742},"font_size":0.0,"text":"74.8"},{"bbox":{"x0":1011,"x1":1054,"y0":717,"y1":742},"font_size":0.0,"text":"64.3"},{"bbox":{"x0":148,"x1":312,"y0":739,"y1":761},"font_size":0.0,"text":"Tau2 airline (Avg@4)"},{"bbox":{"x0":439,"x1":482,"y0":737,"y1":763},"font_size":0.0,"text":"56.5"},{"bbox":{"x0":537,"x1":576,"y0":739,"y1":760},"font_size":0.0,"text":"39.0"},{"bbox":{"x0":630,"x1":672,"y0":737,"y1":761},"font_size":0.0,"text":"26.5"},{"bbox":{"x0":726,"x1":767,"y0":737,"y1":763},"font_size":0.0,"text":"55.5"},{"bbox":{"x0":822,"x1":862,"y0":739,"y1":760},"font_size":0.0,"text":"60.0"},{"bbox":{"x0":916,"x1":958,"y0":737,"y1":763},"font_size":0.0,"text":"54.5"},{"bbox":{"x0":1012,"x1":1053,"y0":738,"y1":763},"font_size":0.0,"text":"42.5"},{"bbox":{"x0":147,"x1":323,"y0":757,"y1":782},"font_size":0.0,"text":"Tau2 telecom (Avg@4)"},{"bbox":{"x0":441,"x1":483,"y0":759,"y1":781},"font_size":0.0,"text":"65.8"},{"bbox":{"x0":535,"x1":578,"y0":757,"y1":782},"font_size":0.0,"text":"32.5"},{"bbox":{"x0":631,"x1":671,"y0":757,"y1":782},"font_size":0.0,"text":"22.1"},{"bbox":{"x0":725,"x1":767,"y0":757,"y1":782},"font_size":0.0,"text":"45.2"},{"bbox":{"x0":819,"x1":864,"y0":756,"y1":784},"font_size":0.0,"text":"57.0"},{"bbox":{"x0":916,"x1":959,"y0":757,"y1":782},"font_size":0.0,"text":"38.6"},{"bbox":{"x0":1010,"x1":1054,"y0":756,"y1":784},"font_size":0.0,"text":"16.9"},{"bbox":{"x0":146,"x1":279,"y0":778,"y1":803},"font_size":0.0,"text":"AceBench (Acc.)"},{"bbox":{"x0":441,"x1":482,"y0":777,"y1":803},"font_size":0.0,"text":"76.5"},{"bbox":{"x0":535,"x1":576,"y0":777,"y1":802},"font_size":0.0,"text":"72.7"},{"bbox":{"x0":631,"x1":672,"y0":777,"y1":802},"font_size":0.0,"text":"70.5"},{"bbox":{"x0":726,"x1":767,"y0":777,"y1":802},"font_size":0.0,"text":"76.2"},{"bbox":{"x0":821,"x1":863,"y0":777,"y1":802},"font_size":0.0,"text":"75.6"},{"bbox":{"x0":916,"x1":957,"y0":777,"y1":802},"font_size":0.0,"text":"80.1"},{"bbox":{"x0":1012,"x1":1053,"y0":777,"y1":802},"font_size":0.0,"text":"74.5"},{"bbox":{"x0":147,"x1":318,"y0":808,"y1":831},"font_size":0.0,"text":"Math & STEM Tasks"},{"bbox":{"x0":148,"x1":320,"y0":838,"y1":861},"font_size":0.0,"text":"AIME 2024 (Avg@64)"},{"bbox":{"x0":439,"x1":482,"y0":837,"y1":862},"font_size":0.0,"text":"69.6"},{"bbox":{"x0":528,"x1":582,"y0":835,"y1":862},"font_size":0.0,"text":"59.4*"},{"bbox":{"x0":623,"x1":677,"y0":835,"y1":862},"font_size":0.0,"text":"40.1*"},{"bbox":{"x0":725,"x1":769,"y0":837,"y1":862},"font_size":0.0,"text":"43.4"},{"bbox":{"x0":820,"x1":863,"y0":837,"y1":862},"font_size":0.0,"text":"48.2"},{"bbox":{"x0":916,"x1":958,"y0":837,"y1":862},"font_size":0.0,"text":"46.5"},{"bbox":{"x0":1011,"x1":1054,"y0":837,"y1":862},"font_size":0.0,"text":"61.3"},{"bbox":{"x0":146,"x1":321,"y0":858,"y1":881},"font_size":0.0,"text":"AIME 2025 (Avg@64)"},{"bbox":{"x0":439,"x1":482,"y0":857,"y1":881},"font_size":0.0,"text":"49.5"},{"bbox":{"x0":534,"x1":576,"y0":859,"y1":881},"font_size":0.0,"text":"46.7"},{"bbox":{"x0":625,"x1":678,"y0":855,"y1":883},"font_size":0.0,"text":"24.7*"},{"bbox":{"x0":721,"x1":771,"y0":858,"y1":881},"font_size":0.0,"text":"33.1*"},{"bbox":{"x0":817,"x1":866,"y0":858,"y1":881},"font_size":0.0,"text":"33.9*"},{"bbox":{"x0":916,"x1":959,"y0":857,"y1":881},"font_size":0.0,"text":"37.0"},{"bbox":{"x0":1012,"x1":1052,"y0":859,"y1":880},"font_size":0.0,"text":"46.6"},{"bbox":{"x0":144,"x1":288,"y0":877,"y1":901},"font_size":0.0,"text":"MATH-500 (Acc.)"},{"bbox":{"x0":441,"x1":480,"y0":879,"y1":900},"font_size":0.0,"text":"97.4"},{"bbox":{"x0":528,"x1":581,"y0":876,"y1":903},"font_size":0.0,"text":"94.0*"},{"bbox":{"x0":625,"x1":676,"y0":878,"y1":901},"font_size":0.0,"text":"91.2*"},{"bbox":{"x0":723,"x1":769,"y0":876,"y1":903},"font_size":0.0,"text":"94.0"},{"bbox":{"x0":821,"x1":863,"y0":879,"y1":901},"font_size":0.0,"text":"94.4"},{"bbox":{"x0":917,"x1":957,"y0":879,"y1":900},"font_size":0.0,"text":"92.4"},{"bbox":{"x0":1012,"x1":1052,"y0":880,"y1":900},"font_size":0.0,"text":"95.4"},{"bbox":{"x0":147,"x1":330,"y0":900,"y1":922},"font_size":0.0,"text":"HMMT 2025 (Avg@32)"},{"bbox":{"x0":439,"x1":482,"y0":897,"y1":922},"font_size":0.0,"text":"38.8"},{"bbox":{"x0":534,"x1":576,"y0":897,"y1":922},"font_size":0.0,"text":"27.5"},{"bbox":{"x0":631,"x1":671,"y0":900,"y1":921},"font_size":0.0,"text":"11.9"},{"bbox":{"x0":728,"x1":767,"y0":897,"y1":922},"font_size":0.0,"text":"15.9"},{"bbox":{"x0":824,"x1":861,"y0":898,"y1":919},"font_size":0.0,"text":"15.9"},{"bbox":{"x0":918,"x1":957,"y0":898,"y1":919},"font_size":0.0,"text":"19.4"},{"bbox":{"x0":1012,"x1":1053,"y0":897,"y1":922},"font_size":0.0,"text":"34.7"},{"bbox":{"x0":147,"x1":328,"y0":919,"y1":941},"font_size":0.0,"text":"CNMO 2024 (Avg@16)"},{"bbox":{"x0":439,"x1":481,"y0":915,"y1":943},"font_size":0.0,"text":"74.3"},{"bbox":{"x0":535,"x1":576,"y0":917,"y1":941},"font_size":0.0,"text":"74.7"},{"bbox":{"x0":631,"x1":671,"y0":919,"y1":940},"font_size":0.0,"text":"48.6"},{"bbox":{"x0":728,"x1":766,"y0":919,"y1":940},"font_size":0.0,"text":"60.4"},{"bbox":{"x0":821,"x1":863,"y0":917,"y1":941},"font_size":0.0,"text":"57.6"},{"bbox":{"x0":916,"x1":958,"y0":918,"y1":943},"font_size":0.0,"text":"56.6"},{"bbox":{"x0":1012,"x1":1053,"y0":917,"y1":941},"font_size":0.0,"text":"75.0"},{"bbox":{"x0":146,"x1":320,"y0":939,"y1":961},"font_size":0.0,"text":"PolyMath-en (Avg@4)"},{"bbox":{"x0":442,"x1":479,"y0":939,"y1":960},"font_size":0.0,"text":"65.1"},{"bbox":{"x0":537,"x1":575,"y0":939,"y1":960},"font_size":0.0,"text":"59.5"},{"bbox":{"x0":631,"x1":671,"y0":939,"y1":960},"font_size":0.0,"text":"51.9"},{"bbox":{"x0":726,"x1":767,"y0":938,"y1":962},"font_size":0.0,"text":"52.8"},{"bbox":{"x0":822,"x1":861,"y0":939,"y1":960},"font_size":0.0,"text":"49.8"},{"bbox":{"x0":917,"x1":957,"y0":939,"y1":960},"font_size":0.0,"text":"54.0"},{"bbox":{"x0":1013,"x1":1052,"y0":939,"y1":960},"font_size":0.0,"text":"49.9"},{"bbox":{"x0":147,"x1":288,"y0":960,"y1":982},"font_size":0.0,"text":"ZebraLogic (Acc.)"},{"bbox":{"x0":441,"x1":480,"y0":958,"y1":979},"font_size":0.0,"text":"89.0"},{"bbox":{"x0":537,"x1":575,"y0":960,"y1":979},"font_size":0.0,"text":"84.0"},{"bbox":{"x0":626,"x1":677,"y0":955,"y1":984},"font_size":0.0,"text":"37.7*"},{"bbox":{"x0":726,"x1":767,"y0":957,"y1":982},"font_size":0.0,"text":"79.7"},{"bbox":{"x0":821,"x1":862,"y0":957,"y1":982},"font_size":0.0,"text":"59.3"},{"bbox":{"x0":917,"x1":957,"y0":960,"y1":981},"font_size":0.0,"text":"58.5"},{"bbox":{"x0":1012,"x1":1053,"y0":957,"y1":982},"font_size":0.0,"text":"57.9"},{"bbox":{"x0":147,"x1":275,"y0":979,"y1":1002},"font_size":0.0,"text":"AutoLogi (Acc.)"},{"bbox":{"x0":439,"x1":482,"y0":978,"y1":1003},"font_size":0.0,"text":"89.5"},{"bbox":{"x0":537,"x1":575,"y0":979,"y1":1000},"font_size":0.0,"text":"88.9"},{"bbox":{"x0":625,"x1":677,"y0":975,"y1":1003},"font_size":0.0,"text":"83.3*"},{"bbox":{"x0":728,"x1":766,"y0":979,"y1":1000},"font_size":0.0,"text":"89.8"},{"bbox":{"x0":821,"x1":861,"y0":979,"y1":1000},"font_size":0.0,"text":"86.1"},{"bbox":{"x0":916,"x1":957,"y0":977,"y1":1003},"font_size":0.0,"text":"88.2"},{"bbox":{"x0":1013,"x1":1052,"y0":979,"y1":1000},"font_size":0.0,"text":"84.1"},{"bbox":{"x0":147,"x1":346,"y0":999,"y1":1021},"font_size":0.0,"text":"GPQA-Diamond (Avg@8)"},{"bbox":{"x0":439,"x1":480,"y0":996,"y1":1021},"font_size":0.0,"text":"75.1"},{"bbox":{"x0":530,"x1":581,"y0":996,"y1":1023},"font_size":0.0,"text":"68.4*"},{"bbox":{"x0":626,"x1":676,"y0":998,"y1":1021},"font_size":0.0,"text":"62.9*"},{"bbox":{"x0":722,"x1":770,"y0":998,"y1":1021},"font_size":0.0,"text":"70.0*"},{"bbox":{"x0":817,"x1":866,"y0":998,"y1":1021},"font_size":0.0,"text":"74.9*"},{"bbox":{"x0":917,"x1":957,"y0":999,"y1":1020},"font_size":0.0,"text":"66.3"},{"bbox":{"x0":1012,"x1":1053,"y0":998,"y1":1022},"font_size":0.0,"text":"68.2"},{"bbox":{"x0":147,"x1":296,"y0":1020,"y1":1042},"font_size":0.0,"text":"SuperGPQA (Acc.)"},{"bbox":{"x0":439,"x1":482,"y0":1017,"y1":1042},"font_size":0.0,"text":"57.2"},{"bbox":{"x0":535,"x1":576,"y0":1017,"y1":1042},"font_size":0.0,"text":"53.7"},{"bbox":{"x0":630,"x1":672,"y0":1017,"y1":1042},"font_size":0.0,"text":"50.2"},{"bbox":{"x0":726,"x1":767,"y0":1017,"y1":1042},"font_size":0.0,"text":"55.7"},{"bbox":{"x0":820,"x1":863,"y0":1017,"y1":1042},"font_size":0.0,"text":"56.5"},{"bbox":{"x0":918,"x1":957,"y0":1020,"y1":1041},"font_size":0.0,"text":"50.8"},{"bbox":{"x0":1013,"x1":1052,"y0":1020,"y1":1041},"font_size":0.0,"text":"49.6"},{"bbox":{"x0":147,"x1":369,"y0":1038,"y1":1060},"font_size":0.0,"text":"Humanity’s Last Exam (Acc.)"},{"bbox":{"x0":444,"x1":479,"y0":1038,"y1":1062},"font_size":0.0,"text":"4.7"},{"bbox":{"x0":539,"x1":574,"y0":1038,"y1":1062},"font_size":0.0,"text":"5.2"},{"bbox":{"x0":633,"x1":669,"y0":1037,"y1":1063},"font_size":0.0,"text":"5.7"},{"bbox":{"x0":730,"x1":762,"y0":1038,"y1":1060},"font_size":0.0,"text":"5.8"},{"bbox":{"x0":825,"x1":860,"y0":1038,"y1":1062},"font_size":0.0,"text":"7.1"},{"bbox":{"x0":921,"x1":953,"y0":1038,"y1":1060},"font_size":0.0,"text":"3.7"},{"bbox":{"x0":1016,"x1":1048,"y0":1038,"y1":1060},"font_size":0.0,"text":"5.6"},{"bbox":{"x0":147,"x1":264,"y0":1068,"y1":1092},"font_size":0.0,"text":"General Tasks"},{"bbox":{"x0":147,"x1":253,"y0":1098,"y1":1120},"font_size":0.0,"text":"MMLU (EM)"},{"bbox":{"x0":441,"x1":482,"y0":1097,"y1":1123},"font_size":0.0,"text":"89.5"},{"bbox":{"x0":535,"x1":578,"y0":1097,"y1":1122},"font_size":0.0,"text":"89.4"},{"bbox":{"x0":631,"x1":674,"y0":1099,"y1":1122},"font_size":0.0,"text":"87.0"},{"bbox":{"x0":725,"x1":767,"y0":1097,"y1":1122},"font_size":0.0,"text":"91.5"},{"bbox":{"x0":820,"x1":863,"y0":1097,"y1":1122},"font_size":0.0,"text":"92.9"},{"bbox":{"x0":917,"x1":959,"y0":1099,"y1":1122},"font_size":0.0,"text":"90.4"},{"bbox":{"x0":1012,"x1":1052,"y0":1099,"y1":1120},"font_size":0.0,"text":"90.1"},{"bbox":{"x0":146,"x1":305,"y0":1118,"y1":1140},"font_size":0.0,"text":"MMLU-Redux (EM)"},{"bbox":{"x0":439,"x1":480,"y0":1118,"y1":1142},"font_size":0.0,"text":"92.7"},{"bbox":{"x0":535,"x1":575,"y0":1119,"y1":1140},"font_size":0.0,"text":"90.5"},{"bbox":{"x0":626,"x1":676,"y0":1118,"y1":1142},"font_size":0.0,"text":"89.2*"},{"bbox":{"x0":726,"x1":766,"y0":1119,"y1":1140},"font_size":0.0,"text":"93.6"},{"bbox":{"x0":821,"x1":862,"y0":1118,"y1":1142},"font_size":0.0,"text":"94.2"},{"bbox":{"x0":917,"x1":957,"y0":1119,"y1":1140},"font_size":0.0,"text":"92.4"},{"bbox":{"x0":1013,"x1":1052,"y0":1119,"y1":1140},"font_size":0.0,"text":"90.6"},{"bbox":{"x0":147,"x1":284,"y0":1139,"y1":1161},"font_size":0.0,"text":"MMLU-Pro (EM)"},{"bbox":{"x0":439,"x1":480,"y0":1137,"y1":1162},"font_size":0.0,"text":"81.1"},{"bbox":{"x0":530,"x1":580,"y0":1137,"y1":1162},"font_size":0.0,"text":"81.2*"},{"bbox":{"x0":630,"x1":672,"y0":1137,"y1":1162},"font_size":0.0,"text":"77.3"},{"bbox":{"x0":725,"x1":767,"y0":1137,"y1":1162},"font_size":0.0,"text":"83.7"},{"bbox":{"x0":821,"x1":863,"y0":1137,"y1":1162},"font_size":0.0,"text":"86.6"},{"bbox":{"x0":916,"x1":958,"y0":1137,"y1":1162},"font_size":0.0,"text":"81.8"},{"bbox":{"x0":1012,"x1":1054,"y0":1137,"y1":1162},"font_size":0.0,"text":"79.4"},{"bbox":{"x0":147,"x1":316,"y0":1157,"y1":1182},"font_size":0.0,"text":"IFEval (Prompt Strict)"},{"bbox":{"x0":439,"x1":482,"y0":1157,"y1":1182},"font_size":0.0,"text":"89.8"},{"bbox":{"x0":535,"x1":575,"y0":1159,"y1":1180},"font_size":0.0,"text":"81.1"},{"bbox":{"x0":626,"x1":677,"y0":1155,"y1":1183},"font_size":0.0,"text":"83.2*"},{"bbox":{"x0":726,"x1":767,"y0":1157,"y1":1182},"font_size":0.0,"text":"87.6"},{"bbox":{"x0":822,"x1":861,"y0":1159,"y1":1180},"font_size":0.0,"text":"87.4"},{"bbox":{"x0":916,"x1":958,"y0":1157,"y1":1182},"font_size":0.0,"text":"88.0"},{"bbox":{"x0":1012,"x1":1053,"y0":1157,"y1":1182},"font_size":0.0,"text":"84.3"},{"bbox":{"x0":146,"x1":323,"y0":1178,"y1":1201},"font_size":0.0,"text":"Multi-Challenge (Acc.)"},{"bbox":{"x0":441,"x1":479,"y0":1179,"y1":1200},"font_size":0.0,"text":"54.1"},{"bbox":{"x0":535,"x1":578,"y0":1178,"y1":1203},"font_size":0.0,"text":"31.4"},{"bbox":{"x0":631,"x1":671,"y0":1179,"y1":1200},"font_size":0.0,"text":"34.0"},{"bbox":{"x0":728,"x1":766,"y0":1179,"y1":1200},"font_size":0.0,"text":"46.8"},{"bbox":{"x0":822,"x1":862,"y0":1179,"y1":1200},"font_size":0.0,"text":"49.0"},{"bbox":{"x0":917,"x1":957,"y0":1179,"y1":1200},"font_size":0.0,"text":"36.4"},{"bbox":{"x0":1012,"x1":1053,"y0":1178,"y1":1203},"font_size":0.0,"text":"39.5"},{"bbox":{"x0":147,"x1":300,"y0":1197,"y1":1219},"font_size":0.0,"text":"SimpleQA (Correct)"},{"bbox":{"x0":439,"x1":482,"y0":1197,"y1":1222},"font_size":0.0,"text":"31.0"},{"bbox":{"x0":535,"x1":578,"y0":1197,"y1":1222},"font_size":0.0,"text":"27.7"},{"bbox":{"x0":631,"x1":672,"y0":1197,"y1":1222},"font_size":0.0,"text":"13.2"},{"bbox":{"x0":726,"x1":767,"y0":1197,"y1":1222},"font_size":0.0,"text":"15.9"},{"bbox":{"x0":821,"x1":863,"y0":1197,"y1":1222},"font_size":0.0,"text":"22.8"},{"bbox":{"x0":916,"x1":958,"y0":1197,"y1":1222},"font_size":0.0,"text":"42.3"},{"bbox":{"x0":1012,"x1":1054,"y0":1197,"y1":1222},"font_size":0.0,"text":"23.3"},{"bbox":{"x0":147,"x1":303,"y0":1219,"y1":1242},"font_size":0.0,"text":"Livebench (Pass@1)"},{"bbox":{"x0":441,"x1":482,"y0":1217,"y1":1242},"font_size":0.0,"text":"76.4"},{"bbox":{"x0":535,"x1":578,"y0":1217,"y1":1243},"font_size":0.0,"text":"72.4"},{"bbox":{"x0":631,"x1":671,"y0":1219,"y1":1240},"font_size":0.0,"text":"67.6"},{"bbox":{"x0":726,"x1":769,"y0":1215,"y1":1245},"font_size":0.0,"text":"74.8"},{"bbox":{"x0":821,"x1":863,"y0":1217,"y1":1242},"font_size":0.0,"text":"74.6"},{"bbox":{"x0":917,"x1":957,"y0":1219,"y1":1240},"font_size":0.0,"text":"69.8"},{"bbox":{"x0":1013,"x1":1052,"y0":1219,"y1":1240},"font_size":0.0,"text":"67.8"},{"bbox":{"x0":147,"x1":275,"y0":1239,"y1":1261},"font_size":0.0,"text":"Arena Hard v2.0"},{"bbox":{"x0":441,"x1":482,"y0":1248,"y1":1273},"font_size":0.0,"text":"54.5"},{"bbox":{"x0":535,"x1":576,"y0":1247,"y1":1272},"font_size":0.0,"text":"39.9"},{"bbox":{"x0":633,"x1":671,"y0":1250,"y1":1270},"font_size":0.0,"text":"39.9"},{"bbox":{"x0":726,"x1":769,"y0":1247,"y1":1272},"font_size":0.0,"text":"51.6"},{"bbox":{"x0":821,"x1":862,"y0":1247,"y1":1272},"font_size":0.0,"text":"59.7"},{"bbox":{"x0":917,"x1":957,"y0":1247,"y1":1272},"font_size":0.0,"text":"51.7"},{"bbox":{"x0":1012,"x1":1053,"y0":1247,"y1":1272},"font_size":0.0,"text":"48.7"},{"bbox":{"x0":147,"x1":326,"y0":1260,"y1":1282},"font_size":0.0,"text":"Hard Prompt (Win rate)"},{"bbox":{"x0":146,"x1":275,"y0":1277,"y1":1302},"font_size":0.0,"text":"Arena Hard v2.0"},{"bbox":{"x0":147,"x1":352,"y0":1298,"y1":1320},"font_size":0.0,"text":"Creative Writing (Win rate)"},{"bbox":{"x0":441,"x1":480,"y0":1289,"y1":1310},"font_size":0.0,"text":"85.0"},{"bbox":{"x0":535,"x1":576,"y0":1287,"y1":1312},"font_size":0.0,"text":"59.3"},{"bbox":{"x0":631,"x1":672,"y0":1287,"y1":1312},"font_size":0.0,"text":"59.8"},{"bbox":{"x0":726,"x1":769,"y0":1287,"y1":1312},"font_size":0.0,"text":"54.6"},{"bbox":{"x0":821,"x1":862,"y0":1287,"y1":1312},"font_size":0.0,"text":"68.5"},{"bbox":{"x0":916,"x1":958,"y0":1287,"y1":1312},"font_size":0.0,"text":"61.5"},{"bbox":{"x0":1012,"x1":1053,"y0":1287,"y1":1312},"font_size":0.0,"text":"72.8"},{"bbox":{"x0":146,"x1":370,"y0":1316,"y1":1341},"font_size":0.0,"text":"FACTS Grounding (Adjusted)"},{"bbox":{"x0":441,"x1":480,"y0":1317,"y1":1338},"font_size":0.0,"text":"88.5"},{"bbox":{"x0":535,"x1":576,"y0":1316,"y1":1341},"font_size":0.0,"text":"68.3"},{"bbox":{"x0":628,"x1":673,"y0":1314,"y1":1343},"font_size":0.0,"text":"68.5"},{"bbox":{"x0":726,"x1":767,"y0":1316,"y1":1341},"font_size":0.0,"text":"83.6"},{"bbox":{"x0":833,"x1":851,"y0":1324,"y1":1340},"font_size":8.0,"text":"—"},{"bbox":{"x0":916,"x1":958,"y0":1316,"y1":1341},"font_size":0.0,"text":"79.2"},{"bbox":{"x0":1012,"x1":1052,"y0":1319,"y1":1340},"font_size":0.0,"text":"86.6"},{"bbox":{"x0":146,"x1":319,"y0":1337,"y1":1361},"font_size":0.0,"text":"HHEM v2.1 (1-Hallu.)"},{"bbox":{"x0":441,"x1":480,"y0":1338,"y1":1359},"font_size":0.0,"text":"98.9"},{"bbox":{"x0":537,"x1":575,"y0":1338,"y1":1359},"font_size":0.0,"text":"88.9"},{"bbox":{"x0":631,"x1":671,"y0":1338,"y1":1359},"font_size":0.0,"text":"94.5"},{"bbox":{"x0":725,"x1":767,"y0":1336,"y1":1360},"font_size":0.0,"text":"94.5"},{"bbox":{"x0":833,"x1":851,"y0":1344,"y1":1360},"font_size":8.0,"text":"—"},{"bbox":{"x0":917,"x1":956,"y0":1338,"y1":1359},"font_size":0.0,"text":"96.7"},{"bbox":{"x0":1013,"x1":1052,"y0":1338,"y1":1359},"font_size":0.0,"text":"97.8"},{"bbox":{"x0":146,"x1":309,"y0":1356,"y1":1380},"font_size":0.0,"text":"FaithJudge (1-Hallu.)"},{"bbox":{"x0":439,"x1":482,"y0":1357,"y1":1381},"font_size":0.0,"text":"92.6"},{"bbox":{"x0":537,"x1":576,"y0":1358,"y1":1379},"font_size":0.0,"text":"83.4"},{"bbox":{"x0":630,"x1":671,"y0":1357,"y1":1381},"font_size":0.0,"text":"75.7"},{"bbox":{"x0":728,"x1":766,"y0":1358,"y1":1379},"font_size":0.0,"text":"83.0"},{"bbox":{"x0":833,"x1":851,"y0":1364,"y1":1380},"font_size":8.0,"text":"—"},{"bbox":{"x0":917,"x1":957,"y0":1358,"y1":1379},"font_size":0.0,"text":"91.0"},{"bbox":{"x0":1013,"x1":1052,"y0":1358,"y1":1379},"font_size":0.0,"text":"93.2"},{"bbox":{"x0":146,"x1":311,"y0":1377,"y1":1401},"font_size":0.0,"text":"LongBench v2 (Acc.)"},{"bbox":{"x0":441,"x1":479,"y0":1379,"y1":1400},"font_size":0.0,"text":"49.1"},{"bbox":{"x0":535,"x1":576,"y0":1376,"y1":1401},"font_size":0.0,"text":"51.1"},{"bbox":{"x0":642,"x1":660,"y0":1383,"y1":1399},"font_size":8.0,"text":"—"},{"bbox":{"x0":726,"x1":767,"y0":1376,"y1":1401},"font_size":0.0,"text":"52.5"},{"bbox":{"x0":833,"x1":851,"y0":1383,"y1":1399},"font_size":8.0,"text":"—"},{"bbox":{"x0":917,"x1":957,"y0":1377,"y1":1398},"font_size":0.0,"text":"54.3"},{"bbox":{"x0":1012,"x1":1053,"y0":1376,"y1":1401},"font_size":0.0,"text":"55.5"},{"bbox":{"x0":146,"x1":275,"y0":1394,"y1":1422},"font_size":0.0,"text":"FRAMES (Acc.)"},{"bbox":{"x0":439,"x1":480,"y0":1396,"y1":1420},"font_size":0.0,"text":"77.1"},{"bbox":{"x0":533,"x1":577,"y0":1394,"y1":1422},"font_size":0.0,"text":"79.2"},{"bbox":{"x0":642,"x1":660,"y0":1403,"y1":1419},"font_size":8.0,"text":"—"},{"bbox":{"x0":726,"x1":767,"y0":1396,"y1":1420},"font_size":0.0,"text":"76.3"},{"bbox":{"x0":833,"x1":851,"y0":1403,"y1":1419},"font_size":8.0,"text":"—"},{"bbox":{"x0":917,"x1":957,"y0":1398,"y1":1419},"font_size":0.0,"text":"87.4"},{"bbox":{"x0":1012,"x1":1053,"y0":1396,"y1":1420},"font_size":0.0,"text":"72.9"},{"bbox":{"x0":144,"x1":258,"y0":1416,"y1":1442},"font_size":0.0,"text":"MRCR (Acc.)"},{"bbox":{"x0":439,"x1":482,"y0":1417,"y1":1443},"font_size":0.0,"text":"55.0"},{"bbox":{"x0":533,"x1":577,"y0":1413,"y1":1442},"font_size":0.0,"text":"50.8"},{"bbox":{"x0":724,"x1":768,"y0":1413,"y1":1442},"font_size":0.0,"text":"74.4"},{"bbox":{"x0":833,"x1":851,"y0":1423,"y1":1439},"font_size":8.0,"text":"—"},{"bbox":{"x0":917,"x1":957,"y0":1419,"y1":1439},"font_size":0.0,"text":"66.9"},{"bbox":{"x0":1012,"x1":1053,"y0":1417,"y1":1441},"font_size":0.0,"text":"81.7"},{"bbox":{"x0":146,"x1":254,"y0":1436,"y1":1461},"font_size":0.0,"text":"DROP (Acc.)"},{"bbox":{"x0":439,"x1":482,"y0":1436,"y1":1461},"font_size":0.0,"text":"93.5"},{"bbox":{"x0":534,"x1":576,"y0":1436,"y1":1462},"font_size":0.0,"text":"91.2"},{"bbox":{"x0":630,"x1":672,"y0":1436,"y1":1461},"font_size":0.0,"text":"84.3"},{"bbox":{"x0":726,"x1":769,"y0":1436,"y1":1461},"font_size":0.0,"text":"92.0"},{"bbox":{"x0":833,"x1":851,"y0":1443,"y1":1459},"font_size":8.0,"text":"—"},{"bbox":{"x0":917,"x1":957,"y0":1436,"y1":1461},"font_size":0.0,"text":"79.1"},{"bbox":{"x0":1012,"x1":1053,"y0":1436,"y1":1461},"font_size":0.0,"text":"81.7"}],"source":"layout det","text":"<html><body><table><thead><tr><td></td><td colspan=\"3\">Open Source</td><td colspan=\"3\">Proprietary</td><td></td></tr><tr><td>Benchmark</td><td>Kimi-K2- Instruct</td><td>DeepSeek- V3-0324</td><td>Qwen3- 235B- A22B</td><td>Claude Sonnet 4</td><td>Claude Opus 4</td><td>GPT-4.1</td><td>Gemini 2.5 Flash</td></tr></thead><tbody><tr><td colspan=\"8\">Coding Tasks</td></tr><tr><td>LiveCodeBench v6 (Pass@1)</td><td>53.7</td><td>46.9</td><td>37.0</td><td>48.5</td><td>47.4</td><td>44.7</td><td>44.7</td></tr><tr><td>OJBench (Pass@1)</td><td>27.1</td><td>24.0</td><td>11.3</td><td>15.3</td><td>19.6</td><td>19.5</td><td>19.5</td></tr><tr><td>MultiPL-E (Pass@1) SWE-bench Verifed</td><td>85.7</td><td>83.1</td><td>78.2</td><td>88.6</td><td>89.6</td><td>86.7</td><td>85.6</td></tr><tr><td>Agentless-Single-Patch (Pass@1)</td><td>51.8</td><td>36.6</td><td>39.4</td><td>50.2</td><td>53.0</td><td>40.8</td><td>32.6</td></tr><tr><td>SWE-bench Verifed Agentic-Single-Attempt (Pass@1)</td><td>65.8</td><td>38.8</td><td>34.4</td><td>72.7*</td><td> $72.5\\text{*}$ </td><td>54.6</td><td>—</td></tr><tr><td>SWE-bench Verifed</td><td>71.6</td><td>—</td><td>—</td><td>80.2*</td><td> $79.4\\text{*}$ </td><td>—</td><td>—</td></tr><tr><td>Agentic-Multi-Attempt (Pass@1) SWE-bench Multilingual (Pass@1)</td><td>47.3</td><td>25.8</td><td>20.9</td><td>51.0</td><td>—</td><td>31.5</td><td>—</td></tr><tr><td>Multi-SWE-bench (Pass@1)</td><td>18.3</td><td>8.0</td><td>9.0</td><td>29.2</td><td>—</td><td>11.7</td><td>14.0</td></tr><tr><td>SWE-Lancer (Pass@1)</td><td>39.1</td><td>30.5</td><td>24.1</td><td>40.8</td><td>—</td><td>23.0</td><td>38.5</td></tr><tr><td>Paper Bench Code-Dev (Acc.)</td><td>27.8</td><td>12.2</td><td>13.2</td><td>43.3</td><td></td><td>29.9</td><td>5.7</td></tr><tr><td>Terminal Bench In-House (Acc.)</td><td>30.0</td><td></td><td></td><td>35.5</td><td>43.2</td><td>8.3</td><td>—</td></tr><tr><td>Terminal Bench Terminus (Acc.)</td><td>25.0</td><td>16.3</td><td>6.6</td><td>—</td><td></td><td>30.3</td><td>16.8</td></tr><tr><td>Aider-Polyglot (Acc.)</td><td>60.0</td><td>55.1</td><td>61.8</td><td>56.4</td><td>70.7</td><td>52.4</td><td>44.0</td></tr><tr><td colspan=\"8\">Tool Use Tasks</td></tr><tr><td>Tau2 retail (Avg@4)</td><td>70.6</td><td>69.1</td><td>57.0</td><td>75.0</td><td>81.8</td><td>74.8</td><td>64.3</td></tr><tr><td>Tau2 airline (Avg@4)</td><td>56.5</td><td>39.0</td><td>26.5</td><td>55.5</td><td>60.0</td><td>54.5</td><td>42.5</td></tr><tr><td>Tau2 telecom (Avg@4)</td><td>65.8</td><td>32.5</td><td>22.1</td><td>45.2</td><td>57.0</td><td>38.6</td><td>16.9</td></tr><tr><td>AceBench (Acc.)</td><td>76.5</td><td>72.7</td><td>70.5</td><td>76.2</td><td>75.6</td><td>80.1</td><td>74.5</td></tr><tr><td colspan=\"8\">Math & STEM Tasks</td></tr><tr><td>AIME 2024 (Avg@64)</td><td>69.6</td><td>59.4*</td><td>40.1*</td><td>43.4</td><td>48.2</td><td>46.5</td><td>61.3</td></tr><tr><td>AIME 2025 (Avg@64)</td><td>49.5</td><td>46.7</td><td>24.7*</td><td>33.1*</td><td>33.9*</td><td>37.0</td><td>46.6</td></tr><tr><td>MATH-500 (Acc.)</td><td>97.4</td><td>94.0*</td><td>91.2*</td><td>94.0</td><td>94.4</td><td>92.4</td><td>95.4</td></tr><tr><td>HMMT 2025 (Avg@32)</td><td>38.8</td><td>27.5</td><td>11.9</td><td>15.9</td><td>15.9</td><td>19.4</td><td>34.7</td></tr><tr><td>CNMO 2024 (Avg@16)</td><td>74.3</td><td>74.7</td><td>48.6</td><td>60.4</td><td>57.6</td><td>56.6</td><td>75.0</td></tr><tr><td>PolyMath-en (Avg@4)</td><td>65.1</td><td>59.5</td><td>51.9</td><td>52.8</td><td>49.8</td><td>54.0</td><td>49.9</td></tr><tr><td>ZebraLogic (Acc.)</td><td>89.0</td><td>84.0</td><td>37.7*</td><td>79.7</td><td>59.3</td><td>58.5</td><td>57.9</td></tr><tr><td>AutoLogi (Acc.)</td><td>89.5</td><td>88.9</td><td>83.3*</td><td>89.8</td><td>86.1</td><td>88.2</td><td>84.1</td></tr><tr><td>GPQA-Diamond (Avg@8)</td><td>75.1</td><td>68.4*</td><td>62.9*</td><td>70.0*</td><td>74.9*</td><td>66.3</td><td>68.2</td></tr><tr><td>SuperGPQA (Acc.)</td><td>57.2 4.7</td><td>53.7 5.2</td><td>50.2 5.7</td><td>55.7 5.8</td><td>56.5 7.1</td><td>50.8 3.7</td><td>49.6 5.6</td></tr><tr><td colspan=\"8\">Humanity’s Last Exam (Acc.) General Tasks</td></tr><tr><td>MMLU (EM)</td><td>89.5</td><td>89.4</td><td>87.0</td><td>91.5</td><td>92.9</td><td>90.4</td><td>90.1</td></tr><tr><td>MMLU-Redux (EM)</td><td>92.7</td><td>90.5</td><td>89.2*</td><td>93.6</td><td>94.2</td><td>92.4</td><td>90.6</td></tr><tr><td>MMLU-Pro (EM)</td><td>81.1</td><td>81.2*</td><td>77.3</td><td>83.7</td><td>86.6</td><td>81.8</td><td>79.4</td></tr><tr><td>IFEval (Prompt Strict)</td><td>89.8</td><td>81.1</td><td>83.2*</td><td>87.6</td><td>87.4</td><td>88.0</td><td>84.3</td></tr><tr><td>Multi-Challenge (Acc.)</td><td>54.1</td><td>31.4</td><td>34.0</td><td>46.8</td><td>49.0</td><td>36.4</td><td>39.5</td></tr><tr><td>SimpleQA (Correct)</td><td>31.0</td><td>27.7</td><td>13.2</td><td>15.9</td><td>22.8</td><td>42.3</td><td>23.3</td></tr><tr><td>Livebench (Pass@1) Arena Hard v2.0</td><td>76.4</td><td>72.4</td><td>67.6</td><td>74.8</td><td>74.6</td><td>69.8</td><td>67.8</td></tr><tr><td>Hard Prompt (Win rate)</td><td>54.5</td><td>39.9</td><td>39.9</td><td>51.6</td><td>59.7</td><td>51.7</td><td>48.7</td></tr><tr><td>Arena Hard v2.0</td><td>85.0</td><td>59.3</td><td>59.8</td><td>54.6</td><td>68.5</td><td>61.5</td><td>72.8</td></tr><tr><td>Creative Writing (Win rate) FACTS Grounding (Adjusted)</td><td>88.5</td><td></td><td></td><td></td><td></td><td>79.2</td><td>86.6</td></tr><tr><td>HHEM v2.1 (1-Hallu.)</td><td>98.9</td><td>68.3 88.9</td><td>68.5 94.5</td><td>83.6 94.5</td><td>—</td><td>96.7</td><td>97.8</td></tr><tr><td>FaithJudge (1-Hallu.)</td><td>92.6</td><td>83.4</td><td>75.7</td><td>83.0</td><td>—</td><td>91.0</td><td>93.2</td></tr><tr><td>LongBench v2 (Acc.)</td><td></td><td></td><td></td><td></td><td>—</td><td>54.3</td><td>55.5</td></tr><tr><td>FRAMES (Acc.)</td><td>49.1 77.1</td><td>51.1 79.2</td><td>—</td><td>52.5 76.3</td><td>—</td><td>87.4</td><td>72.9</td></tr><tr><td>MRCR (Acc.)</td><td>55.0</td><td>50.8</td><td>—</td><td>74.4</td><td>—</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>—</td><td>66.9</td><td>81.7</td></tr><tr><td>DROP (Acc.)</td><td>93.5</td><td>91.2</td><td>84.3</td><td>92.0</td><td>—</td><td>79.1</td><td>81.7</td></tr></tbody></table></body></html>"}],"formula_dets":[{"bbox":{"x0":816,"x1":867,"y0":466,"y1":490},"conf":0.7321,"label":"print_embedding","label_id":0},{"bbox":{"x0":815,"x1":868,"y0":505,"y1":530},"conf":0.6348,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":142,"x1":1085,"y0":221,"y1":1474},"conf":0.9893,"label":"Table","label_id":5},{"bbox":{"x0":134,"x1":1090,"y0":148,"y1":222},"conf":0.9312,"label":"Table caption","label_id":6},{"bbox":{"x0":552,"x1":1088,"y0":64,"y1":95},"conf":0.7603,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":627,"y0":1480,"y1":1506},"conf":0.708,"label":"Abandon","label_id":2},{"bbox":{"x0":134,"x1":1089,"y0":62,"y1":104},"conf":0.3884,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[595,1478],[629,1478],[629,1506],[595,1506]],"score":0.8162},{"poly":[[145,1436],[254,1436],[254,1464],[145,1464]],"score":0.8485},{"poly":[[1011,1436],[1054,1436],[1054,1462],[1011,1462]],"score":0.9396},{"poly":[[916,1436],[958,1436],[958,1462],[916,1462]],"score":0.8794},{"poly":[[725,1436],[770,1436],[770,1462],[725,1462]],"score":0.9049},{"poly":[[629,1436],[672,1436],[672,1462],[629,1462]],"score":0.9206},{"poly":[[534,1436],[577,1436],[577,1462],[534,1462]],"score":0.9474},{"poly":[[439,1436],[482,1436],[482,1462],[439,1462]],"score":0.9504},{"poly":[[145,1414],[258,1418],[257,1442],[144,1439]],"score":0.7476},{"poly":[[1011,1416],[1054,1416],[1054,1442],[1011,1442]],"score":0.8538},{"poly":[[916,1416],[960,1416],[960,1442],[916,1442]],"score":0.8003},{"poly":[[725,1416],[768,1416],[768,1442],[725,1442]],"score":0.7857},{"poly":[[534,1416],[577,1416],[577,1442],[534,1442]],"score":0.8112},{"poly":[[439,1416],[484,1416],[484,1445],[439,1445]],"score":0.868},{"poly":[[146,1398],[278,1398],[278,1421],[146,1421]],"score":0.8472},{"poly":[[1011,1396],[1054,1396],[1054,1421],[1011,1421]],"score":0.9407},{"poly":[[915,1396],[960,1396],[960,1421],[915,1421]],"score":0.933},{"poly":[[725,1396],[768,1396],[768,1421],[725,1421]],"score":0.9327},{"poly":[[439,1396],[481,1396],[481,1421],[439,1421]],"score":0.923},{"poly":[[535,1392],[578,1397],[575,1425],[532,1420]],"score":0.8182},{"poly":[[145,1378],[311,1378],[311,1401],[145,1401]],"score":0.7812},{"poly":[[1011,1376],[1054,1376],[1054,1401],[1011,1401]],"score":0.926},{"poly":[[915,1376],[960,1376],[960,1401],[915,1401]],"score":0.9161},{"poly":[[725,1376],[768,1376],[768,1401],[725,1401]],"score":0.9479},{"poly":[[534,1376],[577,1376],[577,1402],[534,1402]],"score":0.8341},{"poly":[[439,1376],[481,1376],[481,1401],[439,1401]],"score":0.9382},{"poly":[[145,1358],[309,1358],[309,1381],[145,1381]],"score":0.8295},{"poly":[[1011,1356],[1054,1356],[1054,1381],[1011,1381]],"score":0.9484},{"poly":[[915,1356],[960,1356],[960,1381],[915,1381]],"score":0.9107},{"poly":[[725,1356],[768,1356],[768,1381],[725,1381]],"score":0.9419},{"poly":[[534,1356],[577,1356],[577,1381],[534,1381]],"score":0.9243},{"poly":[[439,1356],[482,1356],[482,1383],[439,1383]],"score":0.8874},{"poly":[[630,1355],[672,1355],[672,1383],[630,1383]],"score":0.8003},{"poly":[[1011,1336],[1054,1336],[1054,1361],[1011,1361]],"score":0.9596},{"poly":[[725,1336],[768,1336],[768,1361],[725,1361]],"score":0.8873},{"poly":[[629,1336],[674,1336],[674,1361],[629,1361]],"score":0.8925},{"poly":[[536,1336],[577,1336],[577,1361],[536,1361]],"score":0.968},{"poly":[[439,1336],[482,1336],[482,1361],[439,1361]],"score":0.9164},{"poly":[[145,1335],[319,1338],[319,1361],[145,1358]],"score":0.8059},{"poly":[[916,1335],[960,1335],[960,1361],[916,1361]],"score":0.8213},{"poly":[[146,1317],[371,1317],[371,1340],[146,1340]],"score":0.8322},{"poly":[[1011,1315],[1054,1315],[1054,1341],[1011,1341]],"score":0.8238},{"poly":[[915,1315],[960,1315],[960,1341],[915,1341]],"score":0.8618},{"poly":[[725,1315],[768,1315],[768,1341],[725,1341]],"score":0.8466},{"poly":[[629,1315],[674,1315],[674,1341],[629,1341]],"score":0.843},{"poly":[[534,1315],[577,1315],[577,1341],[534,1341]],"score":0.8685},{"poly":[[439,1315],[482,1315],[482,1341],[439,1341]],"score":0.8439},{"poly":[[146,1299],[354,1299],[354,1320],[146,1320]],"score":0.9568},{"poly":[[915,1287],[960,1287],[960,1313],[915,1313]],"score":0.8841},{"poly":[[820,1287],[863,1287],[863,1312],[820,1312]],"score":0.9718},{"poly":[[725,1287],[770,1287],[770,1312],[725,1312]],"score":0.9423},{"poly":[[629,1287],[674,1287],[674,1312],[629,1312]],"score":0.9478},{"poly":[[1011,1285],[1054,1285],[1054,1312],[1011,1312]],"score":0.879},{"poly":[[534,1285],[579,1285],[579,1315],[534,1315]],"score":0.8081},{"poly":[[437,1285],[484,1285],[484,1312],[437,1312]],"score":0.8052},{"poly":[[145,1277],[276,1275],[276,1298],[145,1300]],"score":0.8433},{"poly":[[146,1259],[328,1259],[328,1282],[146,1282]],"score":0.8399},{"poly":[[1011,1246],[1054,1246],[1054,1272],[1011,1272]],"score":0.9228},{"poly":[[913,1244],[961,1244],[961,1275],[913,1275]],"score":0.8429},{"poly":[[820,1246],[863,1246],[863,1272],[820,1272]],"score":0.9418},{"poly":[[725,1246],[768,1246],[768,1272],[725,1272]],"score":0.9347},{"poly":[[629,1246],[674,1246],[674,1272],[629,1272]],"score":0.876},{"poly":[[534,1246],[577,1246],[577,1272],[534,1272]],"score":0.9001},{"poly":[[437,1244],[484,1244],[484,1277],[437,1277]],"score":0.8642},{"poly":[[148,1241],[276,1241],[276,1261],[148,1261]],"score":0.9722},{"poly":[[145,1219],[304,1219],[304,1242],[145,1242]],"score":0.8375},{"poly":[[1011,1218],[1054,1218],[1054,1242],[1011,1242]],"score":0.9783},{"poly":[[915,1218],[960,1218],[960,1242],[915,1242]],"score":0.9358},{"poly":[[629,1218],[674,1218],[674,1242],[629,1242]],"score":0.907},{"poly":[[820,1216],[865,1216],[865,1242],[820,1242]],"score":0.8306},{"poly":[[725,1216],[768,1216],[768,1242],[725,1242]],"score":0.875},{"poly":[[536,1216],[579,1216],[579,1242],[536,1242]],"score":0.8856},{"poly":[[439,1216],[482,1216],[482,1242],[439,1242]],"score":0.8692},{"poly":[[145,1198],[303,1198],[303,1221],[145,1221]],"score":0.8514},{"poly":[[1011,1196],[1054,1196],[1054,1223],[1011,1223]],"score":0.8679},{"poly":[[916,1196],[960,1196],[960,1223],[916,1223]],"score":0.9086},{"poly":[[820,1196],[863,1196],[863,1223],[820,1223]],"score":0.8533},{"poly":[[725,1196],[770,1196],[770,1223],[725,1223]],"score":0.776},{"poly":[[632,1196],[674,1196],[674,1223],[632,1223]],"score":0.8742},{"poly":[[534,1196],[577,1196],[577,1223],[534,1223]],"score":0.8236},{"poly":[[439,1196],[482,1196],[482,1223],[439,1223]],"score":0.8856},{"poly":[[820,1178],[863,1178],[863,1203],[820,1203]],"score":0.864},{"poly":[[725,1178],[768,1178],[768,1203],[725,1203]],"score":0.8799},{"poly":[[534,1178],[577,1178],[577,1203],[534,1203]],"score":0.8689},{"poly":[[143,1176],[323,1176],[323,1200],[143,1200]],"score":0.7014},{"poly":[[1011,1176],[1054,1176],[1054,1203],[1011,1203]],"score":0.8049},{"poly":[[916,1176],[960,1176],[960,1203],[916,1203]],"score":0.8021},{"poly":[[629,1176],[674,1176],[674,1203],[629,1203]],"score":0.7342},{"poly":[[439,1176],[482,1176],[482,1203],[439,1203]],"score":0.7674},{"poly":[[534,1160],[575,1160],[575,1180],[534,1180]],"score":0.944},{"poly":[[146,1158],[316,1158],[316,1181],[146,1181]],"score":0.8167},{"poly":[[1011,1157],[1054,1157],[1054,1183],[1011,1183]],"score":0.8096},{"poly":[[915,1157],[960,1157],[960,1181],[915,1181]],"score":0.8358},{"poly":[[820,1157],[863,1157],[863,1181],[820,1181]],"score":0.8614},{"poly":[[725,1157],[770,1157],[770,1181],[725,1181]],"score":0.8684},{"poly":[[627,1157],[677,1157],[677,1181],[627,1181]],"score":0.8502},{"poly":[[439,1157],[482,1157],[482,1183],[439,1183]],"score":0.824},{"poly":[[146,1138],[286,1138],[286,1160],[146,1160]],"score":0.9259},{"poly":[[1011,1137],[1054,1137],[1054,1162],[1011,1162]],"score":0.8914},{"poly":[[915,1137],[960,1137],[960,1162],[915,1162]],"score":0.8459},{"poly":[[820,1137],[865,1137],[865,1162],[820,1162]],"score":0.8481},{"poly":[[725,1137],[768,1137],[768,1162],[725,1162]],"score":0.948},{"poly":[[629,1137],[674,1137],[674,1162],[629,1162]],"score":0.9295},{"poly":[[531,1137],[580,1137],[580,1162],[531,1162]],"score":0.9475},{"poly":[[439,1137],[482,1137],[482,1162],[439,1162]],"score":0.8648},{"poly":[[146,1119],[308,1119],[308,1142],[146,1142]],"score":0.8414},{"poly":[[1009,1117],[1054,1117],[1054,1142],[1009,1142]],"score":0.8703},{"poly":[[915,1117],[960,1117],[960,1142],[915,1142]],"score":0.9006},{"poly":[[820,1117],[865,1117],[865,1142],[820,1142]],"score":0.8963},{"poly":[[725,1117],[770,1117],[770,1142],[725,1142]],"score":0.9363},{"poly":[[625,1117],[677,1117],[677,1142],[625,1142]],"score":0.8322},{"poly":[[532,1117],[579,1117],[579,1142],[532,1142]],"score":0.8506},{"poly":[[439,1115],[484,1115],[484,1145],[439,1145]],"score":0.8116},{"poly":[[1009,1097],[1053,1097],[1053,1122],[1009,1122]],"score":0.8983},{"poly":[[915,1097],[960,1097],[960,1122],[915,1122]],"score":0.8869},{"poly":[[820,1097],[863,1097],[863,1122],[820,1122]],"score":0.8889},{"poly":[[725,1097],[768,1097],[768,1122],[725,1122]],"score":0.9242},{"poly":[[629,1097],[674,1097],[674,1122],[629,1122]],"score":0.9366},{"poly":[[534,1097],[577,1097],[577,1122],[534,1122]],"score":0.914},{"poly":[[439,1097],[482,1097],[482,1124],[439,1124]],"score":0.8884},{"poly":[[146,1097],[254,1097],[254,1120],[146,1120]],"score":0.8594},{"poly":[[144,1064],[265,1068],[264,1096],[143,1092]],"score":0.7806},{"poly":[[145,1038],[369,1038],[369,1061],[145,1061]],"score":0.7742},{"poly":[[1013,1036],[1051,1036],[1051,1063],[1013,1063]],"score":0.7996},{"poly":[[918,1036],[956,1036],[956,1061],[918,1061]],"score":0.9092},{"poly":[[823,1036],[861,1036],[861,1061],[823,1061]],"score":0.8793},{"poly":[[727,1036],[765,1036],[765,1061],[727,1061]],"score":0.8872},{"poly":[[632,1036],[670,1036],[670,1064],[632,1064]],"score":0.7995},{"poly":[[539,1038],[574,1038],[574,1061],[539,1061]],"score":0.9635},{"poly":[[441,1036],[479,1036],[479,1061],[441,1061]],"score":0.8948},{"poly":[[145,1020],[296,1020],[296,1043],[145,1043]],"score":0.8356},{"poly":[[1011,1016],[1056,1016],[1056,1043],[1011,1043]],"score":0.7699},{"poly":[[915,1016],[960,1016],[960,1043],[915,1043]],"score":0.8393},{"poly":[[820,1016],[865,1016],[865,1043],[820,1043]],"score":0.8486},{"poly":[[725,1016],[768,1016],[768,1043],[725,1043]],"score":0.9069},{"poly":[[629,1016],[674,1016],[674,1043],[629,1043]],"score":0.8643},{"poly":[[532,1016],[577,1016],[577,1043],[532,1043]],"score":0.8525},{"poly":[[439,1016],[482,1016],[482,1043],[439,1043]],"score":0.921},{"poly":[[146,998],[346,998],[346,1021],[146,1021]],"score":0.7815},{"poly":[[1011,997],[1054,997],[1054,1023],[1011,1023]],"score":0.8886},{"poly":[[915,997],[960,997],[960,1023],[915,1023]],"score":0.8211},{"poly":[[818,997],[866,997],[866,1021],[818,1021]],"score":0.918},{"poly":[[722,997],[772,997],[772,1021],[722,1021]],"score":0.9315},{"poly":[[625,997],[677,997],[677,1021],[625,1021]],"score":0.8859},{"poly":[[531,997],[580,997],[580,1021],[531,1021]],"score":0.8972},{"poly":[[439,997],[482,997],[482,1021],[439,1021]],"score":0.9533},{"poly":[[145,977],[278,979],[278,1002],[145,1000]],"score":0.8526},{"poly":[[1011,977],[1053,977],[1053,1002],[1011,1002]],"score":0.9294},{"poly":[[915,977],[960,977],[960,1002],[915,1002]],"score":0.9331},{"poly":[[818,977],[863,977],[863,1002],[818,1002]],"score":0.9193},{"poly":[[725,977],[770,977],[770,1002],[725,1002]],"score":0.8832},{"poly":[[625,977],[677,977],[677,1002],[625,1002]],"score":0.8633},{"poly":[[534,977],[577,977],[577,1002],[534,1002]],"score":0.9283},{"poly":[[439,977],[482,977],[482,1003],[439,1003]],"score":0.8947},{"poly":[[143,955],[293,959],[292,987],[143,983]],"score":0.7588},{"poly":[[1011,957],[1054,957],[1054,982],[1011,982]],"score":0.9527},{"poly":[[915,957],[960,957],[960,982],[915,982]],"score":0.9181},{"poly":[[820,957],[863,957],[863,982],[820,982]],"score":0.9554},{"poly":[[725,957],[768,957],[768,982],[725,982]],"score":0.9438},{"poly":[[627,957],[675,957],[675,982],[627,982]],"score":0.9323},{"poly":[[534,957],[577,957],[577,982],[534,982]],"score":0.9675},{"poly":[[439,957],[482,957],[482,982],[439,982]],"score":0.9142},{"poly":[[145,939],[321,939],[321,962],[145,962]],"score":0.7938},{"poly":[[1011,937],[1054,937],[1054,962],[1011,962]],"score":0.9304},{"poly":[[915,937],[960,937],[960,962],[915,962]],"score":0.9087},{"poly":[[820,937],[863,937],[863,962],[820,962]],"score":0.9477},{"poly":[[725,937],[768,937],[768,962],[725,962]],"score":0.9677},{"poly":[[629,937],[674,937],[674,962],[629,962]],"score":0.945},{"poly":[[534,937],[577,937],[577,962],[534,962]],"score":0.9027},{"poly":[[439,937],[482,937],[482,962],[439,962]],"score":0.904},{"poly":[[146,919],[329,919],[329,940],[146,940]],"score":0.926},{"poly":[[916,917],[960,917],[960,942],[916,942]],"score":0.9359},{"poly":[[725,917],[768,917],[768,942],[725,942]],"score":0.9703},{"poly":[[629,917],[674,917],[674,942],[629,942]],"score":0.8998},{"poly":[[1011,916],[1054,916],[1054,942],[1011,942]],"score":0.8831},{"poly":[[822,916],[865,916],[865,942],[822,942]],"score":0.8595},{"poly":[[534,916],[577,916],[577,942],[534,942]],"score":0.8855},{"poly":[[439,916],[482,916],[482,942],[439,942]],"score":0.8776},{"poly":[[916,898],[960,898],[960,922],[916,922]],"score":0.9383},{"poly":[[822,898],[863,898],[863,922],[822,922]],"score":0.9499},{"poly":[[629,898],[674,898],[674,922],[629,922]],"score":0.8982},{"poly":[[146,898],[329,898],[329,921],[146,921]],"score":0.7897},{"poly":[[1011,896],[1054,896],[1054,922],[1011,922]],"score":0.8787},{"poly":[[725,896],[768,896],[768,922],[725,922]],"score":0.8669},{"poly":[[532,896],[577,896],[577,922],[532,922]],"score":0.8454},{"poly":[[439,896],[482,896],[482,922],[439,922]],"score":0.8121},{"poly":[[146,878],[291,878],[291,901],[146,901]],"score":0.7943},{"poly":[[1011,876],[1054,876],[1054,903],[1011,903]],"score":0.8565},{"poly":[[915,876],[960,876],[960,903],[915,903]],"score":0.7919},{"poly":[[820,874],[866,879],[863,905],[817,900]],"score":0.8352},{"poly":[[725,872],[771,877],[768,903],[723,898]],"score":0.8087},{"poly":[[625,876],[677,876],[677,901],[625,901]],"score":0.8952},{"poly":[[531,876],[580,876],[580,901],[531,901]],"score":0.8844},{"poly":[[439,872],[483,877],[480,903],[437,898]],"score":0.8377},{"poly":[[1011,860],[1053,860],[1053,879],[1011,879]],"score":0.9484},{"poly":[[145,856],[319,856],[319,879],[145,879]],"score":0.7635},{"poly":[[916,856],[960,856],[960,883],[916,883]],"score":0.8164},{"poly":[[817,856],[866,856],[866,883],[817,883]],"score":0.7928},{"poly":[[722,856],[773,856],[773,881],[722,881]],"score":0.8893},{"poly":[[625,856],[677,856],[677,883],[625,883]],"score":0.807},{"poly":[[532,856],[577,856],[577,881],[532,881]],"score":0.8968},{"poly":[[439,856],[482,856],[482,881],[439,881]],"score":0.9432},{"poly":[[1011,837],[1054,837],[1054,863],[1011,863]],"score":0.9114},{"poly":[[916,837],[960,837],[960,863],[916,863]],"score":0.8693},{"poly":[[820,837],[865,837],[865,863],[820,863]],"score":0.8622},{"poly":[[723,837],[770,837],[770,861],[723,861]],"score":0.9044},{"poly":[[625,837],[677,837],[677,861],[625,861]],"score":0.9079},{"poly":[[531,837],[580,837],[580,863],[531,863]],"score":0.8389},{"poly":[[439,837],[482,837],[482,861],[439,861]],"score":0.9403},{"poly":[[145,835],[323,835],[323,863],[145,863]],"score":0.745},{"poly":[[146,808],[319,808],[319,830],[146,830]],"score":0.9876},{"poly":[[146,779],[281,779],[281,802],[146,802]],"score":0.8349},{"poly":[[1011,777],[1054,777],[1054,804],[1011,804]],"score":0.8675},{"poly":[[915,777],[960,777],[960,802],[915,802]],"score":0.8987},{"poly":[[725,777],[768,777],[768,804],[725,804]],"score":0.9063},{"poly":[[630,777],[674,777],[674,802],[630,802]],"score":0.9387},{"poly":[[439,777],[482,777],[482,804],[439,804]],"score":0.9522},{"poly":[[820,776],[865,776],[865,802],[820,802]],"score":0.7916},{"poly":[[534,776],[577,776],[577,802],[534,802]],"score":0.8752},{"poly":[[1011,757],[1054,757],[1054,782],[1011,782]],"score":0.962},{"poly":[[915,757],[960,757],[960,782],[915,782]],"score":0.9382},{"poly":[[820,757],[865,757],[865,782],[820,782]],"score":0.9508},{"poly":[[439,757],[482,757],[482,782],[439,782]],"score":0.9637},{"poly":[[145,756],[323,757],[322,782],[145,780]],"score":0.7795},{"poly":[[723,754],[772,754],[772,785],[723,785]],"score":0.7605},{"poly":[[629,756],[672,756],[672,782],[629,782]],"score":0.874},{"poly":[[532,756],[577,756],[577,782],[532,782]],"score":0.8689},{"poly":[[916,738],[960,738],[960,762],[916,762]],"score":0.9349},{"poly":[[820,738],[865,738],[865,762],[820,762]],"score":0.8267},{"poly":[[145,736],[314,738],[314,762],[145,761]],"score":0.7221},{"poly":[[1011,736],[1054,736],[1054,762],[1011,762]],"score":0.8301},{"poly":[[725,736],[768,736],[768,762],[725,762]],"score":0.8481},{"poly":[[629,734],[674,738],[672,765],[626,760]],"score":0.8164},{"poly":[[534,734],[578,738],[575,763],[531,758]],"score":0.8253},{"poly":[[439,736],[484,736],[484,766],[439,766]],"score":0.8257},{"poly":[[146,718],[304,718],[304,741],[146,741]],"score":0.8725},{"poly":[[1011,716],[1054,716],[1054,742],[1011,742]],"score":0.9206},{"poly":[[915,716],[960,716],[960,742],[915,742]],"score":0.8958},{"poly":[[820,716],[865,716],[865,742],[820,742]],"score":0.9177},{"poly":[[725,716],[770,716],[770,742],[725,742]],"score":0.8402},{"poly":[[629,716],[674,716],[674,742],[629,742]],"score":0.8819},{"poly":[[534,716],[577,716],[577,742],[534,742]],"score":0.8936},{"poly":[[439,716],[484,716],[484,746],[439,746]],"score":0.8375},{"poly":[[146,686],[269,686],[269,710],[146,710]],"score":0.8582},{"poly":[[146,658],[311,658],[311,681],[146,681]],"score":0.7943},{"poly":[[1011,655],[1056,655],[1056,681],[1011,681]],"score":0.8652},{"poly":[[915,655],[960,655],[960,681],[915,681]],"score":0.8681},{"poly":[[629,655],[674,655],[674,681],[629,681]],"score":0.8772},{"poly":[[534,655],[577,655],[577,681],[534,681]],"score":0.9036},{"poly":[[439,655],[482,655],[482,681],[439,681]],"score":0.7838},{"poly":[[820,653],[865,653],[865,683],[820,683]],"score":0.83},{"poly":[[725,653],[770,653],[770,683],[725,683]],"score":0.8642},{"poly":[[146,639],[391,639],[391,660],[146,660]],"score":0.972},{"poly":[[1013,635],[1054,635],[1054,662],[1013,662]],"score":0.9172},{"poly":[[915,635],[960,635],[960,662],[915,662]],"score":0.7874},{"poly":[[536,635],[577,635],[577,662],[536,662]],"score":0.867},{"poly":[[439,635],[484,635],[484,665],[439,665]],"score":0.8178},{"poly":[[632,634],[670,634],[670,662],[632,662]],"score":0.7971},{"poly":[[146,619],[391,619],[391,640],[146,640]],"score":0.987},{"poly":[[918,615],[958,615],[958,642],[918,642]],"score":0.8387},{"poly":[[725,615],[768,615],[768,642],[725,642]],"score":0.8743},{"poly":[[439,615],[482,615],[482,642],[439,642]],"score":0.8329},{"poly":[[822,610],[864,615],[861,643],[819,638]],"score":0.7704},{"poly":[[145,597],[372,596],[373,619],[145,620]],"score":0.8463},{"poly":[[1014,596],[1051,596],[1051,622],[1014,622]],"score":0.9008},{"poly":[[916,596],[960,596],[960,620],[916,620]],"score":0.8794},{"poly":[[725,596],[768,596],[768,622],[725,622]],"score":0.7959},{"poly":[[632,596],[674,596],[674,622],[632,622]],"score":0.8784},{"poly":[[536,596],[577,596],[577,622],[536,622]],"score":0.9167},{"poly":[[439,596],[482,596],[482,622],[439,622]],"score":0.8268},{"poly":[[1011,576],[1054,576],[1054,601],[1011,601]],"score":0.948},{"poly":[[725,576],[768,576],[768,601],[725,601]],"score":0.9647},{"poly":[[630,576],[670,576],[670,601],[630,601]],"score":0.9735},{"poly":[[534,576],[577,576],[577,601],[534,601]],"score":0.9339},{"poly":[[439,576],[482,576],[482,602],[439,602]],"score":0.8502},{"poly":[[146,576],[323,576],[323,599],[146,599]],"score":0.8464},{"poly":[[916,574],[960,574],[960,601],[916,601]],"score":0.8371},{"poly":[[145,554],[361,556],[361,579],[145,577]],"score":0.8109},{"poly":[[1011,554],[1056,554],[1056,581],[1011,581]],"score":0.7959},{"poly":[[918,554],[960,554],[960,581],[918,581]],"score":0.8206},{"poly":[[725,554],[768,554],[768,581],[725,581]],"score":0.8639},{"poly":[[632,554],[670,554],[670,581],[632,581]],"score":0.8408},{"poly":[[537,554],[575,554],[575,581],[537,581]],"score":0.8019},{"poly":[[439,554],[482,554],[482,581],[439,581]],"score":0.9131},{"poly":[[145,536],[409,536],[409,559],[145,559]],"score":0.7539},{"poly":[[915,535],[960,535],[960,561],[915,561]],"score":0.8497},{"poly":[[725,535],[768,535],[768,559],[725,559]],"score":0.9809},{"poly":[[629,535],[672,535],[672,561],[629,561]],"score":0.83},{"poly":[[534,535],[577,535],[577,561],[534,561]],"score":0.8665},{"poly":[[439,535],[484,535],[484,564],[439,564]],"score":0.8472},{"poly":[[143,516],[391,515],[391,538],[143,540]],"score":0.8221},{"poly":[[1033,513],[1041,521],[1033,530],[1024,521]],"score":0.7101},{"poly":[[928,515],[946,515],[946,526],[928,526]],"score":0.6237},{"poly":[[640,513],[662,513],[662,526],[640,526]],"score":0.7253},{"poly":[[817,505],[868,505],[868,530],[817,530]],"score":0.8998},{"poly":[[437,505],[482,505],[482,531],[437,531]],"score":0.8907},{"poly":[[720,503],[775,503],[775,531],[720,531]],"score":0.8145},{"poly":[[145,497],[304,497],[304,518],[145,518]],"score":0.9053},{"poly":[[143,477],[396,475],[396,498],[143,500]],"score":0.8347},{"poly":[[629,465],[674,465],[674,490],[629,490]],"score":0.9606},{"poly":[[439,465],[482,465],[482,492],[439,492]],"score":0.9732},{"poly":[[915,464],[960,464],[960,490],[915,490]],"score":0.8729},{"poly":[[817,464],[868,464],[868,490],[817,490]],"score":0.813},{"poly":[[720,464],[775,464],[775,492],[720,492]],"score":0.8421},{"poly":[[534,464],[579,464],[579,490],[534,490]],"score":0.8316},{"poly":[[146,457],[303,457],[303,478],[146,478]],"score":0.9918},{"poly":[[145,436],[394,436],[394,457],[145,457]],"score":0.8065},{"poly":[[1011,424],[1054,424],[1054,450],[1011,450]],"score":0.9195},{"poly":[[915,424],[960,424],[960,450],[915,450]],"score":0.898},{"poly":[[820,424],[865,424],[865,450],[820,450]],"score":0.8979},{"poly":[[723,424],[770,424],[770,450],[723,450]],"score":0.8664},{"poly":[[629,424],[674,424],[674,450],[629,450]],"score":0.9456},{"poly":[[534,424],[579,424],[579,450],[534,450]],"score":0.8878},{"poly":[[436,422],[484,422],[484,454],[436,454]],"score":0.8636},{"poly":[[145,416],[301,416],[301,439],[145,439]],"score":0.7995},{"poly":[[146,396],[304,396],[304,419],[146,419]],"score":0.7405},{"poly":[[1011,394],[1056,394],[1056,421],[1011,421]],"score":0.8431},{"poly":[[915,394],[960,394],[960,421],[915,421]],"score":0.879},{"poly":[[818,392],[866,397],[863,421],[816,417]],"score":0.8423},{"poly":[[725,394],[770,394],[770,421],[725,421]],"score":0.8361},{"poly":[[630,394],[674,394],[674,421],[630,421]],"score":0.8839},{"poly":[[534,394],[577,394],[577,421],[534,421]],"score":0.8747},{"poly":[[439,394],[482,394],[482,421],[439,421]],"score":0.9539},{"poly":[[146,376],[298,376],[298,399],[146,399]],"score":0.7295},{"poly":[[1011,375],[1054,375],[1054,401],[1011,401]],"score":0.8629},{"poly":[[916,375],[960,375],[960,401],[916,401]],"score":0.8637},{"poly":[[820,371],[866,375],[863,402],[817,397]],"score":0.8261},{"poly":[[725,375],[768,375],[768,401],[725,401]],"score":0.8902},{"poly":[[630,375],[674,375],[674,401],[630,401]],"score":0.8811},{"poly":[[534,375],[577,375],[577,401],[534,401]],"score":0.8144},{"poly":[[439,375],[482,375],[482,401],[439,401]],"score":0.8571},{"poly":[[146,356],[368,356],[368,380],[146,380]],"score":0.7867},{"poly":[[1009,355],[1054,355],[1054,380],[1009,380]],"score":0.9026},{"poly":[[915,355],[960,355],[960,380],[915,380]],"score":0.9053},{"poly":[[820,355],[865,355],[865,380],[820,380]],"score":0.9151},{"poly":[[725,355],[768,355],[768,380],[725,380]],"score":0.9539},{"poly":[[629,355],[674,355],[674,381],[629,381]],"score":0.8014},{"poly":[[534,355],[579,355],[579,380],[534,380]],"score":0.8893},{"poly":[[439,355],[482,355],[482,380],[439,380]],"score":0.9526},{"poly":[[146,327],[259,327],[259,350],[146,350]],"score":0.9137},{"poly":[[624,295],[677,295],[677,320],[624,320]],"score":0.9556},{"poly":[[424,277],[497,277],[497,300],[424,300]],"score":0.9214},{"poly":[[993,276],[1071,276],[1071,300],[993,300]],"score":0.8071},{"poly":[[808,276],[876,276],[876,300],[808,300]],"score":0.8476},{"poly":[[708,274],[787,278],[786,302],[706,298]],"score":0.807},{"poly":[[622,276],[680,276],[680,300],[622,300]],"score":0.8649},{"poly":[[516,276],[594,276],[594,300],[516,300]],"score":0.8313},{"poly":[[998,256],[1066,256],[1066,279],[998,279]],"score":0.9806},{"poly":[[900,256],[975,256],[975,279],[900,279]],"score":0.9694},{"poly":[[712,256],[782,256],[782,279],[712,279]],"score":0.944},{"poly":[[617,256],[687,256],[687,280],[617,280]],"score":0.8708},{"poly":[[507,254],[604,254],[604,282],[507,282]],"score":0.8269},{"poly":[[422,256],[517,256],[517,279],[422,279]],"score":0.9296},{"poly":[[146,256],[244,256],[244,279],[146,279]],"score":0.8726},{"poly":[[809,252],[877,256],[875,283],[808,278]],"score":0.8171},{"poly":[[502,228],[610,228],[610,251],[502,251]],"score":0.8406},{"poly":[[836,222],[935,226],[934,254],[834,251]],"score":0.8146},{"poly":[[140,198],[742,198],[742,221],[140,221]],"score":0.7659},{"poly":[[140,175],[1083,175],[1083,198],[140,198]],"score":0.824},{"poly":[[141,153],[1083,153],[1083,177],[141,177]],"score":0.8202},{"poly":[[917,66],[1083,69],[1082,93],[916,89]],"score":0.783},{"poly":[[559,64],[665,64],[665,92],[559,92]],"score":0.8543}],"page_no":15,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7763,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":919,"x1":1079,"y0":68,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1506},"conf":0.7004,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":624,"y0":1480,"y1":1503},"font_size":0.0,"text":"17"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":1088,"y0":142,"y1":218},"conf":0.9396,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":145,"y1":168},"font_size":-7.056e-27,"text":"Agentic Tool UseOn multi-turn tool-use benchmarks, Kimi-K2-Instruct sets a new standard. It achieves 66.1 Pass@1"},{"bbox":{"x0":140,"x1":1081,"y0":167,"y1":191},"font_size":-7.056e-27,"text":"on $\\tau^{2}$ Bench and 76.5 on ACEBench, substantially outperforming all baselines. These results affrm its strength ini"},{"bbox":{"x0":140,"x1":732,"y0":188,"y1":215},"font_size":-7.056e-27,"text":"grounded, controlled, and agent-driven tool orchestration across domains."}],"source":"layout det","text":"Agentic Tool UseOn multi-turn tool-use benchmarks, Kimi-K2-Instruct sets a new standard. It achieves 66.1 Pass@1 on $\\tau^{2}$ Bench and 76.5 on ACEBench, substantially outperforming all baselines. These results affrm its strength ini grounded, controlled, and agent-driven tool orchestration across domains."},{"bbox":{"x0":136,"x1":1089,"y0":236,"y1":378},"conf":0.9658,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":241,"y1":262},"font_size":-7.056e-27,"text":"General CapabilitiesKimi-K2-Instruct exhibits strong, balanced performance across general knowledge, math,"},{"bbox":{"x0":141,"x1":1077,"y0":262,"y1":285},"font_size":-7.056e-27,"text":"instruction following, and long-context tasks. It surpasses open-source peers on SimpleQA $(31.0\\%),$  MMLU $(89.5\\%]$"},{"bbox":{"x0":141,"x1":1076,"y0":284,"y1":305},"font_size":-7.056e-27,"text":"and MMLU-Redux (92.7%), and leads all models on instruction benchmarks (IFEval: $89.8\\%,$  Multi-Challenge: $54.1\\%)$"},{"bbox":{"x0":141,"x1":1081,"y0":305,"y1":330},"font_size":-7.056e-27,"text":"In math and STEM, it achieves top-tier scores (AIME 2024: 69.6%, GPQA-Diamond: $75.1\\%)$ , and remains competitive"},{"bbox":{"x0":141,"x1":1081,"y0":327,"y1":350},"font_size":-7.056e-27,"text":"on long-context factuality and retrieval (DROP: 93.5%, MRCR: 55.0%). These results position Kimi-K2-Instruct as a"},{"bbox":{"x0":140,"x1":788,"y0":348,"y1":373},"font_size":-7.056e-27,"text":"well-rounded and capable generalist across both short- and long-context settings."}],"source":"layout det","text":"General CapabilitiesKimi-K2-Instruct exhibits strong, balanced performance across general knowledge, math, instruction following, and long-context tasks. It surpasses open-source peers on SimpleQA $(31.0\\%),$  MMLU $(89.5\\%]$  and MMLU-Redux (92.7%), and leads all models on instruction benchmarks (IFEval: $89.8\\%,$  Multi-Challenge: $54.1\\%)$ In math and STEM, it achieves top-tier scores (AIME 2024: 69.6%, GPQA-Diamond: $75.1\\%)$ , and remains competitive on long-context factuality and retrieval (DROP: 93.5%, MRCR: 55.0%). These results position Kimi-K2-Instruct as a well-rounded and capable generalist across both short- and long-context settings."},{"bbox":{"x0":137,"x1":1089,"y0":396,"y1":474},"conf":0.943,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":401,"y1":422},"font_size":-7.056e-27,"text":"Open-Ended EvaluationOn the LMSYS Arena leaderboard (July 17, 2025), Kimi-K2-Instruct ranks as the top-1"},{"bbox":{"x0":140,"x1":1083,"y0":421,"y1":446},"font_size":-7.056e-27,"text":"open-source model and 5th overall based on over 3,000 user votes. This real-world preference signal—across diverse,"},{"bbox":{"x0":140,"x1":1003,"y0":442,"y1":467},"font_size":-7.056e-27,"text":"blind prompts—underscores Kimi-K2’s strengths in generating high-quality responses on open-ended tasks."}],"source":"layout det","text":"Open-Ended EvaluationOn the LMSYS Arena leaderboard (July 17, 2025), Kimi-K2-Instruct ranks as the top-1 open-source model and 5th overall based on over 3,000 user votes. This real-world preference signal—across diverse,blind prompts—underscores Kimi-K2’s strengths in generating high-quality responses on open-ended tasks."},{"bbox":{"x0":136,"x1":406,"y0":494,"y1":524},"conf":0.8856,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":399,"y0":497,"y1":518},"font_size":-7.056e-27,"text":"4.2Pre-training Evaluations"}],"source":"layout det","text":"4.2Pre-training Evaluations"},{"bbox":{"x0":137,"x1":375,"y0":536,"y1":566},"conf":0.8791,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":371,"y0":540,"y1":561},"font_size":-7.056e-27,"text":"4.2.1Evaluation Settings"}],"source":"layout det","text":"4.2.1Evaluation Settings"},{"bbox":{"x0":137,"x1":1090,"y0":575,"y1":716},"conf":0.9701,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":576,"y1":601},"font_size":-7.056e-27,"text":"BenchmarksWe evaluate Kimi-K2-Base across diverse capability areas. For general capabilities, we assess on"},{"bbox":{"x0":141,"x1":1083,"y0":599,"y1":622},"font_size":-7.056e-27,"text":"MMLU [23], MMLU-Pro [76], MMLU-Redux [17], BBH [67], TriviaQA [34], SuperGPQA [13], SimpleQA [78], Hel-"},{"bbox":{"x0":140,"x1":1081,"y0":620,"y1":644},"font_size":-7.056e-27,"text":"laSwag [88], AGIEval [89], GPQA-Diamond [61], ARC-Challenge [8], and WinoGrande [62]. For coding capabilities,"},{"bbox":{"x0":141,"x1":1081,"y0":644,"y1":667},"font_size":-7.056e-27,"text":"we employ EvalPlus [45] (averaging HumanEval [7], MBPP [1], HumanEval+, and MBPP+), LiveCodeBench v6 [31],"},{"bbox":{"x0":141,"x1":1081,"y0":667,"y1":688},"font_size":-7.056e-27,"text":"and CRUXEval [18]. For mathematical reasoning, we utilize GSM8K [9], GSM8K-Platinum [74], MATH [24], and"},{"bbox":{"x0":141,"x1":1066,"y0":688,"y1":711},"font_size":-7.056e-27,"text":"CMATH [79]. For Chinese language capabilities, we evaluate on C-Eval [29], CMMLU [40], and CSimpleQA [22]."}],"source":"layout det","text":"BenchmarksWe evaluate Kimi-K2-Base across diverse capability areas. For general capabilities, we assess on MMLU [23], MMLU-Pro [76], MMLU-Redux [17], BBH [67], TriviaQA [34], SuperGPQA [13], SimpleQA [78], HellaSwag [88], AGIEval [89], GPQA-Diamond [61], ARC-Challenge [8], and WinoGrande [62]. For coding capabilities,we employ EvalPlus [45] (averaging HumanEval [7], MBPP [1], HumanEval+, and MBPP+), LiveCodeBench v6 [31],and CRUXEval [18]. For mathematical reasoning, we utilize GSM8K [9], GSM8K-Platinum [74], MATH [24], and CMATH [79]. For Chinese language capabilities, we evaluate on C-Eval [29], CMMLU [40], and CSimpleQA [22]."},{"bbox":{"x0":136,"x1":1089,"y0":733,"y1":831},"conf":0.9551,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":738,"y1":759},"font_size":-7.056e-27,"text":"BaselinesWe benchmark against leading open-source foundation models: DeepSeek-V3-Base [10], Qwen2.5-72B-"},{"bbox":{"x0":143,"x1":1079,"y0":761,"y1":782},"font_size":-7.056e-27,"text":"Base [59] (Note that Qwen3-235B-A22B-Base is not open-sourced, and the largest open-sourced base model in the"},{"bbox":{"x0":143,"x1":1079,"y0":780,"y1":804},"font_size":-7.056e-27,"text":"Qwen series is Qwen2.5-72B-Base), and Llama 4-Maverick [70] (Llama 4-Behemoth is also not open-sourced). All"},{"bbox":{"x0":141,"x1":768,"y0":805,"y1":827},"font_size":-7.056e-27,"text":"models are evaluated under identical confgurations to ensure fair comparison.i"}],"source":"layout det","text":"BaselinesWe benchmark against leading open-source foundation models: DeepSeek-V3-Base [10], Qwen2.5-72BBase [59] (Note that Qwen3-235B-A22B-Base is not open-sourced, and the largest open-sourced base model in the Qwen series is Qwen2.5-72B-Base), and Llama 4-Maverick [70] (Llama 4-Behemoth is also not open-sourced). All models are evaluated under identical confgurations to ensure fair comparison.i"},{"bbox":{"x0":136,"x1":1088,"y0":849,"y1":989},"conf":0.9708,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":853,"y1":875},"font_size":-7.056e-27,"text":"Evaluation ConfgurationsWe employ perplexity-based evaluation for MMLU, MMLU-Redux, GPQA-Diamond,i"},{"bbox":{"x0":141,"x1":1081,"y0":876,"y1":898},"font_size":-7.056e-27,"text":"HellaSwag, ARC-Challenge, C-Eval, and CMMLU. Generation-based evaluation is used for MMLU-Pro, SuperGPQA,"},{"bbox":{"x0":143,"x1":1081,"y0":898,"y1":919},"font_size":-7.056e-27,"text":"TriviaQA, BBH, CSimpleQA, MATH, CMATH, GSM8K, GSM8K-Platinum, CRUXEval, LiveCodeBench, and"},{"bbox":{"x0":141,"x1":1081,"y0":919,"y1":940},"font_size":-7.056e-27,"text":"EvalPlus. To mitigate the high variance inherent to GPQA-Diamond, we report the mean score across eight independent"},{"bbox":{"x0":140,"x1":1081,"y0":940,"y1":965},"font_size":-7.056e-27,"text":"runs. All evaluations are conducted using our internal framework derived from LM-Harness-Evaluation [4], ensuring"},{"bbox":{"x0":141,"x1":441,"y0":964,"y1":985},"font_size":-7.056e-27,"text":"consistent settings across all models."}],"source":"layout det","text":"Evaluation ConfgurationsWe employ perplexity-based evaluation for MMLU, MMLU-Redux, GPQA-Diamond,i HellaSwag, ARC-Challenge, C-Eval, and CMMLU. Generation-based evaluation is used for MMLU-Pro, SuperGPQA,TriviaQA, BBH, CSimpleQA, MATH, CMATH, GSM8K, GSM8K-Platinum, CRUXEval, LiveCodeBench, and EvalPlus. To mitigate the high variance inherent to GPQA-Diamond, we report the mean score across eight independent runs. All evaluations are conducted using our internal framework derived from LM-Harness-Evaluation [4], ensuring consistent settings across all models."},{"bbox":{"x0":137,"x1":370,"y0":1010,"y1":1038},"conf":0.9006,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":364,"y0":1011,"y1":1033},"font_size":-7.056e-27,"text":"4.2.2Evaluation Results"}],"source":"layout det","text":"4.2.2Evaluation Results"},{"bbox":{"x0":136,"x1":1088,"y0":1049,"y1":1125},"conf":0.9483,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1049,"y1":1074},"font_size":-7.056e-27,"text":"Table 4 presents a comprehensive comparison of Kimi-K2-Base against leading open-source foundation models across"},{"bbox":{"x0":141,"x1":1079,"y0":1076,"y1":1097},"font_size":-7.056e-27,"text":"diverse evaluation benchmarks. The results demonstrate that Kimi-K2-Base achieves state-of-the-art performance"},{"bbox":{"x0":138,"x1":1046,"y0":1096,"y1":1120},"font_size":-7.056e-27,"text":"across the majority of evaluated tasks, establishing it as a leading foundation model in the open-source landscape."}],"source":"layout det","text":"Table 4 presents a comprehensive comparison of Kimi-K2-Base against leading open-source foundation models across diverse evaluation benchmarks. The results demonstrate that Kimi-K2-Base achieves state-of-the-art performance across the majority of evaluated tasks, establishing it as a leading foundation model in the open-source landscape."},{"bbox":{"x0":136,"x1":1091,"y0":1141,"y1":1219},"conf":0.9508,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1147,"y1":1168},"font_size":-7.056e-27,"text":"General Language UnderstandingKimi-K2-Base achieves state-of-the-art performance on 10 out of 12 English"},{"bbox":{"x0":143,"x1":1083,"y0":1168,"y1":1191},"font_size":-7.056e-27,"text":"language benchmarks. Notable results include MMLU (87.79%), MMLU-Pro (69.17%), MMLU-Redux (90.17%),"},{"bbox":{"x0":141,"x1":868,"y0":1189,"y1":1213},"font_size":-7.056e-27,"text":"SuperGPQA $(44.67\\%)$ , and SimpleQA $(35.25\\%$ , signifcantly outperforming all baselines.i"}],"source":"layout det","text":"General Language UnderstandingKimi-K2-Base achieves state-of-the-art performance on 10 out of 12 English language benchmarks. Notable results include MMLU (87.79%), MMLU-Pro (69.17%), MMLU-Redux (90.17%),SuperGPQA $(44.67\\%)$ , and SimpleQA $(35.25\\%$ , signifcantly outperforming all baselines.i"},{"bbox":{"x0":136,"x1":1089,"y0":1236,"y1":1335},"conf":0.9511,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1241,"y1":1262},"font_size":-7.056e-27,"text":"Coding CapabilitiesOn coding benchmarks, Kimi-K2-Base sets new standards with leading performance across all"},{"bbox":{"x0":140,"x1":1081,"y0":1261,"y1":1284},"font_size":-7.056e-27,"text":"metrics. It achieves $74.00\\%$  on CRUXEval-I-cot, $83.50\\%$ on CRUXEval-O-cot, $26.29\\%$ on LiveCodeBench v6, and"},{"bbox":{"x0":142,"x1":1081,"y0":1284,"y1":1307},"font_size":-7.056e-27,"text":"$80.33\\%$ on EvalPlus, demonstrating superior code generation and comprehension abilities, particularly in scenarios"},{"bbox":{"x0":140,"x1":409,"y0":1308,"y1":1330},"font_size":-7.056e-27,"text":"requiring step-by-step reasoning."}],"source":"layout det","text":"Coding CapabilitiesOn coding benchmarks, Kimi-K2-Base sets new standards with leading performance across all metrics. It achieves $74.00\\%$  on CRUXEval-I-cot, $83.50\\%$ on CRUXEval-O-cot, $26.29\\%$ on LiveCodeBench v6, and $80.33\\%$ on EvalPlus, demonstrating superior code generation and comprehension abilities, particularly in scenarios requiring step-by-step reasoning."},{"bbox":{"x0":136,"x1":1089,"y0":1352,"y1":1451},"conf":0.9453,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1358,"y1":1379},"font_size":-7.056e-27,"text":"Mathematical ReasoningKimi-K2-Base exhibits exceptional mathematical capabilities, leading on three out of"},{"bbox":{"x0":140,"x1":1081,"y0":1376,"y1":1401},"font_size":-7.056e-27,"text":"four benchmarks: MATH $(70.22\\%)$  GSM8K (92.12%), and GSM8K-Platinum $(\\hat{94}.21\\%)$  It maintains competitive"},{"bbox":{"x0":140,"x1":1081,"y0":1399,"y1":1424},"font_size":-7.056e-27,"text":"performance on CMATH $(90.26\\%),$  narrowly behind DeepSeek-V3-Base $(90.53\\%)$ . These results highlight the model’s"},{"bbox":{"x0":141,"x1":762,"y0":1422,"y1":1445},"font_size":-7.056e-27,"text":"robust mathematical problem-solving abilities across varying diffculty levels.i"}],"source":"layout det","text":"Mathematical ReasoningKimi-K2-Base exhibits exceptional mathematical capabilities, leading on three out of four benchmarks: MATH $(70.22\\%)$  GSM8K (92.12%), and GSM8K-Platinum $(\\hat{94}.21\\%)$  It maintains competitive performance on CMATH $(90.26\\%),$  narrowly behind DeepSeek-V3-Base $(90.53\\%)$ . These results highlight the model’s robust mathematical problem-solving abilities across varying diffculty levels.i"}],"formula_dets":[{"bbox":{"x0":142,"x1":207,"y0":1284,"y1":1304},"conf":0.8084,"label":"print_embedding","label_id":0},{"bbox":{"x0":168,"x1":190,"y0":170,"y1":187},"conf":0.7986,"label":"print_embedding","label_id":0},{"bbox":{"x0":304,"x1":368,"y0":1262,"y1":1282},"conf":0.7958,"label":"print_embedding","label_id":0},{"bbox":{"x0":790,"x1":855,"y0":1261,"y1":1283},"conf":0.7224,"label":"print_embedding","label_id":0},{"bbox":{"x0":345,"x1":423,"y0":1400,"y1":1422},"conf":0.7025,"label":"print_embedding","label_id":0},{"bbox":{"x0":818,"x1":876,"y0":284,"y1":304},"conf":0.7007,"label":"print_embedding","label_id":0},{"bbox":{"x0":874,"x1":943,"y0":262,"y1":284},"conf":0.6751,"label":"print_embedding","label_id":0},{"bbox":{"x0":250,"x1":321,"y0":1189,"y1":1212},"conf":0.6623,"label":"print_embedding","label_id":0},{"bbox":{"x0":720,"x1":794,"y0":1400,"y1":1422},"conf":0.6184,"label":"print_embedding","label_id":0},{"bbox":{"x0":819,"x1":879,"y0":307,"y1":327},"conf":0.6063,"label":"print_embedding","label_id":0},{"bbox":{"x0":1016,"x1":1077,"y0":263,"y1":283},"conf":0.5783,"label":"print_embedding","label_id":0},{"bbox":{"x0":543,"x1":608,"y0":1261,"y1":1283},"conf":0.5655,"label":"print_embedding","label_id":0},{"bbox":{"x0":458,"x1":527,"y0":1189,"y1":1212},"conf":0.5613,"label":"print_embedding","label_id":0},{"bbox":{"x0":356,"x1":435,"y0":1378,"y1":1399},"conf":0.5481,"label":"print_embedding","label_id":0},{"bbox":{"x0":792,"x1":872,"y0":1377,"y1":1400},"conf":0.5432,"label":"print_embedding","label_id":0},{"bbox":{"x0":1019,"x1":1076,"y0":285,"y1":305},"conf":0.5195,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1088,"y0":849,"y1":989},"conf":0.9708,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1090,"y0":575,"y1":716},"conf":0.9701,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":236,"y1":378},"conf":0.9658,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":733,"y1":831},"conf":0.9551,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":1236,"y1":1335},"conf":0.9511,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1091,"y0":1141,"y1":1219},"conf":0.9508,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":1049,"y1":1125},"conf":0.9483,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1089,"y0":1352,"y1":1451},"conf":0.9453,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":396,"y1":474},"conf":0.943,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":142,"y1":218},"conf":0.9396,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":370,"y0":1010,"y1":1038},"conf":0.9006,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":406,"y0":494,"y1":524},"conf":0.8856,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":375,"y0":536,"y1":566},"conf":0.8791,"label":"Title","label_id":0},{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":93},"conf":0.7763,"label":"Abandon","label_id":2},{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1506},"conf":0.7004,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1480],[624,1480],[624,1503],[599,1503]],"score":0.8649},{"poly":[[141,1422],[762,1422],[762,1445],[141,1445]],"score":0.723},{"poly":[[140,1401],[1081,1399],[1081,1422],[140,1424]],"score":0.7275},{"poly":[[140,1376],[1081,1378],[1081,1401],[140,1399]],"score":0.7571},{"poly":[[141,1358],[1081,1358],[1081,1379],[141,1379]],"score":0.8356},{"poly":[[140,1308],[409,1308],[409,1330],[140,1330]],"score":0.8238},{"poly":[[141,1285],[1081,1285],[1081,1307],[141,1307]],"score":0.8608},{"poly":[[140,1262],[1081,1262],[1081,1284],[140,1284]],"score":0.7707},{"poly":[[141,1241],[1081,1241],[1081,1262],[141,1262]],"score":0.8298},{"poly":[[141,1191],[868,1191],[868,1213],[141,1213]],"score":0.8248},{"poly":[[143,1168],[1083,1168],[1083,1191],[143,1191]],"score":0.7206},{"poly":[[141,1147],[1081,1147],[1081,1168],[141,1168]],"score":0.8155},{"poly":[[138,1096],[1046,1097],[1046,1120],[138,1119]],"score":0.6977},{"poly":[[141,1076],[1079,1076],[1079,1097],[141,1097]],"score":0.8179},{"poly":[[140,1049],[1081,1051],[1081,1074],[140,1072]],"score":0.7496},{"poly":[[140,1011],[364,1011],[364,1033],[140,1033]],"score":0.716},{"poly":[[141,964],[441,964],[441,985],[141,985]],"score":0.7801},{"poly":[[140,940],[1081,942],[1081,965],[140,964]],"score":0.7547},{"poly":[[141,919],[1081,919],[1081,940],[141,940]],"score":0.8128},{"poly":[[143,898],[1081,898],[1081,919],[143,919]],"score":0.7774},{"poly":[[141,876],[1081,876],[1081,898],[141,898]],"score":0.8264},{"poly":[[141,853],[1081,853],[1081,874],[141,874]],"score":0.8377},{"poly":[[141,805],[768,805],[768,827],[141,827]],"score":0.8298},{"poly":[[143,780],[1079,780],[1079,804],[143,804]],"score":0.6867},{"poly":[[143,761],[1079,761],[1079,782],[143,782]],"score":0.806},{"poly":[[141,738],[1079,738],[1079,759],[141,759]],"score":0.8165},{"poly":[[141,688],[1066,688],[1066,711],[141,711]],"score":0.7155},{"poly":[[141,667],[1081,667],[1081,688],[141,688]],"score":0.8265},{"poly":[[141,644],[1081,644],[1081,667],[141,667]],"score":0.7236},{"poly":[[140,620],[1081,620],[1081,644],[140,644]],"score":0.7251},{"poly":[[141,599],[1083,599],[1083,622],[141,622]],"score":0.7246},{"poly":[[140,576],[1079,578],[1079,601],[140,599]],"score":0.7486},{"poly":[[141,540],[371,540],[371,561],[141,561]],"score":0.8661},{"poly":[[140,497],[399,497],[399,518],[140,518]],"score":0.8358},{"poly":[[140,442],[1003,444],[1003,467],[140,465]],"score":0.7732},{"poly":[[140,421],[1083,422],[1083,446],[140,444]],"score":0.7254},{"poly":[[143,401],[1081,401],[1081,422],[143,422]],"score":0.8272},{"poly":[[140,348],[788,350],[788,373],[140,371]],"score":0.7287},{"poly":[[141,327],[1081,327],[1081,350],[141,350]],"score":0.6996},{"poly":[[141,305],[1081,307],[1081,330],[141,328]],"score":0.7383},{"poly":[[141,284],[1083,284],[1083,305],[141,305]],"score":0.8097},{"poly":[[141,262],[1083,262],[1083,285],[141,285]],"score":0.6918},{"poly":[[143,241],[1081,241],[1081,262],[143,262]],"score":0.8132},{"poly":[[140,191],[732,188],[732,211],[140,215]],"score":0.7349},{"poly":[[140,167],[1081,168],[1081,191],[140,190]],"score":0.7333},{"poly":[[143,145],[1081,145],[1081,168],[143,168]],"score":0.7124},{"poly":[[920,68],[1079,71],[1079,93],[919,89]],"score":0.7732},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8697}],"page_no":16,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":139,"x1":1086,"y0":64,"y1":102},"conf":0.3634,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":66,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":665,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":152,"x1":1029,"y0":1417,"y1":1508},"conf":0.3496,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"18"},{"bbox":{"x0":165,"x1":536,"y0":1419,"y1":1445},"font_size":0.0,"text":"5https://github.com/promptfoo/promptfoo"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":136,"x1":1090,"y0":142,"y1":240},"conf":0.9592,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1086,"y0":140,"y1":170},"font_size":3.162e-29,"text":"Chinese Language UnderstandingThe model demonstrates superior multilingual capabilities, achieving state-of-the-"},{"bbox":{"x0":140,"x1":1083,"y0":167,"y1":190},"font_size":3.162e-29,"text":"art results across all Chinese language benchmarks: C-Eval $(92.50\\%)$ , CMMLU $(90.90\\%$ , and CSimpleQA (77.57%)."},{"bbox":{"x0":136,"x1":1084,"y0":185,"y1":216},"font_size":3.162e-29,"text":"These results establish Kimi-K2-Base as a leading model for Chinese language understanding while maintaining strong"},{"bbox":{"x0":138,"x1":434,"y0":210,"y1":233},"font_size":3.162e-29,"text":"performance across other languages."}],"source":"layout det","text":"Chinese Language UnderstandingThe model demonstrates superior multilingual capabilities, achieving state-of-theart results across all Chinese language benchmarks: C-Eval $(92.50\\%)$ , CMMLU $(90.90\\%$ , and CSimpleQA (77.57%).These results establish Kimi-K2-Base as a leading model for Chinese language understanding while maintaining strong performance across other languages."},{"bbox":{"x0":167,"x1":1051,"y0":270,"y1":301},"conf":0.213,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":173,"x1":1046,"y0":274,"y1":297},"font_size":3.162e-29,"text":"Table 4: Performance comparison of Kimi-K2-Base against leading open-source models across diverse tasks."}],"source":"layout det","text":"Table 4: Performance comparison of Kimi-K2-Base against leading open-source models across diverse tasks."},{"bbox":{"x0":179,"x1":1071,"y0":302,"y1":332},"conf":0.5247,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":218,"x1":1066,"y0":302,"y1":329},"font_size":3.162e-29,"text":"Benchmark (Metric)#Shots Kimi-K2-Base DeepSeek-V3-Base Llama4-Maverick-Base Qwen2.5-72B-Base"}],"source":"layout det","text":"Benchmark (Metric)#Shots Kimi-K2-Base DeepSeek-V3-Base Llama4-Maverick-Base Qwen2.5-72B-Base"},{"bbox":{"x0":149,"x1":1077,"y0":329,"y1":915},"conf":0.9811,"font_size":0.0,"label":"Table","label_id":5,"lines":[{"bbox":{"x0":220,"x1":316,"y0":339,"y1":363},"font_size":0.0,"text":"Architecture"},{"bbox":{"x0":420,"x1":430,"y0":347,"y1":359},"font_size":0.0,"text":"-"},{"bbox":{"x0":493,"x1":535,"y0":341,"y1":361},"font_size":0.0,"text":"MoE"},{"bbox":{"x0":629,"x1":670,"y0":341,"y1":360},"font_size":0.0,"text":"MoE"},{"bbox":{"x0":798,"x1":839,"y0":341,"y1":361},"font_size":0.0,"text":"MoE"},{"bbox":{"x0":964,"x1":1014,"y0":342,"y1":361},"font_size":0.0,"text":"Dense"},{"bbox":{"x0":218,"x1":366,"y0":360,"y1":382},"font_size":0.0,"text":"# Activated Params"},{"bbox":{"x0":420,"x1":430,"y0":368,"y1":379},"font_size":0.0,"text":"-"},{"bbox":{"x0":494,"x1":532,"y0":362,"y1":381},"font_size":0.0,"text":"32B"},{"bbox":{"x0":630,"x1":668,"y0":362,"y1":380},"font_size":0.0,"text":"37B"},{"bbox":{"x0":800,"x1":837,"y0":362,"y1":381},"font_size":0.0,"text":"17B"},{"bbox":{"x0":970,"x1":1007,"y0":361,"y1":380},"font_size":0.0,"text":"72B"},{"bbox":{"x0":219,"x1":333,"y0":381,"y1":401},"font_size":0.0,"text":"# Total Params"},{"bbox":{"x0":419,"x1":431,"y0":386,"y1":400},"font_size":0.0,"text":"-"},{"bbox":{"x0":489,"x1":540,"y0":382,"y1":400},"font_size":0.0,"text":"1043B"},{"bbox":{"x0":628,"x1":671,"y0":382,"y1":400},"font_size":0.0,"text":"671B"},{"bbox":{"x0":797,"x1":840,"y0":382,"y1":400},"font_size":0.0,"text":"400B"},{"bbox":{"x0":971,"x1":1007,"y0":382,"y1":401},"font_size":0.0,"text":"72B"},{"bbox":{"x0":220,"x1":282,"y0":410,"y1":432},"font_size":0.0,"text":"MMLU"},{"bbox":{"x0":394,"x1":454,"y0":410,"y1":429},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":410,"y1":430},"font_size":0.0,"text":"87.79"},{"bbox":{"x0":627,"x1":673,"y0":411,"y1":430},"font_size":0.0,"text":"87.10"},{"bbox":{"x0":796,"x1":841,"y0":411,"y1":430},"font_size":0.0,"text":"84.87"},{"bbox":{"x0":967,"x1":1011,"y0":411,"y1":430},"font_size":0.0,"text":"86.08"},{"bbox":{"x0":220,"x1":311,"y0":432,"y1":452},"font_size":0.0,"text":"MMLU-pro"},{"bbox":{"x0":394,"x1":455,"y0":428,"y1":452},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":491,"x1":537,"y0":431,"y1":450},"font_size":0.0,"text":"69.17"},{"bbox":{"x0":627,"x1":673,"y0":432,"y1":450},"font_size":0.0,"text":"60.59"},{"bbox":{"x0":797,"x1":841,"y0":432,"y1":450},"font_size":0.0,"text":"63.47"},{"bbox":{"x0":966,"x1":1012,"y0":432,"y1":450},"font_size":0.0,"text":"62.80"},{"bbox":{"x0":220,"x1":328,"y0":451,"y1":471},"font_size":0.0,"text":"MMLU-redux"},{"bbox":{"x0":396,"x1":453,"y0":449,"y1":472},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":490,"x1":537,"y0":450,"y1":472},"font_size":0.0,"text":"90.17"},{"bbox":{"x0":626,"x1":672,"y0":450,"y1":472},"font_size":0.0,"text":"89.53"},{"bbox":{"x0":796,"x1":842,"y0":451,"y1":470},"font_size":0.0,"text":"88.18"},{"bbox":{"x0":966,"x1":1011,"y0":452,"y1":470},"font_size":0.0,"text":"87.77"},{"bbox":{"x0":222,"x1":315,"y0":472,"y1":491},"font_size":0.0,"text":"SuperGPQA"},{"bbox":{"x0":395,"x1":454,"y0":468,"y1":492},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":471,"y1":490},"font_size":0.0,"text":"44.67"},{"bbox":{"x0":627,"x1":672,"y0":471,"y1":490},"font_size":0.0,"text":"39.20"},{"bbox":{"x0":797,"x1":842,"y0":471,"y1":490},"font_size":0.0,"text":"38.84"},{"bbox":{"x0":966,"x1":1011,"y0":471,"y1":490},"font_size":0.0,"text":"34.23"},{"bbox":{"x0":221,"x1":394,"y0":492,"y1":512},"font_size":0.0,"text":"GPQA-Diamond(avg@8)"},{"bbox":{"x0":394,"x1":453,"y0":491,"y1":511},"font_size":0.0,"text":" 5-shots"},{"bbox":{"x0":491,"x1":536,"y0":492,"y1":510},"font_size":0.0,"text":"48.11"},{"bbox":{"x0":627,"x1":671,"y0":492,"y1":510},"font_size":0.0,"text":"50.51"},{"bbox":{"x0":796,"x1":841,"y0":492,"y1":510},"font_size":0.0,"text":"49.43"},{"bbox":{"x0":966,"x1":1011,"y0":492,"y1":510},"font_size":0.0,"text":"40.78"},{"bbox":{"x0":221,"x1":302,"y0":511,"y1":532},"font_size":0.0,"text":"SimpleQA"},{"bbox":{"x0":395,"x1":454,"y0":509,"y1":533},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":511,"y1":530},"font_size":0.0,"text":"35.25"},{"bbox":{"x0":627,"x1":672,"y0":511,"y1":530},"font_size":0.0,"text":"26.49"},{"bbox":{"x0":797,"x1":842,"y0":512,"y1":530},"font_size":0.0,"text":"23.74"},{"bbox":{"x0":966,"x1":1011,"y0":510,"y1":532},"font_size":0.0,"text":"10.31"},{"bbox":{"x0":156,"x1":295,"y0":529,"y1":553},"font_size":0.0,"text":"EnglishTriviaQA"},{"bbox":{"x0":396,"x1":453,"y0":529,"y1":552},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":531,"y1":551},"font_size":0.0,"text":"85.09"},{"bbox":{"x0":627,"x1":671,"y0":531,"y1":551},"font_size":0.0,"text":"84.11"},{"bbox":{"x0":797,"x1":841,"y0":531,"y1":551},"font_size":0.0,"text":"79.25"},{"bbox":{"x0":967,"x1":1011,"y0":531,"y1":551},"font_size":0.0,"text":"76.03"},{"bbox":{"x0":221,"x1":263,"y0":552,"y1":571},"font_size":0.0,"text":"BBH"},{"bbox":{"x0":395,"x1":454,"y0":548,"y1":572},"font_size":0.0,"text":"3-shots"},{"bbox":{"x0":492,"x1":536,"y0":552,"y1":570},"font_size":0.0,"text":"88.71"},{"bbox":{"x0":626,"x1":672,"y0":549,"y1":571},"font_size":0.0,"text":"88.37"},{"bbox":{"x0":796,"x1":842,"y0":552,"y1":570},"font_size":0.0,"text":"87.10"},{"bbox":{"x0":966,"x1":1011,"y0":552,"y1":570},"font_size":0.0,"text":"84.09"},{"bbox":{"x0":219,"x1":305,"y0":568,"y1":595},"font_size":0.0,"text":"HellaSwag"},{"bbox":{"x0":396,"x1":453,"y0":570,"y1":593},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":572,"y1":590},"font_size":0.0,"text":"94.60"},{"bbox":{"x0":626,"x1":673,"y0":570,"y1":592},"font_size":0.0,"text":"89.44"},{"bbox":{"x0":796,"x1":841,"y0":572,"y1":590},"font_size":0.0,"text":"86.02"},{"bbox":{"x0":966,"x1":1011,"y0":571,"y1":590},"font_size":0.0,"text":"95.27"},{"bbox":{"x0":221,"x1":290,"y0":592,"y1":611},"font_size":0.0,"text":"AGIEval"},{"bbox":{"x0":421,"x1":430,"y0":599,"y1":607},"font_size":0.0,"text":"-"},{"bbox":{"x0":492,"x1":537,"y0":591,"y1":610},"font_size":0.0,"text":"84.23"},{"bbox":{"x0":627,"x1":672,"y0":591,"y1":610},"font_size":0.0,"text":"81.57"},{"bbox":{"x0":797,"x1":841,"y0":591,"y1":610},"font_size":0.0,"text":"67.55"},{"bbox":{"x0":966,"x1":1011,"y0":591,"y1":610},"font_size":0.0,"text":"76.87"},{"bbox":{"x0":219,"x1":341,"y0":609,"y1":633},"font_size":0.0,"text":"ARC-Challenge"},{"bbox":{"x0":400,"x1":451,"y0":612,"y1":630},"font_size":0.0,"text":"0-shot"},{"bbox":{"x0":491,"x1":537,"y0":612,"y1":630},"font_size":0.0,"text":"95.73"},{"bbox":{"x0":626,"x1":672,"y0":612,"y1":630},"font_size":0.0,"text":"93.77"},{"bbox":{"x0":796,"x1":842,"y0":612,"y1":630},"font_size":0.0,"text":"94.03"},{"bbox":{"x0":966,"x1":1012,"y0":612,"y1":630},"font_size":0.0,"text":"95.56"},{"bbox":{"x0":222,"x1":317,"y0":632,"y1":650},"font_size":0.0,"text":"WinoGrande"},{"bbox":{"x0":395,"x1":454,"y0":630,"y1":652},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":631,"y1":650},"font_size":0.0,"text":"85.32"},{"bbox":{"x0":627,"x1":671,"y0":632,"y1":652},"font_size":0.0,"text":"84.21"},{"bbox":{"x0":797,"x1":841,"y0":632,"y1":652},"font_size":0.0,"text":"77.58"},{"bbox":{"x0":966,"x1":1012,"y0":632,"y1":650},"font_size":0.0,"text":"84.14"},{"bbox":{"x0":222,"x1":347,"y0":663,"y1":680},"font_size":0.0,"text":"CRUXEval-I-cot"},{"bbox":{"x0":395,"x1":454,"y0":659,"y1":681},"font_size":0.0,"text":"0-shots"},{"bbox":{"x0":492,"x1":537,"y0":661,"y1":680},"font_size":0.0,"text":"74.00"},{"bbox":{"x0":627,"x1":672,"y0":661,"y1":680},"font_size":0.0,"text":"62.75"},{"bbox":{"x0":796,"x1":842,"y0":661,"y1":680},"font_size":0.0,"text":"67.13"},{"bbox":{"x0":966,"x1":1012,"y0":661,"y1":680},"font_size":0.0,"text":"61.12"},{"bbox":{"x0":221,"x1":354,"y0":683,"y1":700},"font_size":0.0,"text":"CRUXEval-O-cot"},{"bbox":{"x0":396,"x1":453,"y0":680,"y1":702},"font_size":0.0,"text":"0-shots"},{"bbox":{"x0":492,"x1":537,"y0":681,"y1":700},"font_size":0.0,"text":"83.50"},{"bbox":{"x0":627,"x1":672,"y0":681,"y1":700},"font_size":0.0,"text":"75.25"},{"bbox":{"x0":796,"x1":842,"y0":682,"y1":700},"font_size":0.0,"text":"75.88"},{"bbox":{"x0":965,"x1":1011,"y0":680,"y1":702},"font_size":0.0,"text":"66.13"},{"bbox":{"x0":165,"x1":209,"y0":692,"y1":711},"font_size":0.0,"text":"Code"},{"bbox":{"x0":219,"x1":371,"y0":699,"y1":723},"font_size":0.0,"text":"LiveCodeBench(v6)"},{"bbox":{"x0":398,"x1":453,"y0":702,"y1":721},"font_size":0.0,"text":"1-shots"},{"bbox":{"x0":492,"x1":537,"y0":701,"y1":721},"font_size":0.0,"text":"26.29"},{"bbox":{"x0":627,"x1":672,"y0":701,"y1":721},"font_size":0.0,"text":"24.57"},{"bbox":{"x0":797,"x1":842,"y0":701,"y1":721},"font_size":0.0,"text":"25.14"},{"bbox":{"x0":966,"x1":1011,"y0":701,"y1":721},"font_size":0.0,"text":"22.29"},{"bbox":{"x0":220,"x1":289,"y0":720,"y1":742},"font_size":0.0,"text":"EvalPlus"},{"bbox":{"x0":420,"x1":430,"y0":728,"y1":739},"font_size":0.0,"text":"-"},{"bbox":{"x0":492,"x1":537,"y0":722,"y1":740},"font_size":0.0,"text":"80.33"},{"bbox":{"x0":626,"x1":672,"y0":722,"y1":741},"font_size":0.0,"text":"65.61"},{"bbox":{"x0":796,"x1":842,"y0":722,"y1":741},"font_size":0.0,"text":"65.48"},{"bbox":{"x0":966,"x1":1012,"y0":722,"y1":741},"font_size":0.0,"text":"66.04"},{"bbox":{"x0":220,"x1":277,"y0":750,"y1":772},"font_size":0.0,"text":"MATH"},{"bbox":{"x0":395,"x1":454,"y0":750,"y1":772},"font_size":0.0,"text":"4-shots"},{"bbox":{"x0":490,"x1":538,"y0":748,"y1":773},"font_size":0.0,"text":"70.22"},{"bbox":{"x0":627,"x1":672,"y0":751,"y1":771},"font_size":0.0,"text":"61.70"},{"bbox":{"x0":797,"x1":841,"y0":751,"y1":771},"font_size":0.0,"text":"63.02"},{"bbox":{"x0":967,"x1":1011,"y0":751,"y1":771},"font_size":0.0,"text":"62.68"},{"bbox":{"x0":164,"x1":208,"y0":779,"y1":801},"font_size":0.0,"text":"Math"},{"bbox":{"x0":220,"x1":282,"y0":770,"y1":791},"font_size":0.0,"text":"GSM8k"},{"bbox":{"x0":395,"x1":454,"y0":771,"y1":792},"font_size":0.0,"text":"8-shots"},{"bbox":{"x0":491,"x1":537,"y0":772,"y1":790},"font_size":0.0,"text":"92.12"},{"bbox":{"x0":626,"x1":673,"y0":772,"y1":790},"font_size":0.0,"text":"91.66"},{"bbox":{"x0":796,"x1":841,"y0":772,"y1":790},"font_size":0.0,"text":"86.35"},{"bbox":{"x0":966,"x1":1011,"y0":772,"y1":790},"font_size":0.0,"text":"90.37"},{"bbox":{"x0":220,"x1":352,"y0":789,"y1":813},"font_size":0.0,"text":"GSM8k-platinum"},{"bbox":{"x0":395,"x1":453,"y0":791,"y1":811},"font_size":0.0,"text":"8-shots"},{"bbox":{"x0":491,"x1":536,"y0":792,"y1":810},"font_size":0.0,"text":"94.21"},{"bbox":{"x0":626,"x1":673,"y0":792,"y1":810},"font_size":0.0,"text":"93.38"},{"bbox":{"x0":796,"x1":841,"y0":792,"y1":810},"font_size":0.0,"text":"88.83"},{"bbox":{"x0":966,"x1":1011,"y0":792,"y1":810},"font_size":0.0,"text":"92.47"},{"bbox":{"x0":221,"x1":288,"y0":812,"y1":831},"font_size":0.0,"text":"CMATH"},{"bbox":{"x0":396,"x1":454,"y0":810,"y1":832},"font_size":0.0,"text":"6-shots"},{"bbox":{"x0":491,"x1":537,"y0":812,"y1":831},"font_size":0.0,"text":"90.26"},{"bbox":{"x0":627,"x1":673,"y0":812,"y1":831},"font_size":0.0,"text":"90.53"},{"bbox":{"x0":797,"x1":841,"y0":812,"y1":832},"font_size":0.0,"text":"88.07"},{"bbox":{"x0":966,"x1":1011,"y0":812,"y1":831},"font_size":0.0,"text":"86.98"},{"bbox":{"x0":220,"x1":278,"y0":840,"y1":861},"font_size":0.0,"text":"C-Eval"},{"bbox":{"x0":395,"x1":455,"y0":841,"y1":862},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":491,"x1":537,"y0":841,"y1":860},"font_size":0.0,"text":"92.50"},{"bbox":{"x0":627,"x1":672,"y0":842,"y1":860},"font_size":0.0,"text":"90.04"},{"bbox":{"x0":796,"x1":841,"y0":842,"y1":860},"font_size":0.0,"text":"80.91"},{"bbox":{"x0":966,"x1":1012,"y0":841,"y1":860},"font_size":0.0,"text":"90.86"},{"bbox":{"x0":156,"x1":294,"y0":861,"y1":881},"font_size":0.0,"text":"ChineseCMMLU"},{"bbox":{"x0":395,"x1":454,"y0":859,"y1":883},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":862,"y1":880},"font_size":0.0,"text":"90.90"},{"bbox":{"x0":627,"x1":673,"y0":862,"y1":880},"font_size":0.0,"text":"88.84"},{"bbox":{"x0":796,"x1":842,"y0":862,"y1":880},"font_size":0.0,"text":"81.24"},{"bbox":{"x0":966,"x1":1011,"y0":862,"y1":880},"font_size":0.0,"text":"90.55"},{"bbox":{"x0":221,"x1":314,"y0":881,"y1":903},"font_size":0.0,"text":"CSimpleQA"},{"bbox":{"x0":394,"x1":455,"y0":878,"y1":903},"font_size":0.0,"text":"5-shots"},{"bbox":{"x0":492,"x1":537,"y0":881,"y1":901},"font_size":0.0,"text":"77.57"},{"bbox":{"x0":627,"x1":672,"y0":881,"y1":901},"font_size":0.0,"text":"72.13"},{"bbox":{"x0":796,"x1":841,"y0":882,"y1":901},"font_size":0.0,"text":"53.47"},{"bbox":{"x0":966,"x1":1011,"y0":881,"y1":901},"font_size":0.0,"text":"50.53"}],"source":"layout det","text":"<html><body><table><thead><tr><td># Total Params</td><td>Architecture # Activated Params</td><td>- - -</td><td>MoE 32B 1043B</td><td>MoE 37B 671B</td><td>MoE 17B 400B</td><td>Dense 72B 72B</td></tr></thead><tbody><tr><td rowspan=\"10\"></td><td>MMLU</td><td>5-shots</td><td>87.79</td><td>87.10</td><td>84.87</td><td>86.08</td></tr><tr><td>MMLU-pro</td><td>5-shots</td><td>69.17</td><td>60.59</td><td>63.47</td><td>62.80</td></tr><tr><td>MMLU-redux</td><td>5-shots</td><td>90.17</td><td>89.53</td><td>88.18</td><td>87.77</td></tr><tr><td>SuperGPQA</td><td>5-shots</td><td>44.67</td><td>39.20</td><td>38.84</td><td>34.23</td></tr><tr><td>GPQA-Diamond(avg@8)</td><td> 5-shots</td><td>48.11</td><td>50.51</td><td>49.43</td><td>40.78</td></tr><tr><td>SimpleQA</td><td>5-shots</td><td>35.25</td><td>26.49</td><td>23.74</td><td>10.31</td></tr><tr><td>EnglishTriviaQA</td><td>5-shots</td><td>85.09</td><td>84.11</td><td>79.25</td><td>76.03</td></tr><tr><td>BBH</td><td>3-shots</td><td>88.71</td><td>88.37</td><td>87.10</td><td>84.09</td></tr><tr><td>HellaSwag</td><td>5-shots</td><td>94.60</td><td>89.44</td><td>86.02</td><td>95.27</td></tr><tr><td>AGIEval</td><td>-</td><td>84.23</td><td>81.57</td><td>67.55</td><td>76.87</td></tr><tr><td rowspan=\"3\"></td><td>ARC-Challenge</td><td>0-shot</td><td>95.73</td><td>93.77</td><td>94.03</td><td>95.56</td></tr><tr><td>WinoGrande</td><td>5-shots</td><td>85.32</td><td>84.21</td><td>77.58</td><td>84.14</td></tr><tr><td>CRUXEval-I-cot</td><td>0-shots</td><td>74.00</td><td>62.75</td><td>67.13</td><td>61.12</td></tr><tr><td rowspan=\"4\">Code</td><td>CRUXEval-O-cot LiveCodeBench(v6)</td><td>0-shots</td><td>83.50</td><td>75.25</td><td>75.88</td><td>66.13</td></tr><tr><td>EvalPlus</td><td>1-shots</td><td>26.29</td><td>24.57</td><td>25.14</td><td>22.29</td></tr><tr><td></td><td>-</td><td>80.33</td><td>65.61</td><td>65.48</td><td>66.04</td></tr><tr><td>MATH</td><td>4-shots</td><td>70.22</td><td>61.70</td><td>63.02</td><td>62.68</td></tr><tr><td rowspan=\"4\">Math</td><td>GSM8k</td><td>8-shots</td><td>92.12</td><td>91.66</td><td>86.35</td><td>90.37</td></tr><tr><td>GSM8k-platinum</td><td>8-shots</td><td>94.21</td><td>93.38</td><td>88.83</td><td>92.47</td></tr><tr><td>CMATH</td><td>6-shots</td><td>90.26</td><td>90.53</td><td>88.07</td><td>86.98</td></tr><tr><td>C-Eval</td><td>5-shots</td><td>92.50</td><td>90.04</td><td>80.91</td><td>90.86</td></tr><tr><td rowspan=\"2\">ChineseCMMLU</td><td></td><td>5-shots</td><td>90.90</td><td>88.84</td><td>81.24</td><td>90.55</td></tr><tr><td>CSimpleQA</td><td>5-shots</td><td>77.57</td><td>72.13</td><td>53.47</td><td>50.53</td></tr></tbody></table></body></html>"},{"bbox":{"x0":138,"x1":346,"y0":963,"y1":992},"conf":0.8813,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":343,"y0":964,"y1":987},"font_size":3.162e-29,"text":"4.3Safety Evaluation"}],"source":"layout det","text":"4.3Safety Evaluation"},{"bbox":{"x0":137,"x1":382,"y0":1007,"y1":1036},"conf":0.9024,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":379,"y0":1005,"y1":1035},"font_size":3.162e-29,"text":"4.3.1Experiment Settings"}],"source":"layout det","text":"4.3.1Experiment Settings"},{"bbox":{"x0":137,"x1":1087,"y0":1048,"y1":1122},"conf":0.9448,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1049,"y1":1072},"font_size":3.162e-29,"text":"We conducted red-teaming evaluations on Kimi K2 compare with other open-source LLMs. The evaluation covered a"},{"bbox":{"x0":138,"x1":1083,"y0":1072,"y1":1096},"font_size":3.162e-29,"text":"range of attack scenarios—including harmful content, privacy content, and security content, as well as different attack"},{"bbox":{"x0":140,"x1":604,"y0":1096,"y1":1117},"font_size":3.162e-29,"text":"strategies such as prompt injection and iterative jailbreak."}],"source":"layout det","text":"We conducted red-teaming evaluations on Kimi K2 compare with other open-source LLMs. The evaluation covered a range of attack scenarios—including harmful content, privacy content, and security content, as well as different attack strategies such as prompt injection and iterative jailbreak."},{"bbox":{"x0":137,"x1":1089,"y0":1125,"y1":1175},"conf":0.9053,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":1124,"y1":1148},"font_size":3.162e-29,"text":"We choose Promptfoo5 to generate adversarial prompts and analyze the responses. By this way, we can evaluate model"},{"bbox":{"x0":136,"x1":294,"y0":1148,"y1":1170},"font_size":3.162e-29,"text":"in a scalable ways."}],"source":"layout det","text":"We choose Promptfoo5 to generate adversarial prompts and analyze the responses. By this way, we can evaluate model in a scalable ways."},{"bbox":{"x0":136,"x1":1089,"y0":1180,"y1":1263},"conf":0.8952,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":136,"x1":1084,"y0":1176,"y1":1206},"font_size":3.162e-29,"text":"Model Selection We compare Kimi K2 with three other open-source LLMs: DeepSeek-V3, DeepSeek-R1, and Qwen3."},{"bbox":{"x0":136,"x1":1084,"y0":1209,"y1":1241},"font_size":3.162e-29,"text":"Promptfoo Settings Table 5 lists plugins and strategies evaluated, with each plugin paired with all strategies to assess"},{"bbox":{"x0":138,"x1":293,"y0":1236,"y1":1259},"font_size":3.162e-29,"text":"their performance."}],"source":"layout det","text":"Model Selection We compare Kimi K2 with three other open-source LLMs: DeepSeek-V3, DeepSeek-R1, and Qwen3.Promptfoo Settings Table 5 lists plugins and strategies evaluated, with each plugin paired with all strategies to assess their performance."},{"bbox":{"x0":137,"x1":1089,"y0":1266,"y1":1319},"conf":0.9343,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":1266,"y1":1292},"font_size":3.162e-29,"text":"Test Case Count Given the inherent non-determinism of large language model inference, single-pass outputs may"},{"bbox":{"x0":136,"x1":926,"y0":1290,"y1":1315},"font_size":3.162e-29,"text":"exhibit variability. To account for this, we generated 3 attack prompts per plugin for each strategy."}],"source":"layout det","text":"Test Case Count Given the inherent non-determinism of large language model inference, single-pass outputs may exhibit variability. To account for this, we generated 3 attack prompts per plugin for each strategy."},{"bbox":{"x0":135,"x1":1089,"y0":1321,"y1":1397},"conf":0.9269,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":136,"x1":1084,"y0":1318,"y1":1348},"font_size":3.162e-29,"text":"Prompt Language Settings We pre-tested the language compatibility for each plugin-strategy combination. Some"},{"bbox":{"x0":140,"x1":1083,"y0":1346,"y1":1370},"font_size":3.162e-29,"text":"plugins support both English and Chinese, while others only support English. For combinations that support both, we"},{"bbox":{"x0":138,"x1":772,"y0":1366,"y1":1393},"font_size":3.162e-29,"text":"generated 3 prompts in each language, resulting in 6 prompts per combination."}],"source":"layout det","text":"Prompt Language Settings We pre-tested the language compatibility for each plugin-strategy combination. Some plugins support both English and Chinese, while others only support English. For combinations that support both, we generated 3 prompts in each language, resulting in 6 prompts per combination."}],"formula_dets":[{"bbox":{"x0":618,"x1":693,"y0":168,"y1":190},"conf":0.6208,"label":"print_embedding","label_id":0},{"bbox":{"x0":782,"x1":852,"y0":168,"y1":189},"conf":0.5063,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":149,"x1":1077,"y0":329,"y1":915},"conf":0.9811,"label":"Table","label_id":5},{"bbox":{"x0":136,"x1":1090,"y0":142,"y1":240},"conf":0.9592,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":1048,"y1":1122},"conf":0.9448,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":1266,"y1":1319},"conf":0.9343,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":1321,"y1":1397},"conf":0.9269,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":1125,"y1":1175},"conf":0.9053,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":382,"y0":1007,"y1":1036},"conf":0.9024,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":1089,"y0":1180,"y1":1263},"conf":0.8952,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":346,"y0":963,"y1":992},"conf":0.8813,"label":"Title","label_id":0},{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.7908,"label":"Abandon","label_id":2},{"bbox":{"x0":303,"x1":1045,"y0":274,"y1":300},"conf":0.6955,"label":"Table caption","label_id":6},{"bbox":{"x0":162,"x1":539,"y0":1419,"y1":1451},"conf":0.5829,"label":"Abandon","label_id":2},{"bbox":{"x0":179,"x1":1071,"y0":302,"y1":332},"conf":0.5247,"label":"Table caption","label_id":6},{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1506},"conf":0.4472,"label":"Abandon","label_id":2},{"bbox":{"x0":139,"x1":1086,"y0":64,"y1":102},"conf":0.3634,"label":"Abandon","label_id":2},{"bbox":{"x0":152,"x1":1029,"y0":1417,"y1":1508},"conf":0.3496,"label":"Abandon","label_id":2},{"bbox":{"x0":167,"x1":1051,"y0":270,"y1":301},"conf":0.213,"label":"Table caption","label_id":6}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.9199},{"poly":[[165,1419],[536,1422],[535,1445],[165,1442]],"score":0.7846},{"poly":[[138,1370],[772,1366],[772,1389],[138,1393]],"score":0.7265},{"poly":[[140,1346],[1083,1346],[1083,1370],[140,1370]],"score":0.747},{"poly":[[136,1318],[1084,1320],[1084,1348],[136,1346]],"score":0.6903},{"poly":[[136,1290],[926,1292],[926,1315],[136,1313]],"score":0.8205},{"poly":[[138,1266],[1083,1269],[1083,1292],[138,1289]],"score":0.7413},{"poly":[[138,1236],[293,1238],[293,1259],[138,1257]],"score":0.869},{"poly":[[136,1209],[1084,1213],[1084,1241],[136,1237]],"score":0.707},{"poly":[[136,1176],[1084,1178],[1084,1206],[136,1204]],"score":0.755},{"poly":[[136,1148],[294,1148],[294,1170],[136,1170]],"score":0.8148},{"poly":[[138,1124],[1083,1125],[1083,1148],[138,1147]],"score":0.7568},{"poly":[[140,1096],[604,1096],[604,1117],[140,1117]],"score":0.8845},{"poly":[[138,1072],[1083,1072],[1083,1096],[138,1096]],"score":0.7835},{"poly":[[140,1049],[1083,1049],[1083,1072],[140,1072]],"score":0.7692},{"poly":[[138,1005],[379,1007],[379,1035],[138,1033]],"score":0.7843},{"poly":[[140,964],[343,964],[343,987],[140,987]],"score":0.8465},{"poly":[[963,878],[1014,878],[1014,903],[963,903]],"score":0.9087},{"poly":[[793,878],[843,878],[843,904],[793,904]],"score":0.8914},{"poly":[[624,878],[675,878],[675,904],[624,904]],"score":0.839},{"poly":[[394,874],[456,878],[454,905],[392,900]],"score":0.8007},{"poly":[[215,874],[316,878],[315,908],[214,904]],"score":0.7304},{"poly":[[488,872],[541,877],[538,908],[485,903]],"score":0.8345},{"poly":[[963,858],[1013,858],[1013,883],[963,883]],"score":0.9678},{"poly":[[792,858],[845,858],[845,883],[792,883]],"score":0.952},{"poly":[[622,858],[675,858],[675,883],[622,883]],"score":0.9331},{"poly":[[487,858],[540,858],[540,883],[487,883]],"score":0.9308},{"poly":[[394,856],[456,860],[454,885],[392,881]],"score":0.8351},{"poly":[[153,858],[296,858],[296,881],[153,881]],"score":0.8199},{"poly":[[963,838],[1014,838],[1014,863],[963,863]],"score":0.9383},{"poly":[[793,838],[843,838],[843,863],[793,863]],"score":0.9759},{"poly":[[624,838],[675,838],[675,863],[624,863]],"score":0.9518},{"poly":[[392,834],[456,839],[454,865],[390,861]],"score":0.7819},{"poly":[[217,834],[280,839],[278,863],[216,859]],"score":0.8296},{"poly":[[487,837],[542,837],[542,865],[487,865]],"score":0.8662},{"poly":[[963,808],[1014,808],[1014,833],[963,833]],"score":0.9363},{"poly":[[793,808],[843,808],[843,833],[793,833]],"score":0.9677},{"poly":[[624,808],[675,808],[675,833],[624,833]],"score":0.9538},{"poly":[[487,808],[539,808],[539,833],[487,833]],"score":0.9588},{"poly":[[392,808],[456,808],[456,833],[392,833]],"score":0.8873},{"poly":[[218,808],[291,808],[291,833],[218,833]],"score":0.797},{"poly":[[792,789],[845,789],[845,813],[792,813]],"score":0.856},{"poly":[[394,789],[456,789],[456,813],[394,813]],"score":0.9103},{"poly":[[217,785],[354,789],[354,814],[216,810]],"score":0.766},{"poly":[[963,787],[1014,787],[1014,812],[963,812]],"score":0.853},{"poly":[[623,785],[676,789],[674,814],[621,810]],"score":0.8353},{"poly":[[487,785],[539,789],[537,816],[485,811]],"score":0.8316},{"poly":[[165,780],[211,780],[211,802],[165,802]],"score":0.9821},{"poly":[[963,769],[1014,769],[1014,792],[963,792]],"score":0.9473},{"poly":[[624,769],[675,769],[675,794],[624,794]],"score":0.9105},{"poly":[[394,769],[456,769],[456,794],[394,794]],"score":0.8852},{"poly":[[218,769],[284,769],[284,792],[218,792]],"score":0.9454},{"poly":[[791,770],[843,765],[845,791],[793,796]],"score":0.8086},{"poly":[[487,767],[539,767],[539,794],[487,794]],"score":0.8061},{"poly":[[392,749],[456,749],[456,774],[392,774]],"score":0.8683},{"poly":[[218,749],[279,749],[279,772],[218,772]],"score":0.9769},{"poly":[[963,747],[1014,747],[1014,772],[963,772]],"score":0.8657},{"poly":[[792,747],[846,747],[846,776],[792,776]],"score":0.7766},{"poly":[[624,744],[676,748],[674,774],[621,770]],"score":0.7773},{"poly":[[487,747],[539,747],[539,772],[487,772]],"score":0.9611},{"poly":[[416,724],[434,724],[434,741],[416,741]],"score":0.7773},{"poly":[[963,719],[1014,719],[1014,744],[963,744]],"score":0.8459},{"poly":[[793,718],[845,718],[845,744],[793,744]],"score":0.7939},{"poly":[[624,718],[674,718],[674,744],[624,744]],"score":0.784},{"poly":[[487,718],[539,718],[539,742],[487,742]],"score":0.9594},{"poly":[[217,716],[293,720],[292,745],[216,740]],"score":0.7622},{"poly":[[963,698],[1014,698],[1014,723],[963,723]],"score":0.9211},{"poly":[[793,698],[845,698],[845,723],[793,723]],"score":0.8883},{"poly":[[624,698],[675,698],[675,723],[624,723]],"score":0.9264},{"poly":[[487,698],[539,698],[539,723],[487,723]],"score":0.9637},{"poly":[[394,696],[455,700],[453,725],[392,721]],"score":0.8222},{"poly":[[217,696],[373,700],[372,725],[216,721]],"score":0.74},{"poly":[[163,686],[212,690],[210,715],[161,710]],"score":0.8124},{"poly":[[394,680],[454,680],[454,703],[394,703]],"score":0.968},{"poly":[[963,678],[1014,678],[1014,703],[963,703]],"score":0.8743},{"poly":[[793,678],[845,678],[845,703],[793,703]],"score":0.941},{"poly":[[624,678],[675,678],[675,703],[624,703]],"score":0.93},{"poly":[[487,678],[539,678],[539,703],[487,703]],"score":0.9513},{"poly":[[218,678],[356,678],[356,701],[218,701]],"score":0.8305},{"poly":[[963,658],[1014,658],[1014,683],[963,683]],"score":0.938},{"poly":[[793,658],[845,658],[845,683],[793,683]],"score":0.9637},{"poly":[[624,658],[674,658],[674,683],[624,683]],"score":0.9714},{"poly":[[487,658],[539,658],[539,683],[487,683]],"score":0.8849},{"poly":[[392,658],[456,658],[456,683],[392,683]],"score":0.8599},{"poly":[[218,658],[349,658],[349,681],[218,681]],"score":0.825},{"poly":[[963,629],[1014,629],[1014,653],[963,653]],"score":0.9277},{"poly":[[218,629],[321,629],[321,652],[218,652]],"score":0.8408},{"poly":[[793,627],[845,627],[845,653],[793,653]],"score":0.841},{"poly":[[622,625],[674,629],[672,656],[620,651]],"score":0.7788},{"poly":[[487,627],[539,627],[539,653],[487,653]],"score":0.856},{"poly":[[391,625],[457,625],[457,655],[391,655]],"score":0.7848},{"poly":[[793,609],[845,609],[845,634],[793,634]],"score":0.8562},{"poly":[[218,605],[343,609],[342,634],[218,630]],"score":0.7494},{"poly":[[963,605],[1015,609],[1013,636],[961,631]],"score":0.7972},{"poly":[[624,607],[674,607],[674,634],[624,634]],"score":0.8119},{"poly":[[487,607],[542,607],[542,635],[487,635]],"score":0.8124},{"poly":[[394,606],[454,606],[454,635],[394,635]],"score":0.826},{"poly":[[416,594],[434,594],[434,609],[416,609]],"score":0.857},{"poly":[[218,589],[293,589],[293,612],[218,612]],"score":0.8566},{"poly":[[965,587],[1014,587],[1014,612],[965,612]],"score":0.906},{"poly":[[791,590],[843,585],[845,612],[793,616]],"score":0.821},{"poly":[[622,587],[674,587],[674,614],[622,614]],"score":0.7828},{"poly":[[487,587],[540,587],[540,612],[487,612]],"score":0.9383},{"poly":[[963,568],[1014,568],[1014,592],[963,592]],"score":0.9296},{"poly":[[792,568],[845,568],[845,592],[792,592]],"score":0.8469},{"poly":[[622,568],[675,568],[675,592],[622,592]],"score":0.848},{"poly":[[487,568],[540,568],[540,592],[487,592]],"score":0.8997},{"poly":[[394,565],[455,570],[453,596],[392,592]],"score":0.7813},{"poly":[[215,564],[308,568],[307,596],[214,592]],"score":0.776},{"poly":[[963,548],[1014,548],[1014,573],[963,573]],"score":0.8899},{"poly":[[793,548],[845,548],[845,573],[793,573]],"score":0.8764},{"poly":[[622,548],[674,548],[674,573],[622,573]],"score":0.8779},{"poly":[[487,548],[539,548],[539,573],[487,573]],"score":0.9569},{"poly":[[394,546],[456,550],[454,575],[392,570]],"score":0.7919},{"poly":[[218,548],[269,548],[269,573],[218,573]],"score":0.8719},{"poly":[[155,530],[298,530],[298,553],[155,553]],"score":0.9006},{"poly":[[965,528],[1014,528],[1014,553],[965,553]],"score":0.8658},{"poly":[[793,528],[845,528],[845,553],[793,553]],"score":0.8589},{"poly":[[622,528],[674,528],[674,553],[622,553]],"score":0.8644},{"poly":[[487,528],[539,528],[539,553],[487,553]],"score":0.8561},{"poly":[[394,526],[456,530],[454,555],[392,551]],"score":0.8179},{"poly":[[965,508],[1013,508],[1013,533],[965,533]],"score":0.9555},{"poly":[[793,508],[845,508],[845,533],[793,533]],"score":0.948},{"poly":[[624,508],[675,508],[675,533],[624,533]],"score":0.9107},{"poly":[[394,508],[456,508],[456,533],[394,533]],"score":0.7935},{"poly":[[217,506],[305,510],[304,535],[216,531]],"score":0.8115},{"poly":[[487,507],[539,507],[539,533],[487,533]],"score":0.8352},{"poly":[[963,488],[1014,488],[1014,513],[963,513]],"score":0.9218},{"poly":[[793,488],[845,488],[845,513],[793,513]],"score":0.8722},{"poly":[[624,488],[674,488],[674,513],[624,513]],"score":0.9031},{"poly":[[392,486],[456,491],[455,514],[390,509]],"score":0.8527},{"poly":[[217,487],[394,490],[394,513],[216,510]],"score":0.805},{"poly":[[487,485],[539,489],[537,515],[485,511]],"score":0.8201},{"poly":[[217,467],[320,471],[319,495],[216,491]],"score":0.7974},{"poly":[[963,467],[1014,467],[1014,493],[963,493]],"score":0.7925},{"poly":[[793,467],[845,467],[845,493],[793,493]],"score":0.8303},{"poly":[[624,467],[675,467],[675,493],[624,493]],"score":0.805},{"poly":[[487,467],[539,467],[539,493],[487,493]],"score":0.8724},{"poly":[[394,465],[455,469],[453,494],[392,490]],"score":0.7951},{"poly":[[216,447],[328,447],[328,470],[216,470]],"score":0.7394},{"poly":[[963,447],[1013,447],[1013,472],[963,472]],"score":0.9566},{"poly":[[793,447],[845,447],[845,472],[793,472]],"score":0.8834},{"poly":[[624,447],[675,447],[675,472],[624,472]],"score":0.9131},{"poly":[[487,447],[539,447],[539,472],[487,472]],"score":0.9422},{"poly":[[394,445],[456,449],[454,474],[392,470]],"score":0.7984},{"poly":[[963,427],[1014,427],[1014,452],[963,452]],"score":0.8658},{"poly":[[793,427],[845,427],[845,454],[793,454]],"score":0.805},{"poly":[[624,427],[675,427],[675,454],[624,454]],"score":0.8148},{"poly":[[487,427],[539,427],[539,452],[487,452]],"score":0.9412},{"poly":[[394,425],[456,429],[454,456],[392,452]],"score":0.8101},{"poly":[[216,426],[318,426],[318,454],[216,454]],"score":0.7922},{"poly":[[392,409],[456,409],[456,434],[392,434]],"score":0.831},{"poly":[[218,409],[283,409],[283,432],[218,432]],"score":0.9652},{"poly":[[963,408],[1014,408],[1014,432],[963,432]],"score":0.8691},{"poly":[[793,408],[843,408],[843,432],[793,432]],"score":0.9258},{"poly":[[622,408],[675,408],[675,432],[622,432]],"score":0.9126},{"poly":[[487,408],[540,408],[540,432],[487,432]],"score":0.9234},{"poly":[[417,384],[432,384],[432,398],[417,398]],"score":0.7728},{"poly":[[217,378],[335,381],[334,405],[216,401]],"score":0.8502},{"poly":[[793,378],[843,378],[843,403],[793,403]],"score":0.9432},{"poly":[[624,378],[674,378],[674,403],[624,403]],"score":0.9445},{"poly":[[486,378],[542,378],[542,403],[486,403]],"score":0.9144},{"poly":[[968,376],[1009,376],[1009,403],[968,403]],"score":0.8533},{"poly":[[417,365],[434,365],[434,378],[417,378]],"score":0.8012},{"poly":[[216,358],[368,360],[367,383],[216,381]],"score":0.7603},{"poly":[[967,354],[1012,359],[1009,385],[964,380]],"score":0.7559},{"poly":[[798,358],[842,358],[842,384],[798,384]],"score":0.9039},{"poly":[[627,358],[670,358],[670,384],[627,384]],"score":0.8568},{"poly":[[491,358],[537,358],[537,383],[491,383]],"score":0.8837},{"poly":[[421,348],[431,348],[431,356],[421,356]],"score":0.6182},{"poly":[[221,342],[316,342],[316,360],[221,360]],"score":0.9569},{"poly":[[961,338],[1016,338],[1016,363],[961,363]],"score":0.7978},{"poly":[[795,338],[843,338],[843,363],[795,363]],"score":0.9283},{"poly":[[625,338],[672,338],[672,363],[625,363]],"score":0.9362},{"poly":[[491,338],[539,338],[539,363],[491,363]],"score":0.9057},{"poly":[[394,305],[1066,305],[1066,327],[394,327]],"score":0.9277},{"poly":[[218,302],[364,305],[364,329],[218,325]],"score":0.7406},{"poly":[[173,274],[1046,274],[1046,297],[173,297]],"score":0.7136},{"poly":[[138,210],[434,210],[434,233],[138,233]],"score":0.7158},{"poly":[[136,185],[1084,188],[1084,216],[136,213]],"score":0.7103},{"poly":[[140,167],[1083,167],[1083,190],[140,190]],"score":0.7612},{"poly":[[138,142],[1086,140],[1086,168],[138,170]],"score":0.726},{"poly":[[918,66],[1083,69],[1082,93],[918,89]],"score":0.7833},{"poly":[[559,64],[665,64],[665,92],[559,92]],"score":0.8515}],"page_no":17,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":67,"y1":93},"conf":0.8164,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":916,"x1":1083,"y0":66,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":665,"y0":63,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":597,"x1":625,"y0":1481,"y1":1505},"conf":0.7356,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"19"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":447,"x1":775,"y0":154,"y1":178},"conf":0.4705,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":449,"x1":773,"y0":152,"y1":177},"font_size":-4.204e+31,"text":"Table 5: Enabled Plugins and Strategies"}],"source":"layout det","text":"Table 5: Enabled Plugins and Strategies"},{"bbox":{"x0":166,"x1":1055,"y0":179,"y1":471},"conf":0.9825,"font_size":0.0,"label":"Table","label_id":5,"lines":[{"bbox":{"x0":265,"x1":333,"y0":180,"y1":201},"font_size":0.0,"text":"Harmful"},{"bbox":{"x0":360,"x1":1046,"y0":181,"y1":201},"font_size":0.0,"text":"Graphic Content, Harassment and Bullying, Hate Speech, Insults, Profanity, Radicalization, Self"},{"bbox":{"x0":361,"x1":610,"y0":200,"y1":221},"font_size":0.0,"text":"Harm, Sexual Content, ToxicChat"},{"bbox":{"x0":175,"x1":233,"y0":223,"y1":252},"font_size":0.0,"text":"Plugin"},{"bbox":{"x0":265,"x1":333,"y0":226,"y1":244},"font_size":0.0,"text":"Criminal"},{"bbox":{"x0":361,"x1":1044,"y0":224,"y1":245},"font_size":0.0,"text":"Chemical&Biological Weapons, Child Exploitation, Copyright Violations, Cybercrime, Illegal"},{"bbox":{"x0":362,"x1":1045,"y0":245,"y1":265},"font_size":0.0,"text":"Activities, Illegal Drugs, Indiscriminate Weapons, Intellectual Property Violation, Non-Violent"},{"bbox":{"x0":363,"x1":614,"y0":266,"y1":283},"font_size":0.0,"text":"Crime, Violent Crime, Sex Crimes"},{"bbox":{"x0":239,"x1":359,"y0":289,"y1":309},"font_size":0.0,"text":"Misinformation"},{"bbox":{"x0":360,"x1":1045,"y0":289,"y1":309},"font_size":0.0,"text":" Competitor Endorsement, Unsupervised Contracts, Excessive Agency, Hallucination, Misin-"},{"bbox":{"x0":361,"x1":1045,"y0":309,"y1":329},"font_size":0.0,"text":"formation and Disinformation, Specialized Advice, Unsafe Practices, Imitation, Overreliance,"},{"bbox":{"x0":360,"x1":653,"y0":327,"y1":350},"font_size":0.0,"text":"Political Opinions, Religious Sensitivity"},{"bbox":{"x0":268,"x1":328,"y0":350,"y1":377},"font_size":0.0,"text":"Privacy"},{"bbox":{"x0":360,"x1":1044,"y0":351,"y1":374},"font_size":0.0,"text":"Privacy Violation, PII in API/Database, Direct PII Exposure, PII in Session Data, PII via Social"},{"bbox":{"x0":360,"x1":455,"y0":371,"y1":396},"font_size":0.0,"text":"Engineering"},{"bbox":{"x0":265,"x1":332,"y0":394,"y1":419},"font_size":0.0,"text":"Security"},{"bbox":{"x0":361,"x1":1045,"y0":396,"y1":416},"font_size":0.0,"text":"ASCII Smuggling, CyberSecEval, Harmbench, Debug Access, Divergent Repetition, DoNotAn-"},{"bbox":{"x0":359,"x1":947,"y0":415,"y1":438},"font_size":0.0,"text":"swer, Malicious Code, Pliny, Prompt Extraction, Reasoning DoS, Tool Discovery"},{"bbox":{"x0":173,"x1":243,"y0":443,"y1":461},"font_size":0.0,"text":"Strategy "},{"bbox":{"x0":237,"x1":635,"y0":443,"y1":460},"font_size":0.0,"text":"Basic, Prompt Injection, Iterative Jailbreak, Crescendo"}],"source":"layout det","text":"<html><body><table><tr><td rowspan=\"5\">Plugin</td><td>Harmful</td><td>Graphic Content, Harassment and Bullying, Hate Speech, Insults, Profanity, Radicalization, Self Harm, Sexual Content, ToxicChat</td></tr><tr><td>Criminal</td><td>Chemical&Biological Weapons, Child Exploitation, Copyright Violations, Cybercrime, Illegal Activities, Illegal Drugs, Indiscriminate Weapons, Intellectual Property Violation, Non-Violent Crime, Violent Crime, Sex Crimes</td></tr><tr><td>Misinformation</td><td> Competitor Endorsement, Unsupervised Contracts, Excessive Agency, Hallucination, Misin- formation and Disinformation, Specialized Advice, Unsafe Practices, Imitation, Overreliance, Political Opinions, Religious Sensitivity</td></tr><tr><td>Privacy</td><td>Privacy Violation, PII in API/Database, Direct PII Exposure, PII in Session Data, PII via Social Engineering</td></tr><tr><td>Security</td><td>ASCII Smuggling, CyberSecEval, Harmbench, Debug Access, Divergent Repetition, DoNotAn-</td></tr><tr><td colspan=\"3\">swer, Malicious Code, Pliny, Prompt Extraction, Reasoning DoS, Tool Discovery Strategy Basic, Prompt Injection, Iterative Jailbreak, Crescendo</td></tr></table></body></html>"},{"bbox":{"x0":137,"x1":1086,"y0":508,"y1":582},"conf":0.9532,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":508,"y1":533},"font_size":-4.204e+31,"text":"Manual Review We incorporated human review into the evaluation process. To minimize subjectivity problem, we"},{"bbox":{"x0":140,"x1":1083,"y0":533,"y1":554},"font_size":-4.204e+31,"text":"conducted multiple rounds of review and assigned the same reviewer to evaluate all cases within a given test set to"},{"bbox":{"x0":138,"x1":579,"y0":556,"y1":578},"font_size":-4.204e+31,"text":"ensure consistency and reduce variability in judgment."}],"source":"layout det","text":"Manual Review We incorporated human review into the evaluation process. To minimize subjectivity problem, we conducted multiple rounds of review and assigned the same reviewer to evaluate all cases within a given test set to ensure consistency and reduce variability in judgment."},{"bbox":{"x0":138,"x1":427,"y0":603,"y1":631},"conf":0.8787,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":424,"y0":604,"y1":627},"font_size":-4.204e+31,"text":"4.3.2Safety Evaluation Results"}],"source":"layout det","text":"4.3.2Safety Evaluation Results"},{"bbox":{"x0":138,"x1":931,"y0":642,"y1":671},"conf":0.7997,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":928,"y0":639,"y1":668},"font_size":-4.204e+31,"text":"Table 6 presents the passing rates of different models under various plugin–strategy combinations."}],"source":"layout det","text":"Table 6 presents the passing rates of different models under various plugin–strategy combinations."},{"bbox":{"x0":468,"x1":753,"y0":705,"y1":728},"conf":0.9126,"font_size":0.0,"label":"Table caption","label_id":6,"lines":[{"bbox":{"x0":469,"x1":752,"y0":703,"y1":728},"font_size":-4.204e+31,"text":"Table 6: Safety Evaluation Results"}],"source":"layout det","text":"Table 6: Safety Evaluation Results"},{"bbox":{"x0":198,"x1":1023,"y0":731,"y1":1320},"conf":0.9814,"font_size":0.0,"label":"Table","label_id":5,"lines":[{"bbox":{"x0":233,"x1":292,"y0":733,"y1":758},"font_size":0.0,"text":"Plugin"},{"bbox":{"x0":322,"x1":394,"y0":733,"y1":758},"font_size":0.0,"text":"Strategy"},{"bbox":{"x0":459,"x1":1019,"y0":734,"y1":758},"font_size":0.0,"text":"Kimi-K2-Instruct DeepSeek-V3-0324 DeepSeek-R1 Qwen3-235B-A22B"},{"bbox":{"x0":324,"x1":370,"y0":771,"y1":789},"font_size":0.0,"text":"Basic"},{"bbox":{"x0":508,"x1":554,"y0":771,"y1":789},"font_size":0.0,"text":"98.04"},{"bbox":{"x0":657,"x1":703,"y0":771,"y1":789},"font_size":0.0,"text":"90.45"},{"bbox":{"x0":788,"x1":833,"y0":770,"y1":789},"font_size":0.0,"text":"99.02"},{"bbox":{"x0":920,"x1":965,"y0":770,"y1":789},"font_size":0.0,"text":"98.53"},{"bbox":{"x0":324,"x1":381,"y0":791,"y1":810},"font_size":0.0,"text":"Base64"},{"bbox":{"x0":514,"x1":549,"y0":790,"y1":810},"font_size":0.0,"text":"100"},{"bbox":{"x0":656,"x1":703,"y0":790,"y1":809},"font_size":0.0,"text":"90.20"},{"bbox":{"x0":793,"x1":829,"y0":790,"y1":810},"font_size":0.0,"text":"100"},{"bbox":{"x0":926,"x1":961,"y0":790,"y1":810},"font_size":0.0,"text":"100"},{"bbox":{"x0":230,"x1":295,"y0":801,"y1":819},"font_size":0.0,"text":"Harmful"},{"bbox":{"x0":322,"x1":451,"y0":809,"y1":833},"font_size":0.0,"text":"Prompt Injection"},{"bbox":{"x0":508,"x1":554,"y0":811,"y1":829},"font_size":0.0,"text":"93.14"},{"bbox":{"x0":662,"x1":697,"y0":811,"y1":829},"font_size":0.0,"text":"100"},{"bbox":{"x0":788,"x1":834,"y0":811,"y1":829},"font_size":0.0,"text":"95.10"},{"bbox":{"x0":921,"x1":964,"y0":811,"y1":829},"font_size":0.0,"text":"99.02"},{"bbox":{"x0":324,"x1":456,"y0":830,"y1":850},"font_size":0.0,"text":"Iterative Jailbreak"},{"bbox":{"x0":508,"x1":554,"y0":831,"y1":850},"font_size":0.0,"text":"92.16"},{"bbox":{"x0":658,"x1":701,"y0":832,"y1":848},"font_size":0.0,"text":"66.67"},{"bbox":{"x0":788,"x1":833,"y0":830,"y1":849},"font_size":0.0,"text":"72.55"},{"bbox":{"x0":920,"x1":965,"y0":829,"y1":851},"font_size":0.0,"text":"74.51"},{"bbox":{"x0":325,"x1":404,"y0":852,"y1":869},"font_size":0.0,"text":"Crescendo"},{"bbox":{"x0":508,"x1":552,"y0":852,"y1":870},"font_size":0.0,"text":"64.71"},{"bbox":{"x0":657,"x1":701,"y0":852,"y1":870},"font_size":0.0,"text":"64.71"},{"bbox":{"x0":788,"x1":834,"y0":852,"y1":870},"font_size":0.0,"text":"80.39"},{"bbox":{"x0":921,"x1":965,"y0":852,"y1":870},"font_size":0.0,"text":"86.27"},{"bbox":{"x0":323,"x1":370,"y0":879,"y1":901},"font_size":0.0,"text":"Basic"},{"bbox":{"x0":516,"x1":549,"y0":881,"y1":899},"font_size":0.0,"text":"100"},{"bbox":{"x0":656,"x1":702,"y0":880,"y1":899},"font_size":0.0,"text":"99.62"},{"bbox":{"x0":788,"x1":833,"y0":880,"y1":899},"font_size":0.0,"text":"95.45"},{"bbox":{"x0":921,"x1":965,"y0":880,"y1":899},"font_size":0.0,"text":"99.24"},{"bbox":{"x0":323,"x1":382,"y0":900,"y1":920},"font_size":0.0,"text":"Base64"},{"bbox":{"x0":508,"x1":553,"y0":901,"y1":919},"font_size":0.0,"text":"96.97"},{"bbox":{"x0":657,"x1":702,"y0":901,"y1":919},"font_size":0.0,"text":"89.39"},{"bbox":{"x0":788,"x1":833,"y0":901,"y1":919},"font_size":0.0,"text":"84.85"},{"bbox":{"x0":921,"x1":965,"y0":901,"y1":919},"font_size":0.0,"text":"98.48"},{"bbox":{"x0":230,"x1":297,"y0":912,"y1":929},"font_size":0.0,"text":"Criminal"},{"bbox":{"x0":323,"x1":451,"y0":919,"y1":944},"font_size":0.0,"text":"Prompt Injection"},{"bbox":{"x0":509,"x1":554,"y0":921,"y1":940},"font_size":0.0,"text":"75.76"},{"bbox":{"x0":657,"x1":701,"y0":922,"y1":938},"font_size":0.0,"text":"91.67"},{"bbox":{"x0":788,"x1":834,"y0":921,"y1":940},"font_size":0.0,"text":"69.70"},{"bbox":{"x0":922,"x1":964,"y0":922,"y1":938},"font_size":0.0,"text":"98.47"},{"bbox":{"x0":325,"x1":456,"y0":942,"y1":959},"font_size":0.0,"text":"Iterative Jailbreak"},{"bbox":{"x0":508,"x1":553,"y0":941,"y1":959},"font_size":0.0,"text":"57.57"},{"bbox":{"x0":656,"x1":701,"y0":941,"y1":959},"font_size":0.0,"text":"21.21"},{"bbox":{"x0":788,"x1":834,"y0":941,"y1":959},"font_size":0.0,"text":"25.76"},{"bbox":{"x0":921,"x1":965,"y0":941,"y1":959},"font_size":0.0,"text":"53.03"},{"bbox":{"x0":325,"x1":405,"y0":962,"y1":979},"font_size":0.0,"text":"Crescendo"},{"bbox":{"x0":509,"x1":554,"y0":961,"y1":981},"font_size":0.0,"text":"56.06"},{"bbox":{"x0":656,"x1":702,"y0":961,"y1":981},"font_size":0.0,"text":"31.81"},{"bbox":{"x0":788,"x1":834,"y0":961,"y1":981},"font_size":0.0,"text":"42.42"},{"bbox":{"x0":921,"x1":965,"y0":961,"y1":981},"font_size":0.0,"text":"59.09"},{"bbox":{"x0":323,"x1":370,"y0":988,"y1":1010},"font_size":0.0,"text":"Basic"},{"bbox":{"x0":508,"x1":553,"y0":990,"y1":1009},"font_size":0.0,"text":"97.28"},{"bbox":{"x0":657,"x1":702,"y0":990,"y1":1008},"font_size":0.0,"text":"92.57"},{"bbox":{"x0":788,"x1":833,"y0":990,"y1":1009},"font_size":0.0,"text":"92.46"},{"bbox":{"x0":921,"x1":965,"y0":990,"y1":1009},"font_size":0.0,"text":"94.84"},{"bbox":{"x0":204,"x1":320,"y0":1020,"y1":1042},"font_size":0.0,"text":"Misinformation"},{"bbox":{"x0":324,"x1":381,"y0":1011,"y1":1030},"font_size":0.0,"text":"Base64"},{"bbox":{"x0":508,"x1":553,"y0":1011,"y1":1030},"font_size":0.0,"text":"98.48"},{"bbox":{"x0":656,"x1":702,"y0":1011,"y1":1030},"font_size":0.0,"text":"90.48"},{"bbox":{"x0":788,"x1":833,"y0":1011,"y1":1030},"font_size":0.0,"text":"96.83"},{"bbox":{"x0":921,"x1":965,"y0":1011,"y1":1030},"font_size":0.0,"text":"93.65"},{"bbox":{"x0":322,"x1":451,"y0":1028,"y1":1053},"font_size":0.0,"text":"Prompt Injection"},{"bbox":{"x0":508,"x1":554,"y0":1031,"y1":1049},"font_size":0.0,"text":"98.39"},{"bbox":{"x0":657,"x1":702,"y0":1031,"y1":1049},"font_size":0.0,"text":"86.51"},{"bbox":{"x0":788,"x1":833,"y0":1031,"y1":1049},"font_size":0.0,"text":"93.65"},{"bbox":{"x0":920,"x1":965,"y0":1031,"y1":1049},"font_size":0.0,"text":"93.65"},{"bbox":{"x0":324,"x1":457,"y0":1050,"y1":1070},"font_size":0.0,"text":"Iterative Jailbreak"},{"bbox":{"x0":508,"x1":553,"y0":1050,"y1":1069},"font_size":0.0,"text":"63.97"},{"bbox":{"x0":657,"x1":702,"y0":1050,"y1":1069},"font_size":0.0,"text":"53.97"},{"bbox":{"x0":787,"x1":833,"y0":1049,"y1":1071},"font_size":0.0,"text":"84.13"},{"bbox":{"x0":920,"x1":965,"y0":1051,"y1":1069},"font_size":0.0,"text":"69.84"},{"bbox":{"x0":325,"x1":404,"y0":1072,"y1":1090},"font_size":0.0,"text":"Crescendo"},{"bbox":{"x0":508,"x1":552,"y0":1070,"y1":1090},"font_size":0.0,"text":"85.71"},{"bbox":{"x0":657,"x1":703,"y0":1072,"y1":1090},"font_size":0.0,"text":"55.56"},{"bbox":{"x0":788,"x1":833,"y0":1072,"y1":1090},"font_size":0.0,"text":"88.89"},{"bbox":{"x0":921,"x1":965,"y0":1072,"y1":1090},"font_size":0.0,"text":"84.13"},{"bbox":{"x0":324,"x1":370,"y0":1101,"y1":1120},"font_size":0.0,"text":"Basic"},{"bbox":{"x0":516,"x1":548,"y0":1100,"y1":1120},"font_size":0.0,"text":"100"},{"bbox":{"x0":664,"x1":696,"y0":1100,"y1":1120},"font_size":0.0,"text":"100"},{"bbox":{"x0":795,"x1":827,"y0":1100,"y1":1120},"font_size":0.0,"text":"100"},{"bbox":{"x0":928,"x1":960,"y0":1100,"y1":1120},"font_size":0.0,"text":"100"},{"bbox":{"x0":324,"x1":382,"y0":1118,"y1":1142},"font_size":0.0,"text":"Base64"},{"bbox":{"x0":232,"x1":292,"y0":1129,"y1":1155},"font_size":0.0,"text":"Privacy"},{"bbox":{"x0":515,"x1":549,"y0":1121,"y1":1140},"font_size":0.0,"text":"100"},{"bbox":{"x0":664,"x1":697,"y0":1121,"y1":1140},"font_size":0.0,"text":"100"},{"bbox":{"x0":795,"x1":828,"y0":1121,"y1":1140},"font_size":0.0,"text":"100"},{"bbox":{"x0":927,"x1":961,"y0":1121,"y1":1140},"font_size":0.0,"text":"100"},{"bbox":{"x0":323,"x1":451,"y0":1139,"y1":1163},"font_size":0.0,"text":"Prompt Injection"},{"bbox":{"x0":509,"x1":553,"y0":1141,"y1":1159},"font_size":0.0,"text":"88.33"},{"bbox":{"x0":657,"x1":702,"y0":1141,"y1":1159},"font_size":0.0,"text":"98.33"},{"bbox":{"x0":796,"x1":827,"y0":1142,"y1":1158},"font_size":0.0,"text":"100"},{"bbox":{"x0":921,"x1":964,"y0":1141,"y1":1159},"font_size":0.0,"text":"91.67"},{"bbox":{"x0":324,"x1":457,"y0":1160,"y1":1181},"font_size":0.0,"text":"Iterative Jailbreak"},{"bbox":{"x0":508,"x1":554,"y0":1160,"y1":1179},"font_size":0.0,"text":"76.67"},{"bbox":{"x0":663,"x1":697,"y0":1160,"y1":1180},"font_size":0.0,"text":"100"},{"bbox":{"x0":788,"x1":833,"y0":1160,"y1":1179},"font_size":0.0,"text":"93.33"},{"bbox":{"x0":921,"x1":964,"y0":1160,"y1":1179},"font_size":0.0,"text":"96.67"},{"bbox":{"x0":325,"x1":404,"y0":1182,"y1":1199},"font_size":0.0,"text":"Crescendo"},{"bbox":{"x0":508,"x1":553,"y0":1182,"y1":1200},"font_size":0.0,"text":"96.67"},{"bbox":{"x0":664,"x1":696,"y0":1181,"y1":1200},"font_size":0.0,"text":"100"},{"bbox":{"x0":787,"x1":833,"y0":1180,"y1":1202},"font_size":0.0,"text":"96.67"},{"bbox":{"x0":929,"x1":960,"y0":1183,"y1":1199},"font_size":0.0,"text":"100"},{"bbox":{"x0":323,"x1":371,"y0":1209,"y1":1230},"font_size":0.0,"text":"Basic"},{"bbox":{"x0":508,"x1":554,"y0":1210,"y1":1229},"font_size":0.0,"text":"77.84"},{"bbox":{"x0":657,"x1":702,"y0":1210,"y1":1229},"font_size":0.0,"text":"75.57"},{"bbox":{"x0":788,"x1":834,"y0":1210,"y1":1229},"font_size":0.0,"text":"70.46"},{"bbox":{"x0":921,"x1":964,"y0":1211,"y1":1229},"font_size":0.0,"text":"90.09"},{"bbox":{"x0":229,"x1":294,"y0":1238,"y1":1263},"font_size":0.0,"text":"Security"},{"bbox":{"x0":323,"x1":382,"y0":1230,"y1":1251},"font_size":0.0,"text":"Base64"},{"bbox":{"x0":508,"x1":553,"y0":1231,"y1":1249},"font_size":0.0,"text":"82.93"},{"bbox":{"x0":657,"x1":702,"y0":1231,"y1":1249},"font_size":0.0,"text":"82.93"},{"bbox":{"x0":788,"x1":833,"y0":1231,"y1":1249},"font_size":0.0,"text":"63.41"},{"bbox":{"x0":919,"x1":966,"y0":1229,"y1":1251},"font_size":0.0,"text":"95.12"},{"bbox":{"x0":324,"x1":451,"y0":1250,"y1":1271},"font_size":0.0,"text":"Prompt Injection"},{"bbox":{"x0":507,"x1":554,"y0":1249,"y1":1271},"font_size":0.0,"text":"87.80"},{"bbox":{"x0":655,"x1":703,"y0":1249,"y1":1271},"font_size":0.0,"text":"97.56"},{"bbox":{"x0":788,"x1":833,"y0":1250,"y1":1269},"font_size":0.0,"text":"65.85"},{"bbox":{"x0":921,"x1":965,"y0":1250,"y1":1269},"font_size":0.0,"text":"84.13"},{"bbox":{"x0":325,"x1":456,"y0":1272,"y1":1289},"font_size":0.0,"text":"Iterative Jailbreak"},{"bbox":{"x0":508,"x1":554,"y0":1271,"y1":1289},"font_size":0.0,"text":"43.90"},{"bbox":{"x0":656,"x1":702,"y0":1271,"y1":1289},"font_size":0.0,"text":"60.97"},{"bbox":{"x0":788,"x1":834,"y0":1271,"y1":1289},"font_size":0.0,"text":"43.90"},{"bbox":{"x0":921,"x1":965,"y0":1271,"y1":1289},"font_size":0.0,"text":"78.04"},{"bbox":{"x0":324,"x1":405,"y0":1290,"y1":1311},"font_size":0.0,"text":"Crescendo"},{"bbox":{"x0":508,"x1":554,"y0":1290,"y1":1310},"font_size":0.0,"text":"68.29"},{"bbox":{"x0":656,"x1":703,"y0":1291,"y1":1310},"font_size":0.0,"text":"87.80"},{"bbox":{"x0":787,"x1":833,"y0":1291,"y1":1310},"font_size":0.0,"text":"68.29"},{"bbox":{"x0":920,"x1":965,"y0":1291,"y1":1310},"font_size":0.0,"text":"87.80"}],"source":"layout det","text":"<html><body><table><tr><td>Plugin Strategy</td><td></td><td colspan=\"4\">Kimi-K2-Instruct DeepSeek-V3-0324 DeepSeek-R1 Qwen3-235B-A22B</td></tr><tr><td rowspan=\"5\">Harmful</td><td>Basic</td><td>98.04</td><td>90.45</td><td>99.02</td><td>98.53</td></tr><tr><td>Base64</td><td>100</td><td>90.20</td><td>100</td><td>100</td></tr><tr><td>Prompt Injection</td><td>93.14</td><td>100</td><td>95.10</td><td>99.02</td></tr><tr><td>Iterative Jailbreak</td><td>92.16</td><td>66.67</td><td>72.55</td><td>74.51</td></tr><tr><td>Crescendo</td><td>64.71</td><td>64.71</td><td>80.39</td><td>86.27</td></tr><tr><td rowspan=\"5\">Criminal</td><td>Basic</td><td>100</td><td>99.62</td><td>95.45</td><td>99.24</td></tr><tr><td>Base64</td><td>96.97</td><td>89.39</td><td>84.85</td><td>98.48</td></tr><tr><td>Prompt Injection</td><td>75.76</td><td>91.67</td><td>69.70</td><td>98.47</td></tr><tr><td>Iterative Jailbreak</td><td>57.57</td><td>21.21</td><td>25.76</td><td>53.03</td></tr><tr><td>Crescendo</td><td>56.06</td><td>31.81</td><td>42.42</td><td>59.09</td></tr><tr><td rowspan=\"5\">Misinformation</td><td>Basic</td><td>97.28</td><td>92.57</td><td>92.46</td><td>94.84</td></tr><tr><td>Base64</td><td>98.48</td><td>90.48</td><td>96.83</td><td>93.65</td></tr><tr><td>Prompt Injection</td><td>98.39</td><td>86.51</td><td>93.65</td><td>93.65</td></tr><tr><td>Iterative Jailbreak</td><td>63.97</td><td>53.97</td><td>84.13</td><td>69.84</td></tr><tr><td>Crescendo</td><td>85.71</td><td>55.56</td><td>88.89</td><td>84.13</td></tr><tr><td rowspan=\"5\">Privacy</td><td>Basic</td><td>100</td><td>100</td><td>100</td><td>100</td></tr><tr><td>Base64</td><td>100</td><td>100</td><td>100</td><td>100</td></tr><tr><td>Prompt Injection</td><td>88.33</td><td>98.33</td><td>100</td><td>91.67</td></tr><tr><td>Iterative Jailbreak</td><td>76.67</td><td>100</td><td>93.33</td><td>96.67</td></tr><tr><td>Crescendo</td><td>96.67</td><td>100</td><td>96.67</td><td>100</td></tr><tr><td rowspan=\"5\">Security</td><td>Basic</td><td>77.84</td><td>75.57</td><td>70.46</td><td>90.09</td></tr><tr><td>Base64</td><td>82.93</td><td>82.93</td><td>63.41</td><td>95.12</td></tr><tr><td>Prompt Injection</td><td>87.80</td><td>97.56</td><td>65.85</td><td>84.13</td></tr><tr><td>Iterative Jailbreak</td><td>43.90</td><td>60.97</td><td>43.90</td><td>78.04</td></tr><tr><td>Crescendo</td><td>68.29</td><td>87.80</td><td>68.29</td><td>87.80</td></tr></table></body></html>"},{"bbox":{"x0":135,"x1":1089,"y0":1343,"y1":1393},"conf":0.9107,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1343,"y1":1368},"font_size":-4.204e+31,"text":"Without targeted optimization for specifc evaluation scenarios, the passing rate of some complex cases (e.g., Harm-i"},{"bbox":{"x0":138,"x1":715,"y0":1365,"y1":1389},"font_size":-4.204e+31,"text":"ful–Iterative Jailbreak) was relatively higher compared to other models."}],"source":"layout det","text":"Without targeted optimization for specifc evaluation scenarios, the passing rate of some complex cases (e.g., Harm-i ful–Iterative Jailbreak) was relatively higher compared to other models."},{"bbox":{"x0":136,"x1":1088,"y0":1398,"y1":1449},"conf":0.9016,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1399,"y1":1422},"font_size":-4.204e+31,"text":"Across different attack strategies, the models exhibited varying trends. Under the Base64 strategy, passing rates"},{"bbox":{"x0":136,"x1":1084,"y0":1417,"y1":1447},"font_size":-4.204e+31,"text":"generally approached or reached $100\\%,$  suggesting that encoding transformations had minimal impact on the models’"}],"source":"layout det","text":"Across different attack strategies, the models exhibited varying trends. Under the Base64 strategy, passing rates generally approached or reached $100\\%,$  suggesting that encoding transformations had minimal impact on the models’"}],"formula_dets":[{"bbox":{"x0":408,"x1":460,"y0":1422,"y1":1443},"conf":0.8254,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":166,"x1":1055,"y0":179,"y1":471},"conf":0.9825,"label":"Table","label_id":5},{"bbox":{"x0":198,"x1":1023,"y0":731,"y1":1320},"conf":0.9814,"label":"Table","label_id":5},{"bbox":{"x0":137,"x1":1086,"y0":508,"y1":582},"conf":0.9532,"label":"Text","label_id":1},{"bbox":{"x0":468,"x1":753,"y0":705,"y1":728},"conf":0.9126,"label":"Table caption","label_id":6},{"bbox":{"x0":135,"x1":1089,"y0":1343,"y1":1393},"conf":0.9107,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":1398,"y1":1449},"conf":0.9016,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":427,"y0":603,"y1":631},"conf":0.8787,"label":"Title","label_id":0},{"bbox":{"x0":447,"x1":775,"y0":154,"y1":178},"conf":0.8362,"label":"Table caption","label_id":6},{"bbox":{"x0":558,"x1":1086,"y0":67,"y1":93},"conf":0.8164,"label":"Abandon","label_id":2},{"bbox":{"x0":138,"x1":931,"y0":642,"y1":671},"conf":0.7997,"label":"Text","label_id":1},{"bbox":{"x0":597,"x1":625,"y0":1481,"y1":1505},"conf":0.7356,"label":"Abandon","label_id":2},{"bbox":{"x0":447,"x1":775,"y0":154,"y1":178},"conf":0.4705,"label":"Table caption","label_id":6}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.9168},{"poly":[[136,1419],[1084,1417],[1084,1445],[136,1447]],"score":0.7028},{"poly":[[141,1399],[1083,1399],[1083,1422],[141,1422]],"score":0.7632},{"poly":[[138,1365],[715,1366],[715,1389],[138,1388]],"score":0.7864},{"poly":[[140,1343],[1083,1345],[1083,1368],[140,1366]],"score":0.8345},{"poly":[[916,1287],[968,1287],[968,1313],[916,1313]],"score":0.8552},{"poly":[[785,1287],[837,1287],[837,1313],[785,1313]],"score":0.8699},{"poly":[[654,1287],[705,1287],[705,1313],[654,1313]],"score":0.8941},{"poly":[[504,1287],[559,1287],[559,1315],[504,1315]],"score":0.8332},{"poly":[[320,1285],[409,1289],[408,1314],[319,1310]],"score":0.7742},{"poly":[[321,1269],[457,1269],[457,1292],[321,1292]],"score":0.854},{"poly":[[916,1267],[968,1267],[968,1292],[916,1292]],"score":0.9536},{"poly":[[785,1267],[837,1267],[837,1292],[785,1292]],"score":0.9749},{"poly":[[652,1267],[705,1267],[705,1292],[652,1292]],"score":0.9275},{"poly":[[504,1267],[557,1267],[557,1292],[504,1292]],"score":0.9564},{"poly":[[916,1247],[968,1247],[968,1272],[916,1272]],"score":0.9667},{"poly":[[506,1247],[557,1247],[557,1272],[506,1272]],"score":0.9847},{"poly":[[318,1244],[454,1248],[453,1276],[317,1272]],"score":0.8133},{"poly":[[783,1244],[837,1244],[837,1275],[783,1275]],"score":0.8026},{"poly":[[652,1246],[707,1246],[707,1274],[652,1274]],"score":0.8505},{"poly":[[229,1235],[297,1240],[295,1264],[227,1260]],"score":0.8637},{"poly":[[916,1226],[968,1226],[968,1252],[916,1252]],"score":0.8515},{"poly":[[785,1226],[835,1226],[835,1252],[785,1252]],"score":0.9002},{"poly":[[652,1226],[707,1226],[707,1254],[652,1254]],"score":0.8357},{"poly":[[506,1226],[557,1226],[557,1252],[506,1252]],"score":0.8597},{"poly":[[319,1222],[386,1227],[384,1256],[317,1252]],"score":0.816},{"poly":[[916,1206],[968,1206],[968,1231],[916,1231]],"score":0.9584},{"poly":[[785,1206],[837,1206],[837,1233],[785,1233]],"score":0.9483},{"poly":[[321,1206],[376,1206],[376,1234],[321,1234]],"score":0.9527},{"poly":[[652,1203],[705,1203],[705,1234],[652,1234]],"score":0.8726},{"poly":[[502,1203],[559,1203],[559,1234],[502,1234]],"score":0.8467},{"poly":[[321,1178],[407,1178],[407,1201],[321,1201]],"score":0.8654},{"poly":[[921,1176],[965,1176],[965,1203],[921,1203]],"score":0.8041},{"poly":[[785,1176],[837,1176],[837,1203],[785,1203]],"score":0.8661},{"poly":[[662,1176],[700,1176],[700,1203],[662,1203]],"score":0.9511},{"poly":[[504,1176],[559,1176],[559,1204],[504,1204]],"score":0.7947},{"poly":[[321,1158],[457,1158],[457,1181],[321,1181]],"score":0.8394},{"poly":[[916,1154],[969,1159],[966,1185],[914,1181]],"score":0.8317},{"poly":[[783,1157],[838,1157],[838,1185],[783,1185]],"score":0.7805},{"poly":[[657,1157],[703,1157],[703,1183],[657,1183]],"score":0.8023},{"poly":[[506,1157],[557,1157],[557,1183],[506,1183]],"score":0.8389},{"poly":[[321,1138],[452,1138],[452,1162],[321,1162]],"score":0.804},{"poly":[[916,1137],[968,1137],[968,1162],[916,1162]],"score":0.9325},{"poly":[[790,1137],[832,1137],[832,1162],[790,1162]],"score":0.9364},{"poly":[[654,1137],[705,1137],[705,1162],[654,1162]],"score":0.949},{"poly":[[506,1137],[557,1137],[557,1162],[506,1162]],"score":0.9585},{"poly":[[231,1125],[295,1131],[293,1156],[229,1149]],"score":0.7421},{"poly":[[923,1117],[965,1117],[965,1142],[923,1142]],"score":0.9389},{"poly":[[321,1117],[384,1117],[384,1142],[321,1142]],"score":0.8645},{"poly":[[792,1115],[832,1115],[832,1143],[792,1143]],"score":0.8147},{"poly":[[659,1115],[702,1115],[702,1142],[659,1142]],"score":0.8618},{"poly":[[511,1115],[554,1115],[554,1142],[511,1142]],"score":0.8394},{"poly":[[511,1097],[552,1097],[552,1124],[511,1124]],"score":0.8497},{"poly":[[321,1097],[374,1097],[374,1122],[321,1122]],"score":0.9545},{"poly":[[923,1096],[963,1096],[963,1124],[923,1124]],"score":0.7936},{"poly":[[792,1096],[832,1096],[832,1124],[792,1124]],"score":0.8558},{"poly":[[660,1096],[700,1096],[700,1124],[660,1124]],"score":0.8136},{"poly":[[916,1068],[968,1068],[968,1094],[916,1094]],"score":0.8794},{"poly":[[785,1068],[835,1068],[835,1094],[785,1094]],"score":0.9088},{"poly":[[506,1068],[555,1068],[555,1094],[506,1094]],"score":0.8885},{"poly":[[319,1064],[409,1064],[409,1092],[319,1092]],"score":0.7455},{"poly":[[652,1064],[707,1064],[707,1096],[652,1096]],"score":0.8024},{"poly":[[916,1048],[968,1048],[968,1072],[916,1072]],"score":0.9531},{"poly":[[321,1048],[457,1048],[457,1071],[321,1071]],"score":0.8403},{"poly":[[783,1046],[835,1046],[835,1072],[783,1072]],"score":0.8488},{"poly":[[654,1046],[703,1046],[703,1072],[654,1072]],"score":0.8589},{"poly":[[506,1046],[557,1046],[557,1072],[506,1072]],"score":0.8698},{"poly":[[318,1026],[454,1026],[454,1054],[318,1054]],"score":0.7666},{"poly":[[916,1026],[968,1026],[968,1051],[916,1051]],"score":0.8843},{"poly":[[785,1026],[835,1026],[835,1051],[785,1051]],"score":0.9392},{"poly":[[652,1026],[703,1026],[703,1053],[652,1053]],"score":0.77},{"poly":[[506,1026],[557,1026],[557,1051],[506,1051]],"score":0.8986},{"poly":[[200,1013],[326,1017],[325,1045],[199,1041]],"score":0.7208},{"poly":[[321,1008],[384,1008],[384,1033],[321,1033]],"score":0.862},{"poly":[[916,1006],[968,1006],[968,1031],[916,1031]],"score":0.9094},{"poly":[[785,1006],[835,1006],[835,1031],[785,1031]],"score":0.9189},{"poly":[[652,1006],[703,1006],[703,1031],[652,1031]],"score":0.8759},{"poly":[[506,1006],[557,1006],[557,1033],[506,1033]],"score":0.8175},{"poly":[[916,987],[968,987],[968,1011],[916,1011]],"score":0.9629},{"poly":[[783,987],[837,987],[837,1011],[783,1011]],"score":0.9347},{"poly":[[652,987],[703,987],[703,1011],[652,1011]],"score":0.943},{"poly":[[504,987],[557,987],[557,1011],[504,1011]],"score":0.9606},{"poly":[[321,983],[376,987],[374,1014],[319,1009]],"score":0.7548},{"poly":[[918,957],[968,957],[968,982],[918,982]],"score":0.9519},{"poly":[[785,957],[835,957],[835,983],[785,983]],"score":0.9089},{"poly":[[654,957],[703,957],[703,983],[654,983]],"score":0.8851},{"poly":[[506,957],[557,957],[557,982],[506,982]],"score":0.9568},{"poly":[[320,953],[410,957],[408,985],[319,981]],"score":0.7935},{"poly":[[321,939],[457,939],[457,962],[321,962]],"score":0.8547},{"poly":[[916,937],[968,937],[968,962],[916,962]],"score":0.9353},{"poly":[[785,937],[837,937],[837,962],[785,962]],"score":0.9717},{"poly":[[652,937],[703,937],[703,962],[652,962]],"score":0.9389},{"poly":[[506,936],[555,936],[555,962],[506,962]],"score":0.8859},{"poly":[[785,917],[837,917],[837,942],[785,942]],"score":0.9702},{"poly":[[652,917],[703,917],[703,942],[652,942]],"score":0.9587},{"poly":[[318,914],[454,918],[453,946],[317,942]],"score":0.7812},{"poly":[[916,916],[968,916],[968,942],[916,942]],"score":0.8482},{"poly":[[506,916],[557,916],[557,942],[506,942]],"score":0.9064},{"poly":[[226,908],[299,908],[299,932],[226,932]],"score":0.8127},{"poly":[[916,896],[968,896],[968,922],[916,922]],"score":0.7826},{"poly":[[785,896],[835,896],[835,922],[785,922]],"score":0.8471},{"poly":[[654,896],[705,896],[705,922],[654,922]],"score":0.8088},{"poly":[[506,896],[555,896],[555,922],[506,922]],"score":0.869},{"poly":[[319,892],[386,897],[384,926],[317,922]],"score":0.7802},{"poly":[[916,876],[968,876],[968,901],[916,901]],"score":0.9257},{"poly":[[785,876],[835,876],[835,903],[785,903]],"score":0.9092},{"poly":[[654,876],[705,876],[705,903],[654,903]],"score":0.8719},{"poly":[[509,876],[554,876],[554,903],[509,903]],"score":0.8105},{"poly":[[321,876],[373,876],[373,903],[321,903]],"score":0.8667},{"poly":[[321,848],[407,848],[407,871],[321,871]],"score":0.8843},{"poly":[[916,846],[968,846],[968,873],[916,873]],"score":0.8884},{"poly":[[785,846],[837,846],[837,873],[785,873]],"score":0.9213},{"poly":[[652,846],[703,846],[703,873],[652,873]],"score":0.9003},{"poly":[[504,846],[559,846],[559,874],[504,874]],"score":0.8887},{"poly":[[321,828],[457,828],[457,851],[321,851]],"score":0.8436},{"poly":[[652,827],[707,827],[707,855],[652,855]],"score":0.7916},{"poly":[[504,827],[559,827],[559,855],[504,855]],"score":0.8202},{"poly":[[916,825],[968,825],[968,851],[916,851]],"score":0.834},{"poly":[[785,823],[837,827],[835,855],[783,851]],"score":0.816},{"poly":[[321,808],[452,808],[452,832],[321,832]],"score":0.8277},{"poly":[[916,807],[968,807],[968,833],[916,833]],"score":0.8606},{"poly":[[783,807],[837,807],[837,832],[783,832]],"score":0.9526},{"poly":[[655,807],[703,807],[703,832],[655,832]],"score":0.8807},{"poly":[[504,807],[557,807],[557,832],[504,832]],"score":0.9068},{"poly":[[228,799],[298,799],[298,822],[228,822]],"score":0.9648},{"poly":[[920,787],[966,787],[966,812],[920,812]],"score":0.8674},{"poly":[[788,787],[833,787],[833,812],[788,812]],"score":0.9222},{"poly":[[652,787],[705,787],[705,812],[652,812]],"score":0.9364},{"poly":[[507,787],[554,787],[554,812],[507,812]],"score":0.888},{"poly":[[321,787],[384,787],[384,812],[321,812]],"score":0.8373},{"poly":[[916,767],[968,767],[968,792],[916,792]],"score":0.9151},{"poly":[[783,767],[837,767],[837,792],[783,792]],"score":0.9018},{"poly":[[652,767],[705,767],[705,792],[652,792]],"score":0.8849},{"poly":[[504,767],[557,767],[557,792],[504,792]],"score":0.9072},{"poly":[[321,767],[373,767],[373,792],[321,792]],"score":0.9652},{"poly":[[457,733],[1019,733],[1019,756],[457,756]],"score":0.8069},{"poly":[[319,729],[396,733],[395,761],[317,757]],"score":0.8371},{"poly":[[232,729],[295,733],[293,761],[231,757]],"score":0.8535},{"poly":[[469,703],[752,705],[752,728],[469,726]],"score":0.8296},{"poly":[[138,639],[928,640],[928,668],[138,667]],"score":0.7895},{"poly":[[140,604],[424,604],[424,627],[140,627]],"score":0.8299},{"poly":[[138,556],[579,556],[579,578],[138,578]],"score":0.8859},{"poly":[[140,533],[1083,533],[1083,554],[140,554]],"score":0.9731},{"poly":[[138,508],[1083,510],[1083,533],[138,531]],"score":0.7699},{"poly":[[238,439],[639,439],[639,460],[238,460]],"score":0.8532},{"poly":[[170,439],[244,439],[244,462],[170,462]],"score":0.7828},{"poly":[[359,414],[948,414],[948,437],[359,437]],"score":0.7283},{"poly":[[363,394],[1046,394],[1046,416],[363,416]],"score":0.8793},{"poly":[[262,391],[333,395],[332,420],[261,415]],"score":0.7991},{"poly":[[359,368],[458,373],[456,398],[357,392]],"score":0.7604},{"poly":[[361,350],[1044,350],[1044,373],[361,373]],"score":0.7803},{"poly":[[266,346],[330,352],[327,378],[264,372]],"score":0.7681},{"poly":[[358,325],[655,328],[655,352],[357,348]],"score":0.7258},{"poly":[[358,305],[1046,307],[1046,330],[358,328]],"score":0.7327},{"poly":[[359,287],[1046,287],[1046,310],[359,310]],"score":0.7381},{"poly":[[238,284],[359,284],[359,307],[238,307]],"score":0.6267},{"poly":[[358,261],[615,262],[615,286],[357,284]],"score":0.7963},{"poly":[[361,241],[1044,241],[1044,264],[361,264]],"score":0.7193},{"poly":[[359,221],[1046,223],[1046,246],[359,244]],"score":0.788},{"poly":[[261,223],[338,223],[338,246],[261,246]],"score":0.9148},{"poly":[[173,221],[236,221],[236,252],[173,252]],"score":0.7954},{"poly":[[361,198],[612,198],[612,221],[361,221]],"score":0.8366},{"poly":[[359,178],[1048,178],[1048,201],[359,201]],"score":0.7624},{"poly":[[263,178],[334,178],[334,201],[263,201]],"score":0.9643},{"poly":[[449,152],[773,155],[773,177],[449,173]],"score":0.8965},{"poly":[[917,66],[1083,69],[1082,93],[916,89]],"score":0.7954},{"poly":[[559,63],[665,63],[665,92],[559,92]],"score":0.8163}],"page_no":18,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":559,"x1":1086,"y0":67,"y1":92},"conf":0.8411,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":67,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1505},"conf":0.721,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"20"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":138,"x1":1088,"y0":143,"y1":193},"conf":0.9226,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":147,"y1":168},"font_size":36150000.0,"text":"basic robustness. In contrast, the Crescendo strategy led to a general drop in passing rates, indicating stronger adversarial"},{"bbox":{"x0":139,"x1":253,"y0":165,"y1":192},"font_size":36150000.0,"text":"effectiveness."}],"source":"layout det","text":"basic robustness. In contrast, the Crescendo strategy led to a general drop in passing rates, indicating stronger adversarial effectiveness."},{"bbox":{"x0":138,"x1":1087,"y0":200,"y1":270},"conf":0.9421,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":201,"y1":223},"font_size":36150000.0,"text":"In addition, complex attack strategies do not always outperform basic prompts. Some originally adversarial prompts"},{"bbox":{"x0":138,"x1":1081,"y0":221,"y1":246},"font_size":36150000.0,"text":"may lose their intended meaning after multiple rounds of transformation, rendering the resulting model outputs less"},{"bbox":{"x0":141,"x1":241,"y0":248,"y1":264},"font_size":36150000.0,"text":"meaningful."}],"source":"layout det","text":"In addition, complex attack strategies do not always outperform basic prompts. Some originally adversarial prompts may lose their intended meaning after multiple rounds of transformation, rendering the resulting model outputs less meaningful."},{"bbox":{"x0":138,"x1":1087,"y0":276,"y1":368},"conf":0.9499,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":277,"y1":299},"font_size":36150000.0,"text":"Automated Red-teaming Limitations Due to the involvement of human review, the evaluation results inevitably"},{"bbox":{"x0":140,"x1":1079,"y0":297,"y1":320},"font_size":36150000.0,"text":"contain a degree of subjectivity. Additionally, certain plugin types involve API misuse or external tool invocation, which"},{"bbox":{"x0":140,"x1":1081,"y0":322,"y1":345},"font_size":36150000.0,"text":"are more suitable for evaluating agent models with tool-calling capabilities. In the context of base LLMs, such tests"},{"bbox":{"x0":140,"x1":369,"y0":343,"y1":365},"font_size":36150000.0,"text":"may have limited relevance."}],"source":"layout det","text":"Automated Red-teaming Limitations Due to the involvement of human review, the evaluation results inevitably contain a degree of subjectivity. Additionally, certain plugin types involve API misuse or external tool invocation, which are more suitable for evaluating agent models with tool-calling capabilities. In the context of base LLMs, such tests may have limited relevance."},{"bbox":{"x0":139,"x1":303,"y0":394,"y1":423},"conf":0.8923,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":299,"y0":396,"y1":419},"font_size":36150000.0,"text":"5Limitations"}],"source":"layout det","text":"5Limitations"},{"bbox":{"x0":137,"x1":1087,"y0":443,"y1":560},"conf":0.958,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":439,"y1":472},"font_size":36150000.0,"text":"In our internal tests, we have identifed some limitations in current Kimi K2 models. When dealing with hard reasoningi"},{"bbox":{"x0":141,"x1":1083,"y0":469,"y1":490},"font_size":36150000.0,"text":"tasks or unclear tool defnition, the model may generate excessive tokens, sometimes leading to truncated outputs ori"},{"bbox":{"x0":141,"x1":1081,"y0":490,"y1":512},"font_size":36150000.0,"text":"incomplete tool calls. Additionally, performance may decline on certain tasks if tool use is unnecessarily enabled. When"},{"bbox":{"x0":141,"x1":1081,"y0":512,"y1":533},"font_size":36150000.0,"text":"building complete software projects, the success rate of one-shot prompting is not as good as using K2 under an agentic"},{"bbox":{"x0":140,"x1":1078,"y0":535,"y1":556},"font_size":36150000.0,"text":"coding framework. We are working to address these issues in future releases and looking forward to more feedbacks."}],"source":"layout det","text":"In our internal tests, we have identifed some limitations in current Kimi K2 models. When dealing with hard reasoningi tasks or unclear tool defnition, the model may generate excessive tokens, sometimes leading to truncated outputs ori incomplete tool calls. Additionally, performance may decline on certain tasks if tool use is unnecessarily enabled. When building complete software projects, the success rate of one-shot prompting is not as good as using K2 under an agentic coding framework. We are working to address these issues in future releases and looking forward to more feedbacks."},{"bbox":{"x0":138,"x1":309,"y0":585,"y1":613},"conf":0.9015,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":306,"y0":587,"y1":610},"font_size":36150000.0,"text":"6Conclusions"}],"source":"layout det","text":"6Conclusions"},{"bbox":{"x0":137,"x1":1088,"y0":634,"y1":749},"conf":0.9581,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":634,"y1":658},"font_size":36150000.0,"text":"We introduced Kimi K2, a 1T-parameter open-weight MoE model built for agentic intelligence. Leveraging the token-"},{"bbox":{"x0":140,"x1":1083,"y0":657,"y1":681},"font_size":36150000.0,"text":"effcient MuonClip optimizer and a 15.5T-token high-quality dataset, Kimi K2 achieves stable, scalable pre-training.i"},{"bbox":{"x0":141,"x1":1081,"y0":680,"y1":701},"font_size":36150000.0,"text":"Post-training combines large-scale synthetic tool-use data with a unifed RL framework using both verifable rewardsii"},{"bbox":{"x0":140,"x1":1083,"y0":701,"y1":723},"font_size":36150000.0,"text":"and self-critic feedbacks. Kimi K2 sets new state-of-the-art on agentic and reasoning benchmarks, establishing itself as"},{"bbox":{"x0":138,"x1":494,"y0":721,"y1":746},"font_size":36150000.0,"text":"the most capable open-weight LLM to date."}],"source":"layout det","text":"We introduced Kimi K2, a 1T-parameter open-weight MoE model built for agentic intelligence. Leveraging the tokeneffcient MuonClip optimizer and a 15.5T-token high-quality dataset, Kimi K2 achieves stable, scalable pre-training.i Post-training combines large-scale synthetic tool-use data with a unifed RL framework using both verifable rewardsii and self-critic feedbacks. Kimi K2 sets new state-of-the-art on agentic and reasoning benchmarks, establishing itself as the most capable open-weight LLM to date."},{"bbox":{"x0":137,"x1":372,"y0":775,"y1":807},"conf":0.9028,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":368,"y0":774,"y1":804},"font_size":36150000.0,"text":"7Acknowledgments"}],"source":"layout det","text":"7Acknowledgments"},{"bbox":{"x0":136,"x1":1086,"y0":824,"y1":874},"conf":0.9216,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":823,"y1":848},"font_size":36150000.0,"text":"We would like to acknowledge the valuable support provided by the OpenHands and Multi-SWE-bench teams in"},{"bbox":{"x0":140,"x1":782,"y0":846,"y1":871},"font_size":36150000.0,"text":"evaluating the SWE-bench Verifed and Multi-SWE-bench experimental results.i"}],"source":"layout det","text":"We would like to acknowledge the valuable support provided by the OpenHands and Multi-SWE-bench teams in evaluating the SWE-bench Verifed and Multi-SWE-bench experimental results.i"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1088,"y0":634,"y1":749},"conf":0.9581,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":443,"y1":560},"conf":0.958,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":276,"y1":368},"conf":0.9499,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":200,"y1":270},"conf":0.9421,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":143,"y1":193},"conf":0.9226,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":824,"y1":874},"conf":0.9216,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":372,"y0":775,"y1":807},"conf":0.9028,"label":"Title","label_id":0},{"bbox":{"x0":138,"x1":309,"y0":585,"y1":613},"conf":0.9015,"label":"Title","label_id":0},{"bbox":{"x0":139,"x1":303,"y0":394,"y1":423},"conf":0.8923,"label":"Title","label_id":0},{"bbox":{"x0":559,"x1":1086,"y0":67,"y1":92},"conf":0.8411,"label":"Abandon","label_id":2},{"bbox":{"x0":596,"x1":626,"y0":1480,"y1":1505},"conf":0.721,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1480],[625,1480],[625,1503],[599,1503]],"score":0.8567},{"poly":[[140,848],[782,846],[782,870],[140,871]],"score":0.787},{"poly":[[140,823],[1081,825],[1081,848],[140,846]],"score":0.7757},{"poly":[[140,774],[368,776],[367,804],[140,802]],"score":0.7413},{"poly":[[138,723],[494,721],[494,744],[138,746]],"score":0.8066},{"poly":[[140,701],[1083,701],[1083,723],[140,723]],"score":0.8291},{"poly":[[141,680],[1081,680],[1081,701],[141,701]],"score":0.7966},{"poly":[[140,657],[1083,658],[1083,681],[140,680]],"score":0.7181},{"poly":[[140,634],[1083,635],[1083,658],[140,657]],"score":0.7595},{"poly":[[140,587],[306,587],[306,610],[140,610]],"score":0.8156},{"poly":[[140,535],[1078,535],[1078,556],[140,556]],"score":0.8314},{"poly":[[141,512],[1081,512],[1081,533],[141,533]],"score":0.8303},{"poly":[[141,490],[1081,490],[1081,512],[141,512]],"score":0.804},{"poly":[[141,469],[1083,469],[1083,490],[141,490]],"score":0.8231},{"poly":[[138,439],[1083,444],[1083,472],[138,467]],"score":0.6529},{"poly":[[140,396],[299,396],[299,419],[140,419]],"score":0.8146},{"poly":[[140,343],[369,343],[369,365],[140,365]],"score":0.826},{"poly":[[140,322],[1081,322],[1081,345],[140,345]],"score":0.7413},{"poly":[[140,297],[1079,297],[1079,320],[140,320]],"score":0.7164},{"poly":[[140,277],[1081,277],[1081,299],[140,299]],"score":0.8203},{"poly":[[141,248],[241,248],[241,264],[141,264]],"score":0.9834},{"poly":[[138,223],[1081,221],[1081,244],[138,246]],"score":0.7372},{"poly":[[141,201],[1081,201],[1081,223],[141,223]],"score":0.8518},{"poly":[[140,165],[253,169],[252,192],[139,188]],"score":0.7479},{"poly":[[140,147],[1079,147],[1079,168],[140,168]],"score":0.8821},{"poly":[[918,67],[1083,71],[1082,93],[918,89]],"score":0.7852},{"poly":[[560,68],[662,68],[662,91],[560,91]],"score":0.8875}],"page_no":19,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":559,"x1":1085,"y0":67,"y1":92},"conf":0.8483,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":624,"y0":1480,"y1":1505},"conf":0.6918,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"21"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":139,"x1":259,"y0":142,"y1":169},"conf":0.8891,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":258,"y0":142,"y1":169},"font_size":1.085e-19,"text":"References"}],"source":"layout det","text":"References"},{"bbox":{"x0":148,"x1":1088,"y0":190,"y1":237},"conf":0.9193,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":151,"x1":1083,"y0":191,"y1":214},"font_size":1.085e-19,"text":"[1]Jacob Austin et al. Program Synthesis with Large Language Models. 2021. arXiv: 2108.07732 [cs.PL]. URL:"},{"bbox":{"x0":193,"x1":536,"y0":214,"y1":236},"font_size":1.085e-19,"text":"https://arxiv.org/abs/2108.07732."}],"source":"layout det","text":"[1]Jacob Austin et al. Program Synthesis with Large Language Models. 2021. arXiv: 2108.07732 [cs.PL]. URL:https://arxiv.org/abs/2108.07732."},{"bbox":{"x0":147,"x1":1086,"y0":240,"y1":285},"conf":0.9155,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":153,"x1":1083,"y0":238,"y1":262},"font_size":1.085e-19,"text":"[2]Yushi Bai et al. LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context"},{"bbox":{"x0":193,"x1":971,"y0":262,"y1":284},"font_size":1.085e-19,"text":"Multitasks. 2025. arXiv: 2412.15204 [cs.CL]. URL: https://arxiv.org/abs/2412.15204."}],"source":"layout det","text":"[2]Yushi Bai et al. LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks. 2025. arXiv: 2412.15204 [cs.CL]. URL: https://arxiv.org/abs/2412.15204."},{"bbox":{"x0":146,"x1":1087,"y0":288,"y1":333},"conf":0.9248,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":1084,"y0":284,"y1":312},"font_size":1.085e-19,"text":"[3]Victor Barres et al. $\\boldsymbol{\\tau^{2}}$ Bench: Evaluating Conversational Agents in a Dual-Control Environment. 2025. arXiv:"},{"bbox":{"x0":195,"x1":773,"y0":309,"y1":332},"font_size":1.085e-19,"text":"2506.07982 [cs.AI]. URL: https://arxiv.org/abs/2506.07982."}],"source":"layout det","text":"[3]Victor Barres et al. $\\boldsymbol{\\tau^{2}}$ Bench: Evaluating Conversational Agents in a Dual-Control Environment. 2025. arXiv:2506.07982 [cs.AI]. URL: https://arxiv.org/abs/2506.07982."},{"bbox":{"x0":146,"x1":1086,"y0":336,"y1":380},"conf":0.9272,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":1081,"y0":333,"y1":360},"font_size":1.085e-19,"text":"[4]Stella Biderman et al. “Lessons from the trenches on reproducible evaluation of language models”. In: arXiv"},{"bbox":{"x0":191,"x1":477,"y0":355,"y1":381},"font_size":1.085e-19,"text":"preprint arXiv:2405.14782 (2024)."}],"source":"layout det","text":"[4]Stella Biderman et al. “Lessons from the trenches on reproducible evaluation of language models”. In: arXiv preprint arXiv:2405.14782 (2024)."},{"bbox":{"x0":146,"x1":1088,"y0":383,"y1":448},"conf":0.9298,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":1083,"y0":381,"y1":408},"font_size":1.085e-19,"text":"[5]Federico Cassano et al. “MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Genera-"},{"bbox":{"x0":193,"x1":1081,"y0":404,"y1":427},"font_size":1.085e-19,"text":"tion”. In: IEEE Transactions on Software Engineering 49.7 (2023), pp. 3675–3691. DOI: 10.1109/TSE.2023."},{"bbox":{"x0":191,"x1":276,"y0":422,"y1":449},"font_size":1.085e-19,"text":"3267446."}],"source":"layout det","text":"[5]Federico Cassano et al. “MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation”. In: IEEE Transactions on Software Engineering 49.7 (2023), pp. 3675–3691. DOI: 10.1109/TSE.2023.3267446."},{"bbox":{"x0":147,"x1":1087,"y0":451,"y1":496},"conf":0.9194,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":1078,"y0":450,"y1":477},"font_size":1.085e-19,"text":"[6]Chen Chen et al. “ACEBench: Who Wins the Match Point in Tool Learning?” In: arXiv e-prints (2025), arXiv–"},{"bbox":{"x0":193,"x1":244,"y0":472,"y1":497},"font_size":1.085e-19,"text":"2501."}],"source":"layout det","text":"[6]Chen Chen et al. “ACEBench: Who Wins the Match Point in Tool Learning?” In: arXiv e-prints (2025), arXiv–2501."},{"bbox":{"x0":147,"x1":1083,"y0":499,"y1":544},"conf":0.9154,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":1083,"y0":498,"y1":525},"font_size":1.085e-19,"text":"[7]Mark Chen et al. “Evaluating Large Language Models Trained on Code”. In: (2021). arXiv: 2107.03374"},{"bbox":{"x0":196,"x1":278,"y0":521,"y1":544},"font_size":1.085e-19,"text":"[cs.LG]."}],"source":"layout det","text":"[7]Mark Chen et al. “Evaluating Large Language Models Trained on Code”. In: (2021). arXiv: 2107.03374[cs.LG]."},{"bbox":{"x0":147,"x1":1084,"y0":547,"y1":592},"conf":0.9146,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":150,"x1":1081,"y0":544,"y1":571},"font_size":1.085e-19,"text":"[8]Peter Clark et al. “Think you have solved question answering? try arc, the ai2 reasoning challenge”. In: arXiv"},{"bbox":{"x0":191,"x1":477,"y0":568,"y1":592},"font_size":1.085e-19,"text":"preprint arXiv:1803.05457 (2018)."}],"source":"layout det","text":"[8]Peter Clark et al. “Think you have solved question answering? try arc, the ai2 reasoning challenge”. In: arXiv preprint arXiv:1803.05457 (2018)."},{"bbox":{"x0":145,"x1":1086,"y0":595,"y1":640},"conf":0.9146,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":151,"x1":1083,"y0":596,"y1":619},"font_size":1.085e-19,"text":"[9]Karl Cobbe et al. Training Verifers to Solve Math Word Problems. 2021. arXiv: 2110.14168 [cs.LG]. URL:i"},{"bbox":{"x0":193,"x1":536,"y0":617,"y1":640},"font_size":1.085e-19,"text":"https://arxiv.org/abs/2110.14168."}],"source":"layout det","text":"[9]Karl Cobbe et al. Training Verifers to Solve Math Word Problems. 2021. arXiv: 2110.14168 [cs.LG]. URL:i https://arxiv.org/abs/2110.14168."},{"bbox":{"x0":140,"x1":1089,"y0":643,"y1":686},"conf":0.9131,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":642,"y1":670},"font_size":1.085e-19,"text":"[10]DeepSeek-AI. DeepSeek-V3 Technical Report. 2024. arXiv: 2412.19437 [cs.CL]. URL: https://arxiv."},{"bbox":{"x0":195,"x1":391,"y0":665,"y1":686},"font_size":1.085e-19,"text":"org/abs/2412.19437."}],"source":"layout det","text":"[10]DeepSeek-AI. DeepSeek-V3 Technical Report. 2024. arXiv: 2412.19437 [cs.CL]. URL: https://arxiv.org/abs/2412.19437."},{"bbox":{"x0":138,"x1":1086,"y0":690,"y1":735},"conf":0.9128,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":688,"y1":714},"font_size":1.085e-19,"text":"[11]Mostafa Dehghani et al. “Scaling vision transformers to 22 billion parameters”. In: International conference on"},{"bbox":{"x0":193,"x1":584,"y0":713,"y1":734},"font_size":1.085e-19,"text":"machine learning. PMLR. 2023, pp. 7480–7512."}],"source":"layout det","text":"[11]Mostafa Dehghani et al. “Scaling vision transformers to 22 billion parameters”. In: International conference on machine learning. PMLR. 2023, pp. 7480–7512."},{"bbox":{"x0":137,"x1":1088,"y0":738,"y1":784},"conf":0.9113,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":736,"y1":761},"font_size":1.085e-19,"text":"[12]Guanting Dong et al. Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large"},{"bbox":{"x0":193,"x1":1031,"y0":761,"y1":782},"font_size":1.085e-19,"text":"Language Models. 2024. arXiv: 2406.13542 [cs.CL]. URL: https://arxiv.org/abs/2406.13542."}],"source":"layout det","text":"[12]Guanting Dong et al. Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models. 2024. arXiv: 2406.13542 [cs.CL]. URL: https://arxiv.org/abs/2406.13542."},{"bbox":{"x0":138,"x1":1087,"y0":787,"y1":831},"conf":0.9083,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":784,"y1":808},"font_size":1.085e-19,"text":"[13]Xinrun Du et al. “Supergpqa: Scaling llm evaluation across 285 graduate disciplines”. In: arXiv preprint"},{"bbox":{"x0":193,"x1":409,"y0":807,"y1":828},"font_size":1.085e-19,"text":"arXiv:2502.14739 (2025)."}],"source":"layout det","text":"[13]Xinrun Du et al. “Supergpqa: Scaling llm evaluation across 285 graduate disciplines”. In: arXiv preprint arXiv:2502.14739 (2025)."},{"bbox":{"x0":137,"x1":1088,"y0":834,"y1":879},"conf":0.9213,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":832,"y1":856},"font_size":1.085e-19,"text":"[14]Dheeru Dua et al. “DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Para-"},{"bbox":{"x0":195,"x1":1079,"y0":855,"y1":878},"font_size":1.085e-19,"text":"graphs”. In: CoRR abs/1903.00161 (2019). arXiv: 1903.00161. URL: http://arxiv.org/abs/1903.00161"}],"source":"layout det","text":"[14]Dheeru Dua et al. “DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs”. In: CoRR abs/1903.00161 (2019). arXiv: 1903.00161. URL: http://arxiv.org/abs/1903.00161"},{"bbox":{"x0":137,"x1":1085,"y0":882,"y1":926},"conf":0.9152,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":879,"y1":906},"font_size":1.085e-19,"text":"[15]Kazuki Fujii et al. Rewriting Pre-Training Data Boosts LLM Performance in Math and Code. 2025. arXiv:"},{"bbox":{"x0":196,"x1":772,"y0":901,"y1":922},"font_size":1.085e-19,"text":"2505.02881 [cs.LG]. URL: https://arxiv.org/abs/2505.02881."}],"source":"layout det","text":"[15]Kazuki Fujii et al. Rewriting Pre-Training Data Boosts LLM Performance in Math and Code. 2025. arXiv:2505.02881 [cs.LG]. URL: https://arxiv.org/abs/2505.02881."},{"bbox":{"x0":229,"x1":971,"y0":928,"y1":953},"conf":0.4976,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":188,"x1":973,"y0":922,"y1":952},"font_size":1.085e-19,"text":"l Gauthier. Aider LLM Leaderboards. https://aider.chat/docs/leaderboards/. 2025."}],"source":"layout det","text":"l Gauthier. Aider LLM Leaderboards. https://aider.chat/docs/leaderboards/. 2025."},{"bbox":{"x0":138,"x1":996,"y0":954,"y1":979},"conf":0.8935,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":990,"y0":952,"y1":977},"font_size":1.085e-19,"text":"[17]Aryo Pradipta Gema et al. “Are we done with mmlu?” In: arXiv preprint arXiv:2406.04127 (2024)."}],"source":"layout det","text":"[17]Aryo Pradipta Gema et al. “Are we done with mmlu?” In: arXiv preprint arXiv:2406.04127 (2024)."},{"bbox":{"x0":137,"x1":1085,"y0":981,"y1":1025},"conf":0.9155,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":978,"y1":1003},"font_size":1.085e-19,"text":"[18]Alex Gu et al. “Cruxeval: A benchmark for code reasoning, understanding and execution”. In: arXiv preprint"},{"bbox":{"x0":191,"x1":408,"y0":1000,"y1":1025},"font_size":1.085e-19,"text":"arXiv:2401.03065 (2024)."}],"source":"layout det","text":"[18]Alex Gu et al. “Cruxeval: A benchmark for code reasoning, understanding and execution”. In: arXiv preprint arXiv:2401.03065 (2024)."},{"bbox":{"x0":137,"x1":1085,"y0":1028,"y1":1073},"conf":0.9175,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1026,"y1":1051},"font_size":1.085e-19,"text":"[19]Daya Guo et al. “Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning”. In: arXiv"},{"bbox":{"x0":191,"x1":476,"y0":1048,"y1":1073},"font_size":1.085e-19,"text":"preprint arXiv:2501.12948 (2025)."}],"source":"layout det","text":"[19]Daya Guo et al. “Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning”. In: arXiv preprint arXiv:2501.12948 (2025)."},{"bbox":{"x0":137,"x1":1085,"y0":1076,"y1":1121},"conf":0.9224,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1069,"y1":1101},"font_size":1.085e-19,"text":"[20]Zhicheng Guo et al. “StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large"},{"bbox":{"x0":193,"x1":715,"y0":1097,"y1":1119},"font_size":1.085e-19,"text":"Language Models”. In: arXiv preprint arXiv:2403.07714 (2025)."}],"source":"layout det","text":"[20]Zhicheng Guo et al. “StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models”. In: arXiv preprint arXiv:2403.07714 (2025)."},{"bbox":{"x0":136,"x1":1086,"y0":1124,"y1":1168},"conf":0.9111,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1120,"y1":1147},"font_size":1.085e-19,"text":"[21]Aaron Harlap et al. “Pipedream: Fast and effcient pipeline parallel dnn training”. In: arXiv preprinti"},{"bbox":{"x0":195,"x1":411,"y0":1143,"y1":1165},"font_size":1.085e-19,"text":"arXiv:1806.03377 (2018)."}],"source":"layout det","text":"[21]Aaron Harlap et al. “Pipedream: Fast and effcient pipeline parallel dnn training”. In: arXiv preprinti arXiv:1806.03377 (2018)."},{"bbox":{"x0":136,"x1":1086,"y0":1171,"y1":1215},"conf":0.8998,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1168,"y1":1195},"font_size":1.085e-19,"text":"[22]Y He et al. “Chinese simpleqa: A chinese factuality evaluation for large language models, 2024a”. In: URL"},{"bbox":{"x0":195,"x1":487,"y0":1191,"y1":1213},"font_size":1.085e-19,"text":"https://arxiv. org/abs/2411.07140 ()."}],"source":"layout det","text":"[22]Y He et al. “Chinese simpleqa: A chinese factuality evaluation for large language models, 2024a”. In: URL https://arxiv. org/abs/2411.07140 ()."},{"bbox":{"x0":136,"x1":1088,"y0":1218,"y1":1264},"conf":0.8283,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1216,"y1":1241},"font_size":1.085e-19,"text":"[23]Dan Hendrycks et al. “Measuring massive multitask language understanding”. In: arXiv preprint"},{"bbox":{"x0":193,"x1":407,"y0":1239,"y1":1262},"font_size":1.085e-19,"text":"arXiv:2009.03300 (2020)."}],"source":"layout det","text":"[23]Dan Hendrycks et al. “Measuring massive multitask language understanding”. In: arXiv preprint arXiv:2009.03300 (2020)."},{"bbox":{"x0":136,"x1":1092,"y0":1266,"y1":1314},"conf":0.4263,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1264,"y1":1290},"font_size":1.085e-19,"text":"[24]Dan Hendrycks et al. Measuring Mathematical Problem Solving With the MATH Dataset. 2021. arXiv: 2103."},{"bbox":{"x0":193,"x1":722,"y0":1287,"y1":1310},"font_size":1.085e-19,"text":"03874 [cs.LG]. URL: https://arxiv.org/abs/2103.03874."}],"source":"layout det","text":"[24]Dan Hendrycks et al. Measuring Mathematical Problem Solving With the MATH Dataset. 2021. arXiv: 2103.03874 [cs.LG]. URL: https://arxiv.org/abs/2103.03874."},{"bbox":{"x0":328,"x1":1068,"y0":1313,"y1":1358},"conf":0.6267,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":191,"x1":1083,"y0":1313,"y1":1335},"font_size":1.085e-19,"text":"al. “Minicpm: Unveiling the potential of small language models with scalable training strategies"},{"bbox":{"x0":193,"x1":552,"y0":1335,"y1":1358},"font_size":1.085e-19,"text":"t arXiv:2404.06395 (2024)."}],"source":"layout det","text":"al. “Minicpm: Unveiling the potential of small language models with scalable training strategies t arXiv:2404.06395 (2024)."},{"bbox":{"x0":138,"x1":1064,"y0":1360,"y1":1387},"conf":0.4252,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1058,"y0":1360,"y1":1386},"font_size":1.085e-19,"text":"[26]Jiaxin Huang et al. “Large language models can self-improve”. In: arXiv preprint arXiv:2210.11610 (2022)."}],"source":"layout det","text":"[26]Jiaxin Huang et al. “Large language models can self-improve”. In: arXiv preprint arXiv:2210.11610 (2022)."},{"bbox":{"x0":138,"x1":1089,"y0":1387,"y1":1434},"conf":0.8421,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1384,"y1":1412},"font_size":1.085e-19,"text":"[27]Siming Huang et al. OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models. 2025. arXiv:"},{"bbox":{"x0":195,"x1":775,"y0":1406,"y1":1431},"font_size":1.085e-19,"text":"2411.04905 [cs.CL]. URL: https://arxiv.org/abs/2411.04905."}],"source":"layout det","text":"[27]Siming Huang et al. OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models. 2025. arXiv:2411.04905 [cs.CL]. URL: https://arxiv.org/abs/2411.04905."}],"formula_dets":[{"bbox":{"x0":351,"x1":374,"y0":287,"y1":307},"conf":0.732,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":146,"x1":1088,"y0":383,"y1":448},"conf":0.9298,"label":"Text","label_id":1},{"bbox":{"x0":146,"x1":1086,"y0":336,"y1":380},"conf":0.9272,"label":"Text","label_id":1},{"bbox":{"x0":146,"x1":1087,"y0":288,"y1":333},"conf":0.9248,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1085,"y0":1076,"y1":1121},"conf":0.9224,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":834,"y1":879},"conf":0.9213,"label":"Text","label_id":1},{"bbox":{"x0":147,"x1":1087,"y0":451,"y1":496},"conf":0.9194,"label":"Text","label_id":1},{"bbox":{"x0":148,"x1":1088,"y0":190,"y1":237},"conf":0.9193,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1085,"y0":1028,"y1":1073},"conf":0.9175,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1085,"y0":981,"y1":1025},"conf":0.9155,"label":"Text","label_id":1},{"bbox":{"x0":147,"x1":1086,"y0":240,"y1":285},"conf":0.9155,"label":"Text","label_id":1},{"bbox":{"x0":147,"x1":1083,"y0":499,"y1":544},"conf":0.9154,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1085,"y0":882,"y1":926},"conf":0.9152,"label":"Text","label_id":1},{"bbox":{"x0":145,"x1":1086,"y0":595,"y1":640},"conf":0.9146,"label":"Text","label_id":1},{"bbox":{"x0":147,"x1":1084,"y0":547,"y1":592},"conf":0.9146,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":1089,"y0":643,"y1":686},"conf":0.9131,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":690,"y1":735},"conf":0.9128,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":738,"y1":784},"conf":0.9113,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":1124,"y1":1168},"conf":0.9111,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":787,"y1":831},"conf":0.9083,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":1171,"y1":1215},"conf":0.8998,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":996,"y0":954,"y1":979},"conf":0.8935,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":259,"y0":142,"y1":169},"conf":0.8891,"label":"Title","label_id":0},{"bbox":{"x0":559,"x1":1085,"y0":67,"y1":92},"conf":0.8483,"label":"Abandon","label_id":2},{"bbox":{"x0":138,"x1":1089,"y0":1387,"y1":1434},"conf":0.8421,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":1218,"y1":1264},"conf":0.8283,"label":"Text","label_id":1},{"bbox":{"x0":596,"x1":624,"y0":1480,"y1":1505},"conf":0.6918,"label":"Abandon","label_id":2},{"bbox":{"x0":328,"x1":1068,"y0":1313,"y1":1358},"conf":0.6267,"label":"Text","label_id":1},{"bbox":{"x0":303,"x1":1045,"y0":1361,"y1":1385},"conf":0.5619,"label":"Text","label_id":1},{"bbox":{"x0":328,"x1":1070,"y0":1266,"y1":1310},"conf":0.5175,"label":"Text","label_id":1},{"bbox":{"x0":229,"x1":971,"y0":928,"y1":953},"conf":0.4976,"label":"Text","label_id":1},{"bbox":{"x0":328,"x1":1070,"y0":547,"y1":592},"conf":0.4486,"label":"Text","label_id":1},{"bbox":{"x0":328,"x1":1070,"y0":595,"y1":640},"conf":0.4371,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1092,"y0":1266,"y1":1314},"conf":0.4263,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1064,"y0":1360,"y1":1387},"conf":0.4252,"label":"Text","label_id":1},{"bbox":{"x0":328,"x1":1070,"y0":1218,"y1":1262},"conf":0.3687,"label":"Text","label_id":1},{"bbox":{"x0":328,"x1":1070,"y0":499,"y1":543},"conf":0.2824,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8691},{"poly":[[195,1406],[775,1407],[775,1431],[195,1429]],"score":0.7588},{"poly":[[191,1384],[1083,1386],[1083,1409],[191,1407]],"score":0.7615},{"poly":[[140,1384],[181,1384],[181,1412],[140,1412]],"score":0.8564},{"poly":[[191,1361],[1058,1361],[1058,1383],[191,1383]],"score":0.8557},{"poly":[[140,1360],[183,1360],[183,1386],[140,1386]],"score":0.8258},{"poly":[[193,1335],[552,1335],[552,1358],[193,1358]],"score":0.7223},{"poly":[[191,1313],[1083,1313],[1083,1335],[191,1335]],"score":0.8808},{"poly":[[140,1312],[185,1312],[185,1338],[140,1338]],"score":0.7453},{"poly":[[193,1287],[722,1287],[722,1310],[193,1310]],"score":0.7105},{"poly":[[191,1266],[1081,1266],[1081,1287],[191,1287]],"score":0.8619},{"poly":[[140,1264],[183,1264],[183,1290],[140,1290]],"score":0.8204},{"poly":[[193,1239],[407,1239],[407,1262],[193,1262]],"score":0.718},{"poly":[[191,1218],[1083,1218],[1083,1241],[191,1241]],"score":0.7378},{"poly":[[140,1216],[183,1216],[183,1241],[140,1241]],"score":0.8994},{"poly":[[195,1191],[487,1191],[487,1213],[195,1213]],"score":0.8063},{"poly":[[191,1170],[1081,1170],[1081,1193],[191,1193]],"score":0.7546},{"poly":[[140,1168],[183,1168],[183,1195],[140,1195]],"score":0.8778},{"poly":[[195,1143],[411,1143],[411,1165],[195,1165]],"score":0.7835},{"poly":[[191,1122],[1083,1122],[1083,1145],[191,1145]],"score":0.7774},{"poly":[[140,1120],[183,1120],[183,1147],[140,1147]],"score":0.8333},{"poly":[[193,1097],[715,1097],[715,1119],[193,1119]],"score":0.8504},{"poly":[[188,1069],[1083,1073],[1083,1101],[188,1097]],"score":0.7054},{"poly":[[140,1072],[185,1072],[185,1099],[140,1099]],"score":0.7714},{"poly":[[191,1049],[476,1048],[476,1071],[191,1073]],"score":0.7622},{"poly":[[190,1028],[1081,1028],[1081,1049],[190,1049]],"score":0.8634},{"poly":[[140,1026],[188,1026],[188,1051],[140,1051]],"score":0.7948},{"poly":[[191,1000],[408,1002],[407,1025],[191,1023]],"score":0.7644},{"poly":[[191,980],[1083,980],[1083,1003],[191,1003]],"score":0.7226},{"poly":[[140,978],[183,978],[183,1003],[140,1003]],"score":0.9338},{"poly":[[195,954],[990,954],[990,975],[195,975]],"score":0.8595},{"poly":[[140,952],[183,952],[183,977],[140,977]],"score":0.9355},{"poly":[[188,924],[973,922],[973,950],[188,952]],"score":0.6718},{"poly":[[140,926],[183,926],[183,952],[140,952]],"score":0.8216},{"poly":[[196,901],[772,901],[772,922],[196,922]],"score":0.7202},{"poly":[[193,881],[1084,881],[1084,903],[193,903]],"score":0.8618},{"poly":[[140,879],[186,879],[186,906],[140,906]],"score":0.8059},{"poly":[[195,855],[1079,855],[1079,878],[195,878]],"score":0.7105},{"poly":[[193,832],[1083,832],[1083,855],[193,855]],"score":0.7161},{"poly":[[140,832],[183,832],[183,856],[140,856]],"score":0.8885},{"poly":[[193,807],[409,807],[409,828],[193,828]],"score":0.8147},{"poly":[[191,785],[1083,785],[1083,808],[191,808]],"score":0.7219},{"poly":[[140,784],[185,784],[185,808],[140,808]],"score":0.7956},{"poly":[[193,761],[1031,761],[1031,782],[193,782]],"score":0.8261},{"poly":[[190,736],[1081,738],[1081,761],[190,759]],"score":0.7316},{"poly":[[141,739],[183,739],[183,759],[141,759]],"score":0.9274},{"poly":[[193,713],[584,713],[584,734],[193,734]],"score":0.8205},{"poly":[[190,688],[1083,690],[1083,713],[190,711]],"score":0.7926},{"poly":[[140,688],[185,688],[185,714],[140,714]],"score":0.7734},{"poly":[[195,665],[391,665],[391,686],[195,686]],"score":0.8202},{"poly":[[191,644],[1084,644],[1084,665],[191,665]],"score":0.863},{"poly":[[140,642],[195,642],[195,670],[140,670]],"score":0.6952},{"poly":[[193,617],[536,617],[536,640],[193,640]],"score":0.7425},{"poly":[[193,596],[1083,596],[1083,617],[193,617]],"score":0.8426},{"poly":[[151,596],[186,596],[186,619],[151,619]],"score":0.8459},{"poly":[[191,569],[477,568],[477,591],[191,592]],"score":0.7719},{"poly":[[190,544],[1081,546],[1081,569],[190,568]],"score":0.8387},{"poly":[[150,546],[188,546],[188,571],[150,571]],"score":0.7656},{"poly":[[196,521],[278,521],[278,544],[196,544]],"score":0.7595},{"poly":[[190,500],[1083,500],[1083,521],[190,521]],"score":0.9214},{"poly":[[150,498],[186,498],[186,525],[150,525]],"score":0.7851},{"poly":[[193,472],[244,472],[244,497],[193,497]],"score":0.792},{"poly":[[193,450],[1078,450],[1078,472],[193,472]],"score":0.7809},{"poly":[[150,450],[185,450],[185,477],[150,477]],"score":0.7999},{"poly":[[192,422],[276,426],[275,449],[191,445]],"score":0.8034},{"poly":[[193,404],[1081,404],[1081,427],[193,427]],"score":0.717},{"poly":[[191,383],[1083,383],[1083,404],[191,404]],"score":0.8353},{"poly":[[150,381],[186,381],[186,408],[150,408]],"score":0.7975},{"poly":[[191,358],[477,355],[477,378],[191,381]],"score":0.7424},{"poly":[[191,335],[1081,335],[1081,356],[191,356]],"score":0.8395},{"poly":[[150,333],[185,333],[185,360],[150,360]],"score":0.7548},{"poly":[[195,309],[773,309],[773,332],[195,332]],"score":0.7205},{"poly":[[193,284],[1084,285],[1084,309],[193,307]],"score":0.7498},{"poly":[[150,285],[188,285],[188,312],[150,312]],"score":0.7634},{"poly":[[193,262],[971,262],[971,284],[193,284]],"score":0.8579},{"poly":[[193,238],[1083,239],[1083,262],[193,261]],"score":0.7443},{"poly":[[153,241],[181,241],[181,262],[153,262]],"score":0.8882},{"poly":[[193,214],[536,214],[536,236],[193,236]],"score":0.8948},{"poly":[[188,191],[1083,191],[1083,214],[188,214]],"score":0.7674},{"poly":[[151,193],[198,193],[198,214],[151,214]],"score":0.8109},{"poly":[[142,142],[258,145],[257,169],[141,165]],"score":0.8265},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7619},{"poly":[[560,64],[664,64],[664,92],[560,92]],"score":0.8329}],"page_no":20,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":559,"x1":1085,"y0":67,"y1":92},"conf":0.8553,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":597,"x1":626,"y0":1481,"y1":1505},"conf":0.7514,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"22"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":139,"x1":1087,"y0":145,"y1":191},"conf":0.9057,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":147,"y1":168},"font_size":2.689e-39,"text":"[28]Yanping Huang et al. “Gpipe: Effcient training of giant neural networks using pipeline parallelism”. In: Advancesi"},{"bbox":{"x0":195,"x1":614,"y0":168,"y1":191},"font_size":2.689e-39,"text":"in neural information processing systems 32 (2019)."}],"source":"layout det","text":"[28]Yanping Huang et al. “Gpipe: Effcient training of giant neural networks using pipeline parallelism”. In: Advancesi in neural information processing systems 32 (2019)."},{"bbox":{"x0":139,"x1":1088,"y0":194,"y1":239},"conf":0.8924,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":191,"y1":216},"font_size":2.689e-39,"text":"[29]Yuzhen Huang et al. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models."},{"bbox":{"x0":193,"x1":880,"y0":210,"y1":239},"font_size":2.689e-39,"text":"2023. arXiv: 2305.08322 [cs.CL]. URL: https://arxiv.org/abs/2305.08322."}],"source":"layout det","text":"[29]Yuzhen Huang et al. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models.2023. arXiv: 2305.08322 [cs.CL]. URL: https://arxiv.org/abs/2305.08322."},{"bbox":{"x0":138,"x1":1087,"y0":242,"y1":287},"conf":0.8971,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":239,"y1":264},"font_size":2.689e-39,"text":"[30]Alon Jacovi et al. The FACTS Grounding Leaderboard: Benchmarking LLMs’ Ability to Ground Responses to"},{"bbox":{"x0":195,"x1":1024,"y0":262,"y1":285},"font_size":2.689e-39,"text":"Long-Form Input. 2025. arXiv: 2501.03200 [cs.CL]. URL: https://arxiv.org/abs/2501.03200."}],"source":"layout det","text":"[30]Alon Jacovi et al. The FACTS Grounding Leaderboard: Benchmarking LLMs’ Ability to Ground Responses to Long-Form Input. 2025. arXiv: 2501.03200 [cs.CL]. URL: https://arxiv.org/abs/2501.03200."},{"bbox":{"x0":139,"x1":1087,"y0":290,"y1":334},"conf":0.9176,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":289,"y1":312},"font_size":2.689e-39,"text":"[31]Naman Jain et al. “Livecodebench: Holistic and contamination free evaluation of large language models for"},{"bbox":{"x0":193,"x1":605,"y0":309,"y1":330},"font_size":2.689e-39,"text":"code”. In: arXiv preprint arXiv:2403.07974 (2024)."}],"source":"layout det","text":"[31]Naman Jain et al. “Livecodebench: Holistic and contamination free evaluation of large language models for code”. In: arXiv preprint arXiv:2403.07974 (2024)."},{"bbox":{"x0":137,"x1":1086,"y0":337,"y1":402},"conf":0.9278,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":335,"y1":360},"font_size":2.689e-39,"text":"[32]Carlos E Jimenez et al. “SWE-bench: Can Language Models Resolve Real-world Github Issues?” In: The Twelfth"},{"bbox":{"x0":195,"x1":1079,"y0":358,"y1":380},"font_size":2.689e-39,"text":"International Conference on Learning Representations. 2024. URL: https://openreview.net/forum?id="},{"bbox":{"x0":196,"x1":306,"y0":381,"y1":399},"font_size":2.689e-39,"text":"VTF8yNQM66."}],"source":"layout det","text":"[32]Carlos E Jimenez et al. “SWE-bench: Can Language Models Resolve Real-world Github Issues?” In: The Twelfth International Conference on Learning Representations. 2024. URL: https://openreview.net/forum?id=VTF8yNQM66."},{"bbox":{"x0":137,"x1":1086,"y0":405,"y1":451},"conf":0.9191,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":404,"y1":431},"font_size":2.689e-39,"text":"[33]Keller Jordan et al. Muon: An optimizer for hidden layers in neural networks. 2024. URL: https : / /"},{"bbox":{"x0":196,"x1":557,"y0":427,"y1":449},"font_size":2.689e-39,"text":"kellerjordan.github.io/posts/muon/."}],"source":"layout det","text":"[33]Keller Jordan et al. Muon: An optimizer for hidden layers in neural networks. 2024. URL: https : / /kellerjordan.github.io/posts/muon/."},{"bbox":{"x0":137,"x1":1088,"y0":453,"y1":499},"conf":0.9263,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":450,"y1":477},"font_size":2.689e-39,"text":"[34]Mandar Joshi et al. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension."},{"bbox":{"x0":193,"x1":878,"y0":472,"y1":497},"font_size":2.689e-39,"text":"2017. arXiv: 1705.03551 [cs.CL]. URL: https://arxiv.org/abs/1705.03551."}],"source":"layout det","text":"[34]Mandar Joshi et al. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.2017. arXiv: 1705.03551 [cs.CL]. URL: https://arxiv.org/abs/1705.03551."},{"bbox":{"x0":140,"x1":1084,"y0":501,"y1":526},"conf":0.9016,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":498,"y1":525},"font_size":2.689e-39,"text":"[35]Kimi Team. “Kimi k1. 5: Scaling reinforcement learning with llms”. In: arXiv preprint arXiv:2501.12599 (2025)."}],"source":"layout det","text":"[35]Kimi Team. “Kimi k1. 5: Scaling reinforcement learning with llms”. In: arXiv preprint arXiv:2501.12599 (2025)."},{"bbox":{"x0":137,"x1":1086,"y0":527,"y1":593},"conf":0.9397,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":525,"y1":549},"font_size":2.689e-39,"text":"[36]Diederik P. Kingma and Jimmy Ba. “Adam: A Method for Stochastic Optimization”. In: 3rd International"},{"bbox":{"x0":195,"x1":1083,"y0":548,"y1":569},"font_size":2.689e-39,"text":"Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track"},{"bbox":{"x0":193,"x1":1046,"y0":568,"y1":592},"font_size":2.689e-39,"text":"Proceedings. Ed. by Yoshua Bengio and Yann LeCun. 2015. URL: http://arxiv.org/abs/1412.6980."}],"source":"layout det","text":"[36]Diederik P. Kingma and Jimmy Ba. “Adam: A Method for Stochastic Optimization”. In: 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings. Ed. by Yoshua Bengio and Yann LeCun. 2015. URL: http://arxiv.org/abs/1412.6980."},{"bbox":{"x0":137,"x1":1088,"y0":596,"y1":641},"conf":0.9242,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1084,"y0":596,"y1":617},"font_size":2.689e-39,"text":"[37]Satyapriya Krishna et al. Fact, Fetch, and Reason: A Unifed Evaluation of Retrieval-Augmented Generation.i"},{"bbox":{"x0":195,"x1":878,"y0":615,"y1":640},"font_size":2.689e-39,"text":"2025. arXiv: 2409.12941 [cs.CL]. URL: https://arxiv.org/abs/2409.12941."}],"source":"layout det","text":"[37]Satyapriya Krishna et al. Fact, Fetch, and Reason: A Unifed Evaluation of Retrieval-Augmented Generation.i 2025. arXiv: 2409.12941 [cs.CL]. URL: https://arxiv.org/abs/2409.12941."},{"bbox":{"x0":138,"x1":1086,"y0":644,"y1":688},"conf":0.9148,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":642,"y1":667},"font_size":2.689e-39,"text":"[38]Joel Lamy-Poirier. “Breadth-frst pipeline parallelism”. In: Proceedings of Machine Learning and Systems 5i"},{"bbox":{"x0":195,"x1":348,"y0":665,"y1":688},"font_size":2.689e-39,"text":"(2023), pp. 48–67."}],"source":"layout det","text":"[38]Joel Lamy-Poirier. “Breadth-frst pipeline parallelism”. In: Proceedings of Machine Learning and Systems 5i(2023), pp. 48–67."},{"bbox":{"x0":138,"x1":1088,"y0":691,"y1":736},"conf":0.9085,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":690,"y1":714},"font_size":2.689e-39,"text":"[39]Dmitry Lepikhin et al. “Gshard: Scaling giant models with conditional computation and automatic sharding”. In:"},{"bbox":{"x0":191,"x1":526,"y0":711,"y1":736},"font_size":2.689e-39,"text":"arXiv preprint arXiv:2006.16668 (2020)."}],"source":"layout det","text":"[39]Dmitry Lepikhin et al. “Gshard: Scaling giant models with conditional computation and automatic sharding”. In:arXiv preprint arXiv:2006.16668 (2020)."},{"bbox":{"x0":138,"x1":1088,"y0":739,"y1":784},"conf":0.9068,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1084,"y0":738,"y1":759},"font_size":2.689e-39,"text":"[40]Haonan Li et al. CMMLU: Measuring massive multitask language understanding in Chinese. 2024. arXiv:"},{"bbox":{"x0":195,"x1":775,"y0":761,"y1":782},"font_size":2.689e-39,"text":"2306.09212 [cs.CL]. URL: https://arxiv.org/abs/2306.09212."}],"source":"layout det","text":"[40]Haonan Li et al. CMMLU: Measuring massive multitask language understanding in Chinese. 2024. arXiv:2306.09212 [cs.CL]. URL: https://arxiv.org/abs/2306.09212."},{"bbox":{"x0":137,"x1":1086,"y0":787,"y1":832},"conf":0.9085,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":784,"y1":810},"font_size":2.689e-39,"text":"[41]Jia Li et al. “Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems"},{"bbox":{"x0":193,"x1":690,"y0":808,"y1":830},"font_size":2.689e-39,"text":"and solutions”. In: Hugging Face repository 13.9 (2024), p. 9."}],"source":"layout det","text":"[41]Jia Li et al. “Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions”. In: Hugging Face repository 13.9 (2024), p. 9."},{"bbox":{"x0":137,"x1":1088,"y0":835,"y1":878},"conf":0.9199,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":832,"y1":856},"font_size":2.689e-39,"text":"[42]Tianle Li et al. “From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline”."},{"bbox":{"x0":195,"x1":554,"y0":855,"y1":878},"font_size":2.689e-39,"text":"In: arXiv preprint arXiv:2406.11939 (2024)."}],"source":"layout det","text":"[42]Tianle Li et al. “From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline”.In: arXiv preprint arXiv:2406.11939 (2024)."},{"bbox":{"x0":137,"x1":1088,"y0":882,"y1":927},"conf":0.9248,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":879,"y1":904},"font_size":2.689e-39,"text":"[43]Bill Yuchen Lin et al. ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning. 2025. arXiv: 2502."},{"bbox":{"x0":195,"x1":720,"y0":903,"y1":926},"font_size":2.689e-39,"text":"01100 [cs.AI]. URL: https://arxiv.org/abs/2502.01100."}],"source":"layout det","text":"[43]Bill Yuchen Lin et al. ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning. 2025. arXiv: 2502.01100 [cs.AI]. URL: https://arxiv.org/abs/2502.01100."},{"bbox":{"x0":136,"x1":1088,"y0":930,"y1":973},"conf":0.918,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":927,"y1":954},"font_size":2.689e-39,"text":"[44]Aixin Liu et al. “Deepseek-v2: A strong, economical, and effcient mixture-of-experts language model”. In:i"},{"bbox":{"x0":193,"x1":526,"y0":949,"y1":970},"font_size":2.689e-39,"text":"arXiv preprint arXiv:2405.04434 (2024)."}],"source":"layout det","text":"[44]Aixin Liu et al. “Deepseek-v2: A strong, economical, and effcient mixture-of-experts language model”. In:i arXiv preprint arXiv:2405.04434 (2024)."},{"bbox":{"x0":137,"x1":1085,"y0":976,"y1":1022},"conf":0.9199,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":975,"y1":1000},"font_size":2.689e-39,"text":"[45]Jiawei Liu et al. “Is your code generated by chatgpt really correct? rigorous evaluation of large language models"},{"bbox":{"x0":193,"x1":1053,"y0":998,"y1":1020},"font_size":2.689e-39,"text":"for code generation”. In: Advances in Neural Information Processing Systems 36 (2023), pp. 21558–21572."}],"source":"layout det","text":"[45]Jiawei Liu et al. “Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation”. In: Advances in Neural Information Processing Systems 36 (2023), pp. 21558–21572."},{"bbox":{"x0":254,"x1":995,"y0":1024,"y1":1048},"conf":0.7523,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":191,"x1":1008,"y0":1025,"y1":1046},"font_size":2.689e-39,"text":"an Liu et al. “Muon is scalable for LLM training”. In: arXiv preprint arXiv:2502.16982 (2025"}],"source":"layout det","text":"an Liu et al. “Muon is scalable for LLM training”. In: arXiv preprint arXiv:2502.16982 (2025"},{"bbox":{"x0":136,"x1":1087,"y0":1049,"y1":1138},"conf":0.9412,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1046,"y1":1073},"font_size":2.689e-39,"text":"[47]Ziming Liu et al. “Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training"},{"bbox":{"x0":193,"x1":1083,"y0":1071,"y1":1094},"font_size":2.689e-39,"text":"Effciency”. In: Proceedings of the International Conference for High Performance Computing, Networking,i"},{"bbox":{"x0":193,"x1":1081,"y0":1092,"y1":1115},"font_size":2.689e-39,"text":"Storage and Analysis. SC ’23. ACM, Nov. 2023, pp. 1–13. DOI: 10.1145/3581784.3607073. URL: http:"},{"bbox":{"x0":195,"x1":577,"y0":1115,"y1":1137},"font_size":2.689e-39,"text":"//dx.doi.org/10.1145/3581784.3607073."}],"source":"layout det","text":"[47]Ziming Liu et al. “Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training Effciency”. In: Proceedings of the International Conference for High Performance Computing, Networking,i Storage and Analysis. SC ’23. ACM, Nov. 2023, pp. 1–13. DOI: 10.1145/3581784.3607073. URL: http://dx.doi.org/10.1145/3581784.3607073."},{"bbox":{"x0":138,"x1":1087,"y0":1141,"y1":1186},"conf":0.9225,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1138,"y1":1165},"font_size":2.689e-39,"text":"[48]Ilya Loshchilov and Frank Hutter. “Decoupled Weight Decay Regularization”. In: International Conference on"},{"bbox":{"x0":193,"x1":950,"y0":1163,"y1":1185},"font_size":2.689e-39,"text":"Learning Representations. 2019. URL: https://openreview.net/forum?id=Bkg6RiCqY7."}],"source":"layout det","text":"[48]Ilya Loshchilov and Frank Hutter. “Decoupled Weight Decay Regularization”. In: International Conference on Learning Representations. 2019. URL: https://openreview.net/forum?id=Bkg6RiCqY7."},{"bbox":{"x0":138,"x1":1086,"y0":1189,"y1":1232},"conf":0.9018,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1078,"y0":1186,"y1":1211},"font_size":2.689e-39,"text":"[49]Jan Ludziejewski et al. OpenAI Gym. 2025. arXiv: 2502.05172 [cs.LG]. URL: https://arxiv.org/abs/"},{"bbox":{"x0":196,"x1":306,"y0":1211,"y1":1229},"font_size":2.689e-39,"text":"2502.05172."}],"source":"layout det","text":"[49]Jan Ludziejewski et al. OpenAI Gym. 2025. arXiv: 2502.05172 [cs.LG]. URL: https://arxiv.org/abs/2502.05172."},{"bbox":{"x0":137,"x1":1086,"y0":1235,"y1":1282},"conf":0.9193,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1236,"y1":1261},"font_size":2.689e-39,"text":"[50]Samuel Miserendino et al. “SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance"},{"bbox":{"x0":195,"x1":747,"y0":1259,"y1":1280},"font_size":2.689e-39,"text":"Software Engineering?” In: arXiv preprint arXiv:2502.12115 (2025)."}],"source":"layout det","text":"[50]Samuel Miserendino et al. “SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?” In: arXiv preprint arXiv:2502.12115 (2025)."},{"bbox":{"x0":137,"x1":1087,"y0":1284,"y1":1329},"conf":0.9125,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1280,"y1":1307},"font_size":2.689e-39,"text":"[51]Arindam Mitra et al. “Agentinstruct: Toward generative teaching with agentic fows”. In: arXiv preprintl"},{"bbox":{"x0":195,"x1":409,"y0":1305,"y1":1327},"font_size":2.689e-39,"text":"arXiv:2407.03502 (2024)."}],"source":"layout det","text":"[51]Arindam Mitra et al. “Agentinstruct: Toward generative teaching with agentic fows”. In: arXiv preprintl arXiv:2407.03502 (2024)."},{"bbox":{"x0":138,"x1":1087,"y0":1332,"y1":1377},"conf":0.9143,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1330,"y1":1355},"font_size":2.689e-39,"text":"[52]Ivan Moshkov et al. “Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with"},{"bbox":{"x0":195,"x1":787,"y0":1353,"y1":1376},"font_size":2.689e-39,"text":"openmathreasoning dataset”. In: arXiv preprint arXiv:2504.16891 (2025)."}],"source":"layout det","text":"[52]Ivan Moshkov et al. “Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with openmathreasoning dataset”. In: arXiv preprint arXiv:2504.16891 (2025)."},{"bbox":{"x0":138,"x1":1087,"y0":1380,"y1":1448},"conf":0.9232,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1376,"y1":1401},"font_size":2.689e-39,"text":"[53]Deepak Narayanan et al. “Effcient large-scale language model training on gpu clusters using megatron-lm”. In:i"},{"bbox":{"x0":193,"x1":1084,"y0":1398,"y1":1424},"font_size":2.689e-39,"text":"Proceedings of the international conference for high performance computing, networking, storage and analysis."},{"bbox":{"x0":191,"x1":328,"y0":1417,"y1":1449},"font_size":2.689e-39,"text":"2021, pp. 1–15."}],"source":"layout det","text":"[53]Deepak Narayanan et al. “Effcient large-scale language model training on gpu clusters using megatron-lm”. In:i Proceedings of the international conference for high performance computing, networking, storage and analysis.2021, pp. 1–15."}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1087,"y0":1049,"y1":1138},"conf":0.9412,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":527,"y1":593},"conf":0.9397,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":337,"y1":402},"conf":0.9278,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":453,"y1":499},"conf":0.9263,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":882,"y1":927},"conf":0.9248,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":596,"y1":641},"conf":0.9242,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":1380,"y1":1448},"conf":0.9232,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":1141,"y1":1186},"conf":0.9225,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1085,"y0":976,"y1":1022},"conf":0.9199,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":835,"y1":878},"conf":0.9199,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":1235,"y1":1282},"conf":0.9193,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":405,"y1":451},"conf":0.9191,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":930,"y1":973},"conf":0.918,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1087,"y0":290,"y1":334},"conf":0.9176,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":644,"y1":688},"conf":0.9148,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":1332,"y1":1377},"conf":0.9143,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":1284,"y1":1329},"conf":0.9125,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":787,"y1":832},"conf":0.9085,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":691,"y1":736},"conf":0.9085,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":739,"y1":784},"conf":0.9068,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1087,"y0":145,"y1":191},"conf":0.9057,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":1189,"y1":1232},"conf":0.9018,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":1084,"y0":501,"y1":526},"conf":0.9016,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":242,"y1":287},"conf":0.8971,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1088,"y0":194,"y1":239},"conf":0.8924,"label":"Text","label_id":1},{"bbox":{"x0":559,"x1":1085,"y0":67,"y1":92},"conf":0.8553,"label":"Abandon","label_id":2},{"bbox":{"x0":254,"x1":995,"y0":1024,"y1":1048},"conf":0.7523,"label":"Text","label_id":1},{"bbox":{"x0":597,"x1":626,"y0":1481,"y1":1505},"conf":0.7514,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8472},{"poly":[[192,1417],[328,1421],[327,1449],[191,1445]],"score":0.7754},{"poly":[[193,1398],[1084,1401],[1084,1424],[193,1421]],"score":0.7107},{"poly":[[193,1378],[1083,1378],[1083,1401],[193,1401]],"score":0.7154},{"poly":[[140,1376],[183,1376],[183,1401],[140,1401]],"score":0.8695},{"poly":[[195,1353],[787,1353],[787,1376],[195,1376]],"score":0.7138},{"poly":[[191,1332],[1081,1332],[1081,1353],[191,1353]],"score":0.8541},{"poly":[[140,1330],[183,1330],[183,1355],[140,1355]],"score":0.9064},{"poly":[[195,1305],[409,1305],[409,1327],[195,1327]],"score":0.8832},{"poly":[[193,1280],[1083,1284],[1083,1307],[193,1303]],"score":0.7397},{"poly":[[141,1282],[183,1282],[183,1307],[141,1307]],"score":0.8679},{"poly":[[195,1259],[747,1259],[747,1280],[195,1280]],"score":0.8464},{"poly":[[193,1236],[1081,1236],[1081,1257],[193,1257]],"score":0.873},{"poly":[[140,1236],[186,1236],[186,1261],[140,1261]],"score":0.8026},{"poly":[[196,1211],[306,1211],[306,1229],[196,1229]],"score":0.9296},{"poly":[[191,1186],[1078,1186],[1078,1208],[191,1208]],"score":0.7251},{"poly":[[140,1186],[185,1186],[185,1211],[140,1211]],"score":0.8482},{"poly":[[193,1163],[950,1163],[950,1185],[193,1185]],"score":0.8282},{"poly":[[191,1138],[1081,1140],[1081,1163],[191,1162]],"score":0.7742},{"poly":[[140,1140],[183,1140],[183,1165],[140,1165]],"score":0.8364},{"poly":[[195,1115],[577,1115],[577,1137],[195,1137]],"score":0.813},{"poly":[[193,1092],[1081,1092],[1081,1115],[193,1115]],"score":0.7155},{"poly":[[193,1071],[1083,1071],[1083,1094],[193,1094]],"score":0.7037},{"poly":[[193,1046],[1081,1049],[1081,1073],[193,1069]],"score":0.7628},{"poly":[[140,1048],[183,1048],[183,1072],[140,1072]],"score":0.9212},{"poly":[[191,1025],[1008,1025],[1008,1046],[191,1046]],"score":0.8361},{"poly":[[140,1023],[195,1023],[195,1048],[140,1048]],"score":0.6757},{"poly":[[193,998],[1053,998],[1053,1020],[193,1020]],"score":0.8034},{"poly":[[191,977],[1081,977],[1081,998],[191,998]],"score":0.832},{"poly":[[140,975],[185,975],[185,1000],[140,1000]],"score":0.7907},{"poly":[[193,949],[526,949],[526,970],[193,970]],"score":0.741},{"poly":[[193,929],[1084,929],[1084,952],[193,952]],"score":0.7587},{"poly":[[140,927],[183,927],[183,954],[140,954]],"score":0.8279},{"poly":[[195,903],[720,903],[720,926],[195,926]],"score":0.7311},{"poly":[[193,881],[1081,881],[1081,903],[193,903]],"score":0.8602},{"poly":[[140,879],[186,879],[186,904],[140,904]],"score":0.8624},{"poly":[[195,855],[554,855],[554,878],[195,878]],"score":0.7083},{"poly":[[195,833],[1081,833],[1081,855],[195,855]],"score":0.874},{"poly":[[140,832],[183,832],[183,856],[140,856]],"score":0.9017},{"poly":[[193,808],[690,808],[690,830],[193,830]],"score":0.845},{"poly":[[190,784],[1081,785],[1081,809],[190,807]],"score":0.7923},{"poly":[[140,785],[186,785],[186,810],[140,810]],"score":0.812},{"poly":[[195,761],[775,761],[775,782],[195,782]],"score":0.8395},{"poly":[[191,738],[1084,738],[1084,759],[191,759]],"score":0.8472},{"poly":[[141,739],[181,739],[181,759],[141,759]],"score":0.9512},{"poly":[[191,713],[525,711],[526,734],[191,736]],"score":0.7078},{"poly":[[191,691],[1084,691],[1084,713],[191,713]],"score":0.9069},{"poly":[[140,690],[183,690],[183,714],[140,714]],"score":0.9007},{"poly":[[195,665],[348,665],[348,688],[195,688]],"score":0.7837},{"poly":[[191,644],[1081,644],[1081,667],[191,667]],"score":0.7236},{"poly":[[140,642],[195,642],[195,667],[140,667]],"score":0.704},{"poly":[[195,615],[878,617],[878,640],[195,639]],"score":0.7759},{"poly":[[193,596],[1084,596],[1084,617],[193,617]],"score":0.8431},{"poly":[[141,597],[180,597],[180,617],[141,617]],"score":0.9607},{"poly":[[193,568],[1046,569],[1046,592],[193,591]],"score":0.75},{"poly":[[195,548],[1083,548],[1083,569],[195,569]],"score":0.7883},{"poly":[[193,526],[1083,526],[1083,548],[193,548]],"score":0.8277},{"poly":[[140,525],[183,525],[183,549],[140,549]],"score":0.9167},{"poly":[[190,500],[1083,498],[1083,521],[190,523]],"score":0.7593},{"poly":[[140,500],[183,500],[183,525],[140,525]],"score":0.8256},{"poly":[[193,472],[878,474],[878,497],[193,495]],"score":0.7237},{"poly":[[193,454],[1083,454],[1083,475],[193,475]],"score":0.8389},{"poly":[[140,450],[183,450],[183,477],[140,477]],"score":0.8065},{"poly":[[196,427],[550,427],[550,449],[196,449]],"score":0.8373},{"poly":[[191,406],[1079,406],[1079,427],[191,427]],"score":0.8373},{"poly":[[140,404],[183,404],[183,431],[140,431]],"score":0.8182},{"poly":[[196,381],[306,381],[306,399],[196,399]],"score":0.8333},{"poly":[[195,358],[1079,358],[1079,380],[195,380]],"score":0.8249},{"poly":[[193,335],[1081,335],[1081,358],[193,358]],"score":0.7195},{"poly":[[140,335],[181,335],[181,360],[140,360]],"score":0.8641},{"poly":[[193,309],[605,309],[605,330],[193,330]],"score":0.7081},{"poly":[[191,289],[1083,289],[1083,312],[191,312]],"score":0.7182},{"poly":[[141,290],[181,290],[181,310],[141,310]],"score":0.9259},{"poly":[[195,262],[1024,262],[1024,285],[195,285]],"score":0.7155},{"poly":[[195,241],[1083,241],[1083,262],[195,262]],"score":0.8339},{"poly":[[141,239],[183,239],[183,264],[141,264]],"score":0.8607},{"poly":[[193,210],[880,211],[880,239],[193,238]],"score":0.6783},{"poly":[[195,193],[1084,193],[1084,214],[195,214]],"score":0.8597},{"poly":[[140,191],[183,191],[183,216],[140,216]],"score":0.8356},{"poly":[[195,168],[614,168],[614,191],[195,191]],"score":0.7094},{"poly":[[191,147],[1081,147],[1081,168],[191,168]],"score":0.8527},{"poly":[[143,147],[181,147],[181,167],[143,167]],"score":0.9284},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7514},{"poly":[[560,64],[664,64],[664,92],[560,92]],"score":0.8043}],"page_no":21,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":559,"x1":1085,"y0":67,"y1":92},"conf":0.8488,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":625,"y0":1481,"y1":1505},"conf":0.7429,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"23"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":138,"x1":1086,"y0":145,"y1":192},"conf":0.9174,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":145,"y1":168},"font_size":-618500000000000.0,"text":"[54]Long Ouyang et al. “Training language models to follow instructions with human feedback”. In: Advances in"},{"bbox":{"x0":195,"x1":743,"y0":168,"y1":191},"font_size":-618500000000000.0,"text":"neural information processing systems 35 (2022), pp. 27730–27744."}],"source":"layout det","text":"[54]Long Ouyang et al. “Training language models to follow instructions with human feedback”. In: Advances in neural information processing systems 35 (2022), pp. 27730–27744."},{"bbox":{"x0":138,"x1":1088,"y0":195,"y1":238},"conf":0.9092,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":193,"y1":218},"font_size":-618500000000000.0,"text":"[55]Bowen Peng et al. “Yarn: Effcient context window extension of large language models”. In: arXiv preprinti"},{"bbox":{"x0":191,"x1":408,"y0":213,"y1":238},"font_size":-618500000000000.0,"text":"arXiv:2309.00071 (2023)."}],"source":"layout det","text":"[55]Bowen Peng et al. “Yarn: Effcient context window extension of large language models”. In: arXiv preprinti arXiv:2309.00071 (2023)."},{"bbox":{"x0":138,"x1":1087,"y0":242,"y1":286},"conf":0.9147,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":239,"y1":264},"font_size":-618500000000000.0,"text":"[56]Long Phan et al. Humanity’s Last Exam. 2025. arXiv: 2501.14249 [cs.LG]. URL: https://arxiv.org/"},{"bbox":{"x0":195,"x1":348,"y0":261,"y1":282},"font_size":-618500000000000.0,"text":"abs/2501.14249."}],"source":"layout det","text":"[56]Long Phan et al. Humanity’s Last Exam. 2025. arXiv: 2501.14249 [cs.LG]. URL: https://arxiv.org/abs/2501.14249."},{"bbox":{"x0":229,"x1":971,"y0":288,"y1":314},"conf":0.8696,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":191,"x1":976,"y0":289,"y1":310},"font_size":-618500000000000.0,"text":"ghui Qi et al. “Zero bubble pipeline parallelism”. In: arXiv preprint arXiv:2401.10241 (2023)"}],"source":"layout det","text":"ghui Qi et al. “Zero bubble pipeline parallelism”. In: arXiv preprint arXiv:2401.10241 (2023)"},{"bbox":{"x0":138,"x1":1086,"y0":316,"y1":360},"conf":0.9258,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":314,"y1":338},"font_size":-618500000000000.0,"text":"[58]Yujia Qin et al. “Toolllm: Facilitating large language models to master 16000+ real-world apis”. In: arXiv"},{"bbox":{"x0":191,"x1":476,"y0":335,"y1":360},"font_size":-618500000000000.0,"text":"preprint arXiv:2307.16789 (2023)."}],"source":"layout det","text":"[58]Yujia Qin et al. “Toolllm: Facilitating large language models to master 16000+ real-world apis”. In: arXiv preprint arXiv:2307.16789 (2023)."},{"bbox":{"x0":137,"x1":1087,"y0":361,"y1":407},"conf":0.9282,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1079,"y0":360,"y1":386},"font_size":-618500000000000.0,"text":"[59]Qwen et al. Qwen2.5 Technical Report. 2025. arXiv: 2412.15115 [cs.CL]. URL: https://arxiv.org/abs/"},{"bbox":{"x0":196,"x1":306,"y0":386,"y1":404},"font_size":-618500000000000.0,"text":"2412.15115."}],"source":"layout det","text":"[59]Qwen et al. Qwen2.5 Technical Report. 2025. arXiv: 2412.15115 [cs.CL]. URL: https://arxiv.org/abs/2412.15115."},{"bbox":{"x0":137,"x1":1087,"y0":409,"y1":476},"conf":0.941,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":409,"y1":434},"font_size":-618500000000000.0,"text":"[60]Samyam Rajbhandari et al. “Zero: Memory optimizations toward training trillion parameter models”. In: SC20:"},{"bbox":{"x0":193,"x1":1083,"y0":432,"y1":455},"font_size":-618500000000000.0,"text":"International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE. 2020,"},{"bbox":{"x0":191,"x1":277,"y0":448,"y1":479},"font_size":-618500000000000.0,"text":"pp. 1–16."}],"source":"layout det","text":"[60]Samyam Rajbhandari et al. “Zero: Memory optimizations toward training trillion parameter models”. In: SC20:International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE. 2020,pp. 1–16."},{"bbox":{"x0":137,"x1":1087,"y0":479,"y1":523},"conf":0.9033,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":475,"y1":505},"font_size":-618500000000000.0,"text":"[61]David Rein et al. “Gpqa: A graduate-level google-proof q&a benchmark”. In: First Conference on Language"},{"bbox":{"x0":193,"x1":329,"y0":500,"y1":523},"font_size":-618500000000000.0,"text":"Modeling. 2024."}],"source":"layout det","text":"[61]David Rein et al. “Gpqa: A graduate-level google-proof q&a benchmark”. In: First Conference on Language Modeling. 2024."},{"bbox":{"x0":137,"x1":1086,"y0":526,"y1":574},"conf":0.9078,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":525,"y1":549},"font_size":-618500000000000.0,"text":"[62]Keisuke Sakaguchi et al. “Winogrande: An adversarial winograd schema challenge at scale”. In: Communications"},{"bbox":{"x0":193,"x1":496,"y0":549,"y1":571},"font_size":-618500000000000.0,"text":"of the ACM 64.9 (2021), pp. 99–106."}],"source":"layout det","text":"[62]Keisuke Sakaguchi et al. “Winogrande: An adversarial winograd schema challenge at scale”. In: Communications of the ACM 64.9 (2021), pp. 99–106."},{"bbox":{"x0":229,"x1":970,"y0":576,"y1":598},"conf":0.7287,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":193,"x1":965,"y0":574,"y1":597},"font_size":-618500000000000.0,"text":"id Silver and Richard S Sutton. “Welcome to the era of experience”. In: Google AI 1 (2025)."}],"source":"layout det","text":"id Silver and Richard S Sutton. “Welcome to the era of experience”. In: Google AI 1 (2025)."},{"bbox":{"x0":137,"x1":1087,"y0":600,"y1":646},"conf":0.9183,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":594,"y1":625},"font_size":-618500000000000.0,"text":"[64]Ved Sirdeshmukh et al. MultiChallenge: $A$  Realistic Multi-Turn Conversation Evaluation Benchmark Challenging"},{"bbox":{"x0":193,"x1":1026,"y0":622,"y1":644},"font_size":-618500000000000.0,"text":"to Frontier LLMs. 2025. arXiv: 2501.17399 [cs.CL]. URL: https://arxiv.org/abs/2501.17399."}],"source":"layout det","text":"[64]Ved Sirdeshmukh et al. MultiChallenge: $A$  Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs. 2025. arXiv: 2501.17399 [cs.CL]. URL: https://arxiv.org/abs/2501.17399."},{"bbox":{"x0":138,"x1":1085,"y0":648,"y1":693},"conf":0.9208,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":645,"y1":672},"font_size":-618500000000000.0,"text":"[65]Giulio Starace et al. “PaperBench: Evaluating AI’s Ability to Replicate AI Research”. In: arXiv preprint"},{"bbox":{"x0":193,"x1":409,"y0":670,"y1":691},"font_size":-618500000000000.0,"text":"arXiv:2504.01848 (2025)."}],"source":"layout det","text":"[65]Giulio Starace et al. “PaperBench: Evaluating AI’s Ability to Replicate AI Research”. In: arXiv preprint arXiv:2504.01848 (2025)."},{"bbox":{"x0":139,"x1":1087,"y0":696,"y1":740},"conf":0.9187,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1081,"y0":693,"y1":723},"font_size":-618500000000000.0,"text":"[66]Hao Sun et al. ZeroSearch: Incentivize the Search Capability of LLMs without Searching. 2025. arXiv: 2505."},{"bbox":{"x0":193,"x1":720,"y0":718,"y1":739},"font_size":-618500000000000.0,"text":"04588 [cs.CL]. URL: https://arxiv.org/abs/2505.04588."}],"source":"layout det","text":"[66]Hao Sun et al. ZeroSearch: Incentivize the Search Capability of LLMs without Searching. 2025. arXiv: 2505.04588 [cs.CL]. URL: https://arxiv.org/abs/2505.04588."},{"bbox":{"x0":138,"x1":1086,"y0":743,"y1":788},"conf":0.9199,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":741,"y1":767},"font_size":-618500000000000.0,"text":"[67]Mirac Suzgun et al. Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them. 2022. arXiv:"},{"bbox":{"x0":195,"x1":775,"y0":764,"y1":787},"font_size":-618500000000000.0,"text":"2210.09261 [cs.CL]. URL: https://arxiv.org/abs/2210.09261."}],"source":"layout det","text":"[67]Mirac Suzgun et al. Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them. 2022. arXiv:2210.09261 [cs.CL]. URL: https://arxiv.org/abs/2210.09261."},{"bbox":{"x0":137,"x1":1087,"y0":791,"y1":835},"conf":0.9182,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":790,"y1":813},"font_size":-618500000000000.0,"text":"[68]Manveer Singh Tamber et al. “Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards”. In: arXiv"},{"bbox":{"x0":191,"x1":477,"y0":812,"y1":837},"font_size":-618500000000000.0,"text":"preprint arXiv:2505.04847 (2025)."}],"source":"layout det","text":"[68]Manveer Singh Tamber et al. “Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards”. In: arXiv preprint arXiv:2505.04847 (2025)."},{"bbox":{"x0":137,"x1":1088,"y0":838,"y1":883},"conf":0.909,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":837,"y1":861},"font_size":-618500000000000.0,"text":"[69]Gemma Team et al. “Gemma 2: Improving open language models at a practical size”. In: arXiv preprint"},{"bbox":{"x0":193,"x1":407,"y0":860,"y1":881},"font_size":-618500000000000.0,"text":"arXiv:2408.00118 (2024)."}],"source":"layout det","text":"[69]Gemma Team et al. “Gemma 2: Improving open language models at a practical size”. In: arXiv preprint arXiv:2408.00118 (2024)."},{"bbox":{"x0":137,"x1":1088,"y0":886,"y1":933},"conf":0.911,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":884,"y1":909},"font_size":-618500000000000.0,"text":"[70]LlaMA Team. The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation — ai.meta.com."},{"bbox":{"x0":195,"x1":996,"y0":907,"y1":931},"font_size":-618500000000000.0,"text":"https://ai.meta.com/blog/llama-4-multimodal-intelligence/. [Accessed 15-07-2025]."}],"source":"layout det","text":"[70]LlaMA Team. The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation — ai.meta.com.https://ai.meta.com/blog/llama-4-multimodal-intelligence/. [Accessed 15-07-2025]."},{"bbox":{"x0":138,"x1":1089,"y0":936,"y1":978},"conf":0.9119,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":932,"y1":959},"font_size":-618500000000000.0,"text":"[71]The Terminal-Bench Team. Terminal-Bench: A Benchmark for AI Agents in Terminal Environments. Apr. 2025."},{"bbox":{"x0":195,"x1":758,"y0":954,"y1":975},"font_size":-618500000000000.0,"text":"URL: https://github.com/laude-institute/terminal-bench."}],"source":"layout det","text":"[71]The Terminal-Bench Team. Terminal-Bench: A Benchmark for AI Agents in Terminal Environments. Apr. 2025.URL: https://github.com/laude-institute/terminal-bench."},{"bbox":{"x0":137,"x1":1088,"y0":982,"y1":1049},"conf":0.9299,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":978,"y1":1005},"font_size":-618500000000000.0,"text":"[72]Ashish Vaswani et al. “Attention is All you Need”. In: Advances in Neural Information Processing Systems."},{"bbox":{"x0":193,"x1":1078,"y0":1002,"y1":1026},"font_size":-618500000000000.0,"text":"Ed. by I. Guyon et al. Vol. 30. Curran Associates, Inc., 2017. URL: https://proceedings.neurips.cc/"},{"bbox":{"x0":193,"x1":935,"y0":1023,"y1":1048},"font_size":-618500000000000.0,"text":"paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf."}],"source":"layout det","text":"[72]Ashish Vaswani et al. “Attention is All you Need”. In: Advances in Neural Information Processing Systems.Ed. by I. Guyon et al. Vol. 30. Curran Associates, Inc., 2017. URL: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf."},{"bbox":{"x0":137,"x1":1087,"y0":1051,"y1":1095},"conf":0.9159,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1049,"y1":1076},"font_size":-618500000000000.0,"text":"[73]Vectara. Hallucination Evaluation Model (Revision 7437011). 2024. URL: https://huggingface.co/"},{"bbox":{"x0":196,"x1":595,"y0":1072,"y1":1094},"font_size":-618500000000000.0,"text":"vectara/hallucination_evaluation_model"}],"source":"layout det","text":"[73]Vectara. Hallucination Evaluation Model (Revision 7437011). 2024. URL: https://huggingface.co/vectara/hallucination_evaluation_model"},{"bbox":{"x0":138,"x1":1086,"y0":1098,"y1":1142},"conf":0.9161,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1096,"y1":1122},"font_size":-618500000000000.0,"text":"[74]Joshua Vendrow et al. “Do large language model benchmarks test reliability?” In: arXiv preprint"},{"bbox":{"x0":193,"x1":407,"y0":1120,"y1":1142},"font_size":-618500000000000.0,"text":"arXiv:2502.03461 (2025)."}],"source":"layout det","text":"[74]Joshua Vendrow et al. “Do large language model benchmarks test reliability?” In: arXiv preprint arXiv:2502.03461 (2025)."},{"bbox":{"x0":139,"x1":1084,"y0":1145,"y1":1191},"conf":0.9211,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1143,"y1":1170},"font_size":-618500000000000.0,"text":"[75]Yizhong Wang et al. “Self-instruct: Aligning language models with self-generated instructions”. In: arXiv"},{"bbox":{"x0":193,"x1":479,"y0":1166,"y1":1191},"font_size":-618500000000000.0,"text":"preprint arXiv:2212.10560 (2022)."}],"source":"layout det","text":"[75]Yizhong Wang et al. “Self-instruct: Aligning language models with self-generated instructions”. In: arXiv preprint arXiv:2212.10560 (2022)."},{"bbox":{"x0":139,"x1":1086,"y0":1194,"y1":1239},"conf":0.9149,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1191,"y1":1218},"font_size":-618500000000000.0,"text":"[76]Yubo Wang et al. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark."},{"bbox":{"x0":195,"x1":880,"y0":1213,"y1":1238},"font_size":-618500000000000.0,"text":"2024. arXiv: 2406.01574 [cs.CL]. URL: https://arxiv.org/abs/2406.01574."}],"source":"layout det","text":"[76]Yubo Wang et al. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark.2024. arXiv: 2406.01574 [cs.CL]. URL: https://arxiv.org/abs/2406.01574."},{"bbox":{"x0":138,"x1":1086,"y0":1241,"y1":1287},"conf":0.9187,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":1239,"y1":1266},"font_size":-618500000000000.0,"text":"[77]Zhexu Wang et al. OJBench: A Competition Level Code Benchmark For Large Language Models. 2025. arXiv:"},{"bbox":{"x0":195,"x1":772,"y0":1262,"y1":1285},"font_size":-618500000000000.0,"text":"2506.16395 [cs.CL]. URL: https://arxiv.org/abs/2506.16395."}],"source":"layout det","text":"[77]Zhexu Wang et al. OJBench: A Competition Level Code Benchmark For Large Language Models. 2025. arXiv:2506.16395 [cs.CL]. URL: https://arxiv.org/abs/2506.16395."},{"bbox":{"x0":138,"x1":1086,"y0":1290,"y1":1333},"conf":0.9142,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1289,"y1":1313},"font_size":-618500000000000.0,"text":"[78]Jason Wei et al. “Measuring short-form factuality in large language models”. In: arXiv preprint arXiv:2411.04368"},{"bbox":{"x0":193,"x1":258,"y0":1310,"y1":1333},"font_size":-618500000000000.0,"text":"(2024)."}],"source":"layout det","text":"[78]Jason Wei et al. “Measuring short-form factuality in large language models”. In: arXiv preprint arXiv:2411.04368(2024)."},{"bbox":{"x0":138,"x1":1087,"y0":1336,"y1":1382},"conf":0.9181,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1335,"y1":1360},"font_size":-618500000000000.0,"text":"[79]Tianwen Wei et al. CMATH: Can Your Language Model Pass Chinese Elementary School Math Test? 2023."},{"bbox":{"x0":195,"x1":828,"y0":1358,"y1":1379},"font_size":-618500000000000.0,"text":"arXiv: 2306.16636 [cs.CL]. URL: https://arxiv.org/abs/2306.16636."}],"source":"layout det","text":"[79]Tianwen Wei et al. CMATH: Can Your Language Model Pass Chinese Elementary School Math Test? 2023.arXiv: 2306.16636 [cs.CL]. URL: https://arxiv.org/abs/2306.16636."},{"bbox":{"x0":138,"x1":1086,"y0":1384,"y1":1430},"conf":0.9095,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1381,"y1":1407},"font_size":-618500000000000.0,"text":"[80]Colin White et al. “LiveBench: A Challenging, Contamination-Free LLM Benchmark”. In: The Thirteenth"},{"bbox":{"x0":191,"x1":689,"y0":1404,"y1":1429},"font_size":-618500000000000.0,"text":"International Conference on Learning Representations. 2025."}],"source":"layout det","text":"[80]Colin White et al. “LiveBench: A Challenging, Contamination-Free LLM Benchmark”. In: The Thirteenth International Conference on Learning Representations. 2025."}],"formula_dets":[{"bbox":{"x0":510,"x1":524,"y0":604,"y1":619},"conf":0.521,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1087,"y0":409,"y1":476},"conf":0.941,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":982,"y1":1049},"conf":0.9299,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":361,"y1":407},"conf":0.9282,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":316,"y1":360},"conf":0.9258,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1084,"y0":1145,"y1":1191},"conf":0.9211,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1085,"y0":648,"y1":693},"conf":0.9208,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":743,"y1":788},"conf":0.9199,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1087,"y0":696,"y1":740},"conf":0.9187,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":1241,"y1":1287},"conf":0.9187,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":600,"y1":646},"conf":0.9183,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":791,"y1":835},"conf":0.9182,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":1336,"y1":1382},"conf":0.9181,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":145,"y1":192},"conf":0.9174,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":1098,"y1":1142},"conf":0.9161,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":1051,"y1":1095},"conf":0.9159,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":1086,"y0":1194,"y1":1239},"conf":0.9149,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1087,"y0":242,"y1":286},"conf":0.9147,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":1290,"y1":1333},"conf":0.9142,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1089,"y0":936,"y1":978},"conf":0.9119,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":886,"y1":933},"conf":0.911,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1086,"y0":1384,"y1":1430},"conf":0.9095,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":195,"y1":238},"conf":0.9092,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":838,"y1":883},"conf":0.909,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":526,"y1":574},"conf":0.9078,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":479,"y1":523},"conf":0.9033,"label":"Text","label_id":1},{"bbox":{"x0":229,"x1":971,"y0":288,"y1":314},"conf":0.8696,"label":"Text","label_id":1},{"bbox":{"x0":559,"x1":1085,"y0":67,"y1":92},"conf":0.8488,"label":"Abandon","label_id":2},{"bbox":{"x0":596,"x1":625,"y0":1481,"y1":1505},"conf":0.7429,"label":"Abandon","label_id":2},{"bbox":{"x0":229,"x1":970,"y0":576,"y1":598},"conf":0.7287,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8618},{"poly":[[191,1406],[688,1404],[689,1427],[191,1429]],"score":0.768},{"poly":[[190,1383],[1081,1381],[1081,1404],[190,1406]],"score":0.7972},{"poly":[[140,1383],[183,1383],[183,1407],[140,1407]],"score":0.8751},{"poly":[[195,1358],[828,1358],[828,1379],[195,1379]],"score":0.861},{"poly":[[193,1335],[1083,1335],[1083,1358],[193,1358]],"score":0.7467},{"poly":[[140,1335],[183,1335],[183,1360],[140,1360]],"score":0.938},{"poly":[[193,1310],[258,1310],[258,1333],[193,1333]],"score":0.9194},{"poly":[[191,1289],[1083,1289],[1083,1312],[191,1312]],"score":0.7596},{"poly":[[140,1289],[193,1289],[193,1313],[140,1313]],"score":0.7391},{"poly":[[195,1262],[772,1262],[772,1285],[195,1285]],"score":0.7308},{"poly":[[191,1241],[1084,1241],[1084,1264],[191,1264]],"score":0.7294},{"poly":[[140,1239],[183,1239],[183,1266],[140,1266]],"score":0.8314},{"poly":[[195,1213],[880,1214],[880,1238],[195,1236]],"score":0.7711},{"poly":[[195,1193],[1083,1193],[1083,1216],[195,1216]],"score":0.7509},{"poly":[[140,1191],[183,1191],[183,1218],[140,1218]],"score":0.8475},{"poly":[[193,1168],[479,1166],[479,1190],[193,1191]],"score":0.7586},{"poly":[[195,1145],[1081,1145],[1081,1168],[195,1168]],"score":0.74},{"poly":[[140,1143],[183,1143],[183,1170],[140,1170]],"score":0.8742},{"poly":[[193,1120],[407,1120],[407,1142],[193,1142]],"score":0.8727},{"poly":[[191,1096],[1081,1097],[1081,1120],[191,1119]],"score":0.7729},{"poly":[[140,1097],[183,1097],[183,1122],[140,1122]],"score":0.871},{"poly":[[196,1072],[595,1072],[595,1094],[196,1094]],"score":0.7634},{"poly":[[195,1051],[1081,1051],[1081,1072],[195,1072]],"score":0.8397},{"poly":[[140,1049],[186,1049],[186,1076],[140,1076]],"score":0.7356},{"poly":[[193,1025],[935,1023],[935,1046],[193,1048]],"score":0.6907},{"poly":[[193,1002],[1078,1003],[1078,1026],[193,1025]],"score":0.7605},{"poly":[[193,982],[1083,982],[1083,1003],[193,1003]],"score":0.8376},{"poly":[[140,978],[183,978],[183,1005],[140,1005]],"score":0.8518},{"poly":[[195,954],[758,954],[758,975],[195,975]],"score":0.6858},{"poly":[[195,934],[1083,934],[1083,955],[195,955]],"score":0.8447},{"poly":[[140,932],[186,932],[186,959],[140,959]],"score":0.8295},{"poly":[[195,907],[996,907],[996,931],[195,931]],"score":0.7233},{"poly":[[193,886],[1084,886],[1084,908],[193,908]],"score":0.8463},{"poly":[[140,884],[183,884],[183,909],[140,909]],"score":0.9247},{"poly":[[193,860],[407,860],[407,881],[193,881]],"score":0.8214},{"poly":[[193,838],[1083,838],[1083,861],[193,861]],"score":0.7487},{"poly":[[140,837],[183,837],[183,861],[140,861]],"score":0.8612},{"poly":[[191,813],[477,812],[477,835],[191,837]],"score":0.7703},{"poly":[[191,790],[1081,790],[1081,813],[191,813]],"score":0.7219},{"poly":[[141,792],[185,792],[185,812],[141,812]],"score":0.8908},{"poly":[[195,764],[775,764],[775,787],[195,787]],"score":0.7298},{"poly":[[193,742],[1084,742],[1084,764],[193,764]],"score":0.8525},{"poly":[[140,741],[183,741],[183,767],[140,767]],"score":0.8218},{"poly":[[193,718],[720,718],[720,739],[193,739]],"score":0.8465},{"poly":[[191,696],[1081,696],[1081,718],[191,718]],"score":0.8535},{"poly":[[138,693],[196,693],[196,723],[138,723]],"score":0.6931},{"poly":[[193,670],[409,670],[409,691],[193,691]],"score":0.8301},{"poly":[[190,645],[1083,647],[1083,670],[190,668]],"score":0.8252},{"poly":[[140,647],[183,647],[183,672],[140,672]],"score":0.925},{"poly":[[193,622],[1026,622],[1026,644],[193,644]],"score":0.826},{"poly":[[188,594],[1083,597],[1083,625],[188,622]],"score":0.6513},{"poly":[[140,599],[185,599],[185,624],[140,624]],"score":0.9284},{"poly":[[193,574],[965,574],[965,597],[193,597]],"score":0.7323},{"poly":[[140,574],[183,574],[183,599],[140,599]],"score":0.9111},{"poly":[[193,549],[496,549],[496,571],[193,571]],"score":0.8395},{"poly":[[190,525],[1081,526],[1081,549],[190,548]],"score":0.7566},{"poly":[[141,528],[183,528],[183,548],[141,548]],"score":0.9144},{"poly":[[193,500],[329,500],[329,523],[193,523]],"score":0.7885},{"poly":[[190,475],[1083,477],[1083,505],[190,503]],"score":0.6986},{"poly":[[140,477],[185,477],[185,503],[140,503]],"score":0.754},{"poly":[[191,454],[275,448],[277,473],[192,479]],"score":0.7221},{"poly":[[193,432],[1083,432],[1083,455],[193,455]],"score":0.7331},{"poly":[[191,409],[1083,409],[1083,432],[191,432]],"score":0.7307},{"poly":[[140,409],[183,409],[183,434],[140,434]],"score":0.8704},{"poly":[[196,386],[306,386],[306,404],[196,404]],"score":0.82},{"poly":[[191,360],[1079,361],[1079,384],[191,383]],"score":0.7528},{"poly":[[140,360],[183,360],[183,386],[140,386]],"score":0.7808},{"poly":[[191,337],[476,335],[476,358],[191,360]],"score":0.7658},{"poly":[[195,314],[1081,314],[1081,337],[195,337]],"score":0.7699},{"poly":[[140,314],[183,314],[183,338],[140,338]],"score":0.9447},{"poly":[[191,289],[976,289],[976,310],[191,310]],"score":0.8896},{"poly":[[140,287],[183,287],[183,312],[140,312]],"score":0.9044},{"poly":[[195,261],[348,261],[348,282],[195,282]],"score":0.7057},{"poly":[[190,239],[1079,241],[1079,264],[190,262]],"score":0.7961},{"poly":[[140,239],[183,239],[183,264],[140,264]],"score":0.9039},{"poly":[[191,213],[408,215],[407,238],[191,236]],"score":0.7619},{"poly":[[193,193],[1081,193],[1081,216],[193,216]],"score":0.7699},{"poly":[[140,193],[195,193],[195,218],[140,218]],"score":0.6767},{"poly":[[195,168],[743,168],[743,191],[195,191]],"score":0.7327},{"poly":[[188,145],[1081,145],[1081,168],[188,168]],"score":0.7456},{"poly":[[141,145],[198,145],[198,168],[141,168]],"score":0.7502},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7768},{"poly":[[559,64],[664,64],[664,92],[559,92]],"score":0.8332}],"page_no":22,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1085,"y0":67,"y1":92},"conf":0.8423,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":916,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":665,"y0":63,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":627,"y0":1480,"y1":1505},"conf":0.7469,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":595,"x1":629,"y0":1478,"y1":1505},"font_size":0.0,"text":"24"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":138,"x1":1088,"y0":144,"y1":191},"conf":0.9125,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":145,"y1":170},"font_size":-622800000000000.0,"text":"[81]Mitchell Wortsman et al. “Small-scale proxies for large-scale transformer training instabilities, 2023”. In: URL"},{"bbox":{"x0":191,"x1":491,"y0":163,"y1":193},"font_size":-622800000000000.0,"text":"https://arxiv. org/abs/2309.14322 ()."}],"source":"layout det","text":"[81]Mitchell Wortsman et al. “Small-scale proxies for large-scale transformer training instabilities, 2023”. In: URL https://arxiv. org/abs/2309.14322 ()."},{"bbox":{"x0":138,"x1":1089,"y0":194,"y1":239},"conf":0.9043,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":191,"y1":218},"font_size":-622800000000000.0,"text":"[82]Can Xu et al. WizardLM: Empowering large pre-trained language models to follow complex instructions. 2025."},{"bbox":{"x0":193,"x1":830,"y0":214,"y1":238},"font_size":-622800000000000.0,"text":"arXiv: 2304.12244 [cs.CL]. URL: https://arxiv.org/abs/2304.12244."}],"source":"layout det","text":"[82]Can Xu et al. WizardLM: Empowering large pre-trained language models to follow complex instructions. 2025.arXiv: 2304.12244 [cs.CL]. URL: https://arxiv.org/abs/2304.12244."},{"bbox":{"x0":138,"x1":1089,"y0":242,"y1":287},"conf":0.9083,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1084,"y0":239,"y1":264},"font_size":-622800000000000.0,"text":"[83]Zhangchen Xu et al. KodCode: A Diverse, Challenging, and Verifable Synthetic Dataset for Coding. 2025. arXiv:i"},{"bbox":{"x0":195,"x1":775,"y0":262,"y1":285},"font_size":-622800000000000.0,"text":"2503.02951 [cs.LG]. URL: https://arxiv.org/abs/2503.02951."}],"source":"layout det","text":"[83]Zhangchen Xu et al. KodCode: A Diverse, Challenging, and Verifable Synthetic Dataset for Coding. 2025. arXiv:i 2503.02951 [cs.LG]. URL: https://arxiv.org/abs/2503.02951."},{"bbox":{"x0":137,"x1":1088,"y0":290,"y1":334},"conf":0.9188,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":287,"y1":314},"font_size":-622800000000000.0,"text":"[84]John Yang et al. SWE-smith: Scaling Data for Software Engineering Agents. 2025. arXiv: 2504.21798 [cs.SE]."},{"bbox":{"x0":191,"x1":582,"y0":309,"y1":333},"font_size":-622800000000000.0,"text":"URL: https://arxiv.org/abs/2504.21798."}],"source":"layout det","text":"[84]John Yang et al. SWE-smith: Scaling Data for Software Engineering Agents. 2025. arXiv: 2504.21798 [cs.SE].URL: https://arxiv.org/abs/2504.21798."},{"bbox":{"x0":137,"x1":1086,"y0":337,"y1":381},"conf":0.9253,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":335,"y1":360},"font_size":-622800000000000.0,"text":"[85]Shunyu Yao et al. “tau-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains”. In: arXiv"},{"bbox":{"x0":191,"x1":477,"y0":356,"y1":381},"font_size":-622800000000000.0,"text":"preprint arXiv:2406.12045 (2024)."}],"source":"layout det","text":"[85]Shunyu Yao et al. “tau-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains”. In: arXiv preprint arXiv:2406.12045 (2024)."},{"bbox":{"x0":136,"x1":1086,"y0":384,"y1":429},"conf":0.9216,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":383,"y1":408},"font_size":-622800000000000.0,"text":"[86]Daoguang Zan et al. “Multi-swe-bench: A multilingual benchmark for issue resolving”. In: arXiv preprint"},{"bbox":{"x0":193,"x1":407,"y0":406,"y1":427},"font_size":-622800000000000.0,"text":"arXiv:2504.02605 (2025)."}],"source":"layout det","text":"[86]Daoguang Zan et al. “Multi-swe-bench: A multilingual benchmark for issue resolving”. In: arXiv preprint arXiv:2504.02605 (2025)."},{"bbox":{"x0":136,"x1":1086,"y0":432,"y1":477},"conf":0.917,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1084,"y0":427,"y1":459},"font_size":-622800000000000.0,"text":"[87]Eric Zelikman et al. “Star: Bootstrapping reasoning with reasoning”. In: Advances in Neural Information"},{"bbox":{"x0":193,"x1":594,"y0":450,"y1":478},"font_size":-622800000000000.0,"text":"Processing Systems 35 (2022), pp. 15476–15488."}],"source":"layout det","text":"[87]Eric Zelikman et al. “Star: Bootstrapping reasoning with reasoning”. In: Advances in Neural Information Processing Systems 35 (2022), pp. 15476–15488."},{"bbox":{"x0":136,"x1":1087,"y0":480,"y1":523},"conf":0.8967,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":477,"y1":503},"font_size":-622800000000000.0,"text":"[88]Rowan Zellers et al. “Hellaswag: Can a machine really fnish your sentence?” In: arXiv preprint arXiv:1905.07830i"},{"bbox":{"x0":193,"x1":258,"y0":500,"y1":525},"font_size":-622800000000000.0,"text":"(2019)."}],"source":"layout det","text":"[88]Rowan Zellers et al. “Hellaswag: Can a machine really fnish your sentence?” In: arXiv preprint arXiv:1905.07830i(2019)."},{"bbox":{"x0":135,"x1":1086,"y0":526,"y1":573},"conf":0.8944,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":525,"y1":551},"font_size":-622800000000000.0,"text":"[89]Wanjun Zhong et al. “Agieval: A human-centric benchmark for evaluating foundation models”. In: arXiv preprint"},{"bbox":{"x0":193,"x1":409,"y0":549,"y1":571},"font_size":-622800000000000.0,"text":"arXiv:2304.06364 (2023)."}],"source":"layout det","text":"[89]Wanjun Zhong et al. “Agieval: A human-centric benchmark for evaluating foundation models”. In: arXiv preprint arXiv:2304.06364 (2023)."},{"bbox":{"x0":136,"x1":1086,"y0":575,"y1":621},"conf":0.8635,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":574,"y1":599},"font_size":-622800000000000.0,"text":"[90]Jeffrey Zhou et al. “Instruction-Following Evaluation for Large Language Models”. In: ArXiv abs/2311.07911"},{"bbox":{"x0":195,"x1":644,"y0":596,"y1":619},"font_size":-622800000000000.0,"text":"(2023). URL: https://arxiv.org/abs/2311.07911."}],"source":"layout det","text":"[90]Jeffrey Zhou et al. “Instruction-Following Evaluation for Large Language Models”. In: ArXiv abs/2311.07911(2023). URL: https://arxiv.org/abs/2311.07911."},{"bbox":{"x0":137,"x1":1085,"y0":623,"y1":671},"conf":0.8761,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":620,"y1":645},"font_size":-622800000000000.0,"text":"[91]Qin Zhu et al. AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning Abilities of Large"},{"bbox":{"x0":195,"x1":1031,"y0":644,"y1":667},"font_size":-622800000000000.0,"text":"Language Models. 2025. arXiv: 2502.16906 [cs.CL]. URL: https://arxiv.org/abs/2502.16906."}],"source":"layout det","text":"[91]Qin Zhu et al. AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning Abilities of Large Language Models. 2025. arXiv: 2502.16906 [cs.CL]. URL: https://arxiv.org/abs/2502.16906."}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1086,"y0":337,"y1":381},"conf":0.9253,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":384,"y1":429},"conf":0.9216,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":290,"y1":334},"conf":0.9188,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":432,"y1":477},"conf":0.917,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1088,"y0":144,"y1":191},"conf":0.9125,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1089,"y0":242,"y1":287},"conf":0.9083,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1089,"y0":194,"y1":239},"conf":0.9043,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1087,"y0":480,"y1":523},"conf":0.8967,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1086,"y0":526,"y1":573},"conf":0.8944,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1085,"y0":623,"y1":671},"conf":0.8761,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":575,"y1":621},"conf":0.8635,"label":"Text","label_id":1},{"bbox":{"x0":558,"x1":1085,"y0":67,"y1":92},"conf":0.8423,"label":"Abandon","label_id":2},{"bbox":{"x0":596,"x1":627,"y0":1480,"y1":1505},"conf":0.7469,"label":"Abandon","label_id":2},{"bbox":{"x0":328,"x1":1070,"y0":575,"y1":618},"conf":0.2488,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[595,1478],[629,1478],[629,1505],[595,1505]],"score":0.8885},{"poly":[[195,644],[1031,644],[1031,667],[195,667]],"score":0.7308},{"poly":[[191,620],[1083,622],[1083,645],[191,643]],"score":0.8155},{"poly":[[140,620],[185,620],[185,645],[140,645]],"score":0.9018},{"poly":[[195,596],[644,596],[644,619],[195,619]],"score":0.7562},{"poly":[[191,574],[1081,574],[1081,597],[191,597]],"score":0.7668},{"poly":[[140,574],[186,574],[186,599],[140,599]],"score":0.8819},{"poly":[[193,549],[409,549],[409,571],[193,571]],"score":0.8826},{"poly":[[190,526],[1081,526],[1081,549],[190,549]],"score":0.7492},{"poly":[[140,525],[186,525],[186,551],[140,551]],"score":0.7238},{"poly":[[193,500],[258,500],[258,525],[193,525]],"score":0.8404},{"poly":[[191,478],[1083,478],[1083,502],[191,502]],"score":0.7498},{"poly":[[140,477],[183,477],[183,503],[140,503]],"score":0.8675},{"poly":[[193,450],[594,450],[594,478],[193,478]],"score":0.6617},{"poly":[[188,427],[1084,429],[1084,457],[188,455]],"score":0.7329},{"poly":[[138,427],[190,427],[190,459],[138,459]],"score":0.709},{"poly":[[193,406],[407,406],[407,427],[193,427]],"score":0.8884},{"poly":[[191,383],[1083,383],[1083,406],[191,406]],"score":0.8097},{"poly":[[140,383],[185,383],[185,408],[140,408]],"score":0.9142},{"poly":[[191,358],[477,356],[477,379],[191,381]],"score":0.792},{"poly":[[190,337],[1081,337],[1081,358],[190,358]],"score":0.893},{"poly":[[140,335],[186,335],[186,360],[140,360]],"score":0.8712},{"poly":[[191,310],[582,309],[582,332],[191,333]],"score":0.7668},{"poly":[[190,289],[1083,289],[1083,312],[190,312]],"score":0.8108},{"poly":[[140,287],[188,287],[188,314],[140,314]],"score":0.7696},{"poly":[[195,262],[775,262],[775,285],[195,285]],"score":0.7383},{"poly":[[193,241],[1084,241],[1084,262],[193,262]],"score":0.9043},{"poly":[[140,239],[183,239],[183,264],[140,264]],"score":0.944},{"poly":[[193,214],[830,214],[830,238],[193,238]],"score":0.743},{"poly":[[191,193],[1083,193],[1083,216],[191,216]],"score":0.7672},{"poly":[[140,191],[191,191],[191,218],[140,218]],"score":0.7434},{"poly":[[191,165],[490,163],[491,191],[191,193]],"score":0.7311},{"poly":[[190,145],[1081,145],[1081,168],[190,168]],"score":0.7556},{"poly":[[140,145],[185,145],[185,170],[140,170]],"score":0.8276},{"poly":[[916,68],[1083,69],[1082,92],[916,91]],"score":0.794},{"poly":[[559,63],[665,63],[665,91],[559,91]],"score":0.7476}],"page_no":23,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":555,"x1":1087,"y0":64,"y1":95},"conf":0.7352,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":67,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":594,"x1":627,"y0":1478,"y1":1507},"conf":0.7346,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"25"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":136,"x1":251,"y0":138,"y1":176},"conf":0.8924,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":139,"x1":246,"y0":138,"y1":172},"font_size":1.027e+22,"text":"Appendix"}],"source":"layout det","text":"Appendix"},{"bbox":{"x0":135,"x1":336,"y0":190,"y1":225},"conf":0.898,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":333,"y0":193,"y1":221},"font_size":1.027e+22,"text":"AContributions"}],"source":"layout det","text":"AContributions"},{"bbox":{"x0":134,"x1":1088,"y0":239,"y1":295},"conf":0.9266,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":244,"y1":266},"font_size":1.027e+22,"text":"The listing of authors is in alphabetical order based on their last names. Names marked with an asterisk (*) indicate"},{"bbox":{"x0":138,"x1":484,"y0":266,"y1":290},"font_size":1.027e+22,"text":"people who are no longer part of our team."}],"source":"layout det","text":"The listing of authors is in alphabetical order based on their last names. Names marked with an asterisk (*) indicate people who are no longer part of our team."},{"bbox":{"x0":129,"x1":299,"y0":307,"y1":1260},"conf":0.5989,"font_size":0.0,"label":"Reference","label_id":11,"lines":[{"bbox":{"x0":140,"x1":223,"y0":310,"y1":333},"font_size":1.027e+22,"text":"Yifan Bai"},{"bbox":{"x0":138,"x1":239,"y0":332,"y1":360},"font_size":1.027e+22,"text":"Yiping Bao"},{"bbox":{"x0":138,"x1":268,"y0":353,"y1":380},"font_size":1.027e+22,"text":"Guanduo Chen"},{"bbox":{"x0":141,"x1":244,"y0":380,"y1":398},"font_size":1.027e+22,"text":"Jiahao Chen"},{"bbox":{"x0":136,"x1":261,"y0":394,"y1":426},"font_size":1.027e+22,"text":"Ningxin Chen"},{"bbox":{"x0":140,"x1":248,"y0":421,"y1":444},"font_size":1.027e+22,"text":"Ruijue Chen"},{"bbox":{"x0":140,"x1":243,"y0":442,"y1":465},"font_size":1.027e+22,"text":"Yanru Chen"},{"bbox":{"x0":140,"x1":264,"y0":464,"y1":487},"font_size":1.027e+22,"text":"Yuankun Chen"},{"bbox":{"x0":141,"x1":244,"y0":488,"y1":507},"font_size":1.027e+22,"text":"Yutian Chen"},{"bbox":{"x0":140,"x1":263,"y0":507,"y1":530},"font_size":1.027e+22,"text":"Zhuofu Chen*"},{"bbox":{"x0":140,"x1":220,"y0":530,"y1":548},"font_size":1.027e+22,"text":"Jialei Cui"},{"bbox":{"x0":138,"x1":225,"y0":549,"y1":576},"font_size":1.027e+22,"text":"Hao Ding"},{"bbox":{"x0":136,"x1":273,"y0":569,"y1":601},"font_size":1.027e+22,"text":"Mengnan Dong"},{"bbox":{"x0":140,"x1":248,"y0":596,"y1":619},"font_size":1.027e+22,"text":"Ang’ang Du"},{"bbox":{"x0":138,"x1":276,"y0":614,"y1":642},"font_size":1.027e+22,"text":"Chenzhuang Du"},{"bbox":{"x0":140,"x1":236,"y0":639,"y1":662},"font_size":1.027e+22,"text":"Dikang Du"},{"bbox":{"x0":140,"x1":223,"y0":660,"y1":683},"font_size":1.027e+22,"text":"Yulun Du"},{"bbox":{"x0":140,"x1":203,"y0":681,"y1":705},"font_size":1.027e+22,"text":"Yu Fan"},{"bbox":{"x0":138,"x1":248,"y0":699,"y1":730},"font_size":1.027e+22,"text":"Yichen Feng"},{"bbox":{"x0":140,"x1":220,"y0":726,"y1":749},"font_size":1.027e+22,"text":"Kelin Fu"},{"bbox":{"x0":141,"x1":229,"y0":749,"y1":767},"font_size":1.027e+22,"text":"Bofei Gao"},{"bbox":{"x0":140,"x1":276,"y0":771,"y1":792},"font_size":1.027e+22,"text":"Hongcheng Gao"},{"bbox":{"x0":138,"x1":261,"y0":788,"y1":817},"font_size":1.027e+22,"text":"Peizhong Gao"},{"bbox":{"x0":138,"x1":228,"y0":812,"y1":840},"font_size":1.027e+22,"text":"Tong Gao"},{"bbox":{"x0":140,"x1":230,"y0":835,"y1":858},"font_size":1.027e+22,"text":"Xinran Gu"},{"bbox":{"x0":136,"x1":260,"y0":853,"y1":885},"font_size":1.027e+22,"text":"Longyu Guan"},{"bbox":{"x0":138,"x1":258,"y0":876,"y1":903},"font_size":1.027e+22,"text":"Haiqing Guo*"},{"bbox":{"x0":140,"x1":256,"y0":901,"y1":924},"font_size":1.027e+22,"text":"Jianhang Guo"},{"bbox":{"x0":140,"x1":211,"y0":922,"y1":945},"font_size":1.027e+22,"text":"Hao Hu"},{"bbox":{"x0":140,"x1":241,"y0":944,"y1":967},"font_size":1.027e+22,"text":"Xiaoru Hao"},{"bbox":{"x0":138,"x1":250,"y0":963,"y1":992},"font_size":1.027e+22,"text":"Tianhong He"},{"bbox":{"x0":138,"x1":233,"y0":985,"y1":1012},"font_size":1.027e+22,"text":"Weiran He"},{"bbox":{"x0":138,"x1":248,"y0":1005,"y1":1036},"font_size":1.027e+22,"text":"Wenyang He"},{"bbox":{"x0":138,"x1":240,"y0":1029,"y1":1056},"font_size":1.027e+22,"text":"Chao Hong"},{"bbox":{"x0":136,"x1":256,"y0":1049,"y1":1081},"font_size":1.027e+22,"text":"Yangyang Hu"},{"bbox":{"x0":138,"x1":255,"y0":1072,"y1":1101},"font_size":1.027e+22,"text":"Zhenxing Hu"},{"bbox":{"x0":138,"x1":270,"y0":1092,"y1":1122},"font_size":1.027e+22,"text":"Weixiao Huang"},{"bbox":{"x0":138,"x1":250,"y0":1115,"y1":1144},"font_size":1.027e+22,"text":"Zhiqi Huang"},{"bbox":{"x0":138,"x1":252,"y0":1136,"y1":1167},"font_size":1.027e+22,"text":"Zihao Huang"},{"bbox":{"x0":138,"x1":225,"y0":1160,"y1":1187},"font_size":1.027e+22,"text":"Tao Jiang"},{"bbox":{"x0":138,"x1":251,"y0":1181,"y1":1210},"font_size":1.027e+22,"text":"Zhejun Jiang"},{"bbox":{"x0":138,"x1":222,"y0":1204,"y1":1233},"font_size":1.027e+22,"text":"Xinyi Jin"},{"bbox":{"x0":140,"x1":291,"y0":1226,"y1":1254},"font_size":1.027e+22,"text":"Yongsheng Kang*"}],"source":"layout det","text":"Yifan Bai  \nYiping Bao  \nGuanduo Chen  \nJiahao Chen  \nNingxin Chen  \nRuijue Chen  \nYanru Chen  \nYuankun Chen  \nYutian Chen  \nZhuofu Chen*  \nJialei Cui  \nHao Ding  \nMengnan Dong  \nAng’ang Du  \nChenzhuang Du  \nDikang Du  \nYulun Du  \nYu Fan  \nYichen Feng  \nKelin Fu  \nBofei Gao  \nHongcheng Gao  \nPeizhong Gao  \nTong Gao  \nXinran Gu  \nLongyu Guan  \nHaiqing Guo*  \nJianhang Guo  \nHao Hu  \nXiaoru Hao  \nTianhong He  \nWeiran He  \nWenyang He  \nChao Hong  \nYangyang Hu  \nZhenxing Hu  \nWeixiao Huang  \nZhiqi Huang  \nZihao Huang  \nTao Jiang  \nZhejun Jiang  \nXinyi Jin  \nYongsheng Kang*"},{"bbox":{"x0":370,"x1":522,"y0":306,"y1":1260},"conf":0.7611,"font_size":0.0,"label":"Reference","label_id":11,"lines":[{"bbox":{"x0":379,"x1":482,"y0":310,"y1":333},"font_size":1.027e+22,"text":"Guokun Lai"},{"bbox":{"x0":379,"x1":461,"y0":333,"y1":358},"font_size":1.027e+22,"text":"Cheng Li"},{"bbox":{"x0":377,"x1":451,"y0":353,"y1":382},"font_size":1.027e+22,"text":"Fang Li"},{"bbox":{"x0":379,"x1":481,"y0":376,"y1":399},"font_size":1.027e+22,"text":"Haoyang Li"},{"bbox":{"x0":377,"x1":456,"y0":396,"y1":424},"font_size":1.027e+22,"text":"Ming Li"},{"bbox":{"x0":378,"x1":467,"y0":419,"y1":442},"font_size":1.027e+22,"text":"Wentao Li"},{"bbox":{"x0":377,"x1":468,"y0":439,"y1":469},"font_size":1.027e+22,"text":"Yanhao Li"},{"bbox":{"x0":379,"x1":457,"y0":464,"y1":487},"font_size":1.027e+22,"text":"Yiwei Li"},{"bbox":{"x0":379,"x1":477,"y0":485,"y1":508},"font_size":1.027e+22,"text":"Zhaowei Li"},{"bbox":{"x0":377,"x1":481,"y0":505,"y1":533},"font_size":1.027e+22,"text":"Zheming Li"},{"bbox":{"x0":377,"x1":509,"y0":526,"y1":555},"font_size":1.027e+22,"text":"Hongzhan Lin*"},{"bbox":{"x0":378,"x1":486,"y0":551,"y1":574},"font_size":1.027e+22,"text":"Xiaohan Lin"},{"bbox":{"x0":377,"x1":483,"y0":569,"y1":601},"font_size":1.027e+22,"text":"Zongyu Lin"},{"bbox":{"x0":376,"x1":499,"y0":590,"y1":622},"font_size":1.027e+22,"text":"Chengyin Liu"},{"bbox":{"x0":379,"x1":482,"y0":617,"y1":640},"font_size":1.027e+22,"text":"Chenyu Liu"},{"bbox":{"x0":377,"x1":509,"y0":637,"y1":662},"font_size":1.027e+22,"text":"Hongzhang Liu"},{"bbox":{"x0":376,"x1":501,"y0":658,"y1":686},"font_size":1.027e+22,"text":"Jingyuan Liu*"},{"bbox":{"x0":375,"x1":463,"y0":679,"y1":708},"font_size":1.027e+22,"text":"Junqi Liu"},{"bbox":{"x0":378,"x1":466,"y0":705,"y1":728},"font_size":1.027e+22,"text":"Liang Liu"},{"bbox":{"x0":377,"x1":488,"y0":724,"y1":751},"font_size":1.027e+22,"text":"Shaowei Liu"},{"bbox":{"x0":377,"x1":453,"y0":744,"y1":771},"font_size":1.027e+22,"text":"T.Y. Liu"},{"bbox":{"x0":377,"x1":483,"y0":767,"y1":794},"font_size":1.027e+22,"text":"Tianwei Liu"},{"bbox":{"x0":379,"x1":489,"y0":790,"y1":813},"font_size":1.027e+22,"text":"Weizhou Liu"},{"bbox":{"x0":376,"x1":499,"y0":810,"y1":842},"font_size":1.027e+22,"text":"Yangyang Liu"},{"bbox":{"x0":379,"x1":459,"y0":835,"y1":858},"font_size":1.027e+22,"text":"Yibo Liu"},{"bbox":{"x0":375,"x1":473,"y0":851,"y1":887},"font_size":1.027e+22,"text":"Yiping Liu"},{"bbox":{"x0":379,"x1":451,"y0":878,"y1":901},"font_size":1.027e+22,"text":"Yue Liu"},{"bbox":{"x0":376,"x1":508,"y0":896,"y1":928},"font_size":1.027e+22,"text":"Zhengying Liu"},{"bbox":{"x0":379,"x1":464,"y0":922,"y1":945},"font_size":1.027e+22,"text":"Enzhe Lu"},{"bbox":{"x0":379,"x1":459,"y0":945,"y1":969},"font_size":1.027e+22,"text":"Lijun Lu"},{"bbox":{"x0":376,"x1":498,"y0":962,"y1":994},"font_size":1.027e+22,"text":"Shengling Ma"},{"bbox":{"x0":379,"x1":467,"y0":987,"y1":1010},"font_size":1.027e+22,"text":"Xinyu Ma"},{"bbox":{"x0":376,"x1":486,"y0":1005,"y1":1036},"font_size":1.027e+22,"text":"Yingwei Ma"},{"bbox":{"x0":376,"x1":517,"y0":1028,"y1":1060},"font_size":1.027e+22,"text":"Shaoguang Mao"},{"bbox":{"x0":379,"x1":444,"y0":1056,"y1":1074},"font_size":1.027e+22,"text":"Jie Mei"},{"bbox":{"x0":378,"x1":457,"y0":1074,"y1":1097},"font_size":1.027e+22,"text":"Xin Men"},{"bbox":{"x0":379,"x1":471,"y0":1096,"y1":1119},"font_size":1.027e+22,"text":"Yibo Miao"},{"bbox":{"x0":379,"x1":476,"y0":1119,"y1":1142},"font_size":1.027e+22,"text":"Siyuan Pan"},{"bbox":{"x0":377,"x1":471,"y0":1138,"y1":1165},"font_size":1.027e+22,"text":"Yebo Peng"},{"bbox":{"x0":379,"x1":474,"y0":1160,"y1":1183},"font_size":1.027e+22,"text":"Ruoyu Qin"},{"bbox":{"x0":379,"x1":472,"y0":1185,"y1":1208},"font_size":1.027e+22,"text":"Bowen Qu"},{"bbox":{"x0":377,"x1":481,"y0":1202,"y1":1233},"font_size":1.027e+22,"text":"Zeyu Shang"},{"bbox":{"x0":379,"x1":476,"y0":1228,"y1":1251},"font_size":1.027e+22,"text":"Lidong Shi"}],"source":"layout det","text":"Guokun Lai  \nCheng Li  \nFang Li  \nHaoyang Li  \nMing Li  \nWentao Li  \nYanhao Li  \nYiwei Li  \nZhaowei Li  \nZheming Li  \nHongzhan Lin*  \nXiaohan Lin  \nZongyu Lin  \nChengyin Liu  \nChenyu Liu  \nHongzhang Liu  \nJingyuan Liu*  \nJunqi Liu  \nLiang Liu  \nShaowei Liu  \nT.Y. Liu  \nTianwei Liu  \nWeizhou Liu  \nYangyang Liu  \nYibo Liu  \nYiping Liu  \nYue Liu  \nZhengying Liu  \nEnzhe Lu  \nLijun Lu  \nShengling Ma  \nXinyu Ma  \nYingwei Ma  \nShaoguang Mao  \nJie Mei  \nXin Men  \nYibo Miao  \nSiyuan Pan  \nYebo Peng  \nRuoyu Qin  \nBowen Qu  \nZeyu Shang  \nLidong Shi"},{"bbox":{"x0":609,"x1":762,"y0":306,"y1":1258},"conf":0.7909,"font_size":0.0,"label":"Reference","label_id":11,"lines":[{"bbox":{"x0":620,"x1":743,"y0":314,"y1":332},"font_size":1.027e+22,"text":"Shengyuan Shi"},{"bbox":{"x0":615,"x1":726,"y0":326,"y1":362},"font_size":1.027e+22,"text":"Feifan Song"},{"bbox":{"x0":617,"x1":705,"y0":355,"y1":378},"font_size":1.027e+22,"text":"Jianlin Su"},{"bbox":{"x0":617,"x1":740,"y0":374,"y1":401},"font_size":1.027e+22,"text":"Zhengyuan Su"},{"bbox":{"x0":617,"x1":720,"y0":398,"y1":421},"font_size":1.027e+22,"text":"Xinjie Sun*"},{"bbox":{"x0":615,"x1":717,"y0":415,"y1":446},"font_size":1.027e+22,"text":"Flood Sung"},{"bbox":{"x0":616,"x1":711,"y0":438,"y1":469},"font_size":1.027e+22,"text":"Heyi Tang"},{"bbox":{"x0":617,"x1":713,"y0":464,"y1":487},"font_size":1.027e+22,"text":"Jiawen Tao"},{"bbox":{"x0":617,"x1":727,"y0":483,"y1":512},"font_size":1.027e+22,"text":"Qifeng Teng"},{"bbox":{"x0":617,"x1":730,"y0":505,"y1":532},"font_size":1.027e+22,"text":"Chensi Wang"},{"bbox":{"x0":617,"x1":730,"y0":524,"y1":555},"font_size":1.027e+22,"text":"Dinglu Wang"},{"bbox":{"x0":617,"x1":718,"y0":549,"y1":578},"font_size":1.027e+22,"text":"Feng Wang"},{"bbox":{"x0":617,"x1":747,"y0":569,"y1":599},"font_size":1.027e+22,"text":"Haiming Wang"},{"bbox":{"x0":615,"x1":755,"y0":594,"y1":622},"font_size":1.027e+22,"text":"Jianzhou Wang*"},{"bbox":{"x0":613,"x1":737,"y0":612,"y1":644},"font_size":1.027e+22,"text":"Jiaxing Wang"},{"bbox":{"x0":615,"x1":740,"y0":633,"y1":665},"font_size":1.027e+22,"text":"Jinhong Wang"},{"bbox":{"x0":617,"x1":745,"y0":655,"y1":688},"font_size":1.027e+22,"text":"Shengjie Wang"},{"bbox":{"x0":617,"x1":724,"y0":678,"y1":708},"font_size":1.027e+22,"text":"Shuyi Wang"},{"bbox":{"x0":615,"x1":709,"y0":699,"y1":730},"font_size":1.027e+22,"text":"Yao Wang"},{"bbox":{"x0":617,"x1":717,"y0":722,"y1":751},"font_size":1.027e+22,"text":"Yejie Wang"},{"bbox":{"x0":613,"x1":722,"y0":740,"y1":776},"font_size":1.027e+22,"text":"Yiqin Wang"},{"bbox":{"x0":615,"x1":722,"y0":765,"y1":796},"font_size":1.027e+22,"text":"Yuxin Wang"},{"bbox":{"x0":617,"x1":722,"y0":787,"y1":817},"font_size":1.027e+22,"text":"Yuzhi Wang"},{"bbox":{"x0":617,"x1":729,"y0":810,"y1":838},"font_size":1.027e+22,"text":"Zhaoji Wang"},{"bbox":{"x0":615,"x1":754,"y0":831,"y1":863},"font_size":1.027e+22,"text":"Zhengtao Wang"},{"bbox":{"x0":615,"x1":731,"y0":849,"y1":885},"font_size":1.027e+22,"text":"Zhexu Wang"},{"bbox":{"x0":620,"x1":693,"y0":881,"y1":899},"font_size":1.027e+22,"text":"Chu Wei"},{"bbox":{"x0":619,"x1":733,"y0":901,"y1":924},"font_size":1.027e+22,"text":"Qianqian Wei"},{"bbox":{"x0":615,"x1":722,"y0":919,"y1":946},"font_size":1.027e+22,"text":"Wenhao Wu"},{"bbox":{"x0":617,"x1":720,"y0":945,"y1":964},"font_size":1.027e+22,"text":"Xingzhe Wu"},{"bbox":{"x0":617,"x1":708,"y0":965,"y1":988},"font_size":1.027e+22,"text":"Yuxin Wu"},{"bbox":{"x0":619,"x1":737,"y0":987,"y1":1010},"font_size":1.027e+22,"text":"Chenjun Xiao"},{"bbox":{"x0":615,"x1":734,"y0":1006,"y1":1035},"font_size":1.027e+22,"text":"Xiaotong Xie"},{"bbox":{"x0":615,"x1":750,"y0":1030,"y1":1058},"font_size":1.027e+22,"text":"Weimin Xiong*"},{"bbox":{"x0":617,"x1":697,"y0":1051,"y1":1079},"font_size":1.027e+22,"text":"Boyu Xu"},{"bbox":{"x0":615,"x1":697,"y0":1072,"y1":1101},"font_size":1.027e+22,"text":"Jing Xu*"},{"bbox":{"x0":617,"x1":708,"y0":1097,"y1":1120},"font_size":1.027e+22,"text":"Jinjing Xu"},{"bbox":{"x0":615,"x1":692,"y0":1115,"y1":1142},"font_size":1.027e+22,"text":"L.H. Xu"},{"bbox":{"x0":617,"x1":684,"y0":1140,"y1":1163},"font_size":1.027e+22,"text":"Lin Xu"},{"bbox":{"x0":617,"x1":707,"y0":1162,"y1":1185},"font_size":1.027e+22,"text":"Suting Xu"},{"bbox":{"x0":617,"x1":708,"y0":1183,"y1":1206},"font_size":1.027e+22,"text":"Weixin Xu"},{"bbox":{"x0":619,"x1":710,"y0":1206,"y1":1229},"font_size":1.027e+22,"text":"Xinran Xu"},{"bbox":{"x0":617,"x1":740,"y0":1226,"y1":1249},"font_size":1.027e+22,"text":"Yangchuan Xu"}],"source":"layout det","text":"Shengyuan Shi  \nFeifan Song  \nJianlin Su  \nZhengyuan Su  \nXinjie Sun*  \nFlood Sung  \nHeyi Tang  \nJiawen Tao  \nQifeng Teng  \nChensi Wang  \nDinglu Wang  \nFeng Wang  \nHaiming Wang  \nJianzhou Wang*  \nJiaxing Wang  \nJinhong Wang  \nShengjie Wang  \nShuyi Wang  \nYao Wang  \nYejie Wang  \nYiqin Wang  \nYuxin Wang  \nYuzhi Wang  \nZhaoji Wang  \nZhengtao Wang  \nZhexu Wang  \nChu Wei  \nQianqian Wei  \nWenhao Wu  \nXingzhe Wu  \nYuxin Wu  \nChenjun Xiao  \nXiaotong Xie  \nWeimin Xiong*  \nBoyu Xu  \nJing Xu*  \nJinjing Xu  \nL.H. Xu  \nLin Xu  \nSuting Xu  \nWeixin Xu  \nXinran Xu  \nYangchuan Xu"},{"bbox":{"x0":848,"x1":1008,"y0":311,"y1":1191},"conf":0.852,"font_size":0.0,"label":"Reference","label_id":11,"lines":[{"bbox":{"x0":855,"x1":940,"y0":309,"y1":332},"font_size":1.027e+22,"text":"Ziyao Xu"},{"bbox":{"x0":855,"x1":945,"y0":333,"y1":356},"font_size":1.027e+22,"text":"Junjie Yan"},{"bbox":{"x0":856,"x1":938,"y0":355,"y1":378},"font_size":1.027e+22,"text":"Yuzi Yan"},{"bbox":{"x0":853,"x1":972,"y0":371,"y1":405},"font_size":1.027e+22,"text":"Xiaofei Yang"},{"bbox":{"x0":854,"x1":948,"y0":396,"y1":424},"font_size":1.027e+22,"text":"Ying Yang"},{"bbox":{"x0":854,"x1":952,"y0":415,"y1":446},"font_size":1.027e+22,"text":"Zhen Yang"},{"bbox":{"x0":854,"x1":962,"y0":435,"y1":471},"font_size":1.027e+22,"text":"Zhilin Yang"},{"bbox":{"x0":855,"x1":983,"y0":460,"y1":492},"font_size":1.027e+22,"text":"Zonghan Yang"},{"bbox":{"x0":858,"x1":963,"y0":488,"y1":507},"font_size":1.027e+22,"text":"Haotian Yao"},{"bbox":{"x0":853,"x1":988,"y0":503,"y1":535},"font_size":1.027e+22,"text":"Xingcheng Yao"},{"bbox":{"x0":854,"x1":947,"y0":526,"y1":555},"font_size":1.027e+22,"text":"Wenjie Ye"},{"bbox":{"x0":855,"x1":953,"y0":549,"y1":573},"font_size":1.027e+22,"text":"Zhuorui Ye"},{"bbox":{"x0":858,"x1":960,"y0":574,"y1":597},"font_size":1.027e+22,"text":"Bohong Yin"},{"bbox":{"x0":856,"x1":960,"y0":596,"y1":619},"font_size":1.027e+22,"text":"Longhui Yu"},{"bbox":{"x0":858,"x1":973,"y0":617,"y1":640},"font_size":1.027e+22,"text":"Enming Yuan"},{"bbox":{"x0":855,"x1":1005,"y0":633,"y1":665},"font_size":1.027e+22,"text":"Hongbang Yuan*"},{"bbox":{"x0":855,"x1":976,"y0":658,"y1":685},"font_size":1.027e+22,"text":"Mengjie Yuan"},{"bbox":{"x0":856,"x1":978,"y0":680,"y1":706},"font_size":1.027e+22,"text":"Haobing Zhan"},{"bbox":{"x0":854,"x1":973,"y0":699,"y1":730},"font_size":1.027e+22,"text":"Dehao Zhang"},{"bbox":{"x0":856,"x1":955,"y0":722,"y1":751},"font_size":1.027e+22,"text":"Hao Zhang"},{"bbox":{"x0":854,"x1":972,"y0":742,"y1":773},"font_size":1.027e+22,"text":"Wanlu Zhang"},{"bbox":{"x0":855,"x1":983,"y0":769,"y1":794},"font_size":1.027e+22,"text":"Xiaobin Zhang"},{"bbox":{"x0":856,"x1":990,"y0":787,"y1":817},"font_size":1.027e+22,"text":"Yangkun Zhang"},{"bbox":{"x0":854,"x1":962,"y0":808,"y1":839},"font_size":1.027e+22,"text":"Yizhi Zhang"},{"bbox":{"x0":854,"x1":992,"y0":831,"y1":862},"font_size":1.027e+22,"text":"Yongting Zhang"},{"bbox":{"x0":854,"x1":942,"y0":853,"y1":881},"font_size":1.027e+22,"text":"Yu Zhang"},{"bbox":{"x0":854,"x1":967,"y0":874,"y1":905},"font_size":1.027e+22,"text":"Yutao Zhang"},{"bbox":{"x0":855,"x1":976,"y0":897,"y1":926},"font_size":1.027e+22,"text":"Yutong Zhang"},{"bbox":{"x0":855,"x1":971,"y0":920,"y1":947},"font_size":1.027e+22,"text":"Zheng Zhang"},{"bbox":{"x0":860,"x1":971,"y0":947,"y1":965},"font_size":1.027e+22,"text":"Haotian Zhao"},{"bbox":{"x0":858,"x1":953,"y0":965,"y1":988},"font_size":1.027e+22,"text":"Yikai Zhao"},{"bbox":{"x0":855,"x1":978,"y0":985,"y1":1012},"font_size":1.027e+22,"text":"Huabin Zheng"},{"bbox":{"x0":855,"x1":978,"y0":1005,"y1":1036},"font_size":1.027e+22,"text":"Shaojie Zheng"},{"bbox":{"x0":856,"x1":968,"y0":1031,"y1":1054},"font_size":1.027e+22,"text":"Jianren Zhou"},{"bbox":{"x0":855,"x1":960,"y0":1051,"y1":1078},"font_size":1.027e+22,"text":"Xinyu Zhou"},{"bbox":{"x0":855,"x1":958,"y0":1072,"y1":1099},"font_size":1.027e+22,"text":"Zaida Zhou"},{"bbox":{"x0":856,"x1":943,"y0":1096,"y1":1119},"font_size":1.027e+22,"text":"Zhen Zhu"},{"bbox":{"x0":855,"x1":980,"y0":1114,"y1":1145},"font_size":1.027e+22,"text":"Weiyu Zhuang"},{"bbox":{"x0":854,"x1":957,"y0":1138,"y1":1165},"font_size":1.027e+22,"text":"Xinxing Zu"},{"bbox":{"x0":858,"x1":935,"y0":1162,"y1":1185},"font_size":1.027e+22,"text":"Kimi K2"}],"source":"layout det","text":"Ziyao Xu  \nJunjie Yan  \nYuzi Yan  \nXiaofei Yang  \nYing Yang  \nZhen Yang  \nZhilin Yang  \nZonghan Yang  \nHaotian Yao  \nXingcheng Yao  \nWenjie Ye  \nZhuorui Ye  \nBohong Yin  \nLonghui Yu  \nEnming Yuan  \nHongbang Yuan*  \nMengjie Yuan  \nHaobing Zhan  \nDehao Zhang  \nHao Zhang  \nWanlu Zhang  \nXiaobin Zhang  \nYangkun Zhang  \nYizhi Zhang  \nYongting Zhang  \nYu Zhang  \nYutao Zhang  \nYutong Zhang  \nZheng Zhang  \nHaotian Zhao  \nYikai Zhao  \nHuabin Zheng  \nShaojie Zheng  \nJianren Zhou  \nXinyu Zhou  \nZaida Zhou  \nZhen Zhu  \nWeiyu Zhuang  \nXinxing Zu  \nKimi K2"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":134,"x1":1088,"y0":239,"y1":295},"conf":0.9266,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":336,"y0":190,"y1":225},"conf":0.898,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":251,"y0":138,"y1":176},"conf":0.8924,"label":"Title","label_id":0},{"bbox":{"x0":848,"x1":1008,"y0":311,"y1":1191},"conf":0.852,"label":"Reference","label_id":11},{"bbox":{"x0":609,"x1":762,"y0":306,"y1":1258},"conf":0.7909,"label":"Reference","label_id":11},{"bbox":{"x0":370,"x1":522,"y0":306,"y1":1260},"conf":0.7611,"label":"Reference","label_id":11},{"bbox":{"x0":555,"x1":1087,"y0":64,"y1":95},"conf":0.7352,"label":"Abandon","label_id":2},{"bbox":{"x0":594,"x1":627,"y0":1478,"y1":1507},"conf":0.7346,"label":"Abandon","label_id":2},{"bbox":{"x0":129,"x1":299,"y0":307,"y1":1260},"conf":0.5989,"label":"Reference","label_id":11},{"bbox":{"x0":136,"x1":294,"y0":308,"y1":1259},"conf":0.4113,"label":"Reference","label_id":11}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1480],[625,1480],[625,1503],[599,1503]],"score":0.8084},{"poly":[[617,1226],[740,1226],[740,1249],[617,1249]],"score":0.7373},{"poly":[[379,1228],[476,1228],[476,1251],[379,1251]],"score":0.8367},{"poly":[[140,1226],[291,1226],[291,1254],[140,1254]],"score":0.7422},{"poly":[[619,1206],[710,1206],[710,1229],[619,1229]],"score":0.8745},{"poly":[[378,1202],[481,1208],[480,1233],[377,1227]],"score":0.7707},{"poly":[[139,1204],[222,1208],[220,1233],[138,1229]],"score":0.8022},{"poly":[[379,1185],[472,1185],[472,1208],[379,1208]],"score":0.8713},{"poly":[[139,1181],[251,1185],[251,1210],[138,1206]],"score":0.762},{"poly":[[617,1183],[708,1183],[708,1206],[617,1206]],"score":0.8446},{"poly":[[858,1162],[935,1162],[935,1185],[858,1185]],"score":0.8673},{"poly":[[617,1162],[707,1162],[707,1185],[617,1185]],"score":0.829},{"poly":[[379,1160],[474,1160],[474,1183],[379,1183]],"score":0.6952},{"poly":[[139,1160],[225,1164],[224,1187],[138,1183]],"score":0.8003},{"poly":[[855,1138],[957,1142],[956,1165],[854,1161]],"score":0.8194},{"poly":[[617,1140],[684,1140],[684,1163],[617,1163]],"score":0.9313},{"poly":[[378,1138],[471,1142],[470,1165],[377,1161]],"score":0.8078},{"poly":[[139,1136],[252,1142],[250,1167],[138,1161]],"score":0.6984},{"poly":[[379,1119],[476,1119],[476,1142],[379,1142]],"score":0.7902},{"poly":[[139,1115],[250,1119],[249,1144],[138,1140]],"score":0.7342},{"poly":[[855,1114],[980,1117],[979,1145],[855,1142]],"score":0.7268},{"poly":[[616,1115],[692,1119],[691,1142],[615,1138]],"score":0.8277},{"poly":[[617,1097],[708,1097],[708,1120],[617,1120]],"score":0.8811},{"poly":[[856,1096],[943,1096],[943,1119],[856,1119]],"score":0.8297},{"poly":[[379,1096],[471,1096],[471,1119],[379,1119]],"score":0.8356},{"poly":[[139,1092],[270,1098],[269,1122],[138,1117]],"score":0.7552},{"poly":[[855,1072],[958,1076],[957,1099],[855,1095]],"score":0.7886},{"poly":[[615,1076],[696,1072],[697,1097],[616,1101]],"score":0.8094},{"poly":[[378,1074],[457,1074],[457,1097],[378,1097]],"score":0.8304},{"poly":[[139,1072],[255,1076],[254,1101],[138,1097]],"score":0.7419},{"poly":[[855,1051],[960,1055],[959,1078],[855,1074]],"score":0.844},{"poly":[[379,1056],[444,1056],[444,1074],[379,1074]],"score":0.9541},{"poly":[[618,1051],[697,1055],[696,1079],[617,1075]],"score":0.7928},{"poly":[[137,1049],[256,1053],[255,1081],[136,1077]],"score":0.7352},{"poly":[[856,1031],[968,1031],[968,1054],[856,1054]],"score":0.8449},{"poly":[[615,1030],[750,1030],[750,1058],[615,1058]],"score":0.7178},{"poly":[[376,1028],[517,1031],[517,1060],[376,1056]],"score":0.7501},{"poly":[[139,1029],[240,1033],[239,1056],[138,1052]],"score":0.8203},{"poly":[[855,1005],[978,1008],[977,1036],[855,1033]],"score":0.6852},{"poly":[[616,1006],[734,1012],[733,1035],[615,1029]],"score":0.7451},{"poly":[[377,1005],[486,1008],[485,1036],[376,1033]],"score":0.7155},{"poly":[[139,1005],[248,1008],[247,1036],[138,1033]],"score":0.7482},{"poly":[[855,985],[978,989],[977,1012],[855,1008]],"score":0.7837},{"poly":[[619,987],[737,987],[737,1010],[619,1010]],"score":0.832},{"poly":[[379,987],[467,987],[467,1010],[379,1010]],"score":0.8355},{"poly":[[139,985],[233,989],[232,1012],[138,1008]],"score":0.8202},{"poly":[[858,965],[953,965],[953,988],[858,988]],"score":0.8371},{"poly":[[617,965],[708,965],[708,988],[617,988]],"score":0.8235},{"poly":[[376,962],[498,965],[497,994],[376,990]],"score":0.7733},{"poly":[[139,963],[250,967],[249,992],[138,988]],"score":0.7763},{"poly":[[860,947],[971,947],[971,965],[860,965]],"score":0.9638},{"poly":[[617,945],[720,945],[720,964],[617,964]],"score":0.8131},{"poly":[[379,945],[459,945],[459,969],[379,969]],"score":0.8466},{"poly":[[140,944],[241,944],[241,967],[140,967]],"score":0.8425},{"poly":[[855,920],[971,924],[971,947],[855,944]],"score":0.8058},{"poly":[[616,919],[722,923],[721,946],[615,942]],"score":0.7176},{"poly":[[379,922],[464,922],[464,945],[379,945]],"score":0.8253},{"poly":[[140,922],[211,922],[211,945],[140,945]],"score":0.8484},{"poly":[[619,901],[733,901],[733,924],[619,924]],"score":0.8135},{"poly":[[140,901],[256,901],[256,924],[140,924]],"score":0.8332},{"poly":[[855,897],[976,901],[976,926],[855,922]],"score":0.6978},{"poly":[[376,896],[508,900],[507,928],[376,924]],"score":0.7355},{"poly":[[620,881],[693,881],[693,899],[620,899]],"score":0.9765},{"poly":[[856,874],[967,880],[965,905],[854,899]],"score":0.7424},{"poly":[[379,878],[451,878],[451,901],[379,901]],"score":0.8374},{"poly":[[138,878],[258,876],[258,901],[138,903]],"score":0.7495},{"poly":[[856,853],[942,857],[940,881],[854,877]],"score":0.7367},{"poly":[[616,849],[731,855],[729,885],[615,879]],"score":0.6468},{"poly":[[137,853],[260,857],[259,885],[136,881]],"score":0.7412},{"poly":[[377,851],[473,857],[471,887],[375,881]],"score":0.7183},{"poly":[[856,831],[992,837],[990,862],[854,856]],"score":0.7517},{"poly":[[616,831],[754,835],[753,863],[615,859]],"score":0.692},{"poly":[[379,835],[459,835],[459,858],[379,858]],"score":0.842},{"poly":[[140,835],[230,835],[230,858],[140,858]],"score":0.8792},{"poly":[[618,810],[729,814],[728,838],[617,835]],"score":0.721},{"poly":[[376,810],[499,814],[498,842],[376,838]],"score":0.7891},{"poly":[[138,812],[228,812],[228,840],[138,840]],"score":0.7503},{"poly":[[856,808],[962,814],[960,839],[854,833]],"score":0.7373},{"poly":[[857,787],[990,792],[989,817],[856,812]],"score":0.6841},{"poly":[[618,787],[722,792],[721,817],[617,811]],"score":0.7558},{"poly":[[379,790],[489,790],[489,813],[379,813]],"score":0.7994},{"poly":[[139,788],[261,792],[261,817],[138,813]],"score":0.7304},{"poly":[[855,769],[983,771],[983,794],[855,792]],"score":0.8346},{"poly":[[140,771],[276,771],[276,792],[140,792]],"score":0.9547},{"poly":[[616,765],[722,771],[721,796],[615,790]],"score":0.7483},{"poly":[[378,767],[483,771],[482,794],[377,790]],"score":0.8205},{"poly":[[856,742],[972,748],[970,773],[854,767]],"score":0.7097},{"poly":[[615,740],[722,746],[721,776],[613,770]],"score":0.6644},{"poly":[[378,744],[453,748],[451,771],[377,767]],"score":0.8405},{"poly":[[141,749],[229,749],[229,767],[141,767]],"score":0.9271},{"poly":[[857,722],[955,726],[954,751],[856,747]],"score":0.7103},{"poly":[[618,722],[717,726],[716,751],[617,747]],"score":0.7462},{"poly":[[378,724],[488,728],[487,751],[377,747]],"score":0.8328},{"poly":[[140,726],[220,726],[220,749],[140,749]],"score":0.8481},{"poly":[[856,699],[973,705],[972,730],[854,724]],"score":0.7307},{"poly":[[616,699],[709,705],[707,730],[615,724]],"score":0.7365},{"poly":[[378,705],[466,705],[466,728],[378,728]],"score":0.8171},{"poly":[[139,699],[248,705],[247,730],[138,724]],"score":0.7295},{"poly":[[857,680],[978,683],[977,706],[856,703]],"score":0.8078},{"poly":[[618,678],[724,683],[722,708],[617,703]],"score":0.7652},{"poly":[[377,679],[463,683],[462,708],[375,704]],"score":0.7736},{"poly":[[140,681],[203,681],[203,705],[140,705]],"score":0.8694},{"poly":[[855,658],[976,662],[976,685],[855,681]],"score":0.8184},{"poly":[[618,655],[745,660],[744,688],[617,683]],"score":0.7694},{"poly":[[376,658],[501,658],[501,686],[376,686]],"score":0.7166},{"poly":[[140,660],[223,660],[223,683],[140,683]],"score":0.8501},{"poly":[[616,633],[740,637],[739,665],[615,661]],"score":0.6773},{"poly":[[378,637],[509,639],[509,662],[377,660]],"score":0.815},{"poly":[[140,639],[236,639],[236,662],[140,662]],"score":0.8046},{"poly":[[855,637],[1004,633],[1005,661],[855,665]],"score":0.7289},{"poly":[[858,617],[973,617],[973,640],[858,640]],"score":0.8187},{"poly":[[614,612],[737,616],[736,644],[613,640]],"score":0.7078},{"poly":[[379,617],[482,617],[482,640],[379,640]],"score":0.7964},{"poly":[[138,614],[276,617],[276,642],[138,638]],"score":0.741},{"poly":[[856,596],[960,596],[960,619],[856,619]],"score":0.8468},{"poly":[[615,594],[755,594],[755,622],[615,622]],"score":0.7293},{"poly":[[140,596],[248,596],[248,619],[140,619]],"score":0.832},{"poly":[[376,590],[499,594],[498,622],[376,618]],"score":0.7347},{"poly":[[858,574],[960,574],[960,597],[858,597]],"score":0.8586},{"poly":[[618,569],[747,575],[746,599],[617,594]],"score":0.7436},{"poly":[[378,569],[483,573],[482,601],[377,597]],"score":0.717},{"poly":[[137,569],[273,573],[272,601],[136,597]],"score":0.6897},{"poly":[[855,549],[953,549],[953,573],[855,573]],"score":0.7437},{"poly":[[617,549],[718,549],[718,578],[617,578]],"score":0.7434},{"poly":[[378,551],[486,551],[486,574],[378,574]],"score":0.8207},{"poly":[[139,549],[225,553],[224,576],[138,572]],"score":0.8313},{"poly":[[618,524],[730,530],[729,555],[617,549]],"score":0.7368},{"poly":[[140,530],[220,530],[220,548],[140,548]],"score":0.8119},{"poly":[[856,526],[947,530],[946,555],[854,551]],"score":0.7783},{"poly":[[377,530],[508,526],[509,551],[378,555]],"score":0.7357},{"poly":[[618,505],[730,508],[730,532],[617,528]],"score":0.8452},{"poly":[[854,503],[988,507],[987,535],[853,531]],"score":0.7049},{"poly":[[378,505],[481,508],[480,533],[377,529]],"score":0.7421},{"poly":[[140,507],[263,507],[263,530],[140,530]],"score":0.8138},{"poly":[[858,488],[963,488],[963,507],[858,507]],"score":0.8909},{"poly":[[618,483],[727,487],[726,512],[617,508]],"score":0.705},{"poly":[[141,488],[244,488],[244,507],[141,507]],"score":0.9596},{"poly":[[379,485],[477,485],[477,508],[379,508]],"score":0.844},{"poly":[[855,460],[983,464],[982,492],[855,488]],"score":0.7322},{"poly":[[617,464],[713,464],[713,487],[617,487]],"score":0.8261},{"poly":[[379,464],[457,464],[457,487],[379,487]],"score":0.8805},{"poly":[[140,464],[264,464],[264,487],[140,487]],"score":0.8336},{"poly":[[618,438],[711,444],[709,469],[616,463]],"score":0.7623},{"poly":[[140,442],[243,442],[243,465],[140,465]],"score":0.8408},{"poly":[[856,435],[962,441],[960,471],[854,465]],"score":0.7045},{"poly":[[378,439],[468,443],[466,469],[377,465]],"score":0.7553},{"poly":[[140,421],[248,421],[248,444],[140,444]],"score":0.8068},{"poly":[[856,415],[952,421],[950,446],[854,440]],"score":0.7455},{"poly":[[616,415],[717,421],[716,446],[615,440]],"score":0.75},{"poly":[[378,419],[467,419],[467,442],[378,442]],"score":0.815},{"poly":[[856,396],[948,400],[947,424],[854,420]],"score":0.7374},{"poly":[[617,398],[720,398],[720,421],[617,421]],"score":0.8464},{"poly":[[378,396],[456,400],[455,424],[377,420]],"score":0.7912},{"poly":[[137,394],[261,398],[261,426],[136,422]],"score":0.7603},{"poly":[[141,380],[244,380],[244,398],[141,398]],"score":0.9014},{"poly":[[854,371],[972,377],[970,405],[853,399]],"score":0.7177},{"poly":[[617,374],[740,378],[740,401],[617,397]],"score":0.8029},{"poly":[[379,376],[481,376],[481,399],[379,399]],"score":0.855},{"poly":[[856,355],[938,355],[938,378],[856,378]],"score":0.8383},{"poly":[[617,355],[705,355],[705,378],[617,378]],"score":0.8324},{"poly":[[378,353],[451,357],[450,382],[377,377]],"score":0.8044},{"poly":[[138,353],[268,357],[267,380],[138,376]],"score":0.7763},{"poly":[[855,333],[945,333],[945,356],[855,356]],"score":0.8571},{"poly":[[617,326],[726,334],[724,362],[615,354]],"score":0.697},{"poly":[[379,333],[461,333],[461,358],[379,358]],"score":0.7975},{"poly":[[138,332],[239,332],[239,360],[138,360]],"score":0.7526},{"poly":[[620,314],[743,314],[743,332],[620,332]],"score":0.9749},{"poly":[[855,309],[940,309],[940,332],[855,332]],"score":0.6942},{"poly":[[379,310],[482,310],[482,333],[379,333]],"score":0.8432},{"poly":[[140,310],[223,310],[223,333],[140,333]],"score":0.8864},{"poly":[[138,267],[484,266],[484,289],[138,290]],"score":0.7931},{"poly":[[141,244],[1081,244],[1081,266],[141,266]],"score":0.8468},{"poly":[[138,193],[333,193],[333,221],[138,221]],"score":0.704},{"poly":[[139,142],[245,138],[246,168],[140,172]],"score":0.8452},{"poly":[[918,67],[1083,71],[1082,93],[918,89]],"score":0.7985},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8929}],"page_no":24,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.8275,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":595,"x1":627,"y0":1480,"y1":1506},"conf":0.7666,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":595,"x1":629,"y0":1478,"y1":1505},"font_size":0.0,"text":"26"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":137,"x1":510,"y0":140,"y1":174},"conf":0.9199,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":504,"y0":142,"y1":168},"font_size":5.658e-10,"text":"BToken Template of Tool Calling"}],"source":"layout det","text":"BToken Template of Tool Calling"},{"bbox":{"x0":137,"x1":675,"y0":190,"y1":220},"conf":0.911,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":670,"y0":190,"y1":216},"font_size":5.658e-10,"text":"There are three components in the token structure for tool-calling:"}],"source":"layout det","text":"There are three components in the token structure for tool-calling:"},{"bbox":{"x0":179,"x1":921,"y0":230,"y1":259},"conf":0.8934,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":158,"x1":935,"y0":229,"y1":256},"font_size":8.0,"text":"Tool declaration message: defnes the list of available tools and the schema of the argumenti"}],"source":"layout det","text":"Tool declaration message: defnes the list of available tools and the schema of the argumenti"},{"bbox":{"x0":176,"x1":905,"y0":261,"y1":288},"conf":0.8438,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":158,"x1":896,"y0":261,"y1":285},"font_size":8.0,"text":"Tool invoking section in assistant message: encodes the model’s request to invoke tools;"}],"source":"layout det","text":"Tool invoking section in assistant message: encodes the model’s request to invoke tools;"},{"bbox":{"x0":174,"x1":745,"y0":291,"y1":320},"conf":0.8832,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":158,"x1":738,"y0":290,"y1":315},"font_size":8.0,"text":"Tool result message: encapsulates the invoked tool’s execution result."}],"source":"layout det","text":"Tool result message: encapsulates the invoked tool’s execution result."},{"bbox":{"x0":139,"x1":728,"y0":331,"y1":360},"conf":0.8885,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":723,"y0":332,"y1":356},"font_size":8.0,"text":"The raw tokens of the tool declaration message are formatted as follows:"}],"source":"layout det","text":"The raw tokens of the tool declaration message are formatted as follows:"},{"bbox":{"x0":378,"x1":852,"y0":374,"y1":531},"conf":0.6234,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![47d11a88859d4e6b5c3262995eb318a2](imgs/47d11a88859d4e6b5c3262995eb318a2.jpg)"},{"bbox":{"x0":138,"x1":1088,"y0":542,"y1":703},"conf":0.9683,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":544,"y1":568},"font_size":5.658e-10,"text":"The blue highlighted marks represent special tokens, and the green part, quoted by brackets, is the tool declaration"},{"bbox":{"x0":141,"x1":1083,"y0":568,"y1":589},"font_size":5.658e-10,"text":"content. We use TypeScript to express the tool declaration content, since TypeScript is a concise language with a"},{"bbox":{"x0":140,"x1":1081,"y0":589,"y1":612},"font_size":5.658e-10,"text":"comprehensive type system, able to express the types and constraints of tool parameters with brief text. The code 1"},{"bbox":{"x0":138,"x1":1083,"y0":609,"y1":634},"font_size":5.658e-10,"text":"shows an example for two simple tools in JSON format compatible with OpenAI’s chat completion API, as a comparison,"},{"bbox":{"x0":138,"x1":1083,"y0":630,"y1":655},"font_size":5.658e-10,"text":"the same tools defned in TypeScript (listed in Code 2) is much shorter. To improve compatibility, part of our trainingi"},{"bbox":{"x0":138,"x1":1083,"y0":652,"y1":677},"font_size":5.658e-10,"text":"data also uses JSON as the tool declaration language, so that 3rd-party frameworks need not additional development to"},{"bbox":{"x0":138,"x1":403,"y0":675,"y1":700},"font_size":5.658e-10,"text":"support our tool calling scheme."}],"source":"layout det","text":"The blue highlighted marks represent special tokens, and the green part, quoted by brackets, is the tool declaration content. We use TypeScript to express the tool declaration content, since TypeScript is a concise language with a comprehensive type system, able to express the types and constraints of tool parameters with brief text. The code 1 shows an example for two simple tools in JSON format compatible with OpenAI’s chat completion API, as a comparison,the same tools defned in TypeScript (listed in Code 2) is much shorter. To improve compatibility, part of our trainingi data also uses JSON as the tool declaration language, so that 3rd-party frameworks need not additional development to support our tool calling scheme."},{"bbox":{"x0":347,"x1":874,"y0":713,"y1":743},"conf":0.7913,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":353,"x1":870,"y0":716,"y1":738},"font_size":8.0,"text":"Listing 1: Tool defnition with JSON in OpenAI compatible APIi"}],"source":"layout det","text":"Listing 1: Tool defnition with JSON in OpenAI compatible APIi"},{"bbox":{"x0":142,"x1":171,"y0":745,"y1":767},"conf":0.8317,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":170,"y0":746,"y1":767},"font_size":8.0,"text":"[{"}],"source":"layout det","text":"[{"},{"bbox":{"x0":164,"x1":383,"y0":767,"y1":787},"conf":0.8894,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":165,"x1":379,"y0":764,"y1":787},"font_size":8.0,"text":"\"type\": \"function\","}],"source":"layout det","text":"\"type\": \"function\","},{"bbox":{"x0":165,"x1":319,"y0":788,"y1":806},"conf":0.9054,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":318,"y0":782,"y1":807},"font_size":5.658e-10,"text":"\"function\": {"}],"source":"layout det","text":"\"function\": {"},{"bbox":{"x0":188,"x1":437,"y0":807,"y1":827},"conf":0.9045,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":185,"x1":436,"y0":802,"y1":827},"font_size":5.658e-10,"text":"\"name\": \"get_weather\","}],"source":"layout det","text":"\"name\": \"get_weather\","},{"bbox":{"x0":187,"x1":792,"y0":827,"y1":846},"conf":0.7959,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":185,"x1":788,"y0":822,"y1":846},"font_size":8.0,"text":"\"description\": \"Getweatherfor a locationand date\","}],"source":"layout det","text":"\"description\": \"Getweatherfor a locationand date\","},{"bbox":{"x0":186,"x1":362,"y0":848,"y1":867},"conf":0.9071,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":188,"x1":364,"y0":845,"y1":866},"font_size":5.658e-10,"text":"\"parameters\": {"}],"source":"layout det","text":"\"parameters\": {"},{"bbox":{"x0":207,"x1":407,"y0":867,"y1":887},"conf":0.7858,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":406,"y0":865,"y1":888},"font_size":8.0,"text":"\"type\": \"object\","}],"source":"layout det","text":"\"type\": \"object\","},{"bbox":{"x0":210,"x1":386,"y0":888,"y1":907},"conf":0.9077,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":209,"x1":384,"y0":883,"y1":908},"font_size":5.658e-10,"text":"\"properties\": {"}],"source":"layout det","text":"\"properties\": {"},{"bbox":{"x0":234,"x1":387,"y0":908,"y1":925},"conf":0.9093,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":233,"x1":384,"y0":904,"y1":926},"font_size":5.658e-10,"text":"\"location\": {"}],"source":"layout det","text":"\"location\": {"},{"bbox":{"x0":252,"x1":450,"y0":927,"y1":948},"conf":0.8044,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":256,"x1":446,"y0":926,"y1":947},"font_size":8.0,"text":"\"type\": \"string\","}],"source":"layout det","text":"\"type\": \"string\","},{"bbox":{"x0":253,"x1":859,"y0":948,"y1":970},"conf":0.8734,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":254,"x1":855,"y0":944,"y1":967},"font_size":8.0,"text":"\"description\": \"City andcountry e.g. Beijing , China\""}],"source":"layout det","text":"\"description\": \"City andcountry e.g. Beijing , China\""},{"bbox":{"x0":230,"x1":254,"y0":967,"y1":986},"conf":0.7701,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":231,"x1":254,"y0":965,"y1":987},"font_size":8.0,"text":"},"}],"source":"layout det","text":"},"},{"bbox":{"x0":232,"x1":341,"y0":987,"y1":1006},"conf":0.8814,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":229,"x1":343,"y0":980,"y1":1007},"font_size":8.0,"text":"\"date\": {"}],"source":"layout det","text":"\"date\": {"},{"bbox":{"x0":230,"x1":247,"y0":1046,"y1":1064},"conf":0.8055,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":231,"x1":246,"y0":1046,"y1":1064},"font_size":8.0,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":256,"x1":449,"y0":1007,"y1":1027},"conf":0.9044,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":254,"x1":447,"y0":1005,"y1":1028},"font_size":5.658e-10,"text":"\"type\": \"string\","}],"source":"layout det","text":"\"type\": \"string\","},{"bbox":{"x0":255,"x1":849,"y0":1025,"y1":1049},"conf":0.4463,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":251,"x1":845,"y0":1018,"y1":1049},"font_size":8.0,"text":"\"description\": \"Date to query , format in‘%Y-%m-%d’\""}],"source":"layout det","text":"\"description\": \"Date to query , format in‘%Y-%m-%d’\""},{"bbox":{"x0":209,"x1":230,"y0":1067,"y1":1085},"conf":0.8134,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":212,"x1":233,"y0":1070,"y1":1085},"font_size":8.0,"text":"},"}],"source":"layout det","text":"},"},{"bbox":{"x0":210,"x1":363,"y0":1086,"y1":1106},"conf":0.8844,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":208,"x1":361,"y0":1081,"y1":1106},"font_size":8.0,"text":"\"required\": ["}],"source":"layout det","text":"\"required\": ["},{"bbox":{"x0":235,"x1":347,"y0":1106,"y1":1125},"conf":0.8784,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":231,"x1":351,"y0":1102,"y1":1125},"font_size":8.0,"text":"\"location\""}],"source":"layout det","text":"\"location\""},{"bbox":{"x0":207,"x1":225,"y0":1124,"y1":1145},"conf":0.23,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":221,"y0":1125,"y1":1143},"font_size":8.0,"text":"]"}],"source":"layout det","text":"]"},{"bbox":{"x0":186,"x1":201,"y0":1146,"y1":1164},"conf":0.4569,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":186,"x1":201,"y0":1145,"y1":1163},"font_size":8.0,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":162,"x1":178,"y0":1165,"y1":1183},"conf":0.446,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":165,"x1":178,"y0":1167,"y1":1185},"font_size":8.0,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":140,"x1":157,"y0":1186,"y1":1204},"conf":0.6567,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":144,"x1":154,"y0":1189,"y1":1204},"font_size":8.0,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":140,"x1":158,"y0":1206,"y1":1224},"conf":0.7888,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":144,"x1":154,"y0":1209,"y1":1224},"font_size":8.0,"text":"{"}],"source":"layout det","text":"{"},{"bbox":{"x0":165,"x1":384,"y0":1225,"y1":1246},"conf":0.9003,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":167,"x1":380,"y0":1229,"y1":1244},"font_size":8.0,"text":"\"type\": \"function\","}],"source":"layout det","text":"\"type\": \"function\","},{"bbox":{"x0":165,"x1":313,"y0":1247,"y1":1265},"conf":0.8985,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":318,"y0":1241,"y1":1266},"font_size":8.0,"text":"\"function\": {"}],"source":"layout det","text":"\"function\": {"},{"bbox":{"x0":188,"x1":429,"y0":1266,"y1":1285},"conf":0.898,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":188,"x1":419,"y0":1262,"y1":1285},"font_size":8.0,"text":"\"name\": \"Calculator\","}],"source":"layout det","text":"\"name\": \"Calculator\","},{"bbox":{"x0":187,"x1":587,"y0":1286,"y1":1305},"conf":0.8966,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":186,"x1":584,"y0":1282,"y1":1307},"font_size":8.0,"text":"\"description\": \"Simplecalculator\","}],"source":"layout det","text":"\"description\": \"Simplecalculator\","},{"bbox":{"x0":189,"x1":369,"y0":1307,"y1":1324},"conf":0.8956,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":188,"x1":363,"y0":1302,"y1":1325},"font_size":8.0,"text":"\"parameters\": {"}],"source":"layout det","text":"\"parameters\": {"},{"bbox":{"x0":210,"x1":382,"y0":1325,"y1":1345},"conf":0.4331,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":209,"x1":386,"y0":1320,"y1":1346},"font_size":8.0,"text":"\"properties\": {"}],"source":"layout det","text":"\"properties\": {"},{"bbox":{"x0":234,"x1":339,"y0":1346,"y1":1365},"conf":0.9054,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":229,"x1":341,"y0":1340,"y1":1366},"font_size":5.658e-10,"text":"\"expr\": {"}],"source":"layout det","text":"\"expr\": {"},{"bbox":{"x0":229,"x1":247,"y0":1405,"y1":1423},"conf":0.7981,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":231,"x1":246,"y0":1406,"y1":1421},"font_size":8.0,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":258,"x1":449,"y0":1366,"y1":1386},"conf":0.9043,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":251,"x1":447,"y0":1360,"y1":1388},"font_size":5.658e-10,"text":"\"type\": \"string\","}],"source":"layout det","text":"\"type\": \"string\","},{"bbox":{"x0":256,"x1":848,"y0":1385,"y1":1408},"conf":0.8152,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":253,"x1":845,"y0":1379,"y1":1404},"font_size":8.0,"text":"\"description\": \"Arithmeticexpression in javascript\""}],"source":"layout det","text":"\"description\": \"Arithmeticexpression in javascript\""},{"bbox":{"x0":208,"x1":231,"y0":1425,"y1":1445},"conf":0.7758,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":213,"x1":231,"y0":1426,"y1":1442},"font_size":8.0,"text":"},"}],"source":"layout det","text":"},"}],"formula_dets":[],"height":792,"layout_dets":[{"bbox":{"x0":138,"x1":1088,"y0":542,"y1":703},"conf":0.9683,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":510,"y0":140,"y1":174},"conf":0.9199,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":675,"y0":190,"y1":220},"conf":0.911,"label":"Text","label_id":1},{"bbox":{"x0":234,"x1":387,"y0":908,"y1":925},"conf":0.9093,"label":"Text","label_id":1},{"bbox":{"x0":210,"x1":386,"y0":888,"y1":907},"conf":0.9077,"label":"Text","label_id":1},{"bbox":{"x0":186,"x1":362,"y0":848,"y1":867},"conf":0.9071,"label":"Text","label_id":1},{"bbox":{"x0":234,"x1":339,"y0":1346,"y1":1365},"conf":0.9054,"label":"Text","label_id":1},{"bbox":{"x0":165,"x1":319,"y0":788,"y1":806},"conf":0.9054,"label":"Text","label_id":1},{"bbox":{"x0":188,"x1":437,"y0":807,"y1":827},"conf":0.9045,"label":"Text","label_id":1},{"bbox":{"x0":256,"x1":449,"y0":1007,"y1":1027},"conf":0.9044,"label":"Text","label_id":1},{"bbox":{"x0":258,"x1":449,"y0":1366,"y1":1386},"conf":0.9043,"label":"Text","label_id":1},{"bbox":{"x0":165,"x1":384,"y0":1225,"y1":1246},"conf":0.9003,"label":"Text","label_id":1},{"bbox":{"x0":165,"x1":313,"y0":1247,"y1":1265},"conf":0.8985,"label":"Text","label_id":1},{"bbox":{"x0":188,"x1":429,"y0":1266,"y1":1285},"conf":0.898,"label":"Text","label_id":1},{"bbox":{"x0":187,"x1":587,"y0":1286,"y1":1305},"conf":0.8966,"label":"Text","label_id":1},{"bbox":{"x0":189,"x1":369,"y0":1307,"y1":1324},"conf":0.8956,"label":"Text","label_id":1},{"bbox":{"x0":179,"x1":921,"y0":230,"y1":259},"conf":0.8934,"label":"Text","label_id":1},{"bbox":{"x0":164,"x1":383,"y0":767,"y1":787},"conf":0.8894,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":728,"y0":331,"y1":360},"conf":0.8885,"label":"Text","label_id":1},{"bbox":{"x0":210,"x1":363,"y0":1086,"y1":1106},"conf":0.8844,"label":"Text","label_id":1},{"bbox":{"x0":174,"x1":745,"y0":291,"y1":320},"conf":0.8832,"label":"Text","label_id":1},{"bbox":{"x0":232,"x1":341,"y0":987,"y1":1006},"conf":0.8814,"label":"Text","label_id":1},{"bbox":{"x0":235,"x1":347,"y0":1106,"y1":1125},"conf":0.8784,"label":"Text","label_id":1},{"bbox":{"x0":253,"x1":859,"y0":948,"y1":970},"conf":0.8734,"label":"Text","label_id":1},{"bbox":{"x0":381,"x1":505,"y0":423,"y1":442},"conf":0.8613,"label":"Text","label_id":1},{"bbox":{"x0":176,"x1":905,"y0":261,"y1":288},"conf":0.8438,"label":"Text","label_id":1},{"bbox":{"x0":142,"x1":171,"y0":745,"y1":767},"conf":0.8317,"label":"Text","label_id":1},{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.8275,"label":"Abandon","label_id":2},{"bbox":{"x0":256,"x1":848,"y0":1385,"y1":1408},"conf":0.8152,"label":"Text","label_id":1},{"bbox":{"x0":209,"x1":230,"y0":1067,"y1":1085},"conf":0.8134,"label":"Text","label_id":1},{"bbox":{"x0":230,"x1":247,"y0":1046,"y1":1064},"conf":0.8055,"label":"Text","label_id":1},{"bbox":{"x0":252,"x1":450,"y0":927,"y1":948},"conf":0.8044,"label":"Text","label_id":1},{"bbox":{"x0":379,"x1":452,"y0":443,"y1":462},"conf":0.8043,"label":"Text","label_id":1},{"bbox":{"x0":229,"x1":247,"y0":1405,"y1":1423},"conf":0.7981,"label":"Text","label_id":1},{"bbox":{"x0":187,"x1":792,"y0":827,"y1":846},"conf":0.7959,"label":"Text","label_id":1},{"bbox":{"x0":347,"x1":874,"y0":713,"y1":743},"conf":0.7913,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":158,"y0":1206,"y1":1224},"conf":0.7888,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":407,"y0":867,"y1":887},"conf":0.7858,"label":"Text","label_id":1},{"bbox":{"x0":379,"x1":501,"y0":404,"y1":423},"conf":0.7813,"label":"Text","label_id":1},{"bbox":{"x0":208,"x1":231,"y0":1425,"y1":1445},"conf":0.7758,"label":"Text","label_id":1},{"bbox":{"x0":379,"x1":477,"y0":504,"y1":523},"conf":0.7708,"label":"Text","label_id":1},{"bbox":{"x0":230,"x1":254,"y0":967,"y1":986},"conf":0.7701,"label":"Text","label_id":1},{"bbox":{"x0":595,"x1":627,"y0":1480,"y1":1506},"conf":0.7666,"label":"Abandon","label_id":2},{"bbox":{"x0":207,"x1":223,"y0":1124,"y1":1144},"conf":0.7644,"label":"Text","label_id":1},{"bbox":{"x0":254,"x1":449,"y0":927,"y1":948},"conf":0.7514,"label":"Text","label_id":1},{"bbox":{"x0":209,"x1":381,"y0":1325,"y1":1345},"conf":0.7476,"label":"Text","label_id":1},{"bbox":{"x0":378,"x1":665,"y0":482,"y1":502},"conf":0.7444,"label":"Text","label_id":1},{"bbox":{"x0":379,"x1":499,"y0":383,"y1":405},"conf":0.6623,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":157,"y0":1186,"y1":1204},"conf":0.6567,"label":"Text","label_id":1},{"bbox":{"x0":378,"x1":852,"y0":374,"y1":531},"conf":0.6234,"label":"Figure","label_id":3},{"bbox":{"x0":186,"x1":201,"y0":1146,"y1":1164},"conf":0.4569,"label":"Text","label_id":1},{"bbox":{"x0":255,"x1":849,"y0":1025,"y1":1049},"conf":0.4463,"label":"Text","label_id":1},{"bbox":{"x0":162,"x1":178,"y0":1165,"y1":1183},"conf":0.446,"label":"Text","label_id":1},{"bbox":{"x0":210,"x1":382,"y0":1325,"y1":1345},"conf":0.4331,"label":"Text","label_id":1},{"bbox":{"x0":334,"x1":704,"y0":1028,"y1":1049},"conf":0.2682,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":225,"y0":1124,"y1":1145},"conf":0.23,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[595,1478],[629,1478],[629,1505],[595,1505]],"score":0.7533},{"poly":[[213,1426],[231,1426],[231,1442],[213,1442]],"score":0.6554},{"poly":[[231,1406],[246,1406],[246,1421],[231,1421]],"score":0.8202},{"poly":[[253,1379],[845,1381],[845,1404],[253,1402]],"score":0.689},{"poly":[[251,1360],[447,1360],[447,1388],[251,1388]],"score":0.6418},{"poly":[[230,1340],[341,1343],[340,1366],[229,1363]],"score":0.7301},{"poly":[[209,1322],[386,1320],[386,1345],[210,1346]],"score":0.6602},{"poly":[[188,1302],[363,1302],[363,1325],[188,1325]],"score":0.7037},{"poly":[[186,1282],[584,1285],[584,1307],[186,1303]],"score":0.7707},{"poly":[[188,1262],[419,1262],[419,1285],[188,1285]],"score":0.6909},{"poly":[[163,1241],[318,1243],[317,1266],[163,1264]],"score":0.7103},{"poly":[[140,1183],[166,1183],[166,1224],[140,1224]],"score":0.6227},{"poly":[[165,1167],[178,1167],[178,1185],[165,1185]],"score":0.7286},{"poly":[[186,1145],[201,1145],[201,1163],[186,1163]],"score":0.8314},{"poly":[[210,1125],[221,1125],[221,1143],[210,1143]],"score":0.8433},{"poly":[[231,1102],[351,1102],[351,1125],[231,1125]],"score":0.7256},{"poly":[[208,1081],[361,1082],[361,1106],[208,1104]],"score":0.7602},{"poly":[[219,1060],[234,1076],[220,1090],[205,1074]],"score":0.7221},{"poly":[[231,1046],[246,1046],[246,1064],[231,1064]],"score":0.774},{"poly":[[251,1021],[845,1018],[845,1046],[251,1049]],"score":0.6576},{"poly":[[254,1005],[447,1005],[447,1028],[254,1028]],"score":0.7309},{"poly":[[230,980],[343,984],[342,1007],[229,1003]],"score":0.7433},{"poly":[[231,965],[254,965],[254,987],[231,987]],"score":0.7098},{"poly":[[254,944],[855,944],[855,967],[254,967]],"score":0.7153},{"poly":[[256,926],[446,926],[446,947],[256,947]],"score":0.814},{"poly":[[233,904],[384,904],[384,926],[233,926]],"score":0.8228},{"poly":[[209,884],[384,883],[384,906],[210,908]],"score":0.7464},{"poly":[[210,865],[406,865],[406,888],[210,888]],"score":0.7147},{"poly":[[188,845],[364,845],[364,866],[188,866]],"score":0.779},{"poly":[[185,822],[788,823],[788,846],[185,845]],"score":0.7233},{"poly":[[185,802],[436,804],[436,827],[185,825]],"score":0.72},{"poly":[[163,782],[318,784],[317,807],[163,805]],"score":0.7438},{"poly":[[165,764],[379,764],[379,787],[165,787]],"score":0.7105},{"poly":[[143,746],[170,746],[170,767],[143,767]],"score":0.8999},{"poly":[[353,716],[870,716],[870,738],[353,738]],"score":0.8598},{"poly":[[138,677],[402,675],[403,698],[138,700]],"score":0.7666},{"poly":[[138,652],[1083,653],[1083,677],[138,675]],"score":0.753},{"poly":[[138,630],[1083,632],[1083,655],[138,653]],"score":0.7214},{"poly":[[138,609],[1083,611],[1083,634],[138,632]],"score":0.7226},{"poly":[[140,589],[1081,589],[1081,612],[140,612]],"score":0.7084},{"poly":[[141,568],[1083,568],[1083,589],[141,589]],"score":0.7896},{"poly":[[141,544],[1083,544],[1083,568],[141,568]],"score":0.7194},{"poly":[[379,502],[476,502],[476,520],[379,520]],"score":0.8584},{"poly":[[379,480],[662,480],[662,502],[379,502]],"score":0.8035},{"poly":[[379,441],[452,441],[452,464],[379,464]],"score":0.8328},{"poly":[[381,422],[502,422],[502,441],[381,441]],"score":0.8877},{"poly":[[381,403],[497,403],[497,421],[381,421]],"score":0.9016},{"poly":[[378,379],[496,383],[495,406],[377,402]],"score":0.7636},{"poly":[[141,332],[723,333],[723,356],[141,355]],"score":0.7651},{"poly":[[158,290],[738,292],[738,315],[158,313]],"score":0.7243},{"poly":[[158,261],[896,262],[896,285],[158,284]],"score":0.77},{"poly":[[158,229],[935,233],[935,256],[158,252]],"score":0.7054},{"poly":[[141,190],[670,193],[670,216],[141,213]],"score":0.7085},{"poly":[[140,142],[504,145],[504,168],[140,165]],"score":0.8036},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7339},{"poly":[[560,68],[662,68],[662,91],[560,91]],"score":0.8788}],"page_no":25,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.8385,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":162,"x1":613,"y0":1419,"y1":1506},"conf":0.2595,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":168,"x1":604,"y0":1421,"y1":1444},"font_size":0.0,"text":"6https://github.com/noamgat/lm-format-enforcer"},{"bbox":{"x0":602,"x1":612,"y0":1486,"y1":1504},"font_size":9.0,"text":"2"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":186,"x1":202,"y0":168,"y1":187},"conf":0.7714,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":186,"x1":201,"y0":168,"y1":186},"font_size":-5.078e-22,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":209,"x1":396,"y0":146,"y1":172},"conf":0.8859,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":208,"x1":394,"y0":144,"y1":172},"font_size":-5.078e-22,"text":"\"type\": \"object\""}],"source":"layout det","text":"\"type\": \"object\""},{"bbox":{"x0":164,"x1":180,"y0":188,"y1":207},"conf":0.3261,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":165,"x1":178,"y0":188,"y1":206},"font_size":-5.078e-22,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":139,"x1":168,"y0":208,"y1":230},"conf":0.7953,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":168,"y0":205,"y1":228},"font_size":-5.078e-22,"text":"}]"}],"source":"layout det","text":"}]"},{"bbox":{"x0":450,"x1":774,"y0":255,"y1":283},"conf":0.4375,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":451,"x1":770,"y0":254,"y1":281},"font_size":-5.078e-22,"text":"Listing 2: Tool defnition in TypeScripti"}],"source":"layout det","text":"Listing 2: Tool defnition in TypeScripti"},{"bbox":{"x0":140,"x1":386,"y0":287,"y1":308},"conf":0.8929,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":386,"y0":284,"y1":309},"font_size":-5.078e-22,"text":"namespacefunctions {"}],"source":"layout det","text":"namespacefunctions {"},{"bbox":{"x0":141,"x1":576,"y0":308,"y1":329},"conf":0.2343,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":574,"y0":307,"y1":328},"font_size":-5.078e-22,"text":"// Get weatherfor a locationand date"}],"source":"layout det","text":"// Get weatherfor a locationand date"},{"bbox":{"x0":140,"x1":421,"y0":330,"y1":350},"conf":0.8714,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":422,"y0":325,"y1":350},"font_size":-5.078e-22,"text":"typeget_weather = (_: {"}],"source":"layout det","text":"typeget_weather = (_: {"},{"bbox":{"x0":162,"x1":609,"y0":349,"y1":370},"conf":0.8818,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":609,"y0":346,"y1":370},"font_size":-5.078e-22,"text":"// City andcountry e.g. Beijing , China"}],"source":"layout det","text":"// City andcountry e.g. Beijing , China"},{"bbox":{"x0":162,"x1":359,"y0":370,"y1":387},"conf":0.5168,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":363,"y0":363,"y1":390},"font_size":-5.078e-22,"text":"location: string ,"}],"source":"layout det","text":"location: string ,"},{"bbox":{"x0":161,"x1":597,"y0":388,"y1":409},"conf":0.6657,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":597,"y0":381,"y1":411},"font_size":-5.078e-22,"text":"// Date to query , format in‘%Y-%m-%d’"}],"source":"layout det","text":"// Date to query , format in‘%Y-%m-%d’"},{"bbox":{"x0":163,"x1":313,"y0":409,"y1":427},"conf":0.8017,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":168,"x1":311,"y0":412,"y1":427},"font_size":-5.078e-22,"text":"date ?: string"}],"source":"layout det","text":"date ?: string"},{"bbox":{"x0":140,"x1":259,"y0":428,"y1":447},"conf":0.8777,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":261,"y0":422,"y1":449},"font_size":-5.078e-22,"text":"}) => any;"}],"source":"layout det","text":"}) => any;"},{"bbox":{"x0":140,"x1":372,"y0":449,"y1":467},"conf":0.9055,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":373,"y0":446,"y1":467},"font_size":-5.078e-22,"text":"// Simplecalculator"}],"source":"layout det","text":"// Simplecalculator"},{"bbox":{"x0":139,"x1":409,"y0":468,"y1":489},"conf":0.9076,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":408,"y0":462,"y1":489},"font_size":-5.078e-22,"text":"typeCalculator = (_: {"}],"source":"layout det","text":"typeCalculator = (_: {"},{"bbox":{"x0":164,"x1":599,"y0":489,"y1":509},"conf":0.8547,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":595,"y0":487,"y1":508},"font_size":-5.078e-22,"text":"// Arithmeticexpression in javascript"}],"source":"layout det","text":"// Arithmeticexpression in javascript"},{"bbox":{"x0":160,"x1":317,"y0":509,"y1":529},"conf":0.6764,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":316,"y0":503,"y1":530},"font_size":-5.078e-22,"text":"expr ?: string"}],"source":"layout det","text":"expr ?: string"},{"bbox":{"x0":140,"x1":258,"y0":529,"y1":548},"conf":0.8725,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":259,"y0":523,"y1":551},"font_size":-5.078e-22,"text":"}) => any;"}],"source":"layout det","text":"}) => any;"},{"bbox":{"x0":139,"x1":159,"y0":549,"y1":567},"conf":0.7985,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":158,"y0":548,"y1":566},"font_size":-5.078e-22,"text":"}"}],"source":"layout det","text":"}"},{"bbox":{"x0":204,"x1":946,"y0":587,"y1":616},"conf":0.6778,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":950,"y0":587,"y1":609},"font_size":-5.078e-22,"text":"en template of the tool invoking section in the model’s response messages is listed as follows"}],"source":"layout det","text":"en template of the tool invoking section in the model’s response messages is listed as follows"},{"bbox":{"x0":207,"x1":459,"y0":636,"y1":657},"conf":0.8832,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":457,"y0":634,"y1":657},"font_size":-5.078e-22,"text":"<tool_call_section_begin|>"}],"source":"layout det","text":"<tool_call_section_begin|>"},{"bbox":{"x0":208,"x1":392,"y0":657,"y1":677},"conf":0.8856,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":208,"x1":391,"y0":652,"y1":677},"font_size":-5.078e-22,"text":"<|tool_call_begin|>"}],"source":"layout det","text":"<|tool_call_begin|>"},{"bbox":{"x0":208,"x1":357,"y0":677,"y1":697},"conf":0.887,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":211,"x1":358,"y0":675,"y1":696},"font_size":-5.078e-22,"text":"// call_id part"}],"source":"layout det","text":"// call_id part"},{"bbox":{"x0":209,"x1":545,"y0":697,"y1":717},"conf":0.925,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":544,"y0":695,"y1":716},"font_size":-5.078e-22,"text":"functions.{{tool name}}:{{counter}}"}],"source":"layout det","text":"functions.{{tool name}}:{{counter}}"},{"bbox":{"x0":207,"x1":439,"y0":718,"y1":737},"conf":0.8916,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":441,"y0":714,"y1":738},"font_size":-5.078e-22,"text":"<|tool_arguments_begin|>"}],"source":"layout det","text":"<|tool_arguments_begin|>"},{"bbox":{"x0":205,"x1":551,"y0":738,"y1":757},"conf":0.5296,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":208,"x1":549,"y0":734,"y1":757},"font_size":-5.078e-22,"text":"{{ json serialized call arguments }}"}],"source":"layout det","text":"{{ json serialized call arguments }}"},{"bbox":{"x0":207,"x1":375,"y0":757,"y1":776},"conf":0.864,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":376,"y0":752,"y1":774},"font_size":-5.078e-22,"text":"<|tool_call_end|>"}],"source":"layout det","text":"<|tool_call_end|>"},{"bbox":{"x0":207,"x1":389,"y0":776,"y1":796},"conf":0.8824,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":208,"x1":391,"y0":770,"y1":795},"font_size":-5.078e-22,"text":"<|tool_call_begin|>"}],"source":"layout det","text":"<|tool_call_begin|>"},{"bbox":{"x0":207,"x1":385,"y0":797,"y1":815},"conf":0.8427,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":211,"x1":384,"y0":794,"y1":815},"font_size":-5.078e-22,"text":"// more tool calls"}],"source":"layout det","text":"// more tool calls"},{"bbox":{"x0":209,"x1":377,"y0":816,"y1":835},"conf":0.896,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":210,"x1":373,"y0":813,"y1":835},"font_size":-5.078e-22,"text":"<|tool_call_end|>"}],"source":"layout det","text":"<|tool_call_end|>"},{"bbox":{"x0":208,"x1":447,"y0":837,"y1":857},"conf":0.8635,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":208,"x1":447,"y0":833,"y1":855},"font_size":-5.078e-22,"text":"<|tool_call_section_end|>"}],"source":"layout det","text":"<|tool_call_section_end|>"},{"bbox":{"x0":137,"x1":1088,"y0":874,"y1":947},"conf":0.9336,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":876,"y1":898},"font_size":-5.078e-22,"text":"As shown in the template, we support parallel tool calling by placing multiple tool calls in a single response turn. Each"},{"bbox":{"x0":140,"x1":1083,"y0":898,"y1":919},"font_size":-5.078e-22,"text":"tool call has a unique call id, formatted as functions.{tool-name}:{counter}, where tool-name is the name of"},{"bbox":{"x0":138,"x1":911,"y0":917,"y1":944},"font_size":-5.078e-22,"text":"the tool, and counter is an auto-increasing counter of all tool calls starting from 0 in the dialog."}],"source":"layout det","text":"As shown in the template, we support parallel tool calling by placing multiple tool calls in a single response turn. Each tool call has a unique call id, formatted as functions.{tool-name}:{counter}, where tool-name is the name of the tool, and counter is an auto-increasing counter of all tool calls starting from 0 in the dialog."},{"bbox":{"x0":136,"x1":1086,"y0":950,"y1":1045},"conf":0.9404,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1081,"y0":949,"y1":974},"font_size":-5.078e-22,"text":"During inference, the model may occasionally generate unexpected tokens, leading to format errors when parsing a tool"},{"bbox":{"x0":138,"x1":1081,"y0":970,"y1":995},"font_size":-5.078e-22,"text":"call. To solve this issue, we developed a constrained decoding module named enforcer, inspired by lm-format-enforcer6."},{"bbox":{"x0":140,"x1":1081,"y0":993,"y1":1018},"font_size":-5.078e-22,"text":"When a <tool_call_section_begin|> token is generated, it ensures that the upcoming tool-related tokens follow"},{"bbox":{"x0":140,"x1":818,"y0":1018,"y1":1040},"font_size":-5.078e-22,"text":"the predefned template, and the JSON argument string follows the declared schema.i"}],"source":"layout det","text":"During inference, the model may occasionally generate unexpected tokens, leading to format errors when parsing a tool call. To solve this issue, we developed a constrained decoding module named enforcer, inspired by lm-format-enforcer6.When a <tool_call_section_begin|> token is generated, it ensures that the upcoming tool-related tokens follow the predefned template, and the JSON argument string follows the declared schema.i"},{"bbox":{"x0":138,"x1":1024,"y0":1049,"y1":1078},"conf":0.8955,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1019,"y0":1048,"y1":1073},"font_size":-5.078e-22,"text":"The tool result message is simply a text message encoded with the tool’s call id and the corresponding results."}],"source":"layout det","text":"The tool result message is simply a text message encoded with the tool’s call id and the corresponding results."},{"bbox":{"x0":378,"x1":496,"y0":1096,"y1":1119},"conf":0.7986,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":381,"x1":496,"y0":1097,"y1":1115},"font_size":-5.078e-22,"text":"<|im_begin|>"}],"source":"layout det","text":"<|im_begin|>"},{"bbox":{"x0":379,"x1":422,"y0":1119,"y1":1137},"conf":0.8567,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":381,"x1":424,"y0":1117,"y1":1135},"font_size":-5.078e-22,"text":"tool"}],"source":"layout det","text":"tool"},{"bbox":{"x0":381,"x1":505,"y0":1138,"y1":1157},"conf":0.5252,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":379,"x1":504,"y0":1134,"y1":1157},"font_size":-5.078e-22,"text":"<|im_middle|>"}],"source":"layout det","text":"<|im_middle|>"},{"bbox":{"x0":379,"x1":620,"y0":1158,"y1":1177},"conf":0.8923,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":379,"x1":620,"y0":1155,"y1":1176},"font_size":-5.078e-22,"text":"## Results of {{call_id}}"}],"source":"layout det","text":"## Results of {{call_id}}"},{"bbox":{"x0":378,"x1":665,"y0":1178,"y1":1197},"conf":0.9088,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":377,"x1":664,"y0":1173,"y1":1198},"font_size":-5.078e-22,"text":"{{ execution result content }}"}],"source":"layout det","text":"{{ execution result content }}"},{"bbox":{"x0":378,"x1":476,"y0":1198,"y1":1218},"conf":0.872,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":379,"x1":476,"y0":1196,"y1":1214},"font_size":-5.078e-22,"text":"<|im_end|>"}],"source":"layout det","text":"<|im_end|>"},{"bbox":{"x0":139,"x1":378,"y0":1245,"y1":1276},"conf":0.901,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":376,"y0":1247,"y1":1270},"font_size":-5.078e-22,"text":"CEvaluation Details"}],"source":"layout det","text":"CEvaluation Details"},{"bbox":{"x0":138,"x1":1087,"y0":1294,"y1":1412},"conf":0.9615,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1295,"y1":1318},"font_size":-5.078e-22,"text":"Coding Tasks.We evaluate Kimi-K2-Instruct’s capabilities on competitive coding benchmarks, LiveCodeBench and"},{"bbox":{"x0":140,"x1":1083,"y0":1318,"y1":1341},"font_size":-5.078e-22,"text":"OJBench, where Kimi-K2-Instruct attains superior performance with scores of $53.7\\%$ and $27.1\\%,$  respectively. This"},{"bbox":{"x0":140,"x1":1081,"y0":1340,"y1":1361},"font_size":-5.078e-22,"text":"excellence spans both medium-level coding challenges, such as LeetCode and AtCoder, and hard-level contests like NOI"},{"bbox":{"x0":136,"x1":1084,"y0":1358,"y1":1388},"font_size":-5.078e-22,"text":"and ICPC, outperforming leading open-source and proprietary models. For multilingual programming profciency, wei"},{"bbox":{"x0":140,"x1":1081,"y0":1383,"y1":1407},"font_size":-5.078e-22,"text":"employ MultiPL-E, covering languages including C++, C#, Java, JavaScript, PHP, Go, Kimi-K2-Instruct surpasses top"}],"source":"layout det","text":"Coding Tasks.We evaluate Kimi-K2-Instruct’s capabilities on competitive coding benchmarks, LiveCodeBench and OJBench, where Kimi-K2-Instruct attains superior performance with scores of $53.7\\%$ and $27.1\\%,$  respectively. This excellence spans both medium-level coding challenges, such as LeetCode and AtCoder, and hard-level contests like NOI and ICPC, outperforming leading open-source and proprietary models. For multilingual programming profciency, wei employ MultiPL-E, covering languages including C++, C#, Java, JavaScript, PHP, Go, Kimi-K2-Instruct surpasses top"}],"formula_dets":[{"bbox":{"x0":781,"x1":836,"y0":1319,"y1":1339},"conf":0.8044,"label":"print_embedding","label_id":0},{"bbox":{"x0":873,"x1":932,"y0":1319,"y1":1340},"conf":0.7244,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":138,"x1":1087,"y0":1294,"y1":1412},"conf":0.9615,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1086,"y0":950,"y1":1045},"conf":0.9404,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":874,"y1":947},"conf":0.9336,"label":"Text","label_id":1},{"bbox":{"x0":209,"x1":545,"y0":697,"y1":717},"conf":0.925,"label":"Text","label_id":1},{"bbox":{"x0":378,"x1":665,"y0":1178,"y1":1197},"conf":0.9088,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":409,"y0":468,"y1":489},"conf":0.9076,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":372,"y0":449,"y1":467},"conf":0.9055,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":378,"y0":1245,"y1":1276},"conf":0.901,"label":"Title","label_id":0},{"bbox":{"x0":209,"x1":377,"y0":816,"y1":835},"conf":0.896,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":1024,"y0":1049,"y1":1078},"conf":0.8955,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":386,"y0":287,"y1":308},"conf":0.8929,"label":"Text","label_id":1},{"bbox":{"x0":379,"x1":620,"y0":1158,"y1":1177},"conf":0.8923,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":439,"y0":718,"y1":737},"conf":0.8916,"label":"Text","label_id":1},{"bbox":{"x0":208,"x1":357,"y0":677,"y1":697},"conf":0.887,"label":"Text","label_id":1},{"bbox":{"x0":209,"x1":396,"y0":146,"y1":172},"conf":0.8859,"label":"Text","label_id":1},{"bbox":{"x0":208,"x1":392,"y0":657,"y1":677},"conf":0.8856,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":459,"y0":636,"y1":657},"conf":0.8832,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":389,"y0":776,"y1":796},"conf":0.8824,"label":"Text","label_id":1},{"bbox":{"x0":162,"x1":609,"y0":349,"y1":370},"conf":0.8818,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":259,"y0":428,"y1":447},"conf":0.8777,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":258,"y0":529,"y1":548},"conf":0.8725,"label":"Text","label_id":1},{"bbox":{"x0":378,"x1":476,"y0":1198,"y1":1218},"conf":0.872,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":421,"y0":330,"y1":350},"conf":0.8714,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":375,"y0":757,"y1":776},"conf":0.864,"label":"Text","label_id":1},{"bbox":{"x0":208,"x1":447,"y0":837,"y1":857},"conf":0.8635,"label":"Text","label_id":1},{"bbox":{"x0":379,"x1":422,"y0":1119,"y1":1137},"conf":0.8567,"label":"Text","label_id":1},{"bbox":{"x0":164,"x1":599,"y0":489,"y1":509},"conf":0.8547,"label":"Text","label_id":1},{"bbox":{"x0":206,"x1":551,"y0":738,"y1":757},"conf":0.8437,"label":"Text","label_id":1},{"bbox":{"x0":207,"x1":385,"y0":797,"y1":815},"conf":0.8427,"label":"Text","label_id":1},{"bbox":{"x0":164,"x1":317,"y0":509,"y1":528},"conf":0.84,"label":"Text","label_id":1},{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.8385,"label":"Abandon","label_id":2},{"bbox":{"x0":163,"x1":313,"y0":409,"y1":427},"conf":0.8017,"label":"Text","label_id":1},{"bbox":{"x0":378,"x1":496,"y0":1096,"y1":1119},"conf":0.7986,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":159,"y0":549,"y1":567},"conf":0.7985,"label":"Text","label_id":1},{"bbox":{"x0":140,"x1":392,"y0":309,"y1":328},"conf":0.7977,"label":"Text","label_id":1},{"bbox":{"x0":139,"x1":168,"y0":208,"y1":230},"conf":0.7953,"label":"Text","label_id":1},{"bbox":{"x0":186,"x1":202,"y0":168,"y1":187},"conf":0.7714,"label":"Text","label_id":1},{"bbox":{"x0":381,"x1":505,"y0":1138,"y1":1157},"conf":0.7647,"label":"Text","label_id":1},{"bbox":{"x0":204,"x1":946,"y0":587,"y1":616},"conf":0.6778,"label":"Text","label_id":1},{"bbox":{"x0":160,"x1":317,"y0":509,"y1":529},"conf":0.6764,"label":"Text","label_id":1},{"bbox":{"x0":162,"x1":358,"y0":370,"y1":387},"conf":0.6727,"label":"Text","label_id":1},{"bbox":{"x0":161,"x1":597,"y0":388,"y1":409},"conf":0.6657,"label":"Text","label_id":1},{"bbox":{"x0":595,"x1":627,"y0":1479,"y1":1506},"conf":0.6531,"label":"Abandon","label_id":2},{"bbox":{"x0":211,"x1":574,"y0":309,"y1":328},"conf":0.5773,"label":"Text","label_id":1},{"bbox":{"x0":205,"x1":551,"y0":738,"y1":757},"conf":0.5296,"label":"Text","label_id":1},{"bbox":{"x0":381,"x1":505,"y0":1138,"y1":1157},"conf":0.5252,"label":"Text","label_id":1},{"bbox":{"x0":162,"x1":359,"y0":370,"y1":387},"conf":0.5168,"label":"Text","label_id":1},{"bbox":{"x0":450,"x1":774,"y0":255,"y1":283},"conf":0.4955,"label":"Text","label_id":1},{"bbox":{"x0":162,"x1":607,"y0":1420,"y1":1449},"conf":0.4932,"label":"Abandon","label_id":2},{"bbox":{"x0":163,"x1":178,"y0":188,"y1":207},"conf":0.4748,"label":"Text","label_id":1},{"bbox":{"x0":450,"x1":774,"y0":255,"y1":283},"conf":0.4375,"label":"Title","label_id":0},{"bbox":{"x0":164,"x1":180,"y0":188,"y1":207},"conf":0.3261,"label":"Text","label_id":1},{"bbox":{"x0":223,"x1":593,"y0":388,"y1":408},"conf":0.2966,"label":"Text","label_id":1},{"bbox":{"x0":162,"x1":613,"y0":1419,"y1":1506},"conf":0.2595,"label":"Abandon","label_id":2},{"bbox":{"x0":210,"x1":581,"y0":388,"y1":408},"conf":0.2417,"label":"Text","label_id":1},{"bbox":{"x0":141,"x1":576,"y0":308,"y1":329},"conf":0.2343,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8783},{"poly":[[168,1421],[604,1421],[604,1444],[168,1444]],"score":0.7238},{"poly":[[140,1383],[1081,1384],[1081,1407],[140,1406]],"score":0.7738},{"poly":[[136,1358],[1084,1360],[1084,1388],[136,1386]],"score":0.6877},{"poly":[[140,1340],[1081,1340],[1081,1361],[140,1361]],"score":0.7946},{"poly":[[140,1318],[1083,1318],[1083,1341],[140,1341]],"score":0.7158},{"poly":[[141,1295],[1083,1295],[1083,1318],[141,1318]],"score":0.7341},{"poly":[[141,1247],[376,1247],[376,1270],[141,1270]],"score":0.8287},{"poly":[[379,1196],[476,1196],[476,1214],[379,1214]],"score":0.9019},{"poly":[[378,1173],[664,1175],[663,1198],[377,1196]],"score":0.7752},{"poly":[[379,1155],[620,1155],[620,1176],[379,1176]],"score":0.8923},{"poly":[[379,1134],[504,1134],[504,1157],[379,1157]],"score":0.7549},{"poly":[[381,1117],[424,1117],[424,1135],[381,1135]],"score":0.9238},{"poly":[[381,1097],[496,1097],[496,1115],[381,1115]],"score":0.8855},{"poly":[[140,1048],[1019,1049],[1019,1073],[140,1071]],"score":0.7379},{"poly":[[140,1018],[818,1018],[818,1040],[140,1040]],"score":0.8333},{"poly":[[140,993],[1081,995],[1081,1018],[140,1016]],"score":0.7396},{"poly":[[138,972],[1081,970],[1081,993],[138,995]],"score":0.6943},{"poly":[[138,949],[1081,950],[1081,974],[138,972]],"score":0.7429},{"poly":[[138,917],[911,921],[911,944],[138,940]],"score":0.7186},{"poly":[[140,898],[1083,898],[1083,919],[140,919]],"score":0.815},{"poly":[[140,876],[1081,876],[1081,898],[140,898]],"score":0.8498},{"poly":[[208,833],[447,833],[447,855],[208,855]],"score":0.8644},{"poly":[[210,813],[373,813],[373,835],[210,835]],"score":0.9349},{"poly":[[211,794],[384,794],[384,815],[211,815]],"score":0.8241},{"poly":[[208,770],[391,772],[391,795],[208,794]],"score":0.8},{"poly":[[210,752],[376,752],[376,774],[210,774]],"score":0.8087},{"poly":[[208,734],[549,734],[549,757],[208,757]],"score":0.708},{"poly":[[210,714],[441,714],[441,738],[210,738]],"score":0.7256},{"poly":[[210,695],[544,695],[544,716],[210,716]],"score":0.8732},{"poly":[[211,675],[358,675],[358,696],[211,696]],"score":0.8938},{"poly":[[208,652],[391,653],[391,677],[208,675]],"score":0.808},{"poly":[[210,634],[457,634],[457,657],[210,657]],"score":0.6822},{"poly":[[141,587],[950,587],[950,609],[141,609]],"score":0.7809},{"poly":[[141,548],[158,548],[158,566],[141,566]],"score":0.7509},{"poly":[[138,523],[259,523],[259,551],[138,551]],"score":0.7374},{"poly":[[162,503],[316,507],[316,530],[161,526]],"score":0.7206},{"poly":[[163,487],[595,487],[595,508],[163,508]],"score":0.8361},{"poly":[[140,465],[407,462],[408,485],[140,489]],"score":0.7476},{"poly":[[141,446],[373,446],[373,467],[141,467]],"score":0.84},{"poly":[[139,422],[261,426],[261,449],[138,445]],"score":0.7861},{"poly":[[162,401],[318,408],[317,433],[161,425]],"score":0.6959},{"poly":[[160,383],[597,381],[597,409],[160,411]],"score":0.6748},{"poly":[[162,363],[363,366],[362,390],[161,386]],"score":0.7003},{"poly":[[163,346],[609,346],[609,370],[163,370]],"score":0.7258},{"poly":[[140,327],[422,325],[422,348],[140,350]],"score":0.7314},{"poly":[[143,307],[574,307],[574,328],[143,328]],"score":0.8711},{"poly":[[140,285],[386,284],[386,307],[140,309]],"score":0.7658},{"poly":[[451,254],[770,256],[770,281],[451,279]],"score":0.7078},{"poly":[[143,205],[168,205],[168,228],[143,228]],"score":0.7918},{"poly":[[165,188],[178,188],[178,206],[165,206]],"score":0.8382},{"poly":[[186,168],[201,168],[201,186],[186,186]],"score":0.614},{"poly":[[208,144],[394,144],[394,172],[208,172]],"score":0.7016},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7826},{"poly":[[559,64],[664,64],[664,92],[559,92]],"score":0.8437}],"page_no":26,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":67,"y1":92},"conf":0.8062,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":920,"x1":1083,"y0":71,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":627,"y0":1480,"y1":1505},"conf":0.7238,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"28"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":135,"x1":1089,"y0":143,"y1":261},"conf":0.9558,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":144,"y1":170},"font_size":3.8880000000000005e-34,"text":"open-source models with an accuracy of $85.7\\%,$  compared with $83.1\\%$ for DeepSeek-V3-0324 and $78.2\\%$  for Qwen3-"},{"bbox":{"x0":140,"x1":1081,"y0":167,"y1":191},"font_size":3.8880000000000005e-34,"text":"235B-A22B. In software engineering tasks, Kimi-K2-Instruct demonstrates robust performance on SWE-bench Verifedi"},{"bbox":{"x0":141,"x1":1081,"y0":191,"y1":213},"font_size":3.8880000000000005e-34,"text":"(Python), SWE-lancer (Python), SWE-bench Multilingual, and Multi-SWE-bench datasets. It signifcantly outperformsi"},{"bbox":{"x0":141,"x1":1081,"y0":213,"y1":236},"font_size":3.8880000000000005e-34,"text":"open-source counterparts in resolving real-world code repository issues and notably narrows the performance gap with"},{"bbox":{"x0":140,"x1":413,"y0":231,"y1":259},"font_size":3.8880000000000005e-34,"text":"proprietary models. For example:"}],"source":"layout det","text":"open-source models with an accuracy of $85.7\\%,$  compared with $83.1\\%$ for DeepSeek-V3-0324 and $78.2\\%$  for Qwen3235B-A22B. In software engineering tasks, Kimi-K2-Instruct demonstrates robust performance on SWE-bench Verifedi(Python), SWE-lancer (Python), SWE-bench Multilingual, and Multi-SWE-bench datasets. It signifcantly outperformsi open-source counterparts in resolving real-world code repository issues and notably narrows the performance gap with proprietary models. For example:"},{"bbox":{"x0":172,"x1":965,"y0":270,"y1":302},"conf":0.3715,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":958,"y0":272,"y1":299},"font_size":3.8880000000000005e-34,"text":"SWE-bench Verifed (multiple attempts):i $71.6\\%$ (Kimi-K2-Instruct) vs. $80.2\\%$ (Claude 4 Sonnet)"}],"source":"layout det","text":"SWE-bench Verifed (multiple attempts):i $71.6\\%$ (Kimi-K2-Instruct) vs. $80.2\\%$ (Claude 4 Sonnet)"},{"bbox":{"x0":174,"x1":842,"y0":305,"y1":331},"conf":0.8801,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":838,"y0":304,"y1":328},"font_size":3.8880000000000005e-34,"text":"SWE-bench Multilingual: $47.3\\%$ (Kimi-K2-Instruct) vs. $51.0\\%$ (Claude 4 Sonnet)"}],"source":"layout det","text":"SWE-bench Multilingual: $47.3\\%$ (Kimi-K2-Instruct) vs. $51.0\\%$ (Claude 4 Sonnet)"},{"bbox":{"x0":173,"x1":738,"y0":336,"y1":362},"conf":0.8861,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":733,"y0":335,"y1":360},"font_size":3.8880000000000005e-34,"text":"SWE-lancer: $39.1\\%$ (Kimi-K2-Instruct) vs. $40.8\\%$ (Claude 4 Sonnet)"}],"source":"layout det","text":"SWE-lancer: $39.1\\%$ (Kimi-K2-Instruct) vs. $40.8\\%$ (Claude 4 Sonnet)"},{"bbox":{"x0":136,"x1":1087,"y0":376,"y1":515},"conf":0.9657,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":375,"y1":406},"font_size":3.8880000000000005e-34,"text":"On PaperBench, Kimi-K2-Instruct achieves an accuracy of $27.8\\%,$ closely matching GPT-4.1 and outperforming"},{"bbox":{"x0":141,"x1":1081,"y0":402,"y1":424},"font_size":3.8880000000000005e-34,"text":"DeepSeek-V3-0324 (12.2%) and Qwen3-235B-A22B $(8.2\\%)$  by a substantial margin. In terminal interaction tasks"},{"bbox":{"x0":140,"x1":1081,"y0":424,"y1":446},"font_size":3.8880000000000005e-34,"text":"measured by TerminalBench, Kimi-K2-Instruct attains $25.0\\%$  using the default Terminus framework and rises to"},{"bbox":{"x0":142,"x1":1081,"y0":442,"y1":469},"font_size":3.8880000000000005e-34,"text":"$30\\%$ within Moonshot’s in-house agentic framework, underscoring its capabilities in real-world agentic programming"},{"bbox":{"x0":140,"x1":1081,"y0":465,"y1":492},"font_size":3.8880000000000005e-34,"text":"scenarios. Moreover, on the Aider-Polyglot benchmark, Kimi-K2-Instruct attains a $60.0\\%$  accuracy while employing"},{"bbox":{"x0":141,"x1":1074,"y0":490,"y1":512},"font_size":3.8880000000000005e-34,"text":"rigorous decontamination procedures, further illustrating its strength and reliability across diverse coding environments."}],"source":"layout det","text":"On PaperBench, Kimi-K2-Instruct achieves an accuracy of $27.8\\%,$ closely matching GPT-4.1 and outperforming DeepSeek-V3-0324 (12.2%) and Qwen3-235B-A22B $(8.2\\%)$  by a substantial margin. In terminal interaction tasks measured by TerminalBench, Kimi-K2-Instruct attains $25.0\\%$  using the default Terminus framework and rises to $30\\%$ within Moonshot’s in-house agentic framework, underscoring its capabilities in real-world agentic programming scenarios. Moreover, on the Aider-Polyglot benchmark, Kimi-K2-Instruct attains a $60.0\\%$  accuracy while employing rigorous decontamination procedures, further illustrating its strength and reliability across diverse coding environments."},{"bbox":{"x0":137,"x1":1088,"y0":532,"y1":781},"conf":0.9777,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":536,"y1":559},"font_size":3.8880000000000005e-34,"text":"Tool Use Tasks.We evaluate multi-turn tool use with two complementary suites: $\\boldsymbol{\\tau^{2}}$ -Bench and ACEBench. $\\boldsymbol{\\tau^{2}}$ Bench"},{"bbox":{"x0":141,"x1":1083,"y0":559,"y1":582},"font_size":3.8880000000000005e-34,"text":"extends the original $7$ -bench single-control setup to a dual-control environment in which both the agent and an LLM-"},{"bbox":{"x0":140,"x1":1081,"y0":582,"y1":604},"font_size":3.8880000000000005e-34,"text":"simulated user have constrained tool affordances over a shared state, adding a realistic Telecom troubleshooting domain"},{"bbox":{"x0":141,"x1":1081,"y0":604,"y1":625},"font_size":3.8880000000000005e-34,"text":"alongside the prior Airline/Retail TAU tasks and enabling analysis of coordination vs. pure reasoning. ACEBench is a"},{"bbox":{"x0":143,"x1":1081,"y0":625,"y1":647},"font_size":3.8880000000000005e-34,"text":"large bilingual (En/Zh) API-grounded benchmark (4.5K APIs across 8 domains; 2K annotated eval items) partitioned"},{"bbox":{"x0":140,"x1":1081,"y0":647,"y1":668},"font_size":3.8880000000000005e-34,"text":"into NORMAL (basic/personalized/atomic), SPECIAL (imperfect or out-of-scope inputs), and AGENT (scenario-driven"},{"bbox":{"x0":140,"x1":1081,"y0":668,"y1":691},"font_size":3.8880000000000005e-34,"text":"multi-turn, multi-step sandbox) tracks with automated grading of calls and outcomes. All models run in non-thinking"},{"bbox":{"x0":140,"x1":1081,"y0":690,"y1":713},"font_size":3.8880000000000005e-34,"text":"mode; we set the temperature to 0.0, use deterministic tool adapters, score $\\boldsymbol{\\tau^{2}}$  Airline/Retail/Telecom under Avg@4"},{"bbox":{"x0":141,"x1":1081,"y0":713,"y1":734},"font_size":3.8880000000000005e-34,"text":"seeds with Pass@1/4, and report overall on ACEBench English. Kimi-K2-Instruct averages 66.1 micro Pass@1 across"},{"bbox":{"x0":142,"x1":1081,"y0":734,"y1":756},"font_size":3.8880000000000005e-34,"text":"$\\boldsymbol{\\tau^{2}}$ vs DeepSeek-V3-0324 48.8 / Qwen3-235B-A22B 37.3. On ACEBench Overall Kimi-K2-Instruct scores 76.5 vs"},{"bbox":{"x0":141,"x1":738,"y0":756,"y1":777},"font_size":3.8880000000000005e-34,"text":"DeepSeek 72.7 / Qwen 70.5 and remains competitive with GPT-4.1 (80.1)."}],"source":"layout det","text":"Tool Use Tasks.We evaluate multi-turn tool use with two complementary suites: $\\boldsymbol{\\tau^{2}}$ -Bench and ACEBench. $\\boldsymbol{\\tau^{2}}$ Bench extends the original $7$ -bench single-control setup to a dual-control environment in which both the agent and an LLMsimulated user have constrained tool affordances over a shared state, adding a realistic Telecom troubleshooting domain alongside the prior Airline/Retail TAU tasks and enabling analysis of coordination vs. pure reasoning. ACEBench is a large bilingual (En/Zh) API-grounded benchmark (4.5K APIs across 8 domains; 2K annotated eval items) partitioned into NORMAL (basic/personalized/atomic), SPECIAL (imperfect or out-of-scope inputs), and AGENT (scenario-driven multi-turn, multi-step sandbox) tracks with automated grading of calls and outcomes. All models run in non-thinking mode; we set the temperature to 0.0, use deterministic tool adapters, score $\\boldsymbol{\\tau^{2}}$  Airline/Retail/Telecom under Avg@4 seeds with Pass@1/4, and report overall on ACEBench English. Kimi-K2-Instruct averages 66.1 micro Pass@1 across $\\boldsymbol{\\tau^{2}}$ vs DeepSeek-V3-0324 48.8 / Qwen3-235B-A22B 37.3. On ACEBench Overall Kimi-K2-Instruct scores 76.5 vs DeepSeek 72.7 / Qwen 70.5 and remains competitive with GPT-4.1 (80.1)."},{"bbox":{"x0":137,"x1":1089,"y0":798,"y1":1004},"conf":0.9769,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":804,"y1":827},"font_size":3.8880000000000005e-34,"text":"Math & STEM & Logical Tasks.For Math tasks, Kimi-K2-Instruct achieves consistently strong performance,"},{"bbox":{"x0":140,"x1":1081,"y0":825,"y1":848},"font_size":3.8880000000000005e-34,"text":"averaging over Geimini-2.5-Flash by 5.3 percentage points, over DeepSeek-V3-0324 by 5.5 points and over GPT4.1 by"},{"bbox":{"x0":141,"x1":1081,"y0":846,"y1":870},"font_size":3.8880000000000005e-34,"text":"15.8 points. For example, on AIME 2024, Kimi-K2-Instruct scores $69.6\\%,$  outperforming another two top open-source"},{"bbox":{"x0":141,"x1":1081,"y0":870,"y1":891},"font_size":3.8880000000000005e-34,"text":"models by a large margin, DeepSeek-V3-0324 by 10.2 points and Qwen3-235B-A22B by 29.5 points. In STEM"},{"bbox":{"x0":141,"x1":1081,"y0":890,"y1":912},"font_size":3.8880000000000005e-34,"text":"evaluations, Kimi-K2-Instruct achieves $75.1\\%$ on GPQA-Diamond, outperforming DeepSeek-V3-0324 (68.4%) and all"},{"bbox":{"x0":140,"x1":1081,"y0":912,"y1":936},"font_size":3.8880000000000005e-34,"text":"non-thinking baselines by at least 5 percentage points. On SuperGPQA, it also exceeds the previous best open-source"},{"bbox":{"x0":141,"x1":1081,"y0":934,"y1":957},"font_size":3.8880000000000005e-34,"text":"model, DeepSeek-V3-0324, by 3.5 points. Kimi-K2-Instruct also surpasses the other two leading models in logical"},{"bbox":{"x0":141,"x1":1083,"y0":955,"y1":978},"font_size":3.8880000000000005e-34,"text":"reasoning. It achieves $89.0\\%$ on ZebraLogic and $89.5\\%$  on AutoLogi, exceeding DeepSeek-V3-0324 (84.0%, 88.9%)"},{"bbox":{"x0":140,"x1":701,"y0":977,"y1":1000},"font_size":3.8880000000000005e-34,"text":"and substantially outperforming Qwen3-235B-A22B $(37.7\\%,83.3\\%).$"}],"source":"layout det","text":"Math & STEM & Logical Tasks.For Math tasks, Kimi-K2-Instruct achieves consistently strong performance,averaging over Geimini-2.5-Flash by 5.3 percentage points, over DeepSeek-V3-0324 by 5.5 points and over GPT4.1 by 15.8 points. For example, on AIME 2024, Kimi-K2-Instruct scores $69.6\\%,$  outperforming another two top open-source models by a large margin, DeepSeek-V3-0324 by 10.2 points and Qwen3-235B-A22B by 29.5 points. In STEM evaluations, Kimi-K2-Instruct achieves $75.1\\%$ on GPQA-Diamond, outperforming DeepSeek-V3-0324 (68.4%) and all non-thinking baselines by at least 5 percentage points. On SuperGPQA, it also exceeds the previous best open-source model, DeepSeek-V3-0324, by 3.5 points. Kimi-K2-Instruct also surpasses the other two leading models in logical reasoning. It achieves $89.0\\%$ on ZebraLogic and $89.5\\%$  on AutoLogi, exceeding DeepSeek-V3-0324 (84.0%, 88.9%) and substantially outperforming Qwen3-235B-A22B $(37.7\\%,83.3\\%).$"},{"bbox":{"x0":137,"x1":1088,"y0":1021,"y1":1293},"conf":0.978,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":1028,"y1":1044},"font_size":3.8880000000000005e-34,"text":"General Tasks.Kimi-K2-Instruct ties DeepSeek-V3-0324 on MMLU and MMLU-Pro, and takes the lead on MMLU-"},{"bbox":{"x0":140,"x1":1081,"y0":1046,"y1":1071},"font_size":3.8880000000000005e-34,"text":"Redux with a 92.7 EM score—slightly ahead of GPT-4.1 (92.4) and just 1.5 points behind Claude-Opus-4. Beyond"},{"bbox":{"x0":140,"x1":1081,"y0":1069,"y1":1092},"font_size":3.8880000000000005e-34,"text":"multiple-choice tasks, the model achieves $31.0\\%$  accuracy on the short-answer SimpleQA—3.3 points above DeepSeek-"},{"bbox":{"x0":141,"x1":1081,"y0":1090,"y1":1112},"font_size":3.8880000000000005e-34,"text":"V3-0324 and more than twice that of Qwen3-235B-A22B—though still below GPT-4.1 $(42.\\tilde{3\\%}).$  On the adversarial"},{"bbox":{"x0":140,"x1":1081,"y0":1110,"y1":1137},"font_size":3.8880000000000005e-34,"text":"free-response LiveBench (2024-11-25 snapshot), it reaches $76.4\\%,$  surpassing Claude-Sonnet 4 (74.8%) and leading"},{"bbox":{"x0":140,"x1":1081,"y0":1135,"y1":1157},"font_size":3.8880000000000005e-34,"text":"Gemini 2.5 Flash Preview by 8.6 points. Across this challenging triad measuring breadth, depth, and robustness of world"},{"bbox":{"x0":141,"x1":1081,"y0":1158,"y1":1181},"font_size":3.8880000000000005e-34,"text":"knowledge, Kimi-K2-Instruct secures a top-tier position among open-source models. We evaluate instruction-following"},{"bbox":{"x0":141,"x1":1081,"y0":1178,"y1":1201},"font_size":3.8880000000000005e-34,"text":"with IFEval and Multi-Challenge. On IFEval, Kimi-K2-Instruct scores $89.8\\%,$  higher than DeepSeek-V3-0324 (81.1%)"},{"bbox":{"x0":138,"x1":1081,"y0":1198,"y1":1223},"font_size":3.8880000000000005e-34,"text":"and GPT-4.1 (88.0%). On Multi-Challenge, which involves multi-turn dialogues with conficting instructions, it achievesl"},{"bbox":{"x0":141,"x1":1081,"y0":1220,"y1":1244},"font_size":3.8880000000000005e-34,"text":"54.1%, outperforming DeepSeek-V3-0324 (31.4%), GPT-4.1 (36.4%), and Claude-Opus-4 $\\left(49.0\\%\\right)$ . These results"},{"bbox":{"x0":141,"x1":1081,"y0":1244,"y1":1267},"font_size":3.8880000000000005e-34,"text":"demonstrate that Kimi-K2-Instruct integrates strong factual knowledge with consistent instruction adherence across"},{"bbox":{"x0":140,"x1":863,"y0":1267,"y1":1290},"font_size":3.8880000000000005e-34,"text":"both single- and multi-turn settings, supporting robust and reliable real-world deployment."}],"source":"layout det","text":"General Tasks.Kimi-K2-Instruct ties DeepSeek-V3-0324 on MMLU and MMLU-Pro, and takes the lead on MMLURedux with a 92.7 EM score—slightly ahead of GPT-4.1 (92.4) and just 1.5 points behind Claude-Opus-4. Beyond multiple-choice tasks, the model achieves $31.0\\%$  accuracy on the short-answer SimpleQA—3.3 points above DeepSeekV3-0324 and more than twice that of Qwen3-235B-A22B—though still below GPT-4.1 $(42.\\tilde{3\\%}).$  On the adversarial free-response LiveBench (2024-11-25 snapshot), it reaches $76.4\\%,$  surpassing Claude-Sonnet 4 (74.8%) and leading Gemini 2.5 Flash Preview by 8.6 points. Across this challenging triad measuring breadth, depth, and robustness of world knowledge, Kimi-K2-Instruct secures a top-tier position among open-source models. We evaluate instruction-following with IFEval and Multi-Challenge. On IFEval, Kimi-K2-Instruct scores $89.8\\%,$  higher than DeepSeek-V3-0324 (81.1%)and GPT-4.1 (88.0%). On Multi-Challenge, which involves multi-turn dialogues with conficting instructions, it achievesl 54.1%, outperforming DeepSeek-V3-0324 (31.4%), GPT-4.1 (36.4%), and Claude-Opus-4 $\\left(49.0\\%\\right)$ . These results demonstrate that Kimi-K2-Instruct integrates strong factual knowledge with consistent instruction adherence across both single- and multi-turn settings, supporting robust and reliable real-world deployment."},{"bbox":{"x0":135,"x1":1089,"y0":1309,"y1":1450},"conf":0.9642,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1313,"y1":1336},"font_size":3.8880000000000005e-34,"text":"Long Context and Factuality Tasks.To evaluate the factuality of Kimi-K2-Instruct, we employ three benchmarks:"},{"bbox":{"x0":141,"x1":1079,"y0":1336,"y1":1358},"font_size":3.8880000000000005e-34,"text":"FACTS Grounding, which measures adherence to provided documents using the proprietary models GPT-4o, Gemini"},{"bbox":{"x0":140,"x1":1079,"y0":1356,"y1":1381},"font_size":3.8880000000000005e-34,"text":"1.5 Pro and Claude 3.5 Sonnet; HHEM, which assesses summarization quality via the open-source HHEM-2.1-Open"},{"bbox":{"x0":141,"x1":1081,"y0":1379,"y1":1401},"font_size":3.8880000000000005e-34,"text":"judge; and FaithJudge, which analyzes faithfulness in RAG tasks with o3-mini as the judge. Kimi-K2-Instruct scores"},{"bbox":{"x0":140,"x1":1081,"y0":1399,"y1":1424},"font_size":3.8880000000000005e-34,"text":"88.5 on FACTS Grounding, substantially outperforming all open-source rivals and even surpassing the closed-source"},{"bbox":{"x0":140,"x1":1081,"y0":1421,"y1":1445},"font_size":3.8880000000000005e-34,"text":"Gemini 2.5 Flash. With HHEM-2.1-Open it achieves a hallucination rate of 1.1 %, reported in the tables as 1 minus the"}],"source":"layout det","text":"Long Context and Factuality Tasks.To evaluate the factuality of Kimi-K2-Instruct, we employ three benchmarks:FACTS Grounding, which measures adherence to provided documents using the proprietary models GPT-4o, Gemini 1.5 Pro and Claude 3.5 Sonnet; HHEM, which assesses summarization quality via the open-source HHEM-2.1-Open judge; and FaithJudge, which analyzes faithfulness in RAG tasks with o3-mini as the judge. Kimi-K2-Instruct scores 88.5 on FACTS Grounding, substantially outperforming all open-source rivals and even surpassing the closed-source Gemini 2.5 Flash. With HHEM-2.1-Open it achieves a hallucination rate of 1.1 %, reported in the tables as 1 minus the"}],"formula_dets":[{"bbox":{"x0":748,"x1":768,"y0":690,"y1":708},"conf":0.8398,"label":"print_embedding","label_id":0},{"bbox":{"x0":811,"x1":864,"y0":467,"y1":486},"conf":0.8377,"label":"print_embedding","label_id":0},{"bbox":{"x0":142,"x1":163,"y0":734,"y1":753},"conf":0.8214,"label":"print_embedding","label_id":0},{"bbox":{"x0":600,"x1":654,"y0":424,"y1":443},"conf":0.7984,"label":"print_embedding","label_id":0},{"bbox":{"x0":142,"x1":181,"y0":445,"y1":464},"conf":0.7974,"label":"print_embedding","label_id":0},{"bbox":{"x0":321,"x1":375,"y0":955,"y1":975},"conf":0.7806,"label":"print_embedding","label_id":0},{"bbox":{"x0":700,"x1":757,"y0":1178,"y1":1199},"conf":0.7645,"label":"print_embedding","label_id":0},{"bbox":{"x0":1001,"x1":1024,"y0":537,"y1":555},"conf":0.7555,"label":"print_embedding","label_id":0},{"bbox":{"x0":623,"x1":681,"y0":1112,"y1":1133},"conf":0.7519,"label":"print_embedding","label_id":0},{"bbox":{"x0":389,"x1":444,"y0":304,"y1":327},"conf":0.7515,"label":"print_embedding","label_id":0},{"bbox":{"x0":637,"x1":697,"y0":377,"y1":400},"conf":0.7469,"label":"print_embedding","label_id":0},{"bbox":{"x0":632,"x1":688,"y0":304,"y1":328},"conf":0.7438,"label":"print_embedding","label_id":0},{"bbox":{"x0":529,"x1":584,"y0":336,"y1":358},"conf":0.7352,"label":"print_embedding","label_id":0},{"bbox":{"x0":454,"x1":507,"y0":890,"y1":910},"conf":0.7327,"label":"print_embedding","label_id":0},{"bbox":{"x0":789,"x1":811,"y0":537,"y1":555},"conf":0.7275,"label":"print_embedding","label_id":0},{"bbox":{"x0":753,"x1":808,"y0":273,"y1":296},"conf":0.722,"label":"print_embedding","label_id":0},{"bbox":{"x0":933,"x1":986,"y0":144,"y1":166},"conf":0.7129,"label":"print_embedding","label_id":0},{"bbox":{"x0":674,"x1":731,"y0":846,"y1":867},"conf":0.7129,"label":"print_embedding","label_id":0},{"bbox":{"x0":510,"x1":566,"y0":272,"y1":297},"conf":0.7079,"label":"print_embedding","label_id":0},{"bbox":{"x0":467,"x1":525,"y0":144,"y1":167},"conf":0.6922,"label":"print_embedding","label_id":0},{"bbox":{"x0":472,"x1":524,"y0":1069,"y1":1089},"conf":0.6911,"label":"print_embedding","label_id":0},{"bbox":{"x0":534,"x1":588,"y0":955,"y1":975},"conf":0.6758,"label":"print_embedding","label_id":0},{"bbox":{"x0":286,"x1":341,"y0":335,"y1":359},"conf":0.6671,"label":"print_embedding","label_id":0},{"bbox":{"x0":891,"x1":956,"y0":1220,"y1":1243},"conf":0.6342,"label":"print_embedding","label_id":0},{"bbox":{"x0":588,"x1":642,"y0":402,"y1":422},"conf":0.6336,"label":"print_embedding","label_id":0},{"bbox":{"x0":305,"x1":316,"y0":565,"y1":577},"conf":0.6288,"label":"print_embedding","label_id":0},{"bbox":{"x0":652,"x1":706,"y0":144,"y1":167},"conf":0.6054,"label":"print_embedding","label_id":0},{"bbox":{"x0":854,"x1":924,"y0":1090,"y1":1112},"conf":0.5786,"label":"print_embedding","label_id":0},{"bbox":{"x0":570,"x1":701,"y0":977,"y1":1000},"conf":0.5097,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":137,"x1":1088,"y0":1021,"y1":1293},"conf":0.978,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":532,"y1":781},"conf":0.9777,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":798,"y1":1004},"conf":0.9769,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1087,"y0":376,"y1":515},"conf":0.9657,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":1309,"y1":1450},"conf":0.9642,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1089,"y0":143,"y1":261},"conf":0.9558,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":738,"y0":336,"y1":362},"conf":0.8861,"label":"Text","label_id":1},{"bbox":{"x0":174,"x1":842,"y0":305,"y1":331},"conf":0.8801,"label":"Text","label_id":1},{"bbox":{"x0":558,"x1":1086,"y0":67,"y1":92},"conf":0.8062,"label":"Abandon","label_id":2},{"bbox":{"x0":204,"x1":945,"y0":273,"y1":301},"conf":0.7429,"label":"Text","label_id":1},{"bbox":{"x0":596,"x1":627,"y0":1480,"y1":1505},"conf":0.7238,"label":"Abandon","label_id":2},{"bbox":{"x0":172,"x1":965,"y0":270,"y1":302},"conf":0.3715,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1480],[625,1480],[625,1503],[599,1503]],"score":0.8472},{"poly":[[140,1421],[1081,1422],[1081,1445],[140,1444]],"score":0.7941},{"poly":[[140,1399],[1081,1401],[1081,1424],[140,1422]],"score":0.7593},{"poly":[[141,1379],[1081,1379],[1081,1401],[141,1401]],"score":0.7879},{"poly":[[140,1356],[1079,1358],[1079,1381],[140,1379]],"score":0.7309},{"poly":[[141,1336],[1079,1336],[1079,1358],[141,1358]],"score":0.7983},{"poly":[[141,1313],[1083,1313],[1083,1336],[141,1336]],"score":0.7228},{"poly":[[140,1267],[863,1267],[863,1290],[140,1290]],"score":0.7427},{"poly":[[141,1244],[1081,1244],[1081,1267],[141,1267]],"score":0.6931},{"poly":[[141,1223],[1081,1223],[1081,1244],[141,1244]],"score":0.8174},{"poly":[[138,1198],[1081,1200],[1081,1223],[138,1221]],"score":0.7551},{"poly":[[141,1180],[1081,1180],[1081,1201],[141,1201]],"score":0.8281},{"poly":[[141,1158],[1081,1158],[1081,1181],[141,1181]],"score":0.7016},{"poly":[[140,1135],[1081,1135],[1081,1157],[140,1157]],"score":0.8178},{"poly":[[140,1110],[1081,1114],[1081,1137],[140,1134]],"score":0.698},{"poly":[[141,1091],[1081,1091],[1081,1112],[141,1112]],"score":0.8279},{"poly":[[140,1071],[1081,1071],[1081,1092],[140,1092]],"score":0.7908},{"poly":[[140,1046],[1081,1048],[1081,1071],[140,1069]],"score":0.767},{"poly":[[143,1028],[1081,1028],[1081,1044],[143,1044]],"score":0.9866},{"poly":[[140,978],[700,978],[700,1000],[140,1000]],"score":0.8229},{"poly":[[141,957],[1083,957],[1083,978],[141,978]],"score":0.8143},{"poly":[[141,934],[1081,934],[1081,957],[141,957]],"score":0.7179},{"poly":[[140,912],[1081,912],[1081,936],[140,936]],"score":0.6895},{"poly":[[141,891],[1081,891],[1081,912],[141,912]],"score":0.84},{"poly":[[141,870],[1081,870],[1081,891],[141,891]],"score":0.8249},{"poly":[[141,848],[1081,848],[1081,870],[141,870]],"score":0.8029},{"poly":[[140,825],[1081,825],[1081,848],[140,848]],"score":0.7205},{"poly":[[141,804],[1083,804],[1083,827],[141,827]],"score":0.7156},{"poly":[[141,756],[738,756],[738,777],[141,777]],"score":0.8006},{"poly":[[143,734],[1081,734],[1081,756],[143,756]],"score":0.828},{"poly":[[141,713],[1081,713],[1081,734],[141,734]],"score":0.7641},{"poly":[[140,691],[1081,691],[1081,713],[140,713]],"score":0.829},{"poly":[[140,668],[1081,668],[1081,691],[140,691]],"score":0.6952},{"poly":[[140,647],[1081,647],[1081,668],[140,668]],"score":0.8156},{"poly":[[143,625],[1081,625],[1081,647],[143,647]],"score":0.8341},{"poly":[[141,604],[1081,604],[1081,625],[141,625]],"score":0.7919},{"poly":[[140,582],[1081,582],[1081,604],[140,604]],"score":0.8177},{"poly":[[141,559],[1083,559],[1083,582],[141,582]],"score":0.7152},{"poly":[[141,536],[1081,536],[1081,559],[141,559]],"score":0.7136},{"poly":[[141,490],[1074,490],[1074,512],[141,512]],"score":0.81},{"poly":[[140,465],[1081,469],[1081,492],[140,488]],"score":0.7121},{"poly":[[140,442],[1081,446],[1081,469],[140,465]],"score":0.6879},{"poly":[[140,424],[1081,424],[1081,446],[140,446]],"score":0.7664},{"poly":[[141,403],[1081,403],[1081,424],[141,424]],"score":0.8188},{"poly":[[138,375],[1083,378],[1083,406],[138,403]],"score":0.6145},{"poly":[[160,338],[733,338],[733,360],[160,360]],"score":0.8245},{"poly":[[160,307],[838,307],[838,328],[160,328]],"score":0.8265},{"poly":[[161,277],[958,277],[958,299],[161,299]],"score":0.8303},{"poly":[[140,236],[412,231],[413,254],[140,259]],"score":0.7019},{"poly":[[141,213],[1081,213],[1081,236],[141,236]],"score":0.7081},{"poly":[[141,191],[1081,191],[1081,213],[141,213]],"score":0.8181},{"poly":[[140,167],[1081,168],[1081,191],[140,190]],"score":0.7502},{"poly":[[140,147],[1083,145],[1083,168],[140,170]],"score":0.7671},{"poly":[[920,71],[1083,71],[1083,92],[920,92]],"score":0.7811},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8304}],"page_no":27,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":152,"x1":1051,"y0":1415,"y1":1508},"conf":0.5209,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"29"},{"bbox":{"x0":171,"x1":506,"y0":1422,"y1":1444},"font_size":0.0,"text":"7https://lmarena.ai/leaderboard/text"}],"source":"layout det","text":""},{"bbox":{"x0":137,"x1":1088,"y0":64,"y1":101},"conf":0.2003,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":560,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":234,"x1":991,"y0":140,"y1":512},"conf":0.975,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![9ae91e074d2d46c6bf8a0ffffd5fbc9d](imgs/9ae91e074d2d46c6bf8a0ffffd5fbc9d.jpg)"},{"bbox":{"x0":399,"x1":824,"y0":521,"y1":550},"conf":0.8991,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":404,"x1":817,"y0":523,"y1":544},"font_size":-5.032e-22,"text":"Figure 11: Chinese in-house benchmark evaluation."}],"source":"layout det","text":"Figure 11: Chinese in-house benchmark evaluation."},{"bbox":{"x0":135,"x1":1090,"y0":589,"y1":684},"conf":0.9471,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":590,"y1":614},"font_size":-5.032e-22,"text":"rate, i.e. 98.9. On FaithJudge’s RAG tasks the hallucination rate is $7.4 \\%,$ likewise present as 92.6 for table consistency."},{"bbox":{"x0":141,"x1":1083,"y0":614,"y1":635},"font_size":-5.032e-22,"text":"For long-context capabilities, Kimi-K2-Instruct outperforms all open source and proprietary models on DROP (93.5%),"},{"bbox":{"x0":140,"x1":1079,"y0":635,"y1":657},"font_size":-5.032e-22,"text":"and exceeds DeepSeek-V3-0324 on retrieval task MRCR $(55.0\\%$  vs $50.8\\%$ . For long-context reasoning tasks FRAMES"},{"bbox":{"x0":140,"x1":1022,"y0":656,"y1":680},"font_size":-5.032e-22,"text":"and LongBench v2, Kimi-K2-Instruct $(77.1\\%,49.1\\%)$  lags slightly behind DeepSeek-V3-0324 by around $2\\%.$"}],"source":"layout det","text":"rate, i.e. 98.9. On FaithJudge’s RAG tasks the hallucination rate is $7.4 \\%,$ likewise present as 92.6 for table consistency.For long-context capabilities, Kimi-K2-Instruct outperforms all open source and proprietary models on DROP (93.5%),and exceeds DeepSeek-V3-0324 on retrieval task MRCR $(55.0\\%$  vs $50.8\\%$ . For long-context reasoning tasks FRAMES and LongBench v2, Kimi-K2-Instruct $(77.1\\%,49.1\\%)$  lags slightly behind DeepSeek-V3-0324 by around $2\\%.$"},{"bbox":{"x0":136,"x1":1091,"y0":702,"y1":754},"conf":0.9235,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":703,"y1":728},"font_size":-5.032e-22,"text":"Open-Ended EvaluationBeyond static, closed-ended benchmarks, we evaluate the model’s performance on open-"},{"bbox":{"x0":140,"x1":677,"y0":728,"y1":749},"font_size":-5.032e-22,"text":"ended, nuanced tasks that more closely resemble real-world usage."}],"source":"layout det","text":"Open-Ended EvaluationBeyond static, closed-ended benchmarks, we evaluate the model’s performance on openended, nuanced tasks that more closely resemble real-world usage."},{"bbox":{"x0":137,"x1":1088,"y0":757,"y1":896},"conf":0.972,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":759,"y1":780},"font_size":-5.032e-22,"text":"For English scenarios, we leverage the Arena-Hard-Auto v2.0 benchmark, which use LLM-as-a-judge protocols to"},{"bbox":{"x0":140,"x1":1083,"y0":780,"y1":804},"font_size":-5.032e-22,"text":"assess generation quality across diverse, open-ended prompts [42]. These evaluations cover a wide range of high-"},{"bbox":{"x0":140,"x1":1083,"y0":804,"y1":825},"font_size":-5.032e-22,"text":"diffculty prompts and are widely recognized in the research community. On Arena-Hard-Auto v2.0, Kimi-K2-Instructi"},{"bbox":{"x0":138,"x1":1083,"y0":823,"y1":848},"font_size":-5.032e-22,"text":"achieves state-of-the-art win-rate on both hard prompts $\\left(54.5\\%\\right)$  and creative writing tasks $(85.0\\%)$ , outperforming all"},{"bbox":{"x0":136,"x1":1084,"y0":843,"y1":873},"font_size":-5.032e-22,"text":"open-source models and rivaling top proprietary systems such as GPT-4.1 and Claude Sonnet. These results underscore"},{"bbox":{"x0":138,"x1":1054,"y0":866,"y1":891},"font_size":-5.032e-22,"text":"the model’s strength in handling complex reasoning and nuanced generation under diverse, unconstrained settings."}],"source":"layout det","text":"For English scenarios, we leverage the Arena-Hard-Auto v2.0 benchmark, which use LLM-as-a-judge protocols to assess generation quality across diverse, open-ended prompts [42]. These evaluations cover a wide range of highdiffculty prompts and are widely recognized in the research community. On Arena-Hard-Auto v2.0, Kimi-K2-Instructi achieves state-of-the-art win-rate on both hard prompts $\\left(54.5\\%\\right)$  and creative writing tasks $(85.0\\%)$ , outperforming all open-source models and rivaling top proprietary systems such as GPT-4.1 and Claude Sonnet. These results underscore the model’s strength in handling complex reasoning and nuanced generation under diverse, unconstrained settings."},{"bbox":{"x0":135,"x1":1090,"y0":898,"y1":972},"conf":0.9532,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":901,"y1":924},"font_size":-5.032e-22,"text":"However, Arena-Hard-Auto provides limited coverage of Chinese-specifc tasks. To address this gap, we developedi"},{"bbox":{"x0":140,"x1":1083,"y0":924,"y1":945},"font_size":-5.032e-22,"text":"an in-house held-out benchmark grounded in authentic user queries. To safeguard the integrity of the evaluation, the"},{"bbox":{"x0":138,"x1":768,"y0":942,"y1":969},"font_size":-5.032e-22,"text":"benchmark data is access-restricted, thereby eliminating the risk of overftting.i"}],"source":"layout det","text":"However, Arena-Hard-Auto provides limited coverage of Chinese-specifc tasks. To address this gap, we developedi an in-house held-out benchmark grounded in authentic user queries. To safeguard the integrity of the evaluation, the benchmark data is access-restricted, thereby eliminating the risk of overftting.i"},{"bbox":{"x0":136,"x1":1091,"y0":976,"y1":1070},"conf":0.957,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":977,"y1":998},"font_size":-5.032e-22,"text":"As shown in Figure 11, Kimi-K2-Instruct shows strong performance across all comparisons on Chinese in-house"},{"bbox":{"x0":140,"x1":1083,"y0":998,"y1":1020},"font_size":-5.032e-22,"text":"benchmarks. It outperforms ChatGPT-4o-latest with a $65.4\\%$  win rate, Claude Sonnet 4 with $64.6\\%,$  and DeepSeek-V3-"},{"bbox":{"x0":140,"x1":1083,"y0":1021,"y1":1043},"font_size":-5.032e-22,"text":"0324 with $59.6\\%.$  In all cases, the loss rate stays low (around $17\\%$ ), indicating that Kimi-K2-Instruct rarely falls behind."},{"bbox":{"x0":141,"x1":958,"y0":1041,"y1":1063},"font_size":-5.032e-22,"text":"The high win rates and consistent margins demonstrate its strong ability on open-ended Chinese tasks."}],"source":"layout det","text":"As shown in Figure 11, Kimi-K2-Instruct shows strong performance across all comparisons on Chinese in-house benchmarks. It outperforms ChatGPT-4o-latest with a $65.4\\%$  win rate, Claude Sonnet 4 with $64.6\\%,$  and DeepSeek-V30324 with $59.6\\%.$  In all cases, the loss rate stays low (around $17\\%$ ), indicating that Kimi-K2-Instruct rarely falls behind.The high win rates and consistent margins demonstrate its strong ability on open-ended Chinese tasks."},{"bbox":{"x0":136,"x1":1090,"y0":1074,"y1":1189},"conf":0.9598,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1076,"y1":1097},"font_size":-5.032e-22,"text":"In addition to controlled evaluations, we also consider real-world user preference through public human assessments."},{"bbox":{"x0":141,"x1":1083,"y0":1097,"y1":1120},"font_size":-5.032e-22,"text":"As of July 17, 2025, Kimi-K2-Instruct ranked as the top open-source model and ffth overall on the LMSYS Arenai"},{"bbox":{"x0":140,"x1":1081,"y0":1120,"y1":1142},"font_size":-5.032e-22,"text":"leaderboard7, based on over 3,000 blind votes from real users. Unlike LLM-as-a-judge protocols, this leaderboard"},{"bbox":{"x0":140,"x1":1081,"y0":1142,"y1":1165},"font_size":-5.032e-22,"text":"refects direct human preference on diverse, user-submitted prompts, providing a complementary perspective on practicall"},{"bbox":{"x0":140,"x1":306,"y0":1163,"y1":1185},"font_size":-5.032e-22,"text":"model performance."}],"source":"layout det","text":"In addition to controlled evaluations, we also consider real-world user preference through public human assessments.As of July 17, 2025, Kimi-K2-Instruct ranked as the top open-source model and ffth overall on the LMSYS Arenai leaderboard7, based on over 3,000 blind votes from real users. Unlike LLM-as-a-judge protocols, this leaderboard refects direct human preference on diverse, user-submitted prompts, providing a complementary perspective on practicall model performance."},{"bbox":{"x0":136,"x1":1090,"y0":1193,"y1":1268},"conf":0.9474,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1193,"y1":1218},"font_size":-5.032e-22,"text":"The results on Arena-Hard-Auto, our in-house benchmark and votes from LMSYS Arena collectively offer a compre-"},{"bbox":{"x0":141,"x1":1083,"y0":1218,"y1":1241},"font_size":-5.032e-22,"text":"hensive view of Kimi-K2-Instruct’s open-ended capabilities, showing that it is a highly preferred model in real-world"},{"bbox":{"x0":140,"x1":497,"y0":1241,"y1":1262},"font_size":-5.032e-22,"text":"user experience across English and Chinese."}],"source":"layout det","text":"The results on Arena-Hard-Auto, our in-house benchmark and votes from LMSYS Arena collectively offer a comprehensive view of Kimi-K2-Instruct’s open-ended capabilities, showing that it is a highly preferred model in real-world user experience across English and Chinese."},{"bbox":{"x0":135,"x1":611,"y0":1291,"y1":1327},"conf":0.9223,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":602,"y0":1294,"y1":1320},"font_size":-5.032e-22,"text":"DQK-Clip Does Not Impair Model Quality"}],"source":"layout det","text":"DQK-Clip Does Not Impair Model Quality"},{"bbox":{"x0":135,"x1":1088,"y0":1341,"y1":1397},"conf":0.9105,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1083,"y0":1345,"y1":1366},"font_size":-5.032e-22,"text":"The QK-Clip design follows a minimal intervention principle: it activates only when necessary, and deactivates after"},{"bbox":{"x0":138,"x1":966,"y0":1366,"y1":1391},"font_size":-5.032e-22,"text":"training stabilizes. Empirical evidence and analysis converge on its negligible impact on model quality."}],"source":"layout det","text":"The QK-Clip design follows a minimal intervention principle: it activates only when necessary, and deactivates after training stabilizes. Empirical evidence and analysis converge on its negligible impact on model quality."}],"formula_dets":[{"bbox":{"x0":871,"x1":928,"y0":999,"y1":1020},"conf":0.7869,"label":"print_embedding","label_id":0},{"bbox":{"x0":569,"x1":621,"y0":1000,"y1":1019},"conf":0.7781,"label":"print_embedding","label_id":0},{"bbox":{"x0":225,"x1":282,"y0":1021,"y1":1042},"conf":0.7656,"label":"print_embedding","label_id":0},{"bbox":{"x0":449,"x1":576,"y0":656,"y1":680},"conf":0.7433,"label":"print_embedding","label_id":0},{"bbox":{"x0":989,"x1":1022,"y0":658,"y1":677},"conf":0.7322,"label":"print_embedding","label_id":0},{"bbox":{"x0":587,"x1":650,"y0":825,"y1":847},"conf":0.7236,"label":"print_embedding","label_id":0},{"bbox":{"x0":625,"x1":662,"y0":1021,"y1":1042},"conf":0.7194,"label":"print_embedding","label_id":0},{"bbox":{"x0":593,"x1":649,"y0":635,"y1":655},"conf":0.6881,"label":"print_embedding","label_id":0},{"bbox":{"x0":674,"x1":729,"y0":635,"y1":656},"conf":0.6787,"label":"print_embedding","label_id":0},{"bbox":{"x0":667,"x1":721,"y0":590,"y1":613},"conf":0.6677,"label":"print_embedding","label_id":0},{"bbox":{"x0":865,"x1":927,"y0":825,"y1":847},"conf":0.664,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":234,"x1":991,"y0":140,"y1":512},"conf":0.975,"label":"Figure","label_id":3},{"bbox":{"x0":137,"x1":1088,"y0":757,"y1":896},"conf":0.972,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1090,"y0":1074,"y1":1189},"conf":0.9598,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1091,"y0":976,"y1":1070},"conf":0.957,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1090,"y0":898,"y1":972},"conf":0.9532,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1090,"y0":1193,"y1":1268},"conf":0.9474,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":1090,"y0":589,"y1":684},"conf":0.9471,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1091,"y0":702,"y1":754},"conf":0.9235,"label":"Text","label_id":1},{"bbox":{"x0":135,"x1":611,"y0":1291,"y1":1327},"conf":0.9223,"label":"Title","label_id":0},{"bbox":{"x0":135,"x1":1088,"y0":1341,"y1":1397},"conf":0.9105,"label":"Text","label_id":1},{"bbox":{"x0":399,"x1":824,"y0":521,"y1":550},"conf":0.8991,"label":"Figure caption","label_id":4},{"bbox":{"x0":557,"x1":1087,"y0":66,"y1":94},"conf":0.6743,"label":"Abandon","label_id":2},{"bbox":{"x0":152,"x1":1051,"y0":1415,"y1":1508},"conf":0.5209,"label":"Abandon","label_id":2},{"bbox":{"x0":163,"x1":511,"y0":1419,"y1":1450},"conf":0.4063,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":627,"y0":1479,"y1":1506},"conf":0.3604,"label":"Abandon","label_id":2},{"bbox":{"x0":137,"x1":1088,"y0":64,"y1":101},"conf":0.2003,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8482},{"poly":[[171,1422],[506,1422],[506,1444],[171,1444]],"score":0.8748},{"poly":[[138,1366],[966,1368],[966,1391],[138,1389]],"score":0.7592},{"poly":[[141,1345],[1083,1345],[1083,1366],[141,1366]],"score":0.8479},{"poly":[[140,1294],[602,1297],[602,1320],[140,1317]],"score":0.8099},{"poly":[[140,1241],[497,1241],[497,1262],[140,1262]],"score":0.8186},{"poly":[[141,1218],[1083,1218],[1083,1241],[141,1241]],"score":0.7198},{"poly":[[140,1193],[1081,1195],[1081,1218],[140,1216]],"score":0.7668},{"poly":[[140,1163],[306,1163],[306,1185],[140,1185]],"score":0.8363},{"poly":[[140,1142],[1081,1142],[1081,1165],[140,1165]],"score":0.6836},{"poly":[[140,1120],[1081,1120],[1081,1142],[140,1142]],"score":0.8189},{"poly":[[141,1097],[1083,1097],[1083,1120],[141,1120]],"score":0.707},{"poly":[[140,1076],[1083,1076],[1083,1097],[140,1097]],"score":0.7893},{"poly":[[141,1041],[958,1041],[958,1063],[141,1063]],"score":0.6675},{"poly":[[140,1021],[1083,1021],[1083,1043],[140,1043]],"score":0.7875},{"poly":[[140,998],[1083,998],[1083,1020],[140,1020]],"score":0.8038},{"poly":[[140,977],[1081,977],[1081,998],[140,998]],"score":0.8029},{"poly":[[138,942],[768,945],[768,969],[138,965]],"score":0.7139},{"poly":[[140,924],[1083,924],[1083,945],[140,945]],"score":0.8054},{"poly":[[140,901],[1083,901],[1083,924],[140,924]],"score":0.6782},{"poly":[[138,866],[1054,868],[1054,891],[138,889]],"score":0.7513},{"poly":[[136,846],[1084,843],[1084,870],[136,873]],"score":0.6964},{"poly":[[138,823],[1083,825],[1083,848],[138,846]],"score":0.7079},{"poly":[[140,804],[1083,804],[1083,825],[140,825]],"score":0.8088},{"poly":[[140,780],[1083,780],[1083,804],[140,804]],"score":0.6998},{"poly":[[140,759],[1081,759],[1081,780],[140,780]],"score":0.804},{"poly":[[140,728],[677,728],[677,749],[140,749]],"score":0.7829},{"poly":[[140,703],[1083,705],[1083,728],[140,726]],"score":0.7645},{"poly":[[140,657],[1019,657],[1019,680],[140,680]],"score":0.711},{"poly":[[140,635],[1079,635],[1079,657],[140,657]],"score":0.7931},{"poly":[[141,614],[1083,614],[1083,635],[141,635]],"score":0.7883},{"poly":[[140,592],[1083,592],[1083,614],[140,614]],"score":0.8267},{"poly":[[404,523],[817,523],[817,544],[404,544]],"score":0.8287},{"poly":[[632,490],[690,490],[690,508],[632,508]],"score":0.8163},{"poly":[[950,474],[980,469],[984,491],[954,496]],"score":0.7018},{"poly":[[707,474],[735,474],[735,493],[707,493]],"score":0.7648},{"poly":[[585,474],[614,474],[614,495],[585,495]],"score":0.7646},{"poly":[[464,474],[492,474],[492,495],[464,495]],"score":0.8092},{"poly":[[832,472],[856,472],[856,495],[832,495]],"score":0.7731},{"poly":[[348,474],[363,474],[363,492],[348,492]],"score":0.7091},{"poly":[[244,431],[349,431],[349,447],[244,447]],"score":0.802},{"poly":[[891,416],[938,416],[938,441],[891,441]],"score":0.8201},{"poly":[[788,417],[832,417],[832,437],[788,437]],"score":0.9172},{"poly":[[532,417],[579,417],[579,439],[532,439]],"score":0.9216},{"poly":[[268,414],[351,414],[351,431],[268,431]],"score":0.8082},{"poly":[[251,337],[351,337],[351,355],[251,355]],"score":0.6769},{"poly":[[896,325],[938,325],[938,345],[896,345]],"score":0.9421},{"poly":[[787,325],[830,325],[830,345],[787,345]],"score":0.8994},{"poly":[[530,323],[574,327],[572,347],[528,343]],"score":0.777},{"poly":[[268,322],[353,322],[353,340],[268,340]],"score":0.6873},{"poly":[[241,244],[349,244],[349,261],[241,261]],"score":0.9545},{"poly":[[893,229],[940,229],[940,254],[893,254]],"score":0.8668},{"poly":[[770,231],[813,231],[813,251],[770,251]],"score":0.9587},{"poly":[[514,229],[559,229],[559,254],[514,254]],"score":0.8463},{"poly":[[268,229],[351,229],[351,246],[268,246]],"score":0.8917},{"poly":[[906,188],[961,188],[961,206],[906,206]],"score":0.6283},{"poly":[[627,165],[695,165],[695,183],[627,183]],"score":0.8245},{"poly":[[529,147],[795,147],[795,163],[529,163]],"score":0.9446},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.753},{"poly":[[560,64],[664,64],[664,92],[560,92]],"score":0.8019}],"page_no":28,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":557,"x1":1086,"y0":66,"y1":93},"conf":0.8066,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":919,"x1":1081,"y0":68,"y1":93},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":596,"x1":627,"y0":1480,"y1":1506},"conf":0.7388,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":627,"y0":1482,"y1":1503},"font_size":0.0,"text":"30"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":383,"x1":839,"y0":140,"y1":412},"conf":0.9728,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![c5ba74d06ce322720c11b9b5373e5d71](imgs/c5ba74d06ce322720c11b9b5373e5d71.jpg)"},{"bbox":{"x0":380,"x1":843,"y0":419,"y1":515},"conf":0.9532,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":386,"x1":838,"y0":424,"y1":446},"font_size":-3.085e+36,"text":"Figure 12: Applying QK-Clip to Muon in a small-scale"},{"bbox":{"x0":382,"x1":838,"y0":444,"y1":469},"font_size":-3.085e+36,"text":"setting with an aggresive threshold $(\\tau=30)$  has negligible"},{"bbox":{"x0":386,"x1":838,"y0":469,"y1":490},"font_size":-3.085e+36,"text":"impact on loss, indicating that it is a safe and effective"},{"bbox":{"x0":386,"x1":707,"y0":492,"y1":508},"font_size":-3.085e+36,"text":"method for constraining attention logits."}],"source":"layout det","text":"Figure 12: Applying QK-Clip to Muon in a small-scale setting with an aggresive threshold $(\\tau=30)$  has negligible impact on loss, indicating that it is a safe and effective method for constraining attention logits."},{"bbox":{"x0":136,"x1":1088,"y0":552,"y1":714},"conf":0.9709,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":554,"y1":576},"font_size":-3.085e+36,"text":"Small-Scale AblationsWe train two small-scale 0.5B activated and 3B total parameters MoE models, one with vanilla"},{"bbox":{"x0":141,"x1":1079,"y0":576,"y1":599},"font_size":-3.085e+36,"text":"Muon and the other with MuonClip using a low clipping threshold $\\left(\\tau=30\\right)$  As shown in Figure 12, applying MuonClip"},{"bbox":{"x0":140,"x1":1081,"y0":597,"y1":624},"font_size":-3.085e+36,"text":"has negligible effects on the loss curve, indicating that even aggressive clipping does not impair convergence or training"},{"bbox":{"x0":141,"x1":1081,"y0":622,"y1":644},"font_size":-3.085e+36,"text":"dynamics with MuonClip. This demonstrates that MuonClip is a safe and effective method for bounding attention logits"},{"bbox":{"x0":140,"x1":1081,"y0":644,"y1":665},"font_size":-3.085e+36,"text":"without degrading model performance. Furthermore, evaluation on downstream tasks reveals no statistically signifcanti"},{"bbox":{"x0":141,"x1":1083,"y0":665,"y1":686},"font_size":-3.085e+36,"text":"degradation in performance. These results collectively demonstrate that MuonClip is a safe and effective method for"},{"bbox":{"x0":141,"x1":645,"y0":688,"y1":710},"font_size":-3.085e+36,"text":"bounding attention logits without compromising model quality."}],"source":"layout det","text":"Small-Scale AblationsWe train two small-scale 0.5B activated and 3B total parameters MoE models, one with vanilla Muon and the other with MuonClip using a low clipping threshold $\\left(\\tau=30\\right)$  As shown in Figure 12, applying MuonClip has negligible effects on the loss curve, indicating that even aggressive clipping does not impair convergence or training dynamics with MuonClip. This demonstrates that MuonClip is a safe and effective method for bounding attention logits without degrading model performance. Furthermore, evaluation on downstream tasks reveals no statistically signifcanti degradation in performance. These results collectively demonstrate that MuonClip is a safe and effective method for bounding attention logits without compromising model quality."},{"bbox":{"x0":137,"x1":706,"y0":730,"y1":760},"conf":0.8889,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":700,"y0":731,"y1":756},"font_size":-3.085e+36,"text":"Self-deactivationIn Kimi K2, QK-Clip was only transiently active:"}],"source":"layout det","text":"Self-deactivationIn Kimi K2, QK-Clip was only transiently active:"},{"bbox":{"x0":278,"x1":1019,"y0":771,"y1":800},"conf":0.7726,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1019,"y0":771,"y1":797},"font_size":-3.085e+36,"text":"• Initial 70000 steps: $12.7\\%$ of attention heads triggered QK-Clip for at least once, clamping $S_{\\max}$  to 100."}],"source":"layout det","text":"• Initial 70000 steps: $12.7\\%$ of attention heads triggered QK-Clip for at least once, clamping $S_{\\max}$  to 100."},{"bbox":{"x0":174,"x1":1004,"y0":802,"y1":831},"conf":0.8716,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1000,"y0":802,"y1":827},"font_size":-3.085e+36,"text":"Post-70000 steps: All heads at some point reduced their $S_{\\max}$ below 100, rendering QK-Clip inactive."}],"source":"layout det","text":"Post-70000 steps: All heads at some point reduced their $S_{\\max}$ below 100, rendering QK-Clip inactive."},{"bbox":{"x0":137,"x1":1086,"y0":841,"y1":894},"conf":0.9135,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":843,"y1":868},"font_size":-3.085e+36,"text":"When QK-Clip is active, it is applied per-head (rather than per-layer) to minimize potential over-regularization on other"},{"bbox":{"x0":141,"x1":767,"y0":868,"y1":889},"font_size":-3.085e+36,"text":"heads. After training stabilizes, QK-clip is deactivated and has no effect at all."}],"source":"layout det","text":"When QK-Clip is active, it is applied per-head (rather than per-layer) to minimize potential over-regularization on other heads. After training stabilizes, QK-clip is deactivated and has no effect at all."},{"bbox":{"x0":138,"x1":649,"y0":918,"y1":953},"conf":0.9121,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":644,"y0":921,"y1":945},"font_size":-3.085e+36,"text":"EWhy Muon is More Prone to Logit Explosion"}],"source":"layout det","text":"EWhy Muon is More Prone to Logit Explosion"},{"bbox":{"x0":137,"x1":691,"y0":969,"y1":998},"conf":0.8929,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":685,"y0":972,"y1":993},"font_size":-3.085e+36,"text":"Logit explosion occurs when the largest pre-softmax attention score"}],"source":"layout det","text":"Logit explosion occurs when the largest pre-softmax attention score"},{"bbox":{"x0":525,"x1":696,"y0":1007,"y1":1044},"conf":0.935,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$S_{\\max}=\\max_{i,j} \\left( q_{i} \\cdot k_{j} \\right)$$"},{"bbox":{"x0":1052,"x1":1086,"y0":1009,"y1":1036},"conf":0.8249,"font_size":0.0,"label":"Equation caption","label_id":9,"lines":[{"bbox":{"x0":1053,"x1":1086,"y0":1008,"y1":1036},"font_size":-3.085e+36,"text":"(1)"}],"source":"layout det","text":"(1)"},{"bbox":{"x0":137,"x1":486,"y0":1055,"y1":1084},"conf":0.919,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":484,"y0":1053,"y1":1084},"font_size":-3.085e+36,"text":"grows unboundedly during training. Since"}],"source":"layout det","text":"grows unboundedly during training. Since"},{"bbox":{"x0":426,"x1":796,"y0":1092,"y1":1119},"conf":0.8943,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$|q_{i} \\cdot k_{j}|\\leq\\|q_{i}\\|\\|k_{j}\\|\\leq\\|x_{i}\\|\\|x_{j}\\|\\|\\mathbf{W}_{q}\\|\\|\\mathbf{W}_{k}\\|,$$"},{"bbox":{"x0":1053,"x1":1085,"y0":1092,"y1":1118},"conf":0.8165,"font_size":0.0,"label":"Equation caption","label_id":9,"lines":[{"bbox":{"x0":1053,"x1":1086,"y0":1091,"y1":1119},"font_size":-3.085e+36,"text":"(2)"}],"source":"layout det","text":"(2)"},{"bbox":{"x0":136,"x1":1087,"y0":1126,"y1":1180},"conf":0.9269,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":136,"x1":1084,"y0":1125,"y1":1155},"font_size":-3.085e+36,"text":"and RMS-Norm keeps $\\| x_{i} \\|\\| x_{j} \\|$ bounded, the phenomenon is primarily driven by the growing spectral-norm of $\\mathbf{W}_{q}$ or"},{"bbox":{"x0":141,"x1":1008,"y0":1152,"y1":1174},"font_size":-3.085e+36,"text":"$\\mathbf{W}_{k}$  Empirically, we found that Muon is more susceptible to logit explosion. We give our hypothesis below."}],"source":"layout det","text":"and RMS-Norm keeps $\\| x_{i} \\|\\| x_{j} \\|$ bounded, the phenomenon is primarily driven by the growing spectral-norm of $\\mathbf{W}_{q}$ or $\\mathbf{W}_{k}$  Empirically, we found that Muon is more susceptible to logit explosion. We give our hypothesis below."},{"bbox":{"x0":136,"x1":1089,"y0":1194,"y1":1290},"conf":0.9477,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1198,"y1":1221},"font_size":-3.085e+36,"text":"Structural difference in updatesMuon produces a weight update coming from the msign operation; as a result, $all$"},{"bbox":{"x0":140,"x1":1081,"y0":1221,"y1":1244},"font_size":-3.085e+36,"text":"singular values of the update matrix are equal — its effective rank is full. In contrast, a typical update matrix produced"},{"bbox":{"x0":141,"x1":1081,"y0":1242,"y1":1264},"font_size":-3.085e+36,"text":"by Adam exhibits a skewed spectrum: a few large singular values dominate, and the effective rank is low. This low-rank"},{"bbox":{"x0":140,"x1":785,"y0":1264,"y1":1285},"font_size":-3.085e+36,"text":"assumption for Adam is not new; higher-order muP makes the same assumption."}],"source":"layout det","text":"Structural difference in updatesMuon produces a weight update coming from the msign operation; as a result, $all$ singular values of the update matrix are equal — its effective rank is full. In contrast, a typical update matrix produced by Adam exhibits a skewed spectrum: a few large singular values dominate, and the effective rank is low. This low-rank assumption for Adam is not new; higher-order muP makes the same assumption."},{"bbox":{"x0":136,"x1":1091,"y0":1294,"y1":1346},"conf":0.928,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":1297,"y1":1318},"font_size":-3.085e+36,"text":"Such phenomenon is verifed on the 16 B Moonlight model, which shows weights trained with Muon exhibit higheri"},{"bbox":{"x0":141,"x1":1083,"y0":1320,"y1":1341},"font_size":-3.085e+36,"text":"singular-value entropy (i.e. higher effective rank) than those trained with Adam, corroborating the theoretical intuition."}],"source":"layout det","text":"Such phenomenon is verifed on the 16 B Moonlight model, which shows weights trained with Muon exhibit higheri singular-value entropy (i.e. higher effective rank) than those trained with Adam, corroborating the theoretical intuition."},{"bbox":{"x0":135,"x1":928,"y0":1359,"y1":1394},"conf":0.3175,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":921,"y0":1363,"y1":1388},"font_size":-3.085e+36,"text":"SVD formulationLet the parameter matrix at step $\\boldsymbol{t}-1$  have the singular value decomposition"}],"source":"layout det","text":"SVD formulationLet the parameter matrix at step $\\boldsymbol{t}-1$  have the singular value decomposition"},{"bbox":{"x0":524,"x1":698,"y0":1401,"y1":1450},"conf":0.9302,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$\\mathbf{W}_{t-1}=\\sum_{i}\\sigma_{i} u_{i}v_{i}^{\\top}$$"},{"bbox":{"x0":1052,"x1":1086,"y0":1404,"y1":1432},"conf":0.8265,"font_size":0.0,"label":"Equation caption","label_id":9,"lines":[{"bbox":{"x0":1053,"x1":1086,"y0":1404,"y1":1432},"font_size":-3.085e+36,"text":"(3)"}],"source":"layout det","text":"(3)"}],"formula_dets":[{"bbox":{"x0":525,"x1":696,"y0":1007,"y1":1044},"conf":0.935,"label":"print_isolated","label_id":1},{"bbox":{"x0":524,"x1":698,"y0":1401,"y1":1450},"conf":0.9302,"label":"print_isolated","label_id":1},{"bbox":{"x0":324,"x1":401,"y0":1130,"y1":1154},"conf":0.9064,"label":"print_embedding","label_id":0},{"bbox":{"x0":426,"x1":796,"y0":1092,"y1":1119},"conf":0.8943,"label":"print_isolated","label_id":1},{"bbox":{"x0":633,"x1":677,"y0":807,"y1":827},"conf":0.8796,"label":"print_embedding","label_id":0},{"bbox":{"x0":916,"x1":959,"y0":778,"y1":797},"conf":0.8782,"label":"print_embedding","label_id":0},{"bbox":{"x0":1025,"x1":1058,"y0":1132,"y1":1154},"conf":0.8705,"label":"print_embedding","label_id":0},{"bbox":{"x0":567,"x1":609,"y0":1368,"y1":1385},"conf":0.8599,"label":"print_embedding","label_id":0},{"bbox":{"x0":1057,"x1":1081,"y0":1202,"y1":1218},"conf":0.8217,"label":"print_embedding","label_id":0},{"bbox":{"x0":345,"x1":399,"y0":771,"y1":795},"conf":0.8215,"label":"print_embedding","label_id":0},{"bbox":{"x0":661,"x1":722,"y0":446,"y1":466},"conf":0.8153,"label":"print_embedding","label_id":0},{"bbox":{"x0":663,"x1":734,"y0":578,"y1":598},"conf":0.8045,"label":"print_embedding","label_id":0},{"bbox":{"x0":141,"x1":178,"y0":1154,"y1":1174},"conf":0.7677,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":383,"x1":839,"y0":140,"y1":412},"conf":0.9728,"label":"Figure","label_id":3},{"bbox":{"x0":136,"x1":1088,"y0":552,"y1":714},"conf":0.9709,"label":"Text","label_id":1},{"bbox":{"x0":380,"x1":843,"y0":419,"y1":515},"conf":0.9532,"label":"Figure caption","label_id":4},{"bbox":{"x0":136,"x1":1089,"y0":1194,"y1":1290},"conf":0.9477,"label":"Text","label_id":1},{"bbox":{"x0":422,"x1":801,"y0":1089,"y1":1122},"conf":0.933,"label":"Equation","label_id":8},{"bbox":{"x0":520,"x1":703,"y0":1399,"y1":1453},"conf":0.9287,"label":"Equation","label_id":8},{"bbox":{"x0":136,"x1":1091,"y0":1294,"y1":1346},"conf":0.928,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1087,"y0":1126,"y1":1180},"conf":0.9269,"label":"Text","label_id":1},{"bbox":{"x0":521,"x1":700,"y0":1004,"y1":1048},"conf":0.9253,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":486,"y0":1055,"y1":1084},"conf":0.919,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1086,"y0":841,"y1":894},"conf":0.9135,"label":"Text","label_id":1},{"bbox":{"x0":138,"x1":649,"y0":918,"y1":953},"conf":0.9121,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":691,"y0":969,"y1":998},"conf":0.8929,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":706,"y0":730,"y1":760},"conf":0.8889,"label":"Text","label_id":1},{"bbox":{"x0":174,"x1":1004,"y0":802,"y1":831},"conf":0.8716,"label":"Text","label_id":1},{"bbox":{"x0":1052,"x1":1086,"y0":1404,"y1":1432},"conf":0.8265,"label":"Equation caption","label_id":9},{"bbox":{"x0":1052,"x1":1086,"y0":1009,"y1":1036},"conf":0.8249,"label":"Equation caption","label_id":9},{"bbox":{"x0":1053,"x1":1085,"y0":1092,"y1":1118},"conf":0.8165,"label":"Equation caption","label_id":9},{"bbox":{"x0":557,"x1":1086,"y0":66,"y1":93},"conf":0.8066,"label":"Abandon","label_id":2},{"bbox":{"x0":179,"x1":921,"y0":1362,"y1":1393},"conf":0.7999,"label":"Text","label_id":1},{"bbox":{"x0":278,"x1":1019,"y0":771,"y1":800},"conf":0.7726,"label":"Text","label_id":1},{"bbox":{"x0":596,"x1":627,"y0":1480,"y1":1506},"conf":0.7388,"label":"Abandon","label_id":2},{"bbox":{"x0":135,"x1":928,"y0":1359,"y1":1394},"conf":0.3175,"label":"Text","label_id":1}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1482],[627,1482],[627,1503],[597,1503]],"score":0.8366},{"poly":[[609,1436],[627,1436],[627,1450],[609,1450]],"score":0.7555},{"poly":[[1053,1404],[1086,1404],[1086,1432],[1053,1432]],"score":0.8787},{"poly":[[522,1402],[697,1402],[697,1431],[522,1431]],"score":0.79},{"poly":[[138,1363],[921,1365],[921,1388],[138,1386]],"score":0.7763},{"poly":[[141,1320],[1083,1320],[1083,1341],[141,1341]],"score":0.8335},{"poly":[[141,1297],[1081,1297],[1081,1318],[141,1318]],"score":0.8252},{"poly":[[140,1264],[785,1264],[785,1285],[140,1285]],"score":0.8037},{"poly":[[141,1242],[1081,1242],[1081,1264],[141,1264]],"score":0.8089},{"poly":[[140,1221],[1081,1221],[1081,1244],[140,1244]],"score":0.7042},{"poly":[[141,1198],[1083,1198],[1083,1221],[141,1221]],"score":0.7246},{"poly":[[141,1152],[1008,1152],[1008,1173],[141,1173]],"score":0.8851},{"poly":[[136,1125],[1084,1127],[1084,1155],[136,1153]],"score":0.6727},{"poly":[[427,1094],[797,1094],[797,1117],[427,1117]],"score":0.7917},{"poly":[[1053,1091],[1086,1091],[1086,1119],[1053,1119]],"score":0.9114},{"poly":[[138,1056],[484,1053],[484,1081],[138,1084]],"score":0.6674},{"poly":[[524,1008],[697,1008],[697,1036],[524,1036]],"score":0.8078},{"poly":[[1053,1008],[1086,1008],[1086,1036],[1053,1036]],"score":0.904},{"poly":[[141,972],[685,972],[685,993],[141,993]],"score":0.9089},{"poly":[[138,921],[644,922],[644,945],[138,944]],"score":0.7926},{"poly":[[141,868],[767,868],[767,889],[141,889]],"score":0.8822},{"poly":[[140,843],[1081,845],[1081,868],[140,866]],"score":0.7731},{"poly":[[160,802],[1000,804],[999,827],[160,825]],"score":0.7739},{"poly":[[160,774],[1019,774],[1019,797],[160,797]],"score":0.7407},{"poly":[[140,731],[700,733],[700,756],[140,754]],"score":0.7939},{"poly":[[141,688],[645,688],[645,710],[141,710]],"score":0.8393},{"poly":[[141,665],[1083,665],[1083,686],[141,686]],"score":0.8333},{"poly":[[140,644],[1081,644],[1081,665],[140,665]],"score":0.8311},{"poly":[[141,622],[1081,622],[1081,644],[141,644]],"score":0.8182},{"poly":[[140,597],[1081,601],[1081,624],[140,620]],"score":0.7033},{"poly":[[141,576],[1079,576],[1079,599],[141,599]],"score":0.6977},{"poly":[[141,554],[1081,554],[1081,576],[141,576]],"score":0.828},{"poly":[[386,492],[707,492],[707,508],[386,508]],"score":0.9712},{"poly":[[386,469],[838,469],[838,490],[386,490]],"score":0.8313},{"poly":[[382,446],[838,444],[838,467],[383,469]],"score":0.7258},{"poly":[[386,424],[838,424],[838,446],[386,446]],"score":0.8349},{"poly":[[593,389],[652,393],[651,411],[592,407]],"score":0.8129},{"poly":[[777,160],[827,160],[827,178],[777,178]],"score":0.8011},{"poly":[[778,152],[822,152],[822,163],[778,163]],"score":0.8689},{"poly":[[920,68],[1081,71],[1081,93],[919,89]],"score":0.7855},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8944}],"page_no":29,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":558,"x1":1086,"y0":65,"y1":93},"conf":0.8346,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":67,"y1":94},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":562,"x1":662,"y0":68,"y1":91},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""},{"bbox":{"x0":594,"x1":626,"y0":1479,"y1":1507},"conf":0.702,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":599,"x1":624,"y0":1482,"y1":1503},"font_size":0.0,"text":"31"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":135,"x1":402,"y0":143,"y1":173},"conf":0.8863,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":397,"y0":147,"y1":168},"font_size":-1.267e-19,"text":"We write the update matrices as"}],"source":"layout det","text":"We write the update matrices as"},{"bbox":{"x0":526,"x1":693,"y0":179,"y1":232},"conf":0.9342,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$\\Delta\\mathbf{W}_{t}=\\sum_{j}\\bar{\\sigma} \\bar{u}_{j}\\bar{v}_{j}^{\\top}$$"},{"bbox":{"x0":1052,"x1":1087,"y0":183,"y1":211},"conf":0.8496,"font_size":0.0,"label":"Equation caption","label_id":9,"lines":[{"bbox":{"x0":1053,"x1":1086,"y0":183,"y1":211},"font_size":-1.267e-19,"text":"(4)"}],"source":"layout det","text":"(4)"},{"bbox":{"x0":136,"x1":457,"y0":239,"y1":268},"conf":0.8755,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":452,"y0":243,"y1":264},"font_size":-1.267e-19,"text":"The next parameter update is therefore"}],"source":"layout det","text":"The next parameter update is therefore"},{"bbox":{"x0":476,"x1":745,"y0":275,"y1":327},"conf":0.9367,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$\\mathbf{W}_{t}\\leftrightarrow\\sum_{i}\\sigma_{i}u_{i}v_{i}^{\\top}+\\sum_{j}\\bar{\\sigma} \\bar{u}_{j}\\bar{v}_{j}^{\\top}$$"},{"bbox":{"x0":1052,"x1":1086,"y0":279,"y1":307},"conf":0.8269,"font_size":0.0,"label":"Equation caption","label_id":9,"lines":[{"bbox":{"x0":1054,"x1":1086,"y0":279,"y1":307},"font_size":-1.267e-19,"text":"(5)"}],"source":"layout det","text":"(5)"},{"bbox":{"x0":137,"x1":1088,"y0":344,"y1":419},"conf":0.9492,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":350,"y1":371},"font_size":-1.267e-19,"text":"In Muon, as both the weights and the updates have a higher effective rank than Adam, we hypothesize there is a higher"},{"bbox":{"x0":140,"x1":1079,"y0":369,"y1":398},"font_size":-1.267e-19,"text":"probability for singular-vector pair $u_{i}v_{i}^{\\top}$ to align with $\\bar{\\bar{u}}_{j}\\bar{v}_{j}^{\\top}.$  This could cause the corresponding singular value of $\\mathbf{W}_{t}$"},{"bbox":{"x0":138,"x1":318,"y0":391,"y1":416},"font_size":-1.267e-19,"text":"to increase additively."}],"source":"layout det","text":"In Muon, as both the weights and the updates have a higher effective rank than Adam, we hypothesize there is a higher probability for singular-vector pair $u_{i}v_{i}^{\\top}$ to align with $\\bar{\\bar{u}}_{j}\\bar{v}_{j}^{\\top}.$  This could cause the corresponding singular value of $\\mathbf{W}_{t}$ to increase additively."},{"bbox":{"x0":137,"x1":842,"y0":433,"y1":464},"conf":0.9159,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":837,"y0":439,"y1":460},"font_size":-1.267e-19,"text":"Attention-specifc amplifcationAttention logits are computed via the bilinear formii"}],"source":"layout det","text":"Attention-specifc amplifcationAttention logits are computed via the bilinear formii"},{"bbox":{"x0":496,"x1":726,"y0":470,"y1":496},"conf":0.8968,"font_size":0.0,"label":"isolated","label_id":1,"lines":[],"source":"mfd","text":"$$q_{i}\\cdot k_{j}=(x_{i}\\mathbf{W}_{q})\\cdot(x_{j}\\mathbf{W}_{k}).$$"},{"bbox":{"x0":1053,"x1":1086,"y0":470,"y1":496},"conf":0.8539,"font_size":0.0,"label":"Equation caption","label_id":9,"lines":[{"bbox":{"x0":1053,"x1":1086,"y0":470,"y1":497},"font_size":-1.267e-19,"text":"(6)"}],"source":"layout det","text":"(6)"},{"bbox":{"x0":137,"x1":1087,"y0":504,"y1":558},"conf":0.9244,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":143,"x1":1081,"y0":506,"y1":534},"font_size":-1.267e-19,"text":"The product $\\mathbf{W}_{q}\\mathbf{W}_{k}^{\\top}$ squares the spectral norm, so any singular-value increase in either matrix is compounded. Muon’s"},{"bbox":{"x0":141,"x1":871,"y0":531,"y1":554},"font_size":-1.267e-19,"text":"tendency to enlarge singular values therefore translates into a higher risk of logit explosion."}],"source":"layout det","text":"The product $\\mathbf{W}_{q}\\mathbf{W}_{k}^{\\top}$ squares the spectral norm, so any singular-value increase in either matrix is compounded. Muon’s tendency to enlarge singular values therefore translates into a higher risk of logit explosion."},{"bbox":{"x0":137,"x1":535,"y0":581,"y1":613},"conf":0.9056,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":140,"x1":529,"y0":586,"y1":609},"font_size":-1.267e-19,"text":"FK2 Critic Rubrics for General RL"}],"source":"layout det","text":"FK2 Critic Rubrics for General RL"},{"bbox":{"x0":137,"x1":308,"y0":630,"y1":658},"conf":0.8876,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":304,"y0":634,"y1":655},"font_size":-1.267e-19,"text":"F.1Core Rubrics"}],"source":"layout det","text":"F.1Core Rubrics"},{"bbox":{"x0":173,"x1":1089,"y0":669,"y1":764},"conf":0.9571,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":1081,"y0":673,"y1":695},"font_size":-1.267e-19,"text":"Clarity and Relevance: Assesses the extent to which the response is succinct while fully addressing the user’s"},{"bbox":{"x0":176,"x1":1081,"y0":696,"y1":718},"font_size":-1.267e-19,"text":"intent. The focus is on eliminating unnecessary detail, staying aligned with the central query, and using effcienti"},{"bbox":{"x0":178,"x1":1083,"y0":718,"y1":739},"font_size":-1.267e-19,"text":"formats such as brief paragraphs or compact lists. Unless specifcally required, long itemizations should be avoided.i"},{"bbox":{"x0":176,"x1":901,"y0":739,"y1":761},"font_size":-1.267e-19,"text":"When a choice is expected, the response should clearly offer a single, well-defned answer.i"}],"source":"layout det","text":"Clarity and Relevance: Assesses the extent to which the response is succinct while fully addressing the user’s intent. The focus is on eliminating unnecessary detail, staying aligned with the central query, and using effcienti formats such as brief paragraphs or compact lists. Unless specifcally required, long itemizations should be avoided.i When a choice is expected, the response should clearly offer a single, well-defned answer.i"},{"bbox":{"x0":172,"x1":1089,"y0":766,"y1":881},"conf":0.9709,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":175,"x1":1081,"y0":769,"y1":790},"font_size":-1.267e-19,"text":"Conversational Fluency and Engagement: Evaluates the response’s contribution to a natural, fowing dialogue thatl"},{"bbox":{"x0":175,"x1":1081,"y0":789,"y1":813},"font_size":-1.267e-19,"text":"extends beyond simple question-answering. This includes maintaining coherence, showing appropriate engagement"},{"bbox":{"x0":178,"x1":1078,"y0":813,"y1":835},"font_size":-1.267e-19,"text":"with the topic, offering relevant observations or insights, potentially guiding the conversation constructively when"},{"bbox":{"x0":176,"x1":1083,"y0":833,"y1":858},"font_size":-1.267e-19,"text":"appropriate, using follow-up questions judiciously, handling hypothetical or personal-analogy queries gracefully,"},{"bbox":{"x0":178,"x1":948,"y0":856,"y1":879},"font_size":-1.267e-19,"text":"and adapting tone effectively to suit the conversational context (e.g., empathetic, formal, casual)."}],"source":"layout det","text":"Conversational Fluency and Engagement: Evaluates the response’s contribution to a natural, fowing dialogue thatl extends beyond simple question-answering. This includes maintaining coherence, showing appropriate engagement with the topic, offering relevant observations or insights, potentially guiding the conversation constructively when appropriate, using follow-up questions judiciously, handling hypothetical or personal-analogy queries gracefully,and adapting tone effectively to suit the conversational context (e.g., empathetic, formal, casual)."},{"bbox":{"x0":172,"x1":1087,"y0":882,"y1":1021},"conf":0.9732,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":175,"x1":1079,"y0":884,"y1":906},"font_size":-1.267e-19,"text":"Objective and Grounded Interaction: Assesses the response’s ability to maintain an objective and grounded"},{"bbox":{"x0":178,"x1":1081,"y0":908,"y1":931},"font_size":-1.267e-19,"text":"tone, focusing squarely on the substance of the user’s request. It evaluates the avoidance of both metacommentary"},{"bbox":{"x0":178,"x1":1081,"y0":931,"y1":952},"font_size":-1.267e-19,"text":"(analyzing the query’s structure, topic combination, perceived oddity, or the nature of the interaction itself) and"},{"bbox":{"x0":178,"x1":1081,"y0":952,"y1":974},"font_size":-1.267e-19,"text":"unwarranted fattery or excessive praise directed at the user or their input. Excellent responses interact respectfullyl"},{"bbox":{"x0":178,"x1":1081,"y0":974,"y1":995},"font_size":-1.267e-19,"text":"but neutrally, prioritizing direct, task-focused assistance over commentary on the conversational dynamics or"},{"bbox":{"x0":178,"x1":540,"y0":995,"y1":1016},"font_size":-1.267e-19,"text":"attempts to curry favor through compliments."}],"source":"layout det","text":"Objective and Grounded Interaction: Assesses the response’s ability to maintain an objective and grounded tone, focusing squarely on the substance of the user’s request. It evaluates the avoidance of both metacommentary(analyzing the query’s structure, topic combination, perceived oddity, or the nature of the interaction itself) and unwarranted fattery or excessive praise directed at the user or their input. Excellent responses interact respectfullyl but neutrally, prioritizing direct, task-focused assistance over commentary on the conversational dynamics or attempts to curry favor through compliments."},{"bbox":{"x0":136,"x1":370,"y0":1039,"y1":1068},"conf":0.8918,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":141,"x1":366,"y0":1043,"y1":1064},"font_size":-1.267e-19,"text":"F.2Prescriptive Rubrics"}],"source":"layout det","text":"F.2Prescriptive Rubrics"},{"bbox":{"x0":172,"x1":1087,"y0":1079,"y1":1129},"conf":0.9427,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":160,"x1":1083,"y0":1081,"y1":1106},"font_size":-1.267e-19,"text":"Initial Praise: Responses must not begin with compliments directed at the user or the question (e.g., “That’s a"},{"bbox":{"x0":176,"x1":496,"y0":1106,"y1":1127},"font_size":-1.267e-19,"text":"beautiful question”, “Good question!”)."}],"source":"layout det","text":"Initial Praise: Responses must not begin with compliments directed at the user or the question (e.g., “That’s a beautiful question”, “Good question!”)."},{"bbox":{"x0":173,"x1":1088,"y0":1132,"y1":1183},"conf":0.939,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":1081,"y0":1132,"y1":1157},"font_size":-1.267e-19,"text":"Explicit Justifcation: Any sentence or clause that explains why the response is good or how it successfullyi"},{"bbox":{"x0":178,"x1":813,"y0":1157,"y1":1178},"font_size":-1.267e-19,"text":"fulflled the user’s request. This is different from simply describing the content.i"}],"source":"layout det","text":"Explicit Justifcation: Any sentence or clause that explains why the response is good or how it successfullyi fulflled the user’s request. This is different from simply describing the content.i"},{"bbox":{"x0":138,"x1":293,"y0":1200,"y1":1228},"conf":0.8899,"font_size":0.0,"label":"Title","label_id":0,"lines":[{"bbox":{"x0":138,"x1":291,"y0":1201,"y1":1226},"font_size":-1.267e-19,"text":"F.3Limitations"}],"source":"layout det","text":"F.3Limitations"},{"bbox":{"x0":138,"x1":1090,"y0":1240,"y1":1293},"conf":0.9327,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1083,"y0":1242,"y1":1267},"font_size":-1.267e-19,"text":"One potential side effect of this evaluation framework is that it may favor responses that appear confdent and assertive,i"},{"bbox":{"x0":141,"x1":1024,"y0":1267,"y1":1289},"font_size":-1.267e-19,"text":"even in contexts involving ambiguity or subjectivity. This stems from two key constraints in the current rubric:"}],"source":"layout det","text":"One potential side effect of this evaluation framework is that it may favor responses that appear confdent and assertive,i even in contexts involving ambiguity or subjectivity. This stems from two key constraints in the current rubric:"},{"bbox":{"x0":171,"x1":1090,"y0":1301,"y1":1375},"conf":0.9546,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":161,"x1":1081,"y0":1303,"y1":1330},"font_size":-1.267e-19,"text":"Avoidance of Self-Qualifcation: The prescriptive rules prohibit self-assessments, explicit disclaimers, or hedgingi"},{"bbox":{"x0":178,"x1":1081,"y0":1328,"y1":1351},"font_size":-1.267e-19,"text":"language (e.g., “this may not be accurate”, “I might be wrong”). While these phrases can refect epistemic humility,l"},{"bbox":{"x0":176,"x1":660,"y0":1351,"y1":1373},"font_size":-1.267e-19,"text":"they are often penalized as non-informative or performative."}],"source":"layout det","text":"Avoidance of Self-Qualifcation: The prescriptive rules prohibit self-assessments, explicit disclaimers, or hedgingi language (e.g., “this may not be accurate”, “I might be wrong”). While these phrases can refect epistemic humility,l they are often penalized as non-informative or performative."},{"bbox":{"x0":173,"x1":1089,"y0":1377,"y1":1450},"conf":0.9402,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":163,"x1":1083,"y0":1379,"y1":1401},"font_size":-1.267e-19,"text":"Preference for Clarity and Singularity: The rubric reward direct, decisive answers when users ask for a"},{"bbox":{"x0":178,"x1":1079,"y0":1402,"y1":1424},"font_size":-1.267e-19,"text":"recommendation or explanation. In complex or open-ended scenarios, this may disincentivize appropriately"},{"bbox":{"x0":178,"x1":499,"y0":1424,"y1":1445},"font_size":-1.267e-19,"text":"cautious or multi-perspective responses."}],"source":"layout det","text":"Preference for Clarity and Singularity: The rubric reward direct, decisive answers when users ask for a recommendation or explanation. In complex or open-ended scenarios, this may disincentivize appropriately cautious or multi-perspective responses."}],"formula_dets":[{"bbox":{"x0":476,"x1":745,"y0":275,"y1":327},"conf":0.9367,"label":"print_isolated","label_id":1},{"bbox":{"x0":526,"x1":693,"y0":179,"y1":232},"conf":0.9342,"label":"print_isolated","label_id":1},{"bbox":{"x0":496,"x1":726,"y0":470,"y1":496},"conf":0.8968,"label":"print_isolated","label_id":1},{"bbox":{"x0":572,"x1":621,"y0":369,"y1":397},"conf":0.8755,"label":"print_embedding","label_id":0},{"bbox":{"x0":241,"x1":311,"y0":506,"y1":534},"conf":0.8721,"label":"print_embedding","label_id":0},{"bbox":{"x0":420,"x1":461,"y0":369,"y1":394},"conf":0.8696,"label":"print_embedding","label_id":0},{"bbox":{"x0":1048,"x1":1079,"y0":374,"y1":392},"conf":0.8543,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":172,"x1":1087,"y0":882,"y1":1021},"conf":0.9732,"label":"Text","label_id":1},{"bbox":{"x0":172,"x1":1089,"y0":766,"y1":881},"conf":0.9709,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":1089,"y0":669,"y1":764},"conf":0.9571,"label":"Text","label_id":1},{"bbox":{"x0":171,"x1":1090,"y0":1301,"y1":1375},"conf":0.9546,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1088,"y0":344,"y1":419},"conf":0.9492,"label":"Text","label_id":1},{"bbox":{"x0":172,"x1":1087,"y0":1079,"y1":1129},"conf":0.9427,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":1089,"y0":1377,"y1":1450},"conf":0.9402,"label":"Text","label_id":1},{"bbox":{"x0":173,"x1":1088,"y0":1132,"y1":1183},"conf":0.939,"label":"Text","label_id":1},{"bbox":{"x0":472,"x1":750,"y0":272,"y1":330},"conf":0.934,"label":"Equation","label_id":8},{"bbox":{"x0":138,"x1":1090,"y0":1240,"y1":1293},"conf":0.9327,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1087,"y0":504,"y1":558},"conf":0.9244,"label":"Text","label_id":1},{"bbox":{"x0":524,"x1":699,"y0":176,"y1":234},"conf":0.9243,"label":"Equation","label_id":8},{"bbox":{"x0":492,"x1":731,"y0":468,"y1":500},"conf":0.917,"label":"Equation","label_id":8},{"bbox":{"x0":137,"x1":842,"y0":433,"y1":464},"conf":0.9159,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":535,"y0":581,"y1":613},"conf":0.9056,"label":"Title","label_id":0},{"bbox":{"x0":136,"x1":370,"y0":1039,"y1":1068},"conf":0.8918,"label":"Title","label_id":0},{"bbox":{"x0":138,"x1":293,"y0":1200,"y1":1228},"conf":0.8899,"label":"Title","label_id":0},{"bbox":{"x0":137,"x1":308,"y0":630,"y1":658},"conf":0.8876,"label":"Title","label_id":0},{"bbox":{"x0":135,"x1":402,"y0":143,"y1":173},"conf":0.8863,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":457,"y0":239,"y1":268},"conf":0.8755,"label":"Text","label_id":1},{"bbox":{"x0":1053,"x1":1086,"y0":470,"y1":496},"conf":0.8539,"label":"Equation caption","label_id":9},{"bbox":{"x0":1052,"x1":1087,"y0":183,"y1":211},"conf":0.8496,"label":"Equation caption","label_id":9},{"bbox":{"x0":558,"x1":1086,"y0":65,"y1":93},"conf":0.8346,"label":"Abandon","label_id":2},{"bbox":{"x0":1052,"x1":1086,"y0":279,"y1":307},"conf":0.8269,"label":"Equation caption","label_id":9},{"bbox":{"x0":594,"x1":626,"y0":1479,"y1":1507},"conf":0.702,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[599,1482],[624,1482],[624,1503],[599,1503]],"score":0.9456},{"poly":[[178,1424],[499,1424],[499,1445],[178,1445]],"score":0.8755},{"poly":[[178,1402],[1079,1402],[1079,1424],[178,1424]],"score":0.8395},{"poly":[[163,1379],[1083,1379],[1083,1401],[163,1401]],"score":0.8045},{"poly":[[176,1351],[660,1351],[660,1373],[176,1373]],"score":0.8075},{"poly":[[178,1328],[1081,1328],[1081,1351],[178,1351]],"score":0.7219},{"poly":[[161,1303],[1081,1307],[1081,1330],[161,1327]],"score":0.711},{"poly":[[141,1267],[1024,1267],[1024,1289],[141,1289]],"score":0.8266},{"poly":[[140,1242],[1083,1244],[1083,1267],[140,1266]],"score":0.7039},{"poly":[[138,1201],[291,1205],[291,1226],[138,1222]],"score":0.7863},{"poly":[[178,1157],[813,1157],[813,1178],[178,1178]],"score":0.8525},{"poly":[[163,1132],[1081,1134],[1081,1157],[163,1155]],"score":0.7764},{"poly":[[176,1106],[496,1106],[496,1127],[176,1127]],"score":0.8959},{"poly":[[160,1081],[1083,1082],[1083,1106],[160,1104]],"score":0.7605},{"poly":[[141,1043],[366,1043],[366,1064],[141,1064]],"score":0.8297},{"poly":[[178,995],[540,995],[540,1016],[178,1016]],"score":0.8685},{"poly":[[178,974],[1081,974],[1081,995],[178,995]],"score":0.8202},{"poly":[[178,952],[1081,952],[1081,974],[178,974]],"score":0.7615},{"poly":[[178,931],[1081,931],[1081,952],[178,952]],"score":0.8145},{"poly":[[178,908],[1081,908],[1081,931],[178,931]],"score":0.6577},{"poly":[[175,884],[1079,884],[1079,906],[175,906]],"score":0.7907},{"poly":[[178,856],[948,856],[948,879],[178,879]],"score":0.7173},{"poly":[[176,835],[1083,833],[1083,856],[176,858]],"score":0.6877},{"poly":[[178,813],[1078,813],[1078,835],[178,835]],"score":0.8142},{"poly":[[175,789],[1081,790],[1081,813],[175,812]],"score":0.7136},{"poly":[[175,769],[1081,769],[1081,790],[175,790]],"score":0.82},{"poly":[[176,739],[901,739],[901,761],[176,761]],"score":0.7847},{"poly":[[178,718],[1083,718],[1083,739],[178,739]],"score":0.815},{"poly":[[176,696],[1081,696],[1081,718],[176,718]],"score":0.8298},{"poly":[[163,673],[1081,673],[1081,695],[163,695]],"score":0.8394},{"poly":[[141,634],[304,634],[304,655],[141,655]],"score":0.9443},{"poly":[[140,586],[529,586],[529,609],[140,609]],"score":0.7326},{"poly":[[141,531],[871,531],[871,554],[141,554]],"score":0.7205},{"poly":[[143,508],[1081,508],[1081,530],[143,530]],"score":0.7934},{"poly":[[492,474],[727,472],[727,495],[492,497]],"score":0.8615},{"poly":[[1053,470],[1086,470],[1086,497],[1053,497]],"score":0.8784},{"poly":[[141,439],[837,439],[837,460],[141,460]],"score":0.8477},{"poly":[[138,391],[318,393],[317,416],[138,414]],"score":0.7434},{"poly":[[140,370],[1081,370],[1081,398],[140,398]],"score":0.6488},{"poly":[[141,350],[1081,350],[1081,371],[141,371]],"score":0.8395},{"poly":[[660,314],[677,314],[677,327],[660,327]],"score":0.864},{"poly":[[552,307],[563,318],[554,327],[543,316]],"score":0.6223},{"poly":[[472,277],[748,277],[748,312],[472,312]],"score":0.6661},{"poly":[[1054,279],[1086,279],[1086,307],[1054,307]],"score":0.937},{"poly":[[143,243],[452,243],[452,264],[143,264]],"score":0.9135},{"poly":[[610,216],[624,216],[624,231],[610,231]],"score":0.6421},{"poly":[[1053,183],[1086,183],[1086,211],[1053,211]],"score":0.8312},{"poly":[[524,178],[697,178],[697,218],[524,218]],"score":0.7156},{"poly":[[141,147],[397,147],[397,168],[141,168]],"score":0.8469},{"poly":[[918,67],[1083,71],[1082,94],[918,91]],"score":0.6823},{"poly":[[562,68],[662,68],[662,91],[562,91]],"score":0.8454}],"page_no":30,"scale":2.0,"width":612},{"abandon_blocks":[{"bbox":{"x0":595,"x1":627,"y0":1479,"y1":1507},"conf":0.7087,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":597,"x1":625,"y0":1480,"y1":1503},"font_size":0.0,"text":"32"}],"source":"layout det","text":""},{"bbox":{"x0":138,"x1":1087,"y0":64,"y1":101},"conf":0.2314,"font_size":0.0,"label":"Abandon","label_id":2,"lines":[{"bbox":{"x0":918,"x1":1083,"y0":68,"y1":92},"font_size":0.0,"text":"TECHNICAL REPORT"},{"bbox":{"x0":559,"x1":664,"y0":64,"y1":92},"font_size":0.0,"text":"Kimi K2"}],"source":"layout det","text":""}],"blocks":[{"bbox":{"x0":136,"x1":1088,"y0":142,"y1":220},"conf":0.938,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1081,"y0":144,"y1":168},"font_size":2232000000000.0,"text":"As a result, the model may occasionally overstate certainty in areas where ambiguity, nuance, or epistemic modesty"},{"bbox":{"x0":140,"x1":1081,"y0":168,"y1":191},"font_size":2232000000000.0,"text":"would be more appropriate. Future iterations of the framework may incorporate more fne-grained handling of calibratedi"},{"bbox":{"x0":141,"x1":239,"y0":193,"y1":211},"font_size":2232000000000.0,"text":"uncertainty."}],"source":"layout det","text":"As a result, the model may occasionally overstate certainty in areas where ambiguity, nuance, or epistemic modesty would be more appropriate. Future iterations of the framework may incorporate more fne-grained handling of calibratedi uncertainty."},{"bbox":{"x0":136,"x1":632,"y0":238,"y1":276},"conf":0.3455,"font_size":0.0,"label":"Title","label_id":0,"lines":[],"source":"layout det","text":""},{"bbox":{"x0":136,"x1":632,"y0":238,"y1":276},"conf":0.5522,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":138,"x1":625,"y0":241,"y1":271},"font_size":2232000000000.0,"text":"GEngine Switching Pipeline for RL Training"}],"source":"layout det","text":"GEngine Switching Pipeline for RL Training"},{"bbox":{"x0":292,"x1":963,"y0":313,"y1":911},"conf":0.947,"font_size":0.0,"label":"Figure","label_id":3,"lines":[],"source":"layout det","text":"![9843eaf10fc63c6003417cf5ad5de03d](imgs/9843eaf10fc63c6003417cf5ad5de03d.jpg)"},{"bbox":{"x0":440,"x1":782,"y0":917,"y1":947},"conf":0.3096,"font_size":0.0,"label":"Figure caption","label_id":4,"lines":[{"bbox":{"x0":446,"x1":778,"y0":919,"y1":940},"font_size":2232000000000.0,"text":"Figure 13: pipeline for RL weight update"}],"source":"layout det","text":"Figure 13: pipeline for RL weight update"},{"bbox":{"x0":136,"x1":1089,"y0":962,"y1":1060},"conf":0.9385,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1081,"y0":964,"y1":988},"font_size":2232000000000.0,"text":"The checkpoint engine manages three equal-size device buffers on each GPU: an H2D buffer for loading the offoadedl"},{"bbox":{"x0":140,"x1":1083,"y0":988,"y1":1010},"font_size":2232000000000.0,"text":"model parameters, and two IPC buffers for GPU-to-GPU broadcast. The IPC buffers are shared to inference engines,"},{"bbox":{"x0":140,"x1":1083,"y0":1010,"y1":1033},"font_size":2232000000000.0,"text":"allowing it to directly access the same physical memory. These three buffers allow us to arrange the three steps in a"},{"bbox":{"x0":137,"x1":217,"y0":1027,"y1":1058},"font_size":2232000000000.0,"text":"pipeline."}],"source":"layout det","text":"The checkpoint engine manages three equal-size device buffers on each GPU: an H2D buffer for loading the offoadedl model parameters, and two IPC buffers for GPU-to-GPU broadcast. The IPC buffers are shared to inference engines,allowing it to directly access the same physical memory. These three buffers allow us to arrange the three steps in a pipeline."},{"bbox":{"x0":137,"x1":1089,"y0":1074,"y1":1169},"conf":0.9541,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1084,"y0":1072,"y1":1102},"font_size":2232000000000.0,"text":"Theoretical three-stage pipeline.As illustrated in Figure 13a, a three-stage pipeline is introduced. (1) $\\mathit{H2D:}$  a shard"},{"bbox":{"x0":140,"x1":1083,"y0":1101,"y1":1124},"font_size":2232000000000.0,"text":"of the latest weights is copied into the H2D buffer asynchronously. (2) Broadcast: Once the copy completes, the shard"},{"bbox":{"x0":138,"x1":1083,"y0":1119,"y1":1143},"font_size":2232000000000.0,"text":"will be copied to one IPC buffers and broadcast to all devices. (3) Reload: Inference engines simultaneously load"},{"bbox":{"x0":138,"x1":447,"y0":1142,"y1":1167},"font_size":2232000000000.0,"text":"parameters from the other IPC buffer."}],"source":"layout det","text":"Theoretical three-stage pipeline.As illustrated in Figure 13a, a three-stage pipeline is introduced. (1) $\\mathit{H2D:}$  a shard of the latest weights is copied into the H2D buffer asynchronously. (2) Broadcast: Once the copy completes, the shard will be copied to one IPC buffers and broadcast to all devices. (3) Reload: Inference engines simultaneously load parameters from the other IPC buffer."},{"bbox":{"x0":137,"x1":1090,"y0":1186,"y1":1282},"conf":0.9565,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":138,"x1":1083,"y0":1186,"y1":1211},"font_size":2232000000000.0,"text":"Two-stage pipeline due to PCIe saturation.On NVIDIA H800 clusters, concurrent H2D and broadcast saturate the"},{"bbox":{"x0":138,"x1":1084,"y0":1209,"y1":1234},"font_size":2232000000000.0,"text":"shared PCIe fabric, collapsing the three stages into a sequential procedure (Figure 13b). We therefore adopt a simpler,"},{"bbox":{"x0":140,"x1":1083,"y0":1233,"y1":1254},"font_size":2232000000000.0,"text":"two-stage scheme (Figure 13c): (1) All devices perform a single, synchronous H2D transfer. (2) The broadcast and"},{"bbox":{"x0":138,"x1":353,"y0":1254,"y1":1275},"font_size":2232000000000.0,"text":"reload proceed in parallel."}],"source":"layout det","text":"Two-stage pipeline due to PCIe saturation.On NVIDIA H800 clusters, concurrent H2D and broadcast saturate the shared PCIe fabric, collapsing the three stages into a sequential procedure (Figure 13b). We therefore adopt a simpler,two-stage scheme (Figure 13c): (1) All devices perform a single, synchronous H2D transfer. (2) The broadcast and reload proceed in parallel."},{"bbox":{"x0":136,"x1":1090,"y0":1286,"y1":1358},"conf":0.9596,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":141,"x1":1079,"y0":1287,"y1":1310},"font_size":2232000000000.0,"text":"The two-stage pipeline will be bound by multiple synchronous H2D copy operations. But in large scale devices, model"},{"bbox":{"x0":140,"x1":1081,"y0":1310,"y1":1332},"font_size":2232000000000.0,"text":"will be split into small shards, the entire parameter set fts into the H2D buffer in one transfer, the overhead willi"},{"bbox":{"x0":138,"x1":228,"y0":1330,"y1":1357},"font_size":2232000000000.0,"text":"disappear."}],"source":"layout det","text":"The two-stage pipeline will be bound by multiple synchronous H2D copy operations. But in large scale devices, model will be split into small shards, the entire parameter set fts into the H2D buffer in one transfer, the overhead willi disappear."},{"bbox":{"x0":136,"x1":1087,"y0":1361,"y1":1414},"conf":0.8716,"font_size":0.0,"label":"Text","label_id":1,"lines":[{"bbox":{"x0":140,"x1":1081,"y0":1361,"y1":1386},"font_size":2232000000000.0,"text":"By overlapping H2D, Broadcast, and Reload weights, we can obtain a high bandwidth to reshard the weights from train"},{"bbox":{"x0":140,"x1":401,"y0":1388,"y1":1409},"font_size":2232000000000.0,"text":"engines to all inference engines."}],"source":"layout det","text":"By overlapping H2D, Broadcast, and Reload weights, we can obtain a high bandwidth to reshard the weights from train engines to all inference engines."}],"formula_dets":[{"bbox":{"x0":972,"x1":1017,"y0":1077,"y1":1099},"conf":0.7678,"label":"print_embedding","label_id":0}],"height":792,"layout_dets":[{"bbox":{"x0":136,"x1":1090,"y0":1286,"y1":1358},"conf":0.9596,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1090,"y0":1186,"y1":1282},"conf":0.9565,"label":"Text","label_id":1},{"bbox":{"x0":137,"x1":1089,"y0":1074,"y1":1169},"conf":0.9541,"label":"Text","label_id":1},{"bbox":{"x0":292,"x1":963,"y0":313,"y1":911},"conf":0.947,"label":"Figure","label_id":3},{"bbox":{"x0":136,"x1":1089,"y0":962,"y1":1060},"conf":0.9385,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1088,"y0":142,"y1":220},"conf":0.938,"label":"Text","label_id":1},{"bbox":{"x0":136,"x1":1087,"y0":1361,"y1":1414},"conf":0.8716,"label":"Text","label_id":1},{"bbox":{"x0":558,"x1":1086,"y0":66,"y1":93},"conf":0.8081,"label":"Abandon","label_id":2},{"bbox":{"x0":595,"x1":627,"y0":1479,"y1":1507},"conf":0.7087,"label":"Abandon","label_id":2},{"bbox":{"x0":440,"x1":782,"y0":917,"y1":947},"conf":0.6621,"label":"Figure caption","label_id":4},{"bbox":{"x0":136,"x1":632,"y0":238,"y1":276},"conf":0.5522,"label":"Figure caption","label_id":4},{"bbox":{"x0":136,"x1":632,"y0":238,"y1":276},"conf":0.3455,"label":"Title","label_id":0},{"bbox":{"x0":440,"x1":782,"y0":917,"y1":947},"conf":0.3096,"label":"Figure caption","label_id":4},{"bbox":{"x0":138,"x1":1087,"y0":64,"y1":101},"conf":0.2314,"label":"Abandon","label_id":2}],"ocr_all":false,"ocr_dets":[{"poly":[[597,1480],[625,1480],[625,1503],[597,1503]],"score":0.8841},{"poly":[[140,1388],[401,1388],[401,1409],[140,1409]],"score":0.8395},{"poly":[[140,1361],[1081,1363],[1081,1386],[140,1384]],"score":0.7838},{"poly":[[139,1330],[228,1334],[227,1357],[138,1353]],"score":0.8036},{"poly":[[140,1310],[1081,1310],[1081,1332],[140,1332]],"score":0.885},{"poly":[[141,1287],[1079,1287],[1079,1310],[141,1310]],"score":0.7327},{"poly":[[138,1254],[353,1254],[353,1275],[138,1275]],"score":0.8046},{"poly":[[140,1233],[1083,1233],[1083,1254],[140,1254]],"score":0.8389},{"poly":[[138,1209],[1084,1211],[1084,1234],[138,1233]],"score":0.7548},{"poly":[[138,1186],[1083,1188],[1083,1211],[138,1209]],"score":0.7587},{"poly":[[138,1143],[447,1142],[447,1165],[138,1167]],"score":0.7773},{"poly":[[138,1119],[1083,1120],[1083,1143],[138,1142]],"score":0.7622},{"poly":[[140,1101],[1083,1101],[1083,1124],[140,1124]],"score":0.7499},{"poly":[[138,1072],[1084,1074],[1084,1102],[138,1101]],"score":0.7139},{"poly":[[137,1033],[215,1027],[217,1052],[139,1058]],"score":0.758},{"poly":[[140,1010],[1083,1010],[1083,1033],[140,1033]],"score":0.7138},{"poly":[[140,988],[1083,988],[1083,1010],[140,1010]],"score":0.8418},{"poly":[[141,964],[1081,964],[1081,987],[141,987]],"score":0.7453},{"poly":[[446,919],[778,919],[778,940],[446,940]],"score":0.8913},{"poly":[[709,883],[916,886],[916,908],[708,904]],"score":0.8405},{"poly":[[283,883],[584,884],[584,908],[283,906]],"score":0.7868},{"poly":[[456,726],[474,726],[474,738],[456,738]],"score":0.66},{"poly":[[402,658],[820,658],[820,680],[402,680]],"score":0.8411},{"poly":[[314,591],[366,591],[366,609],[314,609]],"score":0.8253},{"poly":[[314,530],[368,530],[368,548],[314,548]],"score":0.8517},{"poly":[[311,470],[368,470],[368,493],[311,493]],"score":0.8093},{"poly":[[313,412],[368,412],[368,431],[313,431]],"score":0.8354},{"poly":[[567,355],[655,355],[655,371],[567,371]],"score":0.8834},{"poly":[[747,351],[835,353],[835,371],[747,369]],"score":0.8169},{"poly":[[312,349],[376,353],[375,372],[311,368]],"score":0.7424},{"poly":[[747,322],[835,324],[835,342],[747,340]],"score":0.813},{"poly":[[311,323],[376,323],[376,342],[311,342]],"score":0.8185},{"poly":[[567,322],[599,322],[599,342],[567,342]],"score":0.8518},{"poly":[[138,241],[625,243],[625,271],[138,269]],"score":0.7938},{"poly":[[141,193],[239,193],[239,211],[141,211]],"score":0.8358},{"poly":[[140,168],[1081,168],[1081,191],[140,191]],"score":0.7529},{"poly":[[138,144],[1081,145],[1081,168],[138,167]],"score":0.7345},{"poly":[[918,68],[1083,69],[1082,92],[918,91]],"score":0.7654},{"poly":[[559,64],[664,64],[664,92],[559,92]],"score":0.7848}],"page_no":31,"scale":2.0,"width":612}],"pages_success_ratio":0.0,"src_path":"oss://glm-data-ocr-data/services/maas/docs/72ea8940-be5d-4994-826e-71afd30fa460","text":"KKIMI K2: OPEN AGENTIC INTELLIGENCE\nTECHNICAL REPORT OF KIMI K2\nKimi Team\nABSTRACT\nWe introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token effciency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zeroi loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the model improves its capabilities through interactions with real and synthetic environments.\nKimi K2 achieves state-of-the-art performance among open-source non-thinking models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench(En), 65.8 on SWE-Bench Verifed, and 47.3 on SWE-Bench Multilingual — surpassing most openi and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding,mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025,75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position Kimi K2 as one of the most capable open-source large language models to date, particularly in software engineering and agentic tasks. We release our base and post-trained model checkpoints1 to facilitate future research and applications of agentic intelligence.\nFigure 1: Kimi K2 main results.2\n\n1Introduction\nThe development of Large Language Models (LLMs) is undergoing a profound paradigm shift towards Agentic Intelligence – the capabilities for models to autonomously perceive, plan, reason, and act within complex and dynamic environments. This transition marks a departure from static imitation learning towards models that actively learn through interactions, acquire new skills beyond their training distribution, and adapt behavior through experiences [63].It is believed that this approach allows an AI agent to go beyond the limitation of static human-generated data, and acquire superhuman capabilities through its own exploration and exploitation. Agentic intelligence is thus rapidly emerging as a defning capability for the next generation of foundation models, with wide-ranging implications acrossi tool use, software development, and real-world autonomy.\nAchieving agentic intelligence introduces challenges in both pre-training and post-training. Pre-training must endow models with broad general-purpose priors under constraints of limited high-quality data, elevating token eff-i ciency—learning signal per token—as a critical scaling coeffcient. Post-training must transform those priors intoi actionable behaviors, yet agentic capabilities such as multi-step reasoning, long-term planning, and tool use are rare in natural data and costly to scale. Scalable synthesis of structured, high-quality agentic trajectories, combined with general reinforcement learning (RL) techniques that incorporate preferences and self-critique, are essential to bridge this gap.\nIn this work, we introduce Kimi K2, a 1.04 trillion-parameter Mixture-of-Experts (MoE) LLM with 32 billion activated parameters, purposefully designed to address the core challenges and push the boundaries of agentic capability. Our contributions span both the pre-training and post-training frontiers:\nWe present MuonClip, a novel optimizer that integrates the token-effcient Muon algorithm with a stability-i enhancing mechanism called QK-Clip. Using MuonClip, we successfully pre-trained Kimi K2 on 15.5 trillion tokens without a single loss spike.\nWe introduce a large-scale agentic data synthesis pipeline that systematically generates tool-use demonstrations via simulated and real-world environments. This system constructs diverse tools, agents, tasks, and trajectories to create high-fdelity, verifably correct agentic interactions at scale.ii\nWe design a general reinforcement learning framework that combines verifable rewards (RLVR) with a self-i critique rubric reward mechanism. The model learns not only from externally defned tasks but also from evaluatingi its own outputs, extending alignment from static into open-ended domains.\nKimi K2 demonstrates strong performance across a broad spectrum of agentic and frontier benchmarks. It achieves scores of 66.1 on Tau2-bench, 76.5 on ACEBench (en), 65.8 on SWE-bench Verifed, and 47.3 on SWE-benchi Multilingual, outperforming most open- and closed-weight baselines under non-thinking evaluation settings, closing the gap with Claude 4 Opus and Sonnet. In coding, mathematics, and broader STEM domains, Kimi K2 achieves 53.7 on LiveCodeBench v6, 27.1 on OJBench, 49.5 on AIME 2025, and 75.1 on GPQA-Diamond, further highlighting its capabilities in general tasks. On the LMSYS Arena leaderboard (July 17, 2025)3, Kimi K2 ranks as the top 1 open-source model and 5th overall based on over 3,000 user votes.\nTo spur further progress in Agentic Intelligence, we are open-sourcing our base and post-trained checkpoints, enabling the community to explore, refne, and deploy agentic intelligence at scale.i\n2Pre-training\nThe base model of Kimi K2 is a trillion-parameter mixture-of-experts (MoE) transformer [72] model, pre-trained on 15.5 trillion high-quality tokens. Given the increasingly limited availability of high-quality human data, we posit that token effciency is emerging as a critical coeffcient in the scaling of large language models. To address this,ii we introduce a suite of pre-training techniques explicitly designed for maximizing token effciency. Specifcally, weii employ the token-effcient Muon optimizer [33, 46] and mitigate its training instabilities through the introduction ofi QK-Clip. Additionally, we incorporate synthetic data generation to further squeeze the intelligence out of available high-quality tokens. The model architecture follows an ultra-sparse MoE with multi-head latent attention (MLA) similar to DeepSeek-V3 [10] , derived from empirical scaling law analysis. The underlying infrastructure is built to optimize both training effciency and research effciency.ii\n\n2.1MuonClip: Stable Training with Weight Clipping\nWe train Kimi K2 using the token-effcient Muon optimizer [33], incorporating weight decay and consistent updatei RMS scaling [46]. Experiments in our previous work Moonlight [46] show that, under the same compute budget and model size $.$ and therefore the same amount of training data — Muon substantially outperforms AdamW [36, 48],making it an effective choice for improving token effciency in large language model training.i\nTraining instability when scaling MuonDespite its effciency, scaling up Muon training reveals a challenge: trainingi instability due to exploding attention logits, an issue that occurs more frequently with Muon but less with AdamW in our experiments. Existing mitigation strategies are insuffcient. For instance, logit soft-cap [69] directly clips thei attention logits, but the dot products between queries and keys can still grow excessively before capping is applied. On the other hand, Query-Key Normalization (QK-Norm) [11, 81] is not applicable to multi-head latent attention (MLA),because its Key matrices are not fully materialized during inference.\nTaming Muon with QK-ClipTo address this issue, we propose a novel weight-clipping mechanism $\\mathit{QK\\text{-}Clip}$  to explicitly constrain attention logits. QK-Clip works by rescaling the query and key projection weights post-update to bound the growth of attention logits.\nLet the input representation of a transformer layer be X. For each attention head h, its query, key, and value projections are computed as\n$$\\textbf{Q}^{h}=\\textbf{X}\\textbf{W}_{q}^{h},\\quad\\textbf{K}^{h}=\\textbf{X} \\textbf{W}_{k}^{h},\\quad\\textbf{V}^{h}=\\textbf{X}\\textbf{W}_{v}^{h}.$$\nwhere $\\mathbf{W}_{q},\\mathbf{W}_{k},\\mathbf{W}_{v}$ are model parameters. The attention output is:\n$$\\mathbf{O}^{h}=\\text{softmax}\\left(\\frac{1}{\\sqrt{d}}\\mathbf{Q}^{h}\\mathbf{K}^{h\\top}\\right)\\mathbf{V}^{h}.$$\nWe defne the max logit, a per-head scalar, as the maximum input to softmax in this batch Bi\n$$S_{\\max}^{h}=\\frac{1}{\\sqrt{d}}\\max_{\\mathbf{X}\\in B}\\max_{i,j}\\mathbf{Q}_{i}^{h}\\mathbf{K}_{j}^{h\\top}$$\nwhere $i,j$ are indices of different tokens in a training sample X.\nThe core idea of QK-Clip is to rescale $\\mathbf{W}_{k},\\mathbf{W}_{q}$ whenever $S^{h}_{\\max}$ exceeds a target threshold τ. Importantly, this operation does not alter the forward/backward computation in the current step — we merely use the max logit as a guiding signal to determine the strength to control the weight growth.\nA naïve implementation clips all heads at the same time:\n$$\\mathbf{W}_{q}^{h}\\leftrightarrow\\gamma^{\\alpha}\\mathbf{W}_{q}^{h}\\qquad\\mathbf{W}_{k}^{h}\\leftrightarrow\\gamma^{1-\\alpha}\\mathbf{W}_{k}^{h}$$\nwhere $\\gamma=\\min(1,\\tau/S_{\\max})$  with $S_{\\max}=\\text{max}_{h} S_{\\max}^{h},$  and $\\alpha$  is a balancing parameter typically set to 0.5, applying equal scaling to queries and keys.\nHowever, we observe that in practice, only a small subset of heads exhibit exploding logits. In order to minimize our intervention on model training, we determine a per-head scaling factor $\\gamma_{h}=\\min(1,\\tau{/S_{\\max}^{h}}),$  and opt to apply per-head QK-Clip. Such clipping is straightforward for regular multi-head attention (MHA). For MLA, we apply clipping only on unshared attention head components:\n• $\\mathbf{q}^{\\boldsymbol{C}}$ and $\\mathbf{k}^{\\boldsymbol{C}}$ (head-specifc components): each scaled byi $\\sqrt{\\gamma_{h}}$\n• $\\mathbf{q}^{R}$ (head-specifc rotary): scaled by γh,i\n· $\\mathbf{k}^{\\boldsymbol{R}}$ (shared rotary): left untouched to avoid effect across heads.\nMuonClip: The New OptimizerWe integrate Muon with weight decay, consistent RMS matching, and QK-Clip into a single optimizer, which we refer to as MuonClip (see Algorithm 1).\nWe demonstrate the effectiveness of MuonClip from several scaling experiments. First, we train a mid-scale 9B activated and 53B total parameters Mixture-of-Experts (MoE) model using the vanilla Muon. As shown in Figure 2 (Left), we observe that the maximum attention logits quickly exceed a magnitude of 1000, showing that attention logits explosion is already evident in Muon training to this scale. Max logits at this level usually result in instability during training,including signifcant loss spikes and occasional divergence.i\n\nAlgorithm 1 MuonClip Optimizer\n1: for each training step $t$  do\n2:// 1. Muon optimizer step\n3:for each weight $\\mathbf{W}\\in\\mathbb{R}^{\\tiny n \\times\\tiny m}$  do\n4: $\\mathbf{M}_{t}=\\mu\\mathbf{M}_{t-1}+\\mathbf{G}_{t}$\n$\\mathbf{O}_{t}=$ Newton-Schulz $(\\mathbf{M}_{t})\\cdot\\sqrt{\\max(n,m)}\\cdot0.2$\n6: $\\mathbf{W}_{t}=\\mathbf{W}_{t-1}-\\eta\\big(\\mathbf{O}_{t}+\\lambda\\mathbf{W}_{t-1}\\big)$\n7:end for\n8: $//2$  QK-Clip\n9:for each attention head $h$  in every attention layer of the model do\n10:Obtain $S^{h}_{\\max}$  already computed during forward\n11:if $S^{h}_{\\max}>\\tau$ then\n12: $\\gamma\\leftrightarrow\\tau/S_{\\text{m}}^{h}$ ax\n13: $\\mathbf{W}_{qc}^{n}\\leftrightarrow\\mathbf{W}_{qc}^{n}\\cdot\\sqrt{\\gamma}$\n14: $\\mathbf{W}_{kc}^{h}\\leftrightarrow\\mathbf{W}_{kc}^{h}\\cdot\\sqrt{\\gamma}$\n15: $\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\leftrightarrow\\mathbf{W}_{\\mathit{qr}}^{\\mathit{h}}\\cdot\\gamma$\n17:end for\nFigure 2: Left: During a mid-scale training run, attention logits rapidly exceed 1000, which could lead to potential numerical instabilities and even training divergence. Right: Maximum logits for Kimi K2 with MuonClip and $\\tau=100$ over the entire training run. The max logits rapidly increase to the capped value of 100, and only decay to a stable range after approximately $30\\%$  of the training steps, demonstrating the effective regulation effect of QK-Clip.\nNext, we demonstrate that QK-Clip does not degrade model performance and confrm that the MuonClip optimizeri preserves the optimization characteristics of Muon without adversely affecting the loss trajectory. A detailed discussion of the experiment designs and fndings is provided in the Appendix D.i\nFinally, we train Kimi K2, a large-scale MoE model, using MuonClip with $\\tau=100$  and monitor the maximum attention logits throughout the training run (Figure 2 (Right)). Initially, the logits are capped at 100 due to QK-Clip. Over the course of training, the maximum logits gradually decay to a typical operating range without requiring any adjustment toτ. Importantly, the training loss remains smooth and stable, with no observable spikes, as shown in Figure 3, validating that MuonClip provides robust and scalable control over attention dynamics in large-scale language model training.\n2.2Pre-training Data: Improving Token Utility with Rephrasing\nToken effciency in pre-training refers to how much performance improvement is achieved for each token consumedi during training. Increasing token utility—the effective learning signal each token contributes—enhances the per-token impact on model updates, thereby directly improving token effciency. This is particularly important when the supply ofi high-quality tokens is limited and must be maximally leveraged. A naive approach to increasing token utility is through repeated exposure to the same tokens, which can lead to overftting and reduced generalization.i\n\nFigure 3: Per-step training loss curve of Kimi K2, without smoothing or sub-sampling. It shows no spikes throughout the entire training process. Note that we omit the very beginning of training for clarity.\nA key advancement in the pre-training data of Kimi K2 over Kimi K1.5 is the introduction of a synthetic data generation strategy to increase token utility. Specifcally, a carefully designed rephrasing pipeline is employed to amplify the volumei of high-quality tokens without inducing signifcant overftting. In this report, we describe two domain-specializedii rephrasing techniques—targeted respectively at the Knowledge and Mathematics domains—that enable this controlled data augmentation.\nKnowledge Data RephrasingPre-training on natural, knowledge-intensive text presents a trade-off: a single epoch is insuffcient for comprehensive knowledge absorption, while multi-epoch repetition yields diminishing returns andi increases the risk of overftting. To improve the token utility of high-quality knowledge tokens, we propose a synthetici rephrasing framework composed of the following key components:\nStyle- and perspective-diverse prompting: To enhance linguistic diversity while maintaining factual integrity, we apply a range of carefully engineered prompts. These prompts guide a large language model to generate faithful rephrasings of the original texts in varied styles and from different perspectives.\nChunk-wise autoregressive generation: To preserve global coherence and avoid information loss in long documents, we adopt a chunk-based autoregressive rewriting strategy. Texts are divided into segments, rephrased individually, and then stitched back together to form complete passages. This method mitigates implicit output length limitations that typically exist with LLMs. An overview of this pipeline is presented in Figure 4.\nFidelity verifcation: To ensure consistency between original and rewritten content, we perform fdelity checksii that compare the semantic alignment of each rephrased passage with its source. This serves as an initial quality control step prior to training.\nWe compare data rephrasing with multi-epoch repetition by testing their corresponding accuracy on SimpleQA. We experiment with an early checkpoint of K2 and evaluate three training strategies: (1) repeating the original dataset for 10 epochs, (2) rephrasing the data once and repeating it for 10 epochs, and (3) rephrasing the data 10 times with a single training pass. As shown in Table 1, the accuracy consistently improves across these strategies, demonstrating the effcacy of our rephrasing-based augmentation. We extended this method to other large-scale knowledge corpora andi observed similarly encouraging results, and each corpora is rephrased at most twice.\nTable 1: SimpleQA Accuracy under three rephrasing-epoch confgurationsi\n\n\n<html><body><table><thead><tr><td># Rephrasings</td><td># Epochs</td><td>SimpleQA Accuracy</td></tr></thead><tbody><tr><td>0 (raw wiki-text)</td><td>10</td><td>23.76</td></tr><tr><td>1</td><td>10</td><td>27.39</td></tr><tr><td>10</td><td>1</td><td>28.94</td></tr></tbody></table></body></html>\n\n\nFigure 4: Auto-regressive chunk-wise rephrasing pipeline for long input excerpts. The input is split into smaller chunks with preserved context, rewritten sequentially, and then concatenated into a full rewritten passage.\nMathematics Data RephrasingTo enhance mathematical reasoning capabilities, we rewrite high-quality mathematical documents into a “learning-note” style, following the methodology introduced in SwallowMath [15]. In addition,we increased data diversity by translating high-quality mathematical materials from other languages into English.\nAlthough initial experiments with rephrased subsets of our datasets show promising results, the use of synthetic data as a strategy for continued scaling remains an active area of investigation. Key challenges include generalizing the approach to diverse source domains without compromising factual accuracy, minimizing hallucinations and unintended toxicity, and ensuring scalability to large-scale datasets.\nPre-training Data OverallThe Kimi K2 pre-training corpus comprises 15.5 trillion tokens of curated, high-quality data spanning four primary domains: Web Text, Code, Mathematics, and Knowledge. Most data processing pipelines follow the methodologies outlined in Kimi K1.5 [35]. For each domain, we performed rigorous correctness and quality validation and designed targeted data experiments to ensure the curated dataset achieved both high diversity and effectiveness.\n2.3Model Architecture\nKimi K2 is a 1.04 trillion-parameter Mixture-of-Experts (MoE) transformer model with 32 billion activated parameters.The architecture follows a similar design to DeepSeek-V3 [10] , employing Multi-head Latent Attention (MLA) [44] as the attention mechanism, with a model hidden dimension of 7168 and an MoE expert hidden dimension of 2048. Our scaling law analysis reveals that continued increases in sparsity yield substantial performance improvements, which motivated us to increase the number of experts to 384, compared to 256 in DeepSeek-V3. To reduce computational overhead during inference, we cut the number of attention heads to 64, as opposed to 128 in DeepSeek-V3. Table 2 presents a detailed comparison of architectural parameters between Kimi K2 and DeepSeek-V3.\nTable 2: Architectural comparison between Kimi K2 and DeepSeek-V3\n\n\n<html><body><table><tr><td></td><td>DeepSeek-V3</td><td>Kimi K2</td><td> $\\Delta$ </td></tr><tr><td>#Layers</td><td>61</td><td>61</td><td>=</td></tr><tr><td>Total Parameters</td><td>671B</td><td>1.04T</td><td>￪54%</td></tr><tr><td>Activated Parameters</td><td>37B</td><td>32.6B</td><td> $\\downarrow13\\%$ </td></tr><tr><td>Experts (total)</td><td>256</td><td>384</td><td> $\\uparrow50\\%$ </td></tr><tr><td>Experts Active per Token</td><td>8</td><td>8</td><td>=</td></tr><tr><td>Shared Experts</td><td>1</td><td>1</td><td>=</td></tr><tr><td>Attention Heads</td><td>128</td><td>64</td><td> $\\downarrow50\\%$ </td></tr><tr><td>Number of Dense Layers</td><td>3</td><td>1</td><td> $\\downarrow67\\%$ </td></tr><tr><td>Expert Grouping</td><td>Yes</td><td>No</td><td>-</td></tr></table></body></html>\n\n\nSparsity Scaling LawWe develop a sparsity scaling law tailored for the Mixture-of-Experts (MoE) model family using Muon. Sparsity is defned as the ratio of the total number of experts to the number of activated experts. Throughi carefully controlled small-scale experiments, we observe that — under a fxed number of activated parameters (i.e.,i constant FLOPs) — increasing the total number of experts (i.e., increasing sparsity) consistently lowers both the training and validation loss, thereby enhancing overall model performance (Figure 5). Concretely, under the compute-optimal sparsity scaling law, achieving the same validation loss of 1.5, sparsity 48 reduces FLOPs by $1.69\\times,1.39\\times,$  and $1.15\\times$ compared to sparsity levels 8, 16, and 32, respectively. Though increasing sparsity leads to better performance, this gain comes with increased infrastructure complexity. To balance model performance with cost, we adopt a sparsity of 48 for Kimi K2, activating 8 out of 384 experts per forward pass.\nFigure 5: Sparsity Scaling Law. Increasing sparsity leads to improved model performance. We fxed the number ofi activated experts to 8 and the number of shared experts to 1, and varied the total number of experts, resulting in models with different sparsity levels.\nFigure 6: Scaling curves for models with number of attention heads equals to number of layers and their counterparts with doubled attention heads. Doubling the number of attention heads leads to a reduction in validation loss of approximately $0.5\\%$ to $1.2\\%.$\nNumber of Attention HeadsDeepSeek-V3 [10] sets the number of attention heads to roughly twice the number of model layers to better utilize memory bandwidth and enhance computational effciency. However, as the context lengthi increases, doubling the number of attention heads leads to signifcant inference overhead, reducing effciency at longerii sequence lengths. This becomes a major limitation in agentic applications, where effcient long context processing isi essential. For example, with a sequence length of 128k, increasing the number of attention heads from 64 to 128, while keeping the total expert count fxed at 384, leads to ani $83\\%$  increase in inference FLOPs. To evaluate the impact of this design, we conduct controlled experiments comparing confgurations where the number of attention heads equalsi the number of layers against those with double number of heads, under varying training FLOPs. Under iso-token training conditions, we observe that doubling the attention heads yields only modest improvements in validation loss(ranging from $0.5\\%$ to $1.2\\%$  across different compute budgets (Figure 6). Given that sparsity 48 already offers strong performance, the marginal gains from doubling attention heads do not justify the inference cost. Therefore we choose to 64 attention heads.\n2.4Training Infrastructure\n2.4.1Compute Cluster\nKimi K2 was trained on a cluster equipped with NVIDIA H800 GPUs. Each node in the H800 cluster contains 2 TB RAM and 8 GPUs connected by NVLink and NVSwitch within nodes. Across different nodes, $8 \\times400$ Gbps RoCE interconnects are utilized to facilitate communications.\n2.4.2Parallelism for Model Scaling\nTraining of large language models often progresses under dynamic resource availability. Instead of optimizing one parallelism strategy that’s only applicable under specifc amount of resources, we pursue a fexible strategy that allowsil Kimi K2 to be trained on any number of nodes that is a multiple of 32. Our strategy leverages a combination of 16-way\n\nFigure 7: Computation, communication and offoading overlapped in different PP phases.l\nPipeline Parallelism (PP) with virtual stages [28, 53, 38, 57, 47, 21], 16-way Expert Parallelism (EP) [39], and ZeRO-1 Data Parallelism [60].\nUnder this setting, storing the model parameters in BF16 and their gradient accumulation buffer in FP32 requires approximately 6 TB of GPU memory, distributed over a model-parallel group of 256 GPUs. Placement of optimizer states depends on the training confgurations. When the total number of training nodes is large, the optimizer states arei distributed, reducing its per-device memory footprint to a negligible level. When the total number of training nodes is small (e.g., 32), we can offoad some optimizer states to CPU.l\nThis approach allows us to reuse an identical parallelism confguration for both small- and large-scale experiments,i while letting each GPU hold approximately 30 GB of GPU memory for all states. The rest of the GPU memory are used for activations, as described in Sec. 2.4.3. Such a consistent design is important for research effciency, as it simplifesii the system and substantially accelerates experimental iteration.\nEP communication overlap with interleaved 1F1BBy increasing the number of warm-up micro-batches, we can overlap EP all-to-all communication with computation under the standard interleaved 1F1B schedule [21, 53]. In comparison, DualPipe [10] doubles the memory required for parameters and gradients, necessitating an increase in parallelism to compensate. Increasing PP introduces more bubbles, while increasing EP, as discussed below, incurs higher overhead. The additional costs are prohibitively high for training a large model with over 1 trillion parameters and thus we opted not to use DualPipe.\nHowever, interleaved 1F1B splits the model into more stages, introducing non-trivial PP communication overhead. To mitigate this cost, we decouple the weight-gradient computation from each micro-batch’s backward pass and execute it in parallel with the corresponding PP communication. Consequently, all PP communications can be effectively overlapped except for the warm-up phase.\nSmaller EP sizeTo ensure full computation-communication overlap during the 1F1B stage, the reduced attention computation time in K2 (which has 64 attention heads compared to 128 heads in DeepSeek-V3) necessitates minimizing the time of EP operations. This is achieved by adopting the smallest feasible EP parallelization strategy, specifcallyi $\\mathrm{EP}=16.$  Utilizing a smaller EP group also relaxes expert-balance constraints, allowing for near-optimal speed to be achieved without further tuning.\n2.4.3Activation Reduction\nAfter reserving space for parameters, gradient buffers, and optimizer states, the remaining GPU memory on each device is insuffcient to hold the full MoE activations. To ensure the activation memory fts within the constraints, especiallyii for the initial pipeline stages that accumulate the largest activations during the 1F1B warm-up phase, the following techniques are employed.\nSelective recomputationRecomputation is applied to inexpensive, high-footprint stages, including LayerNorm,SwiGLU, and MLA up-projections [10]. Additionally, MoE down-projections are recomputed during training to further reduce activation memory. While optional, this recomputation maintains adequate GPU memory, preventing crashes caused by expert imbalance in early training stages.\nFP8 storage for insensitive activationsInputs of MoE up-projections and SwiGLU are compressed to FP8-E4M3 in $1 \\times128$ tiles with FP32 scales. Small-scale experiments show no measurable loss increase. Due to potential risks of performance degradation that we observed during preliminary study, we do not apply FP8 in computation.\n\nActivation CPU offoadAll remaining activations are offoaded to CPU RAM. A copy engine is responsible forll streaming the offoad and onload, overlapping with both computation and communication kernels. During the 1F1Bl phase, we offoad the forward activations of the previous micro-batch while prefetching the backward activations of thel next. The warm-up and cool-down phases are handled similarly and the overall pattern is shown in Figure 7. Although offoading may slightly affect EP traffc due to PCIe traffc congestion, our tests show that EP communication remainslii fully overlapped.\n2.5Training recipe\nWe pre-trained the model with a 4,096-token context window using the MuonClip optimizer (Algorithm 1) and the WSD learning rate schedule [25], processing a total of 15.5T tokens. The frst 10T tokens were trained with a constanti learning rate of 2e-4 after a 500-step warm-up, followed by 5.5T tokens with a cosine decay from 2e-4 to 2e-5. Weight decay was set to 0.1 throughout, and the global batch size was held at 67M tokens. The overall training curve is shown in Figure 3.\nTowards the end of pre-training, we conducted an annealing phase followed by a long-context activation stage. The batch size was kept constant at 67M tokens, while the learning rate was decayed from 2e-5 to 7e-6. In this phase, the model was trained on 400 billion tokens with a 4k sequence length, followed by an additional 60 billion tokens with a 32k sequence length. To extend the context window to 128k, we employed the YaRN method [55].\n3Post-Training\n3.1Supervised Fine-Tuning\nWe employ the Muon optimizer [33] in our post-training and recommend its use for fne-tuning with K2. This followsi from the conclusion of our previous work [46] that a Muon-pre-trained checkpoint produces the best performance with Muon fne-tuning.i\nWe construct a large-scale instruction-tuning dataset spanning diverse domains, guided by two core principles: maximizing prompt diversity and ensuring high response quality. To this end, we develop a suite of data generation pipelines tailored to different task domains, each utilizing a combination of human annotation, prompt engineering, and verifcation processes. We adopt K1.5 [35] and other in-house domain-specialized expert models to generate candidatei responses for various tasks, followed by LLMs or human-based judges to perform automated quality evaluation and fltering. For agentic data, we create a data synthesis pipeline to teach models tool-use capabilities through multi-step,i interactive reasoning.\n3.1.1Large-Scale Agentic Data Synthesis for Tool Use Learning\nA critical capability of modern LLM agents is their ability to autonomously use unfamiliar tools, interact with external environments, and iteratively refne their actions through reasoning, execution, and error correction. Agentic tool usei capability is essential for solving complex, multi-step tasks that require dynamic interaction with real-world systems.Recent benchmarks such as ACEBench [6] and $7$ -bench [85] have highlighted the importance of comprehensive tool-use evaluation, while frameworks like ToolLLM [58] and ACEBench [6] have demonstrated the potential of teaching models to use thousands of tools effectively.\nHowever, training such capabilities at scale presents a signifcant challenge: while real-world environments providei rich and authentic interaction signals, they are often diffcult to construct at scale due to cost, complexity, privacyi and accessibility constraints. Recent work on synthetic data generation (AgentInstruct [51]; Self-Instruct [75];StableToolBench [20]; ZeroSearch [66]) has shown promising results in creating large-scale data without relying on real-world interactions. Building on these advances and inspired by ACEBench [6]’s comprehensive data synthesis framework, we developed a pipeline that simulates real-world tool-use scenarios at scale, enabling the generation of tens of thousands of diverse and high-quality training examples.\nThere are three stages in our data synthesis pipeline, depicted in Fig. 8.\nTool spec generation: we frst construct a large repository of tool specs from both real-world tools and LLM-i synthetic tools;\nAgent and task generation: for each tool-set sampled from the tool repository, we generate an agent to use the toolset and some corresponding tasks;\nTrajectory generation: for each agent and task, we generate trajectories where the agent fnishes the task byi invoking tools.\n\n(a) Synthesizing tool specs, agents and tasks(b) Generating agent trajectories\n(a) Synthesizing tool specs, agents and tasks\nFigure 8: Data synthesis pipeline for tool use. (a) Tool specs are from both real-world tools and LLMs; agents and tasks are the generated from the tool repo. (b) Multi-agent pipeline to generate and flter trajectories with tool calling.i\n(b) t-SNE visualization of synthetic tools, colored by pre-defnedi domain categories\ni\n(a) t-SNE visualization of real MCP tools, colored by their original source categories\nFigure 9: t-SNE visualizations of tool embeddings. (a) Real-world MCP tools exhibit natural clustering based on their original source categories. (b) Synthetic tools are organized into pre-defned domain categories, providing systematici coverage of the tool space. Together, they ensure comprehensive representation across different tool functionalities.\nDomain Evolution and Tool Generation.We construct a comprehensive tool repository through two complementary approaches. First, we directly fetch 3000+ real MCP (Model Context Protocol) tools from GitHub repositories,leveraging existing high-quality tool specs. Second, we systematically evolve [82] synthetic tools through a hierarchical domain generation process: we begin with key categories (e.g., fnancial trading, software applications, robot control),i then evolve multiple specifc application domains within each category. Specialized tools are then synthesized for eachi domain, with clear interfaces, descriptions, and operational semantics. This evolution process produces over 20,000 synthetic tools. Figure 9 visualizes the diversity of our tool collection through t-SNE embeddings, demonstrating that both MCP and synthetic tools cover complementary regions of the tool space.\nAgent Diversifcation.We generate thousands of distinct agents by synthesizing various system prompts andi equipping them with different combinations of tools from our repository. This creates a diverse population of agents with varied capabilities, areas of expertise, and behavioral patterns, ensuring a broad coverage of potential use cases.\nRubric-Based Task Generation.For each agent confguration, we generate tasks that range from simple to complexi operations. Each task is paired with an explicit rubric that specifes success criteria, expected tool-use patterns, andi evaluation checkpoints. This rubric-based approach ensures a consistent and objective evaluation of agent performance.\nMulti-turn Trajectory Generation.We simulate realistic tool-use scenarios through several components:\nUser Simulation: LLM-generated user personas with distinct communication styles and preferences engage in multi-turn dialogues with agents, creating naturalistic interaction patterns.\n\nTool Execution Environment: A sophisticated tool simulator (functionally equivalent to a world model) executes tool calls and provides realistic feedback. The simulator maintains and updates state after each tool execution,enabling complex multi-step interactions with persistent effects. It introduces controlled stochasticity to produce varied outcomes including successes, partial failures, and edge cases.\nQuality Evaluation and Filtering.An LLM-based judge evaluates each trajectory against the task rubrics. Only trajectories that meet the success criteria are retained for training, ensuring high-quality data while allowing natural variation in task-completion strategies.\nHybrid Approach with Real Execution Environments.While simulation provides scalability, we acknowledge the inherent limitation of simulation fdelity. To address this, we complement our simulated environments with reali execution sandboxes for scenarios where authenticity is crucial, particularly in coding and software engineering tasks.These real sandboxes execute actual code, interact with genuine development environments, and provide ground-truth feedback through objective metrics such as test suite pass rates. This combination ensures that our models learn from both the diversity of simulated scenarios and the authenticity of real executions, signifcantly strengthening practicali agent capabilities.\nBy leveraging this hybrid pipeline that combines scalable simulation with targeted real-world execution, we generate diverse, high-quality tool-use demonstrations that balance coverage and authenticity. The scale and automation of our synthetic data generation, coupled with the grounding provided by real execution environments, effectively implements large-scale rejection sampling [26, 87] through our quality fltering process. This high-quality synthetic data, wheni used for supervised fne-tuning, has demonstrated signifcant improvements in the model’s tool-use capabilities across aii wide range of real-world applications.\n3.2Reinforcement Learning\nReinforcement learning (RL) is believed to have better token effciency and generalization than SFT. Based on the worki of K1.5 [35], we continue to scale RL in both task diversity and training FLOPs in K2. To support this, we develop a Gym-like extensible framework that facilitates RL across a wide range of scenarios. We extend the framework with a large number of tasks with verifable rewards. For tasks that rely on subjective preferences, such as creative writing andi open-ended question answering, we introduce a self-critic reward in which the model performs pairwise comparisons to judge its own outputs. This approach allows tasks from various domains to all beneft from the RL paradigm.i\n3.2.1Verifable Rewards Gymi\nMath, STEM and Logical TasksFor math, stem and logical reasoning domains, our RL data preparation follows two key principles, diverse coverage and moderate diffculty.i\nDiverse Coverage. For math and stem tasks, we collect high-quality QA pairs using a combination of expert annotations,internal QA extraction pipelines, and open datasets [41, 52]. During the collection process, we leverage a tagging system to deliberately increase coverage of under-covered domains. For logical tasks, our dataset comprises a variety of formats, including structured data tasks (e.g., multi-hop tabular reasoning, cross-table aggregation) and logic puzzles(e.g., the 24-game, Sudoku, riddles, cryptarithms, and Morse-code decoding).\nModerate Diffculty. The RL prompt-set should be neither too easy nor too hard, both of which may produce little signali and reduce learning effciency. We assess the diffculty of each problem using the SFT model’s pass@k accuracy andii select only problems with moderate diffculty.i\nComplex Instruction FollowingEffective instruction following requires not only understanding explicit constraints but also navigating implicit requirements, handling edge cases, and maintaining consistency over extended dialogues.We address these challenges through a hybrid verifcation framework that combines automated verifcation withii adversarial detection, coupled with a scalable curriculum generation pipeline. Our approach employs a dual-path system to ensure both precision and robustness:\nHybrid Rule Verifcation. We implement two verifcation mechanisms: (1) deterministic evaluation via code interpretersii for instructions with verifable outputs (e.g., length, style constraints), and (2) LLM-as-judge evaluation for instructionsi requiring nuanced understanding of constraints. To address potential adversarial behaviors where models might claim instruction fulfllment without actual compliance, we incorporate an additional hack-check layer that specifcally detectsii such deceptive claims.\nMulti-Source Instruction Generation. To construct our training data, we employ three distinct generation strategies to ensure comprehensive coverage: (1) expert-crafted complex conditional prompts and rubrics developed by our datateam (2) agentic instruction augmentation inspired by AutoIF [12], and (3) a fne-tuned model specialized for generatingi additional instructions that probe specifc failure modes or edge cases. This multipronged approach ensures both breadthi and depth in instruction coverage.\nFaithfulnessFaithfulness is essential for an agentic model operating in scenarios such as multi-turn tool use, selfgenerated reasoning chains, and open-environment interactions. Inspired by the evaluation framework from FACTS Grounding [30], we train a sentence-level faithfulness judge model to perform automated verifcation. The judge isi effective in detecting sentences that make a factual claim without supporting evidence in context. It serves as a reward model to enhance overall faithfulness performance.\nCoding $\\&$  Software EngineeringTo enhance our capability in tackling competition-level programming problems,we gather problems and their judges from both open-source datasets [27, 83] and synthetic sources. To ensure the diversity of the synthetic data and the correctness of reward signals, we incorporate high-quality human-written unit tests retrieved from pre-training data.\nFor software engineering tasks, we collect a vast amount of pull requests and issues from GitHub to build software development environment that consists of user prompts/issues and executable unit tests. This environment was built on a robust sandbox infrastructure, powered by Kubernetes for scalability and security. It supports over 10,000 concurrent sandbox instances with stable performance, making it ideal for both competitive coding and software engineering tasks.\nSafetyOur work to enhance the safety begins with a human-curated set of seed prompts, manually crafted to encompass prevalent risk categories such as violence, fraud, and discrimination.\nTo simulate sophisticated jailbreak attempts (e.g., role-playing, literary narratives, and academic discourse), we employ an automated prompt evolution pipeline with three key components:\nAttack Model: Iteratively generates adversarial prompts designed to elicit unsafe responses from the target LLM.\nTarget Model: Produces responses to these prompts, simulating potential vulnerabilities.\nJudge Model: Evaluates the interaction to determine if the adversarial prompt successfully bypasses safety mechanisms.\nEach interaction is assessed using a task-specifc rubric, enabling the judge model to provide a binary success/failurei label.\n3.2.2Beyond Verifcation: Self-Critique Rubric Rewardi\nTo extend model alignment beyond tasks with verifable reward, we introduce a framework for general reinforcementi learning from self-critic feedbacks. This approach is designed to align LLMs with nuanced human preferences,including helpfulness, creativity, depth of reasoning, factuality, and safety, by extending the capabilities learned from verifable scenarios to a broader range of subjective tasks. The framework operates using a Self-Critique Rubric Rewardi mechanism, where the model evaluates its own outputs to generate preference signals. To bootstrap K2 as a competent judge, we curated a mixture of open-source and in-house preference datasets and initialize its critic capability in the SFT stage.\nSelf-Critiqued Policy OptimizationIn the frst core process of the learning loop, the K2 actor generates responsesi for general prompts that cover a wide range of use cases. The K2 critic then ranks all results by performing pairwise evaluations against a combination of rubrics, which incorporates both core rubrics (Appendix. F.1), which represent the fundamental values of our AI assistant that Kimi cherish, prescriptive rubrics (Appendix. F.2) that aim to eliminate reward hacking, and human-annotated rubrics crafted by our data team for specifc instructional contexts. Althoughi certain rubrics can be designated as mandatory, K2 retains the fexibility to weigh them against its internal priors. Thisl capacity enables a dynamic and continuous alignment with its evolving on-policy behavior, ensuring that the model’s responses remain coherent with its core identity while adapting to specifc instructions.i\nClosed-Loop Critic Refnement and AlignmentDuring RL training, the critic model is refned using verifableiii signals. On-policy rollouts generated from verifable-reward prompts are used to continuously update the critic, a cruciali step that distills objective performance signals from RLVR directly into its evaluation model. This transfer learning process grounds its more subjective judgments in verifable data, allowing the performance gains from verifableii tasks to enhance the critic’s judgment on complex tasks that lack explicit reward signals. This closed-loop process ensures that the critic continuously recalibrates its evaluation standards in lockstep with the policy’s evolution. Bygrounding subjective evaluation in verifable data, the framework enables robust and scalable alignment with complex,i non-verifable human objectives.i\nConsequently, this holistic alignment yields comprehensive performance improvements across a wide spectrum of domains, including user intent understanding, creative writing, complex reasoning, and nuanced language comprehension.\n3.2.3RL Algorithm\nWe adopt the policy optimization algorithm introduced in K1.5 [35] as the foundation for K2. For each problem x,we sample $K$  responses $\\{y_{1},\\ldots,y_{k}\\}$  from the previous policy $\\pi_{\\text{old}},$  and optimize the model $\\pi_{\\theta}$  with respect to the following objective:\n$$L_{\\text{RL}}(\\theta)=\\mathbb{E}_{x\\sim\\mathcal{D}}\\left[\\frac{1}{K}\\sum_{i=1}^{K}\\left[\\left(r(x,y_{i})-\\bar{r}(x)-\\tau\\log\\frac{\\pi_{\\theta}(y_{i}|x)}{\\pi_{\\text{old}}(y_{i}|x)}\\right)^{2}\\right]\\right] ,$$\nwhere $$  is the mean rewards of the sampled responses, $\\tau>0$  is a regularization parameter that promotes stablke learning. As in SFT, we employ the Muon optimizer [33] to minimize this objective. As we scale RL training to encompass a broader range of tasks in K2, a primary challenge is achieving consistent performance improvements across all domains. To address this, we introduce several additions to the RL algorithm.\nBudget ControlIt has been widely observed that RL often results in a substantial increase in the length of modelgenerated responses [35, 19]. While longer responses can enable the model to utilize additional test-time compute for improved performance on complex reasoning tasks, the benefts often do not justify its inference cost in non-reasoningi domains. To encourage the model to properly distribute inference budget, we enforce a per-sample maximum token budget throughout RL training, where the budget is determined based on the type of task. Responses that exceed this token budget are truncated and assigned a penalty, which incentivizes the model to generate solutions within the specifed limit. Empirically, this approach signifcantly enhances the model’s token effciency, encouraging concise yetiii effective solutions across all domains.\nPTX LossTo prevent the potential forgetting of valuable, high-quality data during joint RL training, we curate a dataset comprising hand-selected, high-quality samples and integrate it into the RL objective through an auxiliary PTX loss [54]. This strategy not only leverages the advantages of high-quality data, but also mitigates the risk of overfttingi to the limited set of tasks explicitly present in the training regime. This augmentation substantially improves the model’s generalization across a broader range of domains.\nTemperature DecayFor tasks such as creative writing and complex reasoning, we fnd that promoting explorationi via a high sampling temperature during the initial stages of training is crucial. A high temperature allow the model to generate diverse and innovative responses, thereby facilitating the discovery of effective strategies and reducing the risk of premature convergence to suboptimal solutions. However, retaining a high temperature in the later stages of training or during evaluation can be detrimental, as it introduces excessive randomness and compromises the reliability and consistency of the model’s outputs. To address this, we employ a temperature decay schedule, to shift from exploration to exploitation throughout the training. This strategy ensures that the model leverages exploration when it is most benefcial, while ultimately converge on stable and high-quality outputs.i\n3.3RL Infrastructure\n3.3.1Colocated Architecture\nSimilar to K1.5 [35], we adopt a hybrid colocated architecture for our synchronized RL training, where the training and inference engines live on the same workers. When one engine is actively working, the other engine releases or offoadsl its GPU resources to accommodate. In each iteration of RL training, a centralized controller frst calls the inferencei engine to generate new data for training. It then notifes the training engine to train on the new data, and send updatedi parameters to the inference engine for the next iteration.\nEach engine is heavily optimized for throughput. In addition, as the model scales to the size of K2, the latency of engine switching and failure recovery becomes signifcant. We present our system design considerations in these aspects.i\n\nFigure 10: Parameter update utilizing a checkpoint engine\n3.3.2Effcient Engine Switchingi\nDuring rollout, the parameters of the training engine are offoaded to DRAM. Bringing up the training engine isl therefore a simple step of H2D transmission. However, bringing up the inference engine is a bigger challenge, as it must obtain updated parameters from the training engine with a different sharding paradigm.\nGiven the scale of K2 and the vast number of devices involved, using a network fle system for resharding andi broadcasting parameters is impractical. The aggregate bandwidth required to keep overhead low reaches several petabytes per second. To address this challenge, we developed a distributed checkpoint engine co-located on training nodes to manage parameter states. To perform a parameter update, each checkpoint engine worker obtains a local copy of parameters from the training engine, then broadcasts the full parameter set across all checkpoint engine workers.Subsequently, the inference engine retrieves only the parameter shard it requires from the checkpoint engine. This process is illustrated in Figure 10. To enable this for a 1T model, updates are performed parameter-by-parameter in a pipelined manner, minimizing memory footprint (see Appendix G).\nWe opt to broadcast the full parameter set across the entire cluster, regardless of the specifc sharding schemes on eachi inference worker. While this transfers several times more data than a theoretically optimal approach, it offers a simpler system design that is less intrusive to the training and inference engines. We chose to trade off this minor overhead to fully decouple the training engine and the inference engine, signifcantly simplifying maintenance and testing.i\nNotably, this approach outperforms the transfer-what-you-need method due to reduced synchronization overhead and higher network bandwidth utilization. Our system can complete a full parameter update for Kimi K2 with less than 30 seconds, a negligible duration for a typical RL training iteration.\n3.3.3Effcient System Startupi\nAs large-scale training is prone to system failure, optimizing the startup time is crucial for models as large as Kimi K2.To start the training engine, we let each training worker selectively read part or none of the parameters from disk, and broadcast necessary parameters to its peers. The design goal is to ensure all workers collectively read the checkpoint only once, minimizing expensive disk IO.\nAs the inference engines are independent replicas, we would like to avoid introducing extra synchronization barriers between them. Therefore, we opt to reuse checkpoint engine for startup: we let checkpoint engine collectively read the checkpoint from disk, similar to how the training engine starts. Then it updates the state of the uninitialized inference engine, using the approach introduced in the previous section. By leveraging the dedicated checkpoint engine, the system also becomes robust to single-point failures, because an inference replica can restart without communicating with other replicas.\n3.3.4Agentic Rollout\nOur RL infrastructure supports the training of long-horizon, multi-turn agentic tasks. During rollout, these tasks present distinct challenges, such as complex environmental interactions and prolonged rollout durations. Here we introduce a few optimizations to alleviate these issues.\nDue to the diversity of environments, certain interactions may be blocked on waiting for environment feedback (e.g., a virtual machine or a code interpreter), leaving the GPUs idle. We employ two strategies to maximize GPU utilization:(i) we deploy heavy environments as dedicated services that can scale up more easily; (ii) we employ a large number of concurrent rollouts to amortize the latency induced by certain expensive interactions.\nAnother challenge in agentic rollout is that individual rollout trajectories can be extremely long. To prevent long-tail trajectories from blocking the entire rollout process, we employ the partial rollout [35] technique. This strategy allows long-tail unfnished tasks to be paused, and resumed in the next RL iteration.i\nTo improve research effciency, we also design a unifed interface inspired by the OpenAI Gym framework [49] toii streamline the integration of new environments. We hope to scale our RL infrastructure to more diverse interactive environments in the future.\n4Evaluations\nThis section begins with the post-training evaluation of Kimi-K2-Instruct, followed by a brief overview of the capabilities of Kimi-K2-Base. We conclude with a comprehensive safety evaluation.\n4.1Post-training Evaluations\n4.1.1Evaluation Settings\nBenchmarksWe assess Kimi-K2-Instruct across different areas. For coding, we adopt LiveCodeBench v6 [31](questions from August 2024 to May 2025), OJBench [77], MultiPL-E [5], SWE-bench Verifed [32, 84], TerminalBench [71],i Multi-SWE-bench [86], SWE-Lancer [50], PaperBench [65], and Aider-Polyglot [16]. For tool use tasks, we evaluate performance on $\\boldsymbol{\\tau^{2}}$ -Bench [3] and AceBench [6], which emphasize multi-turn tool-calling capabilities. In reasoning,we include a wide range of mathematical, science and logical tasks: AIME 2024/2025, MATH-500, HMMT 2025,CNMO 2024, PolyMath-en, ZebraLogic [43], AutoLogi [91], GPQA-Diamond [61], SuperGPQA [13], and Humanity’s Last Exam (Text-Only) [56]. We benchmark the long-context capabilities on: MRCR4 for long-context retrieval, and DROP [14], FRAMES [37] and LongBench v2 [2] for long-context reasoning. For factuality, we evaluate FACTS Grounding [30], the Vectara Hallucination Leaderboard [73], and FaithJudge [68]. Finally, general capabilities are assessed using MMLU [23], MMLU-Redux [17], MMLU-Pro [76], IFEval [90], Multi-Challenge [64], SimpleQA [78],and LiveBench [80] (as of 2024-11-25).\nBaselinesWe benchmark against both open-source and proprietary frontier models, ensuring every candidate is evaluated under its non-thinking confguration to eliminate additional gains from test-time compute. Open-sourcei baselines: DeepSeek-V3-0324 and Qwen3-235B-A22B, with the latter run in the vendor-recommended no-thinking regime. Proprietary baselines: Claude Sonnet 4, Claude Opus 4, GPT-4.1, and Gemini 2.5 Flash Preview (2025-05-20).Each invoked in its respective non-thinking mode via offcial APIs under unifed temperature and top-p settings.ii\nEvaluation Confgurations All runs query models in their non-thinking mode. Output token length is capped ati 8192 tokens everywhere except SWE-bench Verifed (Agentless), which is raised to 16384. For benchmarks with highi per-question variance, we adopt repeated sampling $k$  times and average the results to obtain stable scores, denoted as Avg@k. For long-context tasks, we set the context window size to 128K tokens during evaluation, truncating any input that exceeds this limit to ft within the window. SWE-bench Verifed is evaluated in two modes: Agentless Codingii via Single Patch without Test (Acc) and Agentic Coding via bash/editor tools under both Single Attempt (Acc) and Multiple Attempts (Acc) using best-of-N selection with an internal verifer; SWE-bench Multilingual is tested only ini the single-attempt agentic setting. Some data points have been omitted due to prohibitively expensive evaluation costs.\n4.1.2Evaluation Results\nA comprehensive evaluation results of Kimi-K2-Instruct is shown in Table 3, with detailed explanation provided in the Appendix C. Below, we highlight key results across four core domains:\nAgentic and Competitive CodingKimi-K2-Instruct demonstrates state-of-the-art open-source performance on real-world SWE tasks. It outperforms most baselines on SWE-bench Verifedi $(65.8\\%,71.6\\%$ with multiple attemps),SWE-bench Multilingual $(47.3\\%]$ , and SWE-lancer (39.1%), signifcantly closing the gap with Claude 4 Opus andi Sonnet. On competitive coding benchmarks (e.g., LiveCodeBench v6 $53.7\\%,$  OJBench $\\bar{27.1\\%})$ , it also leads among all models, highlighting its practical coding profciency across diffculty levels.ii\n\nTable 3: Performance comparison of Kimi-K2-Instruct against leading open-source and proprietary models across diverse tasks. Bold denotes the global SOTA; underlined bold indicates the best open-source result. Data points marked with * are taken directly from the model’s technical report or blog.\n\n\n<html><body><table><thead><tr><td></td><td colspan=\"3\">Open Source</td><td colspan=\"3\">Proprietary</td><td></td></tr><tr><td>Benchmark</td><td>Kimi-K2- Instruct</td><td>DeepSeek- V3-0324</td><td>Qwen3- 235B- A22B</td><td>Claude Sonnet 4</td><td>Claude Opus 4</td><td>GPT-4.1</td><td>Gemini 2.5 Flash</td></tr></thead><tbody><tr><td colspan=\"8\">Coding Tasks</td></tr><tr><td>LiveCodeBench v6 (Pass@1)</td><td>53.7</td><td>46.9</td><td>37.0</td><td>48.5</td><td>47.4</td><td>44.7</td><td>44.7</td></tr><tr><td>OJBench (Pass@1)</td><td>27.1</td><td>24.0</td><td>11.3</td><td>15.3</td><td>19.6</td><td>19.5</td><td>19.5</td></tr><tr><td>MultiPL-E (Pass@1) SWE-bench Verifed</td><td>85.7</td><td>83.1</td><td>78.2</td><td>88.6</td><td>89.6</td><td>86.7</td><td>85.6</td></tr><tr><td>Agentless-Single-Patch (Pass@1)</td><td>51.8</td><td>36.6</td><td>39.4</td><td>50.2</td><td>53.0</td><td>40.8</td><td>32.6</td></tr><tr><td>SWE-bench Verifed Agentic-Single-Attempt (Pass@1)</td><td>65.8</td><td>38.8</td><td>34.4</td><td>72.7*</td><td> $72.5\\text{*}$ </td><td>54.6</td><td>—</td></tr><tr><td>SWE-bench Verifed</td><td>71.6</td><td>—</td><td>—</td><td>80.2*</td><td> $79.4\\text{*}$ </td><td>—</td><td>—</td></tr><tr><td>Agentic-Multi-Attempt (Pass@1) SWE-bench Multilingual (Pass@1)</td><td>47.3</td><td>25.8</td><td>20.9</td><td>51.0</td><td>—</td><td>31.5</td><td>—</td></tr><tr><td>Multi-SWE-bench (Pass@1)</td><td>18.3</td><td>8.0</td><td>9.0</td><td>29.2</td><td>—</td><td>11.7</td><td>14.0</td></tr><tr><td>SWE-Lancer (Pass@1)</td><td>39.1</td><td>30.5</td><td>24.1</td><td>40.8</td><td>—</td><td>23.0</td><td>38.5</td></tr><tr><td>Paper Bench Code-Dev (Acc.)</td><td>27.8</td><td>12.2</td><td>13.2</td><td>43.3</td><td></td><td>29.9</td><td>5.7</td></tr><tr><td>Terminal Bench In-House (Acc.)</td><td>30.0</td><td></td><td></td><td>35.5</td><td>43.2</td><td>8.3</td><td>—</td></tr><tr><td>Terminal Bench Terminus (Acc.)</td><td>25.0</td><td>16.3</td><td>6.6</td><td>—</td><td></td><td>30.3</td><td>16.8</td></tr><tr><td>Aider-Polyglot (Acc.)</td><td>60.0</td><td>55.1</td><td>61.8</td><td>56.4</td><td>70.7</td><td>52.4</td><td>44.0</td></tr><tr><td colspan=\"8\">Tool Use Tasks</td></tr><tr><td>Tau2 retail (Avg@4)</td><td>70.6</td><td>69.1</td><td>57.0</td><td>75.0</td><td>81.8</td><td>74.8</td><td>64.3</td></tr><tr><td>Tau2 airline (Avg@4)</td><td>56.5</td><td>39.0</td><td>26.5</td><td>55.5</td><td>60.0</td><td>54.5</td><td>42.5</td></tr><tr><td>Tau2 telecom (Avg@4)</td><td>65.8</td><td>32.5</td><td>22.1</td><td>45.2</td><td>57.0</td><td>38.6</td><td>16.9</td></tr><tr><td>AceBench (Acc.)</td><td>76.5</td><td>72.7</td><td>70.5</td><td>76.2</td><td>75.6</td><td>80.1</td><td>74.5</td></tr><tr><td colspan=\"8\">Math & STEM Tasks</td></tr><tr><td>AIME 2024 (Avg@64)</td><td>69.6</td><td>59.4*</td><td>40.1*</td><td>43.4</td><td>48.2</td><td>46.5</td><td>61.3</td></tr><tr><td>AIME 2025 (Avg@64)</td><td>49.5</td><td>46.7</td><td>24.7*</td><td>33.1*</td><td>33.9*</td><td>37.0</td><td>46.6</td></tr><tr><td>MATH-500 (Acc.)</td><td>97.4</td><td>94.0*</td><td>91.2*</td><td>94.0</td><td>94.4</td><td>92.4</td><td>95.4</td></tr><tr><td>HMMT 2025 (Avg@32)</td><td>38.8</td><td>27.5</td><td>11.9</td><td>15.9</td><td>15.9</td><td>19.4</td><td>34.7</td></tr><tr><td>CNMO 2024 (Avg@16)</td><td>74.3</td><td>74.7</td><td>48.6</td><td>60.4</td><td>57.6</td><td>56.6</td><td>75.0</td></tr><tr><td>PolyMath-en (Avg@4)</td><td>65.1</td><td>59.5</td><td>51.9</td><td>52.8</td><td>49.8</td><td>54.0</td><td>49.9</td></tr><tr><td>ZebraLogic (Acc.)</td><td>89.0</td><td>84.0</td><td>37.7*</td><td>79.7</td><td>59.3</td><td>58.5</td><td>57.9</td></tr><tr><td>AutoLogi (Acc.)</td><td>89.5</td><td>88.9</td><td>83.3*</td><td>89.8</td><td>86.1</td><td>88.2</td><td>84.1</td></tr><tr><td>GPQA-Diamond (Avg@8)</td><td>75.1</td><td>68.4*</td><td>62.9*</td><td>70.0*</td><td>74.9*</td><td>66.3</td><td>68.2</td></tr><tr><td>SuperGPQA (Acc.)</td><td>57.2 4.7</td><td>53.7 5.2</td><td>50.2 5.7</td><td>55.7 5.8</td><td>56.5 7.1</td><td>50.8 3.7</td><td>49.6 5.6</td></tr><tr><td colspan=\"8\">Humanity’s Last Exam (Acc.) General Tasks</td></tr><tr><td>MMLU (EM)</td><td>89.5</td><td>89.4</td><td>87.0</td><td>91.5</td><td>92.9</td><td>90.4</td><td>90.1</td></tr><tr><td>MMLU-Redux (EM)</td><td>92.7</td><td>90.5</td><td>89.2*</td><td>93.6</td><td>94.2</td><td>92.4</td><td>90.6</td></tr><tr><td>MMLU-Pro (EM)</td><td>81.1</td><td>81.2*</td><td>77.3</td><td>83.7</td><td>86.6</td><td>81.8</td><td>79.4</td></tr><tr><td>IFEval (Prompt Strict)</td><td>89.8</td><td>81.1</td><td>83.2*</td><td>87.6</td><td>87.4</td><td>88.0</td><td>84.3</td></tr><tr><td>Multi-Challenge (Acc.)</td><td>54.1</td><td>31.4</td><td>34.0</td><td>46.8</td><td>49.0</td><td>36.4</td><td>39.5</td></tr><tr><td>SimpleQA (Correct)</td><td>31.0</td><td>27.7</td><td>13.2</td><td>15.9</td><td>22.8</td><td>42.3</td><td>23.3</td></tr><tr><td>Livebench (Pass@1) Arena Hard v2.0</td><td>76.4</td><td>72.4</td><td>67.6</td><td>74.8</td><td>74.6</td><td>69.8</td><td>67.8</td></tr><tr><td>Hard Prompt (Win rate)</td><td>54.5</td><td>39.9</td><td>39.9</td><td>51.6</td><td>59.7</td><td>51.7</td><td>48.7</td></tr><tr><td>Arena Hard v2.0</td><td>85.0</td><td>59.3</td><td>59.8</td><td>54.6</td><td>68.5</td><td>61.5</td><td>72.8</td></tr><tr><td>Creative Writing (Win rate) FACTS Grounding (Adjusted)</td><td>88.5</td><td></td><td></td><td></td><td></td><td>79.2</td><td>86.6</td></tr><tr><td>HHEM v2.1 (1-Hallu.)</td><td>98.9</td><td>68.3 88.9</td><td>68.5 94.5</td><td>83.6 94.5</td><td>—</td><td>96.7</td><td>97.8</td></tr><tr><td>FaithJudge (1-Hallu.)</td><td>92.6</td><td>83.4</td><td>75.7</td><td>83.0</td><td>—</td><td>91.0</td><td>93.2</td></tr><tr><td>LongBench v2 (Acc.)</td><td></td><td></td><td></td><td></td><td>—</td><td>54.3</td><td>55.5</td></tr><tr><td>FRAMES (Acc.)</td><td>49.1 77.1</td><td>51.1 79.2</td><td>—</td><td>52.5 76.3</td><td>—</td><td>87.4</td><td>72.9</td></tr><tr><td>MRCR (Acc.)</td><td>55.0</td><td>50.8</td><td>—</td><td>74.4</td><td>—</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>—</td><td>66.9</td><td>81.7</td></tr><tr><td>DROP (Acc.)</td><td>93.5</td><td>91.2</td><td>84.3</td><td>92.0</td><td>—</td><td>79.1</td><td>81.7</td></tr></tbody></table></body></html>\n\n\nAgentic Tool UseOn multi-turn tool-use benchmarks, Kimi-K2-Instruct sets a new standard. It achieves 66.1 Pass@1 on $\\tau^{2}$ Bench and 76.5 on ACEBench, substantially outperforming all baselines. These results affrm its strength ini grounded, controlled, and agent-driven tool orchestration across domains.\nGeneral CapabilitiesKimi-K2-Instruct exhibits strong, balanced performance across general knowledge, math, instruction following, and long-context tasks. It surpasses open-source peers on SimpleQA $(31.0\\%),$  MMLU $(89.5\\%]$  and MMLU-Redux (92.7%), and leads all models on instruction benchmarks (IFEval: $89.8\\%,$  Multi-Challenge: $54.1\\%)$ In math and STEM, it achieves top-tier scores (AIME 2024: 69.6%, GPQA-Diamond: $75.1\\%)$ , and remains competitive on long-context factuality and retrieval (DROP: 93.5%, MRCR: 55.0%). These results position Kimi-K2-Instruct as a well-rounded and capable generalist across both short- and long-context settings.\nOpen-Ended EvaluationOn the LMSYS Arena leaderboard (July 17, 2025), Kimi-K2-Instruct ranks as the top-1 open-source model and 5th overall based on over 3,000 user votes. This real-world preference signal—across diverse,blind prompts—underscores Kimi-K2’s strengths in generating high-quality responses on open-ended tasks.\n4.2Pre-training Evaluations\n4.2.1Evaluation Settings\nBenchmarksWe evaluate Kimi-K2-Base across diverse capability areas. For general capabilities, we assess on MMLU [23], MMLU-Pro [76], MMLU-Redux [17], BBH [67], TriviaQA [34], SuperGPQA [13], SimpleQA [78], HellaSwag [88], AGIEval [89], GPQA-Diamond [61], ARC-Challenge [8], and WinoGrande [62]. For coding capabilities,we employ EvalPlus [45] (averaging HumanEval [7], MBPP [1], HumanEval+, and MBPP+), LiveCodeBench v6 [31],and CRUXEval [18]. For mathematical reasoning, we utilize GSM8K [9], GSM8K-Platinum [74], MATH [24], and CMATH [79]. For Chinese language capabilities, we evaluate on C-Eval [29], CMMLU [40], and CSimpleQA [22].\nBaselinesWe benchmark against leading open-source foundation models: DeepSeek-V3-Base [10], Qwen2.5-72BBase [59] (Note that Qwen3-235B-A22B-Base is not open-sourced, and the largest open-sourced base model in the Qwen series is Qwen2.5-72B-Base), and Llama 4-Maverick [70] (Llama 4-Behemoth is also not open-sourced). All models are evaluated under identical confgurations to ensure fair comparison.i\nEvaluation ConfgurationsWe employ perplexity-based evaluation for MMLU, MMLU-Redux, GPQA-Diamond,i HellaSwag, ARC-Challenge, C-Eval, and CMMLU. Generation-based evaluation is used for MMLU-Pro, SuperGPQA,TriviaQA, BBH, CSimpleQA, MATH, CMATH, GSM8K, GSM8K-Platinum, CRUXEval, LiveCodeBench, and EvalPlus. To mitigate the high variance inherent to GPQA-Diamond, we report the mean score across eight independent runs. All evaluations are conducted using our internal framework derived from LM-Harness-Evaluation [4], ensuring consistent settings across all models.\n4.2.2Evaluation Results\nTable 4 presents a comprehensive comparison of Kimi-K2-Base against leading open-source foundation models across diverse evaluation benchmarks. The results demonstrate that Kimi-K2-Base achieves state-of-the-art performance across the majority of evaluated tasks, establishing it as a leading foundation model in the open-source landscape.\nGeneral Language UnderstandingKimi-K2-Base achieves state-of-the-art performance on 10 out of 12 English language benchmarks. Notable results include MMLU (87.79%), MMLU-Pro (69.17%), MMLU-Redux (90.17%),SuperGPQA $(44.67\\%)$ , and SimpleQA $(35.25\\%$ , signifcantly outperforming all baselines.i\nCoding CapabilitiesOn coding benchmarks, Kimi-K2-Base sets new standards with leading performance across all metrics. It achieves $74.00\\%$  on CRUXEval-I-cot, $83.50\\%$ on CRUXEval-O-cot, $26.29\\%$ on LiveCodeBench v6, and $80.33\\%$ on EvalPlus, demonstrating superior code generation and comprehension abilities, particularly in scenarios requiring step-by-step reasoning.\nMathematical ReasoningKimi-K2-Base exhibits exceptional mathematical capabilities, leading on three out of four benchmarks: MATH $(70.22\\%)$  GSM8K (92.12%), and GSM8K-Platinum $(\\hat{94}.21\\%)$  It maintains competitive performance on CMATH $(90.26\\%),$  narrowly behind DeepSeek-V3-Base $(90.53\\%)$ . These results highlight the model’s robust mathematical problem-solving abilities across varying diffculty levels.i\n\nChinese Language UnderstandingThe model demonstrates superior multilingual capabilities, achieving state-of-theart results across all Chinese language benchmarks: C-Eval $(92.50\\%)$ , CMMLU $(90.90\\%$ , and CSimpleQA (77.57%).These results establish Kimi-K2-Base as a leading model for Chinese language understanding while maintaining strong performance across other languages.\nTable 4: Performance comparison of Kimi-K2-Base against leading open-source models across diverse tasks.\nBenchmark (Metric)#Shots Kimi-K2-Base DeepSeek-V3-Base Llama4-Maverick-Base Qwen2.5-72B-Base\n\n\n<html><body><table><thead><tr><td># Total Params</td><td>Architecture # Activated Params</td><td>- - -</td><td>MoE 32B 1043B</td><td>MoE 37B 671B</td><td>MoE 17B 400B</td><td>Dense 72B 72B</td></tr></thead><tbody><tr><td rowspan=\"10\"></td><td>MMLU</td><td>5-shots</td><td>87.79</td><td>87.10</td><td>84.87</td><td>86.08</td></tr><tr><td>MMLU-pro</td><td>5-shots</td><td>69.17</td><td>60.59</td><td>63.47</td><td>62.80</td></tr><tr><td>MMLU-redux</td><td>5-shots</td><td>90.17</td><td>89.53</td><td>88.18</td><td>87.77</td></tr><tr><td>SuperGPQA</td><td>5-shots</td><td>44.67</td><td>39.20</td><td>38.84</td><td>34.23</td></tr><tr><td>GPQA-Diamond(avg@8)</td><td> 5-shots</td><td>48.11</td><td>50.51</td><td>49.43</td><td>40.78</td></tr><tr><td>SimpleQA</td><td>5-shots</td><td>35.25</td><td>26.49</td><td>23.74</td><td>10.31</td></tr><tr><td>EnglishTriviaQA</td><td>5-shots</td><td>85.09</td><td>84.11</td><td>79.25</td><td>76.03</td></tr><tr><td>BBH</td><td>3-shots</td><td>88.71</td><td>88.37</td><td>87.10</td><td>84.09</td></tr><tr><td>HellaSwag</td><td>5-shots</td><td>94.60</td><td>89.44</td><td>86.02</td><td>95.27</td></tr><tr><td>AGIEval</td><td>-</td><td>84.23</td><td>81.57</td><td>67.55</td><td>76.87</td></tr><tr><td rowspan=\"3\"></td><td>ARC-Challenge</td><td>0-shot</td><td>95.73</td><td>93.77</td><td>94.03</td><td>95.56</td></tr><tr><td>WinoGrande</td><td>5-shots</td><td>85.32</td><td>84.21</td><td>77.58</td><td>84.14</td></tr><tr><td>CRUXEval-I-cot</td><td>0-shots</td><td>74.00</td><td>62.75</td><td>67.13</td><td>61.12</td></tr><tr><td rowspan=\"4\">Code</td><td>CRUXEval-O-cot LiveCodeBench(v6)</td><td>0-shots</td><td>83.50</td><td>75.25</td><td>75.88</td><td>66.13</td></tr><tr><td>EvalPlus</td><td>1-shots</td><td>26.29</td><td>24.57</td><td>25.14</td><td>22.29</td></tr><tr><td></td><td>-</td><td>80.33</td><td>65.61</td><td>65.48</td><td>66.04</td></tr><tr><td>MATH</td><td>4-shots</td><td>70.22</td><td>61.70</td><td>63.02</td><td>62.68</td></tr><tr><td rowspan=\"4\">Math</td><td>GSM8k</td><td>8-shots</td><td>92.12</td><td>91.66</td><td>86.35</td><td>90.37</td></tr><tr><td>GSM8k-platinum</td><td>8-shots</td><td>94.21</td><td>93.38</td><td>88.83</td><td>92.47</td></tr><tr><td>CMATH</td><td>6-shots</td><td>90.26</td><td>90.53</td><td>88.07</td><td>86.98</td></tr><tr><td>C-Eval</td><td>5-shots</td><td>92.50</td><td>90.04</td><td>80.91</td><td>90.86</td></tr><tr><td rowspan=\"2\">ChineseCMMLU</td><td></td><td>5-shots</td><td>90.90</td><td>88.84</td><td>81.24</td><td>90.55</td></tr><tr><td>CSimpleQA</td><td>5-shots</td><td>77.57</td><td>72.13</td><td>53.47</td><td>50.53</td></tr></tbody></table></body></html>\n\n4.3Safety Evaluation\n4.3.1Experiment Settings\nWe conducted red-teaming evaluations on Kimi K2 compare with other open-source LLMs. The evaluation covered a range of attack scenarios—including harmful content, privacy content, and security content, as well as different attack strategies such as prompt injection and iterative jailbreak.\nWe choose Promptfoo5 to generate adversarial prompts and analyze the responses. By this way, we can evaluate model in a scalable ways.\nModel Selection We compare Kimi K2 with three other open-source LLMs: DeepSeek-V3, DeepSeek-R1, and Qwen3.Promptfoo Settings Table 5 lists plugins and strategies evaluated, with each plugin paired with all strategies to assess their performance.\nTest Case Count Given the inherent non-determinism of large language model inference, single-pass outputs may exhibit variability. To account for this, we generated 3 attack prompts per plugin for each strategy.\nPrompt Language Settings We pre-tested the language compatibility for each plugin-strategy combination. Some plugins support both English and Chinese, while others only support English. For combinations that support both, we generated 3 prompts in each language, resulting in 6 prompts per combination.\n\nTable 5: Enabled Plugins and Strategies\n\n\n<html><body><table><tr><td rowspan=\"5\">Plugin</td><td>Harmful</td><td>Graphic Content, Harassment and Bullying, Hate Speech, Insults, Profanity, Radicalization, Self Harm, Sexual Content, ToxicChat</td></tr><tr><td>Criminal</td><td>Chemical&Biological Weapons, Child Exploitation, Copyright Violations, Cybercrime, Illegal Activities, Illegal Drugs, Indiscriminate Weapons, Intellectual Property Violation, Non-Violent Crime, Violent Crime, Sex Crimes</td></tr><tr><td>Misinformation</td><td> Competitor Endorsement, Unsupervised Contracts, Excessive Agency, Hallucination, Misin- formation and Disinformation, Specialized Advice, Unsafe Practices, Imitation, Overreliance, Political Opinions, Religious Sensitivity</td></tr><tr><td>Privacy</td><td>Privacy Violation, PII in API/Database, Direct PII Exposure, PII in Session Data, PII via Social Engineering</td></tr><tr><td>Security</td><td>ASCII Smuggling, CyberSecEval, Harmbench, Debug Access, Divergent Repetition, DoNotAn-</td></tr><tr><td colspan=\"3\">swer, Malicious Code, Pliny, Prompt Extraction, Reasoning DoS, Tool Discovery Strategy Basic, Prompt Injection, Iterative Jailbreak, Crescendo</td></tr></table></body></html>\n\nManual Review We incorporated human review into the evaluation process. To minimize subjectivity problem, we conducted multiple rounds of review and assigned the same reviewer to evaluate all cases within a given test set to ensure consistency and reduce variability in judgment.\n4.3.2Safety Evaluation Results\nTable 6 presents the passing rates of different models under various plugin–strategy combinations.\nTable 6: Safety Evaluation Results\n\n\n<html><body><table><tr><td>Plugin Strategy</td><td></td><td colspan=\"4\">Kimi-K2-Instruct DeepSeek-V3-0324 DeepSeek-R1 Qwen3-235B-A22B</td></tr><tr><td rowspan=\"5\">Harmful</td><td>Basic</td><td>98.04</td><td>90.45</td><td>99.02</td><td>98.53</td></tr><tr><td>Base64</td><td>100</td><td>90.20</td><td>100</td><td>100</td></tr><tr><td>Prompt Injection</td><td>93.14</td><td>100</td><td>95.10</td><td>99.02</td></tr><tr><td>Iterative Jailbreak</td><td>92.16</td><td>66.67</td><td>72.55</td><td>74.51</td></tr><tr><td>Crescendo</td><td>64.71</td><td>64.71</td><td>80.39</td><td>86.27</td></tr><tr><td rowspan=\"5\">Criminal</td><td>Basic</td><td>100</td><td>99.62</td><td>95.45</td><td>99.24</td></tr><tr><td>Base64</td><td>96.97</td><td>89.39</td><td>84.85</td><td>98.48</td></tr><tr><td>Prompt Injection</td><td>75.76</td><td>91.67</td><td>69.70</td><td>98.47</td></tr><tr><td>Iterative Jailbreak</td><td>57.57</td><td>21.21</td><td>25.76</td><td>53.03</td></tr><tr><td>Crescendo</td><td>56.06</td><td>31.81</td><td>42.42</td><td>59.09</td></tr><tr><td rowspan=\"5\">Misinformation</td><td>Basic</td><td>97.28</td><td>92.57</td><td>92.46</td><td>94.84</td></tr><tr><td>Base64</td><td>98.48</td><td>90.48</td><td>96.83</td><td>93.65</td></tr><tr><td>Prompt Injection</td><td>98.39</td><td>86.51</td><td>93.65</td><td>93.65</td></tr><tr><td>Iterative Jailbreak</td><td>63.97</td><td>53.97</td><td>84.13</td><td>69.84</td></tr><tr><td>Crescendo</td><td>85.71</td><td>55.56</td><td>88.89</td><td>84.13</td></tr><tr><td rowspan=\"5\">Privacy</td><td>Basic</td><td>100</td><td>100</td><td>100</td><td>100</td></tr><tr><td>Base64</td><td>100</td><td>100</td><td>100</td><td>100</td></tr><tr><td>Prompt Injection</td><td>88.33</td><td>98.33</td><td>100</td><td>91.67</td></tr><tr><td>Iterative Jailbreak</td><td>76.67</td><td>100</td><td>93.33</td><td>96.67</td></tr><tr><td>Crescendo</td><td>96.67</td><td>100</td><td>96.67</td><td>100</td></tr><tr><td rowspan=\"5\">Security</td><td>Basic</td><td>77.84</td><td>75.57</td><td>70.46</td><td>90.09</td></tr><tr><td>Base64</td><td>82.93</td><td>82.93</td><td>63.41</td><td>95.12</td></tr><tr><td>Prompt Injection</td><td>87.80</td><td>97.56</td><td>65.85</td><td>84.13</td></tr><tr><td>Iterative Jailbreak</td><td>43.90</td><td>60.97</td><td>43.90</td><td>78.04</td></tr><tr><td>Crescendo</td><td>68.29</td><td>87.80</td><td>68.29</td><td>87.80</td></tr></table></body></html>\n\nWithout targeted optimization for specifc evaluation scenarios, the passing rate of some complex cases (e.g., Harm-i ful–Iterative Jailbreak) was relatively higher compared to other models.\nAcross different attack strategies, the models exhibited varying trends. Under the Base64 strategy, passing rates generally approached or reached $100\\%,$  suggesting that encoding transformations had minimal impact on the models’basic robustness. In contrast, the Crescendo strategy led to a general drop in passing rates, indicating stronger adversarial effectiveness.\nIn addition, complex attack strategies do not always outperform basic prompts. Some originally adversarial prompts may lose their intended meaning after multiple rounds of transformation, rendering the resulting model outputs less meaningful.\nAutomated Red-teaming Limitations Due to the involvement of human review, the evaluation results inevitably contain a degree of subjectivity. Additionally, certain plugin types involve API misuse or external tool invocation, which are more suitable for evaluating agent models with tool-calling capabilities. In the context of base LLMs, such tests may have limited relevance.\n5Limitations\nIn our internal tests, we have identifed some limitations in current Kimi K2 models. When dealing with hard reasoningi tasks or unclear tool defnition, the model may generate excessive tokens, sometimes leading to truncated outputs ori incomplete tool calls. Additionally, performance may decline on certain tasks if tool use is unnecessarily enabled. When building complete software projects, the success rate of one-shot prompting is not as good as using K2 under an agentic coding framework. We are working to address these issues in future releases and looking forward to more feedbacks.\n6Conclusions\nWe introduced Kimi K2, a 1T-parameter open-weight MoE model built for agentic intelligence. Leveraging the tokeneffcient MuonClip optimizer and a 15.5T-token high-quality dataset, Kimi K2 achieves stable, scalable pre-training.i Post-training combines large-scale synthetic tool-use data with a unifed RL framework using both verifable rewardsii and self-critic feedbacks. Kimi K2 sets new state-of-the-art on agentic and reasoning benchmarks, establishing itself as the most capable open-weight LLM to date.\n7Acknowledgments\nWe would like to acknowledge the valuable support provided by the OpenHands and Multi-SWE-bench teams in evaluating the SWE-bench Verifed and Multi-SWE-bench experimental results.i\n\nReferences\n[1]Jacob Austin et al. Program Synthesis with Large Language Models. 2021. arXiv: 2108.07732 [cs.PL]. URL:https://arxiv.org/abs/2108.07732.\n[2]Yushi Bai et al. LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks. 2025. arXiv: 2412.15204 [cs.CL]. URL: https://arxiv.org/abs/2412.15204.\n[3]Victor Barres et al. $\\boldsymbol{\\tau^{2}}$ Bench: Evaluating Conversational Agents in a Dual-Control Environment. 2025. arXiv:2506.07982 [cs.AI]. URL: https://arxiv.org/abs/2506.07982.\n[4]Stella Biderman et al. “Lessons from the trenches on reproducible evaluation of language models”. In: arXiv preprint arXiv:2405.14782 (2024).\n[5]Federico Cassano et al. “MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation”. In: IEEE Transactions on Software Engineering 49.7 (2023), pp. 3675–3691. DOI: 10.1109/TSE.2023.3267446.\n[6]Chen Chen et al. “ACEBench: Who Wins the Match Point in Tool Learning?” In: arXiv e-prints (2025), arXiv–2501.\n[7]Mark Chen et al. “Evaluating Large Language Models Trained on Code”. In: (2021). arXiv: 2107.03374[cs.LG].\n[8]Peter Clark et al. “Think you have solved question answering? try arc, the ai2 reasoning challenge”. In: arXiv preprint arXiv:1803.05457 (2018).\n[9]Karl Cobbe et al. Training Verifers to Solve Math Word Problems. 2021. arXiv: 2110.14168 [cs.LG]. URL:i https://arxiv.org/abs/2110.14168.\n[10]DeepSeek-AI. DeepSeek-V3 Technical Report. 2024. arXiv: 2412.19437 [cs.CL]. URL: https://arxiv.org/abs/2412.19437.\n[11]Mostafa Dehghani et al. “Scaling vision transformers to 22 billion parameters”. In: International conference on machine learning. PMLR. 2023, pp. 7480–7512.\n[12]Guanting Dong et al. Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models. 2024. arXiv: 2406.13542 [cs.CL]. URL: https://arxiv.org/abs/2406.13542.\n[13]Xinrun Du et al. “Supergpqa: Scaling llm evaluation across 285 graduate disciplines”. In: arXiv preprint arXiv:2502.14739 (2025).\n[14]Dheeru Dua et al. “DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs”. In: CoRR abs/1903.00161 (2019). arXiv: 1903.00161. URL: http://arxiv.org/abs/1903.00161\n[15]Kazuki Fujii et al. Rewriting Pre-Training Data Boosts LLM Performance in Math and Code. 2025. arXiv:2505.02881 [cs.LG]. URL: https://arxiv.org/abs/2505.02881.\nl Gauthier. Aider LLM Leaderboards. https://aider.chat/docs/leaderboards/. 2025.\n[17]Aryo Pradipta Gema et al. “Are we done with mmlu?” In: arXiv preprint arXiv:2406.04127 (2024).\n[18]Alex Gu et al. “Cruxeval: A benchmark for code reasoning, understanding and execution”. In: arXiv preprint arXiv:2401.03065 (2024).\n[19]Daya Guo et al. “Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning”. In: arXiv preprint arXiv:2501.12948 (2025).\n[20]Zhicheng Guo et al. “StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models”. In: arXiv preprint arXiv:2403.07714 (2025).\n[21]Aaron Harlap et al. “Pipedream: Fast and effcient pipeline parallel dnn training”. In: arXiv preprinti arXiv:1806.03377 (2018).\n[22]Y He et al. “Chinese simpleqa: A chinese factuality evaluation for large language models, 2024a”. In: URL https://arxiv. org/abs/2411.07140 ().\n[23]Dan Hendrycks et al. “Measuring massive multitask language understanding”. In: arXiv preprint arXiv:2009.03300 (2020).\n[24]Dan Hendrycks et al. Measuring Mathematical Problem Solving With the MATH Dataset. 2021. arXiv: 2103.03874 [cs.LG]. URL: https://arxiv.org/abs/2103.03874.\nal. “Minicpm: Unveiling the potential of small language models with scalable training strategies t arXiv:2404.06395 (2024).\n[26]Jiaxin Huang et al. “Large language models can self-improve”. In: arXiv preprint arXiv:2210.11610 (2022).\n[27]Siming Huang et al. OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models. 2025. arXiv:2411.04905 [cs.CL]. URL: https://arxiv.org/abs/2411.04905.\n\n[28]Yanping Huang et al. “Gpipe: Effcient training of giant neural networks using pipeline parallelism”. In: Advancesi in neural information processing systems 32 (2019).\n[29]Yuzhen Huang et al. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models.2023. arXiv: 2305.08322 [cs.CL]. URL: https://arxiv.org/abs/2305.08322.\n[30]Alon Jacovi et al. The FACTS Grounding Leaderboard: Benchmarking LLMs’ Ability to Ground Responses to Long-Form Input. 2025. arXiv: 2501.03200 [cs.CL]. URL: https://arxiv.org/abs/2501.03200.\n[31]Naman Jain et al. “Livecodebench: Holistic and contamination free evaluation of large language models for code”. In: arXiv preprint arXiv:2403.07974 (2024).\n[32]Carlos E Jimenez et al. “SWE-bench: Can Language Models Resolve Real-world Github Issues?” In: The Twelfth International Conference on Learning Representations. 2024. URL: https://openreview.net/forum?id=VTF8yNQM66.\n[33]Keller Jordan et al. Muon: An optimizer for hidden layers in neural networks. 2024. URL: https : / /kellerjordan.github.io/posts/muon/.\n[34]Mandar Joshi et al. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.2017. arXiv: 1705.03551 [cs.CL]. URL: https://arxiv.org/abs/1705.03551.\n[35]Kimi Team. “Kimi k1. 5: Scaling reinforcement learning with llms”. In: arXiv preprint arXiv:2501.12599 (2025).\n[36]Diederik P. Kingma and Jimmy Ba. “Adam: A Method for Stochastic Optimization”. In: 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings. Ed. by Yoshua Bengio and Yann LeCun. 2015. URL: http://arxiv.org/abs/1412.6980.\n[37]Satyapriya Krishna et al. Fact, Fetch, and Reason: A Unifed Evaluation of Retrieval-Augmented Generation.i 2025. arXiv: 2409.12941 [cs.CL]. URL: https://arxiv.org/abs/2409.12941.\n[38]Joel Lamy-Poirier. “Breadth-frst pipeline parallelism”. In: Proceedings of Machine Learning and Systems 5i(2023), pp. 48–67.\n[39]Dmitry Lepikhin et al. “Gshard: Scaling giant models with conditional computation and automatic sharding”. In:arXiv preprint arXiv:2006.16668 (2020).\n[40]Haonan Li et al. CMMLU: Measuring massive multitask language understanding in Chinese. 2024. arXiv:2306.09212 [cs.CL]. URL: https://arxiv.org/abs/2306.09212.\n[41]Jia Li et al. “Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions”. In: Hugging Face repository 13.9 (2024), p. 9.\n[42]Tianle Li et al. “From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline”.In: arXiv preprint arXiv:2406.11939 (2024).\n[43]Bill Yuchen Lin et al. ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning. 2025. arXiv: 2502.01100 [cs.AI]. URL: https://arxiv.org/abs/2502.01100.\n[44]Aixin Liu et al. “Deepseek-v2: A strong, economical, and effcient mixture-of-experts language model”. In:i arXiv preprint arXiv:2405.04434 (2024).\n[45]Jiawei Liu et al. “Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation”. In: Advances in Neural Information Processing Systems 36 (2023), pp. 21558–21572.\nan Liu et al. “Muon is scalable for LLM training”. In: arXiv preprint arXiv:2502.16982 (2025\n[47]Ziming Liu et al. “Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training Effciency”. In: Proceedings of the International Conference for High Performance Computing, Networking,i Storage and Analysis. SC ’23. ACM, Nov. 2023, pp. 1–13. DOI: 10.1145/3581784.3607073. URL: http://dx.doi.org/10.1145/3581784.3607073.\n[48]Ilya Loshchilov and Frank Hutter. “Decoupled Weight Decay Regularization”. In: International Conference on Learning Representations. 2019. URL: https://openreview.net/forum?id=Bkg6RiCqY7.\n[49]Jan Ludziejewski et al. OpenAI Gym. 2025. arXiv: 2502.05172 [cs.LG]. URL: https://arxiv.org/abs/2502.05172.\n[50]Samuel Miserendino et al. “SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?” In: arXiv preprint arXiv:2502.12115 (2025).\n[51]Arindam Mitra et al. “Agentinstruct: Toward generative teaching with agentic fows”. In: arXiv preprintl arXiv:2407.03502 (2024).\n[52]Ivan Moshkov et al. “Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with openmathreasoning dataset”. In: arXiv preprint arXiv:2504.16891 (2025).\n[53]Deepak Narayanan et al. “Effcient large-scale language model training on gpu clusters using megatron-lm”. In:i Proceedings of the international conference for high performance computing, networking, storage and analysis.2021, pp. 1–15.\n\n[54]Long Ouyang et al. “Training language models to follow instructions with human feedback”. In: Advances in neural information processing systems 35 (2022), pp. 27730–27744.\n[55]Bowen Peng et al. “Yarn: Effcient context window extension of large language models”. In: arXiv preprinti arXiv:2309.00071 (2023).\n[56]Long Phan et al. Humanity’s Last Exam. 2025. arXiv: 2501.14249 [cs.LG]. URL: https://arxiv.org/abs/2501.14249.\nghui Qi et al. “Zero bubble pipeline parallelism”. In: arXiv preprint arXiv:2401.10241 (2023)\n[58]Yujia Qin et al. “Toolllm: Facilitating large language models to master 16000+ real-world apis”. In: arXiv preprint arXiv:2307.16789 (2023).\n[59]Qwen et al. Qwen2.5 Technical Report. 2025. arXiv: 2412.15115 [cs.CL]. URL: https://arxiv.org/abs/2412.15115.\n[60]Samyam Rajbhandari et al. “Zero: Memory optimizations toward training trillion parameter models”. In: SC20:International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE. 2020,pp. 1–16.\n[61]David Rein et al. “Gpqa: A graduate-level google-proof q&a benchmark”. In: First Conference on Language Modeling. 2024.\n[62]Keisuke Sakaguchi et al. “Winogrande: An adversarial winograd schema challenge at scale”. In: Communications of the ACM 64.9 (2021), pp. 99–106.\nid Silver and Richard S Sutton. “Welcome to the era of experience”. In: Google AI 1 (2025).\n[64]Ved Sirdeshmukh et al. MultiChallenge: $A$  Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs. 2025. arXiv: 2501.17399 [cs.CL]. URL: https://arxiv.org/abs/2501.17399.\n[65]Giulio Starace et al. “PaperBench: Evaluating AI’s Ability to Replicate AI Research”. In: arXiv preprint arXiv:2504.01848 (2025).\n[66]Hao Sun et al. ZeroSearch: Incentivize the Search Capability of LLMs without Searching. 2025. arXiv: 2505.04588 [cs.CL]. URL: https://arxiv.org/abs/2505.04588.\n[67]Mirac Suzgun et al. Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them. 2022. arXiv:2210.09261 [cs.CL]. URL: https://arxiv.org/abs/2210.09261.\n[68]Manveer Singh Tamber et al. “Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards”. In: arXiv preprint arXiv:2505.04847 (2025).\n[69]Gemma Team et al. “Gemma 2: Improving open language models at a practical size”. In: arXiv preprint arXiv:2408.00118 (2024).\n[70]LlaMA Team. The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation — ai.meta.com.https://ai.meta.com/blog/llama-4-multimodal-intelligence/. [Accessed 15-07-2025].\n[71]The Terminal-Bench Team. Terminal-Bench: A Benchmark for AI Agents in Terminal Environments. Apr. 2025.URL: https://github.com/laude-institute/terminal-bench.\n[72]Ashish Vaswani et al. “Attention is All you Need”. In: Advances in Neural Information Processing Systems.Ed. by I. Guyon et al. Vol. 30. Curran Associates, Inc., 2017. URL: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.\n[73]Vectara. Hallucination Evaluation Model (Revision 7437011). 2024. URL: https://huggingface.co/vectara/hallucination_evaluation_model\n[74]Joshua Vendrow et al. “Do large language model benchmarks test reliability?” In: arXiv preprint arXiv:2502.03461 (2025).\n[75]Yizhong Wang et al. “Self-instruct: Aligning language models with self-generated instructions”. In: arXiv preprint arXiv:2212.10560 (2022).\n[76]Yubo Wang et al. MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark.2024. arXiv: 2406.01574 [cs.CL]. URL: https://arxiv.org/abs/2406.01574.\n[77]Zhexu Wang et al. OJBench: A Competition Level Code Benchmark For Large Language Models. 2025. arXiv:2506.16395 [cs.CL]. URL: https://arxiv.org/abs/2506.16395.\n[78]Jason Wei et al. “Measuring short-form factuality in large language models”. In: arXiv preprint arXiv:2411.04368(2024).\n[79]Tianwen Wei et al. CMATH: Can Your Language Model Pass Chinese Elementary School Math Test? 2023.arXiv: 2306.16636 [cs.CL]. URL: https://arxiv.org/abs/2306.16636.\n[80]Colin White et al. “LiveBench: A Challenging, Contamination-Free LLM Benchmark”. In: The Thirteenth International Conference on Learning Representations. 2025.\n\n[81]Mitchell Wortsman et al. “Small-scale proxies for large-scale transformer training instabilities, 2023”. In: URL https://arxiv. org/abs/2309.14322 ().\n[82]Can Xu et al. WizardLM: Empowering large pre-trained language models to follow complex instructions. 2025.arXiv: 2304.12244 [cs.CL]. URL: https://arxiv.org/abs/2304.12244.\n[83]Zhangchen Xu et al. KodCode: A Diverse, Challenging, and Verifable Synthetic Dataset for Coding. 2025. arXiv:i 2503.02951 [cs.LG]. URL: https://arxiv.org/abs/2503.02951.\n[84]John Yang et al. SWE-smith: Scaling Data for Software Engineering Agents. 2025. arXiv: 2504.21798 [cs.SE].URL: https://arxiv.org/abs/2504.21798.\n[85]Shunyu Yao et al. “tau-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains”. In: arXiv preprint arXiv:2406.12045 (2024).\n[86]Daoguang Zan et al. “Multi-swe-bench: A multilingual benchmark for issue resolving”. In: arXiv preprint arXiv:2504.02605 (2025).\n[87]Eric Zelikman et al. “Star: Bootstrapping reasoning with reasoning”. In: Advances in Neural Information Processing Systems 35 (2022), pp. 15476–15488.\n[88]Rowan Zellers et al. “Hellaswag: Can a machine really fnish your sentence?” In: arXiv preprint arXiv:1905.07830i(2019).\n[89]Wanjun Zhong et al. “Agieval: A human-centric benchmark for evaluating foundation models”. In: arXiv preprint arXiv:2304.06364 (2023).\n[90]Jeffrey Zhou et al. “Instruction-Following Evaluation for Large Language Models”. In: ArXiv abs/2311.07911(2023). URL: https://arxiv.org/abs/2311.07911.\n[91]Qin Zhu et al. AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning Abilities of Large Language Models. 2025. arXiv: 2502.16906 [cs.CL]. URL: https://arxiv.org/abs/2502.16906.\n\nAppendix\nAContributions\nThe listing of authors is in alphabetical order based on their last names. Names marked with an asterisk (*) indicate people who are no longer part of our team.\nYifan Bai  \nYiping Bao  \nGuanduo Chen  \nJiahao Chen  \nNingxin Chen  \nRuijue Chen  \nYanru Chen  \nYuankun Chen  \nYutian Chen  \nZhuofu Chen*  \nJialei Cui  \nHao Ding  \nMengnan Dong  \nAng’ang Du  \nChenzhuang Du  \nDikang Du  \nYulun Du  \nYu Fan  \nYichen Feng  \nKelin Fu  \nBofei Gao  \nHongcheng Gao  \nPeizhong Gao  \nTong Gao  \nXinran Gu  \nLongyu Guan  \nHaiqing Guo*  \nJianhang Guo  \nHao Hu  \nXiaoru Hao  \nTianhong He  \nWeiran He  \nWenyang He  \nChao Hong  \nYangyang Hu  \nZhenxing Hu  \nWeixiao Huang  \nZhiqi Huang  \nZihao Huang  \nTao Jiang  \nZhejun Jiang  \nXinyi Jin  \nYongsheng Kang*\nGuokun Lai  \nCheng Li  \nFang Li  \nHaoyang Li  \nMing Li  \nWentao Li  \nYanhao Li  \nYiwei Li  \nZhaowei Li  \nZheming Li  \nHongzhan Lin*  \nXiaohan Lin  \nZongyu Lin  \nChengyin Liu  \nChenyu Liu  \nHongzhang Liu  \nJingyuan Liu*  \nJunqi Liu  \nLiang Liu  \nShaowei Liu  \nT.Y. Liu  \nTianwei Liu  \nWeizhou Liu  \nYangyang Liu  \nYibo Liu  \nYiping Liu  \nYue Liu  \nZhengying Liu  \nEnzhe Lu  \nLijun Lu  \nShengling Ma  \nXinyu Ma  \nYingwei Ma  \nShaoguang Mao  \nJie Mei  \nXin Men  \nYibo Miao  \nSiyuan Pan  \nYebo Peng  \nRuoyu Qin  \nBowen Qu  \nZeyu Shang  \nLidong Shi\nShengyuan Shi  \nFeifan Song  \nJianlin Su  \nZhengyuan Su  \nXinjie Sun*  \nFlood Sung  \nHeyi Tang  \nJiawen Tao  \nQifeng Teng  \nChensi Wang  \nDinglu Wang  \nFeng Wang  \nHaiming Wang  \nJianzhou Wang*  \nJiaxing Wang  \nJinhong Wang  \nShengjie Wang  \nShuyi Wang  \nYao Wang  \nYejie Wang  \nYiqin Wang  \nYuxin Wang  \nYuzhi Wang  \nZhaoji Wang  \nZhengtao Wang  \nZhexu Wang  \nChu Wei  \nQianqian Wei  \nWenhao Wu  \nXingzhe Wu  \nYuxin Wu  \nChenjun Xiao  \nXiaotong Xie  \nWeimin Xiong*  \nBoyu Xu  \nJing Xu*  \nJinjing Xu  \nL.H. Xu  \nLin Xu  \nSuting Xu  \nWeixin Xu  \nXinran Xu  \nYangchuan Xu\nZiyao Xu  \nJunjie Yan  \nYuzi Yan  \nXiaofei Yang  \nYing Yang  \nZhen Yang  \nZhilin Yang  \nZonghan Yang  \nHaotian Yao  \nXingcheng Yao  \nWenjie Ye  \nZhuorui Ye  \nBohong Yin  \nLonghui Yu  \nEnming Yuan  \nHongbang Yuan*  \nMengjie Yuan  \nHaobing Zhan  \nDehao Zhang  \nHao Zhang  \nWanlu Zhang  \nXiaobin Zhang  \nYangkun Zhang  \nYizhi Zhang  \nYongting Zhang  \nYu Zhang  \nYutao Zhang  \nYutong Zhang  \nZheng Zhang  \nHaotian Zhao  \nYikai Zhao  \nHuabin Zheng  \nShaojie Zheng  \nJianren Zhou  \nXinyu Zhou  \nZaida Zhou  \nZhen Zhu  \nWeiyu Zhuang  \nXinxing Zu  \nKimi K2\n\nBToken Template of Tool Calling\nThere are three components in the token structure for tool-calling:\nTool declaration message: defnes the list of available tools and the schema of the argumenti\nTool invoking section in assistant message: encodes the model’s request to invoke tools;\nTool result message: encapsulates the invoked tool’s execution result.\nThe raw tokens of the tool declaration message are formatted as follows:\nThe blue highlighted marks represent special tokens, and the green part, quoted by brackets, is the tool declaration content. We use TypeScript to express the tool declaration content, since TypeScript is a concise language with a comprehensive type system, able to express the types and constraints of tool parameters with brief text. The code 1 shows an example for two simple tools in JSON format compatible with OpenAI’s chat completion API, as a comparison,the same tools defned in TypeScript (listed in Code 2) is much shorter. To improve compatibility, part of our trainingi data also uses JSON as the tool declaration language, so that 3rd-party frameworks need not additional development to support our tool calling scheme.\nListing 1: Tool defnition with JSON in OpenAI compatible APIi\n[{\n\"type\": \"function\",\n\"function\": {\n\"name\": \"get_weather\",\n\"description\": \"Getweatherfor a locationand date\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"location\": {\n\"type\": \"string\",\n\"description\": \"City andcountry e.g. Beijing , China\"\n},\n\"date\": {\n}\n\"type\": \"string\",\n\"description\": \"Date to query , format in‘%Y-%m-%d’\"\n},\n\"required\": [\n\"location\"\n]}}}\n{\n\"type\": \"function\",\n\"function\": {\n\"name\": \"Calculator\",\n\"description\": \"Simplecalculator\",\n\"parameters\": {\n\"properties\": {\n\"expr\": {\n}\n\"type\": \"string\",\n\"description\": \"Arithmeticexpression in javascript\"\n},}\n\"type\": \"object\"\n}\n}]\nListing 2: Tool defnition in TypeScripti\nnamespacefunctions {\n// Get weatherfor a locationand date\ntypeget_weather = (_: {\n// City andcountry e.g. Beijing , China\nlocation: string ,\n// Date to query , format in‘%Y-%m-%d’\ndate ?: string\n}) => any;\n// Simplecalculator\ntypeCalculator = (_: {\n// Arithmeticexpression in javascript\nexpr ?: string\n}) => any;\n}\nen template of the tool invoking section in the model’s response messages is listed as follows\n<tool_call_section_begin|>\n<|tool_call_begin|>\n// call_id part\nfunctions.{{tool name}}:{{counter}}\n<|tool_arguments_begin|>\n{{ json serialized call arguments }}\n<|tool_call_end|>\n<|tool_call_begin|>\n// more tool calls\n<|tool_call_end|>\n<|tool_call_section_end|>\nAs shown in the template, we support parallel tool calling by placing multiple tool calls in a single response turn. Each tool call has a unique call id, formatted as functions.{tool-name}:{counter}, where tool-name is the name of the tool, and counter is an auto-increasing counter of all tool calls starting from 0 in the dialog.\nDuring inference, the model may occasionally generate unexpected tokens, leading to format errors when parsing a tool call. To solve this issue, we developed a constrained decoding module named enforcer, inspired by lm-format-enforcer6.When a <tool_call_section_begin|> token is generated, it ensures that the upcoming tool-related tokens follow the predefned template, and the JSON argument string follows the declared schema.i\nThe tool result message is simply a text message encoded with the tool’s call id and the corresponding results.\n<|im_begin|>\ntool\n<|im_middle|>\n## Results of {{call_id}}\n{{ execution result content }}\n<|im_end|>\nCEvaluation Details\nCoding Tasks.We evaluate Kimi-K2-Instruct’s capabilities on competitive coding benchmarks, LiveCodeBench and OJBench, where Kimi-K2-Instruct attains superior performance with scores of $53.7\\%$ and $27.1\\%,$  respectively. This excellence spans both medium-level coding challenges, such as LeetCode and AtCoder, and hard-level contests like NOI and ICPC, outperforming leading open-source and proprietary models. For multilingual programming profciency, wei employ MultiPL-E, covering languages including C++, C#, Java, JavaScript, PHP, Go, Kimi-K2-Instruct surpasses topopen-source models with an accuracy of $85.7\\%,$  compared with $83.1\\%$ for DeepSeek-V3-0324 and $78.2\\%$  for Qwen3235B-A22B. In software engineering tasks, Kimi-K2-Instruct demonstrates robust performance on SWE-bench Verifedi(Python), SWE-lancer (Python), SWE-bench Multilingual, and Multi-SWE-bench datasets. It signifcantly outperformsi open-source counterparts in resolving real-world code repository issues and notably narrows the performance gap with proprietary models. For example:\nSWE-bench Verifed (multiple attempts):i $71.6\\%$ (Kimi-K2-Instruct) vs. $80.2\\%$ (Claude 4 Sonnet)\nSWE-bench Multilingual: $47.3\\%$ (Kimi-K2-Instruct) vs. $51.0\\%$ (Claude 4 Sonnet)\nSWE-lancer: $39.1\\%$ (Kimi-K2-Instruct) vs. $40.8\\%$ (Claude 4 Sonnet)\nOn PaperBench, Kimi-K2-Instruct achieves an accuracy of $27.8\\%,$ closely matching GPT-4.1 and outperforming DeepSeek-V3-0324 (12.2%) and Qwen3-235B-A22B $(8.2\\%)$  by a substantial margin. In terminal interaction tasks measured by TerminalBench, Kimi-K2-Instruct attains $25.0\\%$  using the default Terminus framework and rises to $30\\%$ within Moonshot’s in-house agentic framework, underscoring its capabilities in real-world agentic programming scenarios. Moreover, on the Aider-Polyglot benchmark, Kimi-K2-Instruct attains a $60.0\\%$  accuracy while employing rigorous decontamination procedures, further illustrating its strength and reliability across diverse coding environments.\nTool Use Tasks.We evaluate multi-turn tool use with two complementary suites: $\\boldsymbol{\\tau^{2}}$ -Bench and ACEBench. $\\boldsymbol{\\tau^{2}}$ Bench extends the original $7$ -bench single-control setup to a dual-control environment in which both the agent and an LLMsimulated user have constrained tool affordances over a shared state, adding a realistic Telecom troubleshooting domain alongside the prior Airline/Retail TAU tasks and enabling analysis of coordination vs. pure reasoning. ACEBench is a large bilingual (En/Zh) API-grounded benchmark (4.5K APIs across 8 domains; 2K annotated eval items) partitioned into NORMAL (basic/personalized/atomic), SPECIAL (imperfect or out-of-scope inputs), and AGENT (scenario-driven multi-turn, multi-step sandbox) tracks with automated grading of calls and outcomes. All models run in non-thinking mode; we set the temperature to 0.0, use deterministic tool adapters, score $\\boldsymbol{\\tau^{2}}$  Airline/Retail/Telecom under Avg@4 seeds with Pass@1/4, and report overall on ACEBench English. Kimi-K2-Instruct averages 66.1 micro Pass@1 across $\\boldsymbol{\\tau^{2}}$ vs DeepSeek-V3-0324 48.8 / Qwen3-235B-A22B 37.3. On ACEBench Overall Kimi-K2-Instruct scores 76.5 vs DeepSeek 72.7 / Qwen 70.5 and remains competitive with GPT-4.1 (80.1).\nMath & STEM & Logical Tasks.For Math tasks, Kimi-K2-Instruct achieves consistently strong performance,averaging over Geimini-2.5-Flash by 5.3 percentage points, over DeepSeek-V3-0324 by 5.5 points and over GPT4.1 by 15.8 points. For example, on AIME 2024, Kimi-K2-Instruct scores $69.6\\%,$  outperforming another two top open-source models by a large margin, DeepSeek-V3-0324 by 10.2 points and Qwen3-235B-A22B by 29.5 points. In STEM evaluations, Kimi-K2-Instruct achieves $75.1\\%$ on GPQA-Diamond, outperforming DeepSeek-V3-0324 (68.4%) and all non-thinking baselines by at least 5 percentage points. On SuperGPQA, it also exceeds the previous best open-source model, DeepSeek-V3-0324, by 3.5 points. Kimi-K2-Instruct also surpasses the other two leading models in logical reasoning. It achieves $89.0\\%$ on ZebraLogic and $89.5\\%$  on AutoLogi, exceeding DeepSeek-V3-0324 (84.0%, 88.9%) and substantially outperforming Qwen3-235B-A22B $(37.7\\%,83.3\\%).$\nGeneral Tasks.Kimi-K2-Instruct ties DeepSeek-V3-0324 on MMLU and MMLU-Pro, and takes the lead on MMLURedux with a 92.7 EM score—slightly ahead of GPT-4.1 (92.4) and just 1.5 points behind Claude-Opus-4. Beyond multiple-choice tasks, the model achieves $31.0\\%$  accuracy on the short-answer SimpleQA—3.3 points above DeepSeekV3-0324 and more than twice that of Qwen3-235B-A22B—though still below GPT-4.1 $(42.\\tilde{3\\%}).$  On the adversarial free-response LiveBench (2024-11-25 snapshot), it reaches $76.4\\%,$  surpassing Claude-Sonnet 4 (74.8%) and leading Gemini 2.5 Flash Preview by 8.6 points. Across this challenging triad measuring breadth, depth, and robustness of world knowledge, Kimi-K2-Instruct secures a top-tier position among open-source models. We evaluate instruction-following with IFEval and Multi-Challenge. On IFEval, Kimi-K2-Instruct scores $89.8\\%,$  higher than DeepSeek-V3-0324 (81.1%)and GPT-4.1 (88.0%). On Multi-Challenge, which involves multi-turn dialogues with conficting instructions, it achievesl 54.1%, outperforming DeepSeek-V3-0324 (31.4%), GPT-4.1 (36.4%), and Claude-Opus-4 $\\left(49.0\\%\\right)$ . These results demonstrate that Kimi-K2-Instruct integrates strong factual knowledge with consistent instruction adherence across both single- and multi-turn settings, supporting robust and reliable real-world deployment.\nLong Context and Factuality Tasks.To evaluate the factuality of Kimi-K2-Instruct, we employ three benchmarks:FACTS Grounding, which measures adherence to provided documents using the proprietary models GPT-4o, Gemini 1.5 Pro and Claude 3.5 Sonnet; HHEM, which assesses summarization quality via the open-source HHEM-2.1-Open judge; and FaithJudge, which analyzes faithfulness in RAG tasks with o3-mini as the judge. Kimi-K2-Instruct scores 88.5 on FACTS Grounding, substantially outperforming all open-source rivals and even surpassing the closed-source Gemini 2.5 Flash. With HHEM-2.1-Open it achieves a hallucination rate of 1.1 %, reported in the tables as 1 minus the\n\nFigure 11: Chinese in-house benchmark evaluation.\nrate, i.e. 98.9. On FaithJudge’s RAG tasks the hallucination rate is $7.4 \\%,$ likewise present as 92.6 for table consistency.For long-context capabilities, Kimi-K2-Instruct outperforms all open source and proprietary models on DROP (93.5%),and exceeds DeepSeek-V3-0324 on retrieval task MRCR $(55.0\\%$  vs $50.8\\%$ . For long-context reasoning tasks FRAMES and LongBench v2, Kimi-K2-Instruct $(77.1\\%,49.1\\%)$  lags slightly behind DeepSeek-V3-0324 by around $2\\%.$\nOpen-Ended EvaluationBeyond static, closed-ended benchmarks, we evaluate the model’s performance on openended, nuanced tasks that more closely resemble real-world usage.\nFor English scenarios, we leverage the Arena-Hard-Auto v2.0 benchmark, which use LLM-as-a-judge protocols to assess generation quality across diverse, open-ended prompts [42]. These evaluations cover a wide range of highdiffculty prompts and are widely recognized in the research community. On Arena-Hard-Auto v2.0, Kimi-K2-Instructi achieves state-of-the-art win-rate on both hard prompts $\\left(54.5\\%\\right)$  and creative writing tasks $(85.0\\%)$ , outperforming all open-source models and rivaling top proprietary systems such as GPT-4.1 and Claude Sonnet. These results underscore the model’s strength in handling complex reasoning and nuanced generation under diverse, unconstrained settings.\nHowever, Arena-Hard-Auto provides limited coverage of Chinese-specifc tasks. To address this gap, we developedi an in-house held-out benchmark grounded in authentic user queries. To safeguard the integrity of the evaluation, the benchmark data is access-restricted, thereby eliminating the risk of overftting.i\nAs shown in Figure 11, Kimi-K2-Instruct shows strong performance across all comparisons on Chinese in-house benchmarks. It outperforms ChatGPT-4o-latest with a $65.4\\%$  win rate, Claude Sonnet 4 with $64.6\\%,$  and DeepSeek-V30324 with $59.6\\%.$  In all cases, the loss rate stays low (around $17\\%$ ), indicating that Kimi-K2-Instruct rarely falls behind.The high win rates and consistent margins demonstrate its strong ability on open-ended Chinese tasks.\nIn addition to controlled evaluations, we also consider real-world user preference through public human assessments.As of July 17, 2025, Kimi-K2-Instruct ranked as the top open-source model and ffth overall on the LMSYS Arenai leaderboard7, based on over 3,000 blind votes from real users. Unlike LLM-as-a-judge protocols, this leaderboard refects direct human preference on diverse, user-submitted prompts, providing a complementary perspective on practicall model performance.\nThe results on Arena-Hard-Auto, our in-house benchmark and votes from LMSYS Arena collectively offer a comprehensive view of Kimi-K2-Instruct’s open-ended capabilities, showing that it is a highly preferred model in real-world user experience across English and Chinese.\nDQK-Clip Does Not Impair Model Quality\nThe QK-Clip design follows a minimal intervention principle: it activates only when necessary, and deactivates after training stabilizes. Empirical evidence and analysis converge on its negligible impact on model quality.\n\nFigure 12: Applying QK-Clip to Muon in a small-scale setting with an aggresive threshold $(\\tau=30)$  has negligible impact on loss, indicating that it is a safe and effective method for constraining attention logits.\nSmall-Scale AblationsWe train two small-scale 0.5B activated and 3B total parameters MoE models, one with vanilla Muon and the other with MuonClip using a low clipping threshold $\\left(\\tau=30\\right)$  As shown in Figure 12, applying MuonClip has negligible effects on the loss curve, indicating that even aggressive clipping does not impair convergence or training dynamics with MuonClip. This demonstrates that MuonClip is a safe and effective method for bounding attention logits without degrading model performance. Furthermore, evaluation on downstream tasks reveals no statistically signifcanti degradation in performance. These results collectively demonstrate that MuonClip is a safe and effective method for bounding attention logits without compromising model quality.\nSelf-deactivationIn Kimi K2, QK-Clip was only transiently active:\n• Initial 70000 steps: $12.7\\%$ of attention heads triggered QK-Clip for at least once, clamping $S_{\\max}$  to 100.\nPost-70000 steps: All heads at some point reduced their $S_{\\max}$ below 100, rendering QK-Clip inactive.\nWhen QK-Clip is active, it is applied per-head (rather than per-layer) to minimize potential over-regularization on other heads. After training stabilizes, QK-clip is deactivated and has no effect at all.\nEWhy Muon is More Prone to Logit Explosion\nLogit explosion occurs when the largest pre-softmax attention score\n$$S_{\\max}=\\max_{i,j} \\left( q_{i} \\cdot k_{j} \\right)$$\n(1)\ngrows unboundedly during training. Since\n$$|q_{i} \\cdot k_{j}|\\leq\\|q_{i}\\|\\|k_{j}\\|\\leq\\|x_{i}\\|\\|x_{j}\\|\\|\\mathbf{W}_{q}\\|\\|\\mathbf{W}_{k}\\|,$$\n(2)\nand RMS-Norm keeps $\\| x_{i} \\|\\| x_{j} \\|$ bounded, the phenomenon is primarily driven by the growing spectral-norm of $\\mathbf{W}_{q}$ or $\\mathbf{W}_{k}$  Empirically, we found that Muon is more susceptible to logit explosion. We give our hypothesis below.\nStructural difference in updatesMuon produces a weight update coming from the msign operation; as a result, $all$ singular values of the update matrix are equal — its effective rank is full. In contrast, a typical update matrix produced by Adam exhibits a skewed spectrum: a few large singular values dominate, and the effective rank is low. This low-rank assumption for Adam is not new; higher-order muP makes the same assumption.\nSuch phenomenon is verifed on the 16 B Moonlight model, which shows weights trained with Muon exhibit higheri singular-value entropy (i.e. higher effective rank) than those trained with Adam, corroborating the theoretical intuition.\nSVD formulationLet the parameter matrix at step $\\boldsymbol{t}-1$  have the singular value decomposition\n$$\\mathbf{W}_{t-1}=\\sum_{i}\\sigma_{i} u_{i}v_{i}^{\\top}$$\n(3)\n\nWe write the update matrices as\n$$\\Delta\\mathbf{W}_{t}=\\sum_{j}\\bar{\\sigma} \\bar{u}_{j}\\bar{v}_{j}^{\\top}$$\n(4)\nThe next parameter update is therefore\n$$\\mathbf{W}_{t}\\leftrightarrow\\sum_{i}\\sigma_{i}u_{i}v_{i}^{\\top}+\\sum_{j}\\bar{\\sigma} \\bar{u}_{j}\\bar{v}_{j}^{\\top}$$\n(5)\nIn Muon, as both the weights and the updates have a higher effective rank than Adam, we hypothesize there is a higher probability for singular-vector pair $u_{i}v_{i}^{\\top}$ to align with $\\bar{\\bar{u}}_{j}\\bar{v}_{j}^{\\top}.$  This could cause the corresponding singular value of $\\mathbf{W}_{t}$ to increase additively.\nAttention-specifc amplifcationAttention logits are computed via the bilinear formii\n$$q_{i}\\cdot k_{j}=(x_{i}\\mathbf{W}_{q})\\cdot(x_{j}\\mathbf{W}_{k}).$$\n(6)\nThe product $\\mathbf{W}_{q}\\mathbf{W}_{k}^{\\top}$ squares the spectral norm, so any singular-value increase in either matrix is compounded. Muon’s tendency to enlarge singular values therefore translates into a higher risk of logit explosion.\nFK2 Critic Rubrics for General RL\nF.1Core Rubrics\nClarity and Relevance: Assesses the extent to which the response is succinct while fully addressing the user’s intent. The focus is on eliminating unnecessary detail, staying aligned with the central query, and using effcienti formats such as brief paragraphs or compact lists. Unless specifcally required, long itemizations should be avoided.i When a choice is expected, the response should clearly offer a single, well-defned answer.i\nConversational Fluency and Engagement: Evaluates the response’s contribution to a natural, fowing dialogue thatl extends beyond simple question-answering. This includes maintaining coherence, showing appropriate engagement with the topic, offering relevant observations or insights, potentially guiding the conversation constructively when appropriate, using follow-up questions judiciously, handling hypothetical or personal-analogy queries gracefully,and adapting tone effectively to suit the conversational context (e.g., empathetic, formal, casual).\nObjective and Grounded Interaction: Assesses the response’s ability to maintain an objective and grounded tone, focusing squarely on the substance of the user’s request. It evaluates the avoidance of both metacommentary(analyzing the query’s structure, topic combination, perceived oddity, or the nature of the interaction itself) and unwarranted fattery or excessive praise directed at the user or their input. Excellent responses interact respectfullyl but neutrally, prioritizing direct, task-focused assistance over commentary on the conversational dynamics or attempts to curry favor through compliments.\nF.2Prescriptive Rubrics\nInitial Praise: Responses must not begin with compliments directed at the user or the question (e.g., “That’s a beautiful question”, “Good question!”).\nExplicit Justifcation: Any sentence or clause that explains why the response is good or how it successfullyi fulflled the user’s request. This is different from simply describing the content.i\nF.3Limitations\nOne potential side effect of this evaluation framework is that it may favor responses that appear confdent and assertive,i even in contexts involving ambiguity or subjectivity. This stems from two key constraints in the current rubric:\nAvoidance of Self-Qualifcation: The prescriptive rules prohibit self-assessments, explicit disclaimers, or hedgingi language (e.g., “this may not be accurate”, “I might be wrong”). While these phrases can refect epistemic humility,l they are often penalized as non-informative or performative.\nPreference for Clarity and Singularity: The rubric reward direct, decisive answers when users ask for a recommendation or explanation. In complex or open-ended scenarios, this may disincentivize appropriately cautious or multi-perspective responses.\n\nAs a result, the model may occasionally overstate certainty in areas where ambiguity, nuance, or epistemic modesty would be more appropriate. Future iterations of the framework may incorporate more fne-grained handling of calibratedi uncertainty.\n\nGEngine Switching Pipeline for RL Training\nFigure 13: pipeline for RL weight update\nThe checkpoint engine manages three equal-size device buffers on each GPU: an H2D buffer for loading the offoadedl model parameters, and two IPC buffers for GPU-to-GPU broadcast. The IPC buffers are shared to inference engines,allowing it to directly access the same physical memory. These three buffers allow us to arrange the three steps in a pipeline.\nTheoretical three-stage pipeline.As illustrated in Figure 13a, a three-stage pipeline is introduced. (1) $\\mathit{H2D:}$  a shard of the latest weights is copied into the H2D buffer asynchronously. (2) Broadcast: Once the copy completes, the shard will be copied to one IPC buffers and broadcast to all devices. (3) Reload: Inference engines simultaneously load parameters from the other IPC buffer.\nTwo-stage pipeline due to PCIe saturation.On NVIDIA H800 clusters, concurrent H2D and broadcast saturate the shared PCIe fabric, collapsing the three stages into a sequential procedure (Figure 13b). We therefore adopt a simpler,two-stage scheme (Figure 13c): (1) All devices perform a single, synchronous H2D transfer. (2) The broadcast and reload proceed in parallel.\nThe two-stage pipeline will be bound by multiple synchronous H2D copy operations. But in large scale devices, model will be split into small shards, the entire parameter set fts into the H2D buffer in one transfer, the overhead willi disappear.\nBy overlapping H2D, Broadcast, and Reload weights, we can obtain a high bandwidth to reshard the weights from train engines to all inference engines.\n"}